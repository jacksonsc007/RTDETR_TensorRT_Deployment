{"Layers": [{
  "Name": "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "images",
    "Location": "Device",
    "Dimensions": [1,3,640,640],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,3,640,640],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,3,640,640],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 864},
  "Bias": {"Type": "Float", "Count": 32},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_first_layer_i8i8_i8i32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_vect_c_32_tilesize8x16x32x32_stage1_warpsize4x1x1_tensor16x8x16_r3s3_u2v2_aligna4_alignc8",
  "TacticValue": "0x5cc792a989a1d1a6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/conv/Conv]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/act/Relu]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 9216},
  "Bias": {"Type": "Float", "Count": 32},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3",
  "TacticValue": "0x13463e9bf9ae0d73",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/Conv]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/act/Relu]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/MaxPool_output_0",
    "Location": "Device",
    "Dimensions": [1,64,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 18432},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x9dafb2758560cc1d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/Conv]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/backbone/MaxPool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/MaxPool_output_0",
    "Location": "Device",
    "Dimensions": [1,64,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/MaxPool]"
},{
  "Name": "model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x9dafb2758560cc1d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xe2bc5a4963d23ad0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 4096},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x1cfa820c55616892",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x9dafb2758560cc1d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xe2bc5a4963d23ad0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_UP",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 0,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE",
  "TacticValue": "0xd9375d43b61ffbcb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x705baf38e41eee0b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4133eb8759ee0d6d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 8192},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x8e1dd2962c589dd4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x128x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x214f03e23f252333",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4133eb8759ee0d6d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_UP",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 0,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE",
  "TacticValue": "0xd9375d43b61ffbcb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 294912},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xbb88763c3b0e94d4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xad6872a374321f7e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x8e1dd2962c589dd4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xbb88763c3b0e94d4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xad6872a374321f7e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_UP",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 0,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE",
  "TacticValue": "0xd9375d43b61ffbcb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1179648},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32",
  "TacticValue": "0x322f337abc345152",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32",
  "TacticValue": "0xccdb99df0646c7b3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 131072},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x7de8ad674a85e82a",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x64x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x1d53511430a5d47e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xc5159665a920f22c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/act/Relu]"
},{
  "Name": "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 131072},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x7524377e24bc511f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_MulAddReshMoveTranAddTran_myl38_0",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_1_first_transpose_output.1",
    "Dimensions": [400,1,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_4",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/encoder/encoder_0/layers_0/Add_output_0'.1",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_MulAddReshMoveTranAddTran_0xe457aa15a1457e4d9ada1b8a9ac84074",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.2/norm/BatchNormalization]\u001f[ONNX Layer: /model/encoder/Reshape]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/Add]\u001f[ONNX Layer: /model/encoder/Transpose]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1]"
},{
  "Name": "__mye8856_myl38_1",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 1,
  "Metadata": ""
},{
  "Name": "__mye8858_myl38_2",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 1,
  "Metadata": ""
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl38_3",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_1_first_transpose_output.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_2]"
},{
  "Name": "__mye8860_myl38_4",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 2,
  "Metadata": ""
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_5",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/Add_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__mye8634",
    "Dimensions": [2,400,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add]"
},{
  "Name": "__mye8862_myl38_6",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 2,
  "Metadata": ""
},{
  "Name": "_gemm_mha_v2_myl38_7",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye8634",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye8634",
    "Dimensions": [8,32,400],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_7",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Half"
  }],
  "TacticName": "_gemm_mha_v2_0x4b3d43298bdfabe601b05a79fbfdf8c8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Softmax]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Mul_1]"
},{
  "Name": "__myl_Tran_myl38_8",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_7",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_5 _ /model/encoder/encoder_0/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [400,8,32],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_Tran_0x15e794fcfc5aadd50d4214509ec23820",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5]\u001e[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3]"
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl38_9",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_5 _ /model/encoder/encoder_0/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Gemm]"
},{
  "Name": "__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl38_10",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_4",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0x6fe4e7c4010102ac41311fb055daac74",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/encoder/encoder_0/layers_0/linear1/MatMul_myl38_11",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "cast__mye8737_12",
    "Dimensions": [1,400,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_gelu_erf",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Add]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Div]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Erf]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/Add]"
},{
  "Name": "/model/encoder/encoder_0/layers_0/linear2/MatMul_myl38_12",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "cast__mye8737_12",
    "Dimensions": [1,400,1024],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]"
},{
  "Name": "__myl_CastAddAddCastMeanSubMulMean_myl38_13",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,400,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_CastAddAddCastMeanSubMulMean_0xc644c0fa4f3484d88e9acca381e2d8a8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_2]"
},{
  "Name": "__myl_AddSqrtDivMulCastMulAddTranResh_myl38_14",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,400,1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Reshape_1_output_0",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_AddSqrtDivMulCastMulAddTranResh_0x18e715b50f8bff9f493fb3c5e3266869",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]\u001f[ONNX Layer: /model/encoder/Transpose_1]\u001e[ONNX Layer: /model/encoder/Reshape_1]"
},{
  "Name": "model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x483ad1560c6e5e27",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/input_proj.0/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x483ad1560c6e5e27",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/input_proj.1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Reshape_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/act/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);"],
  "TacticValue": "0x000000000000001f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/act/Mul]"
},{
  "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/act/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Resize_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/encoder/Resize",
  "LayerType": "Resize",
  "Inputs": [
  {
    "Name": "/model/encoder/Resize_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Resize",
  "InterpolationMode": "NEAREST",
  "ResizeScales": [1, 1, 2, 2, 0, 0, 0, 0],
  "ExcludeOutside": 0,
  "CubicCoeff": -0.75,
  "CoordTransform": "kASYMMETRIC",
  "ResizeSelector": "kFORMULA",
  "NNRounding": "kFLOOR",
  "TacticValue": "0x0000000000000005",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Resize]"
},{
  "Name": "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Concat_2]"
},{
  "Name": "model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x8e1dd2962c589dd4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc722efd60bc6ea84",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc722efd60bc6ea84",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xad6872a374321f7e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  },
  {
    "Name": "/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/Add]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Mul]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Resize_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/Resize_1",
  "LayerType": "Resize",
  "Inputs": [
  {
    "Name": "/model/encoder/Resize_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Resize",
  "InterpolationMode": "NEAREST",
  "ResizeScales": [1, 1, 2, 2, 0, 0, 0, 0],
  "ExcludeOutside": 0,
  "CubicCoeff": -0.75,
  "CoordTransform": "kASYMMETRIC",
  "ResizeSelector": "kFORMULA",
  "NNRounding": "kFLOOR",
  "TacticValue": "0x0000000000000005",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Resize_1]"
},{
  "Name": "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Concat_3]"
},{
  "Name": "model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x758f8b2079a95b2e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x458f02d2b10db57c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xfdf7509af98902e0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xfdf7509af98902e0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4133eb8759ee0d6d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  },
  {
    "Name": "/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000019",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/Add]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x65a38dbc9e991257",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Mul]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.0/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x8486adb55ae0ca6c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc722efd60bc6ea84",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/Resize_1_output_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Resize_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Concat_4]"
},{
  "Name": "model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x8e1dd2962c589dd4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc722efd60bc6ea84",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc722efd60bc6ea84",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xad6872a374321f7e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  },
  {
    "Name": "/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/Add]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Mul]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.1/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x733ba2a91a48d431",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc985777c89c6b3a4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/act/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0xc6cdb1e47323bb01",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc985777c89c6b3a4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc985777c89c6b3a4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xd14bd6d95fefd45e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  },
  {
    "Name": "/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/Add]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0xc6cdb1e47323bb01",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Mul]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x5e4f6d7c83746fd6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/Conv]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/decoder/input_proj.0/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Reformatting CopyNode for Input Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/decoder/input_proj.1/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Reformatting CopyNode for Input Tensor 3 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 3 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "entry^bb^signal^1_myl88_0",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 19,
  "Metadata": ""
},{
  "Name": "entry^bb^wait^1_myl88_1",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 19,
  "Metadata": ""
},{
  "Name": "__myl_MulAddReshMulMinMaxRounCastTran_myl88_2",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_6",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_5",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_MulAddReshMulMinMaxRounCastTran_0x5358adb630fbfcb554dd5ceff3cef1db",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.0/norm/BatchNormalization]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape]\u001e[ONNX Layer: /model/decoder/Transpose]"
},{
  "Name": "__myl_MulMinMaxRounCastReshTran_myl88_3",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_5",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_7",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRounCastReshTran_0xf99f3d478a31416d3ca508b83f50f6cf",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape]\u001e[ONNX Layer: /model/decoder/Transpose]"
},{
  "Name": "__myl_MulAddReshMulMinMaxRounCastTran_myl88_4",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_MulAddReshMulMinMaxRounCastTran_0x3ce46b5387fb3712faa5ac5851c46aa2",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.1/norm/BatchNormalization]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape_1]\u001e[ONNX Layer: /model/decoder/Transpose_1]"
},{
  "Name": "__myl_MulMinMaxRounCastReshTran_myl88_5",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRounCastReshTran_0x0289c18f1e1ff0d7a480407e8817adc8",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape_1]\u001e[ONNX Layer: /model/decoder/Transpose_1]"
},{
  "Name": "__mye154345_myl88_6",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 1,
  "Metadata": ""
},{
  "Name": "__mye154347_myl88_7",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 1,
  "Metadata": ""
},{
  "Name": "__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl88_8",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_7",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_6",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "Reformatted Input Tensor 3 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_12",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_0xbf3c9a060b5f9802aa564f39e2f1f020",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.2/norm/BatchNormalization]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Concat_3]\u001f[ONNX Layer: /model/decoder/Reshape_2]\u001e[ONNX Layer: /model/decoder/Transpose_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye154349_myl88_9",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 2,
  "Metadata": ""
},{
  "Name": "__mye154351_myl88_10",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 2,
  "Metadata": ""
},{
  "Name": "__myl_FcMulCastAdd_myl88_11",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_12",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__mye150630",
    "Dimensions": [3,8400,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add]"
},{
  "Name": "__myl_FcCastAdd_myl88_12",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_output/proj/MatMul]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_output/proj/Add]"
},{
  "Name": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_13",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_16",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0xe2d727d35a85bd2c3cc2eb53c7452092",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_output/norm/LayerNormalization]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye154353_myl88_14",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 3,
  "Metadata": ""
},{
  "Name": "__mye154355_myl88_15",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 3,
  "Metadata": ""
},{
  "Name": "/model/decoder/enc_score_head/MatMul_myl88_16",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [1,8400,80],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/enc_score_head/MatMul]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_score_head/Add]"
},{
  "Name": "__myl_CastAddMaxr_myl88_17",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [1,8400,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/ReduceMax_output_0'_unsqueezed0.1",
    "Dimensions": [1,8400,1],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_CastAddMaxr_0x19151a86595916c177b83b4afe8dd8e1",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/enc_score_head/MatMul]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_score_head/Add]\u001f[ONNX Layer: /model/decoder/ReduceMax]"
},{
  "Name": "__myl_Topk_myl88_18",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/ReduceMax_output_0'_unsqueezed0.1",
    "Dimensions": [1,8400],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/TopK_output_0'.1",
    "Dimensions": [1,300],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_20",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  }],
  "TacticName": "__myl_Topk_0x3801d91b92fc69261d17a37dbf46b775",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/TopK]"
},{
  "Name": "__mye154357_myl88_19",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 4,
  "Metadata": ""
},{
  "Name": "/model/decoder/enc_bbox_head/layers_0/MatMul_myl88_20",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/enc_bbox_head/layers_2/input_quantizer/QuantizeLinear_output_0'.1_21",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/act/Relu]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/Add]"
},{
  "Name": "/model/decoder/enc_bbox_head/layers_1/MatMul_myl88_21",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/enc_bbox_head/layers_2/input_quantizer/QuantizeLinear_output_0'.1_21",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_22",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/act_1/Relu]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/Add]"
},{
  "Name": "__myl_FcCastAddAdd_myl88_22",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_22",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_23",
    "Dimensions": [1,8400,4],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x64x64_stage3_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/Add]\u001f[ONNX Layer: /model/decoder/Add]"
},{
  "Name": "__mye154359_myl88_23",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 4,
  "Metadata": ""
},{
  "Name": "__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl88_24",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_20",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_23",
    "Dimensions": [1,8400,4],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_27",
    "Dimensions": [1,300,1],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_26",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_25",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_24",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_0x4e0b1a71403d082fda5d4916d8107860",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/GatherElements]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/Log]\u001f[ONNX Layer: /model/decoder/decoder/Div]\u001f[ONNX Layer: /model/decoder/decoder/Sub]\u001f[ONNX Layer: /model/decoder/decoder/Clip]\u001f[ONNX Layer: /model/decoder/Unsqueeze]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl88_25",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_25",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_28",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]"
},{
  "Name": "__myl_FcCastAdd_myl88_26",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_28",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_29",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/Add]"
},{
  "Name": "__myl_ReplGathReshReshAdd_myl88_27",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_27",
    "Dimensions": [1,300,1],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_16",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_29",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/GatherElements_1_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_32",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_ReplGathReshReshAdd_0x53452db711fa8db38ccc9a01cdb12399",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/Add]\u001f[ONNX Layer: /model/decoder/GatherElements_1]"
},{
  "Name": "__mye154361_myl88_28",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 5,
  "Metadata": ""
},{
  "Name": "__mye154363_myl88_29",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 5,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl88_30",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/GatherElements_1_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_2]"
},{
  "Name": "__mye154365_myl88_31",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 6,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl88_32",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__mye150615",
    "Dimensions": [2,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add]"
},{
  "Name": "__mye154367_myl88_33",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 6,
  "Metadata": ""
},{
  "Name": "_gemm_mha_v2_myl88_34",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye150615",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye150615",
    "Dimensions": [8,32,300],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_35",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Half"
  }],
  "TacticName": "_gemm_mha_v2_0x742379e0e620f0cf024dbdbe86bf6611",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Mul_1]"
},{
  "Name": "__myl_Tran_myl88_35",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_35",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Transpose_5 _ /model/decoder/decoder/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,8,32],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_Tran_0x068242bad4efe24d77461cc051df5e82",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Transpose_5]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Reshape_3]"
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/Gemm_myl88_36",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Transpose_5 _ /model/decoder/decoder/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Gemm]"
},{
  "Name": "__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshAddMulMinMaxRounCast_myl88_37",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_32",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/GatherElements_1_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_39",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshAddMulMinMaxRounCast_0x0e34c2b971ec15ffba3b5ab843fdf854",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/norm1/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye154369_myl88_38",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 7,
  "Metadata": ""
},{
  "Name": "__myl_FcCastAdd_myl88_39",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_40",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add]"
},{
  "Name": "__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_40",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_24",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_40",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_43",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_42",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_41",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_0x166f11fca798ea25bbab70ff7c539643",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Sub]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_1]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Split]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8]"
},{
  "Name": "__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_41",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_43",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_42",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_41",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye150630",
    "Dimensions": [8400,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_46",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_45",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_44",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_0xc71bbed5e42c2906a2f6f45ea1d7a78c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_7]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_8]"
},{
  "Name": "__mye154371_myl88_42",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 7,
  "Metadata": ""
},{
  "Name": "__myl_FcCastAdd_myl88_43",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_47",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add]"
},{
  "Name": "__myl_ReshMaxrSubExpSum_myl88_44",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_47",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_49",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_48",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_ReshMaxrSubExpSum_0xba6a237155991369f77bdf11d50a3c03",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]"
},{
  "Name": "__mye154373_myl88_45",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 8,
  "Metadata": ""
},{
  "Name": "__mye154375_myl88_46",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 8,
  "Metadata": ""
},{
  "Name": "__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_47",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_48",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_44",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_46",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_45",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_49",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__mye147553_q8",
    "Dimensions": [8,32,300,1],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_0x8497f2d8c2f5630da07536b4f9cc18f0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_2]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_9]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Concat_10]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/ReduceSum]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_8]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_Move_myl88_48",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye147553_q8",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_51",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_Move_0xe44b2845ee5a2c900106157eaed1d520",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]"
},{
  "Name": "__myl_FcCastAddAdd_myl88_49",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_39",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_51",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_52",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/Add_3]"
},{
  "Name": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_50",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_52",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_54",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_53",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0xcc497afe211f479634492d5ba512e7ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/norm2/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_0/linear1/MatMul_myl88_51",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_53",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_55",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/linear1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/activation/Relu]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/Add]"
},{
  "Name": "__myl_FcCastAddAdd_myl88_52",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_54",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_55",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_56",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/linear2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/Add_4]"
},{
  "Name": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_53",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_56",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_58",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0xf06434bfbed1dc027cac0cf6800444ba",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye154377_myl88_54",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 9,
  "Metadata": ""
},{
  "Name": "__mye154379_myl88_55",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 9,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl88_56",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Add_2_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_2]"
},{
  "Name": "__mye154381_myl88_57",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 10,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl88_58",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_58",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/input_quantizer/QuantizeLinear_output_0'.1_60",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl88_59",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/input_quantizer/QuantizeLinear_output_0'.1_60",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_61",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add]"
},{
  "Name": "__myl_FcCastAddAddSigm_myl88_60",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_26",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_61",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_62",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add]\u001f[ONNX Layer: /model/decoder/decoder/Add]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid_1]"
},{
  "Name": "__myl_MulMinMaxRounConcCast_myl88_61",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_62",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/input_quantizer_1/QuantizeLinear_output_0'.1_63",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRounConcCast_0x675a534c6ff964b95c70b269e3fd48e9",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl88_62",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/input_quantizer_1/QuantizeLinear_output_0'.1_63",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_64",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/Add]"
},{
  "Name": "__myl_FcCastAdd_myl88_63",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_64",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_65",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/Add]"
},{
  "Name": "__myl_Add_myl88_64",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_65",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_Add_0xdde52a3a8d7160d5661d1cdb3767660f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/Add]"
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl88_65",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__mye150540",
    "Dimensions": [2,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add]"
},{
  "Name": "__mye154383_myl88_66",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 10,
  "Metadata": ""
},{
  "Name": "_gemm_mha_v2_myl88_67",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye150540",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye150540",
    "Dimensions": [8,32,300],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_68",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Half"
  }],
  "TacticName": "_gemm_mha_v2_0x742379e0e620f0cf024dbdbe86bf6611",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Mul_1]"
},{
  "Name": "__myl_Tran_myl88_68",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_68",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Transpose_5 _ /model/decoder/decoder/layers_1/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,8,32],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_Tran_0x068242bad4efe24d77461cc051df5e82",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Transpose_5]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Reshape_3]"
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/Gemm_myl88_69",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Transpose_5 _ /model/decoder/decoder/layers_1/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Gemm_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Gemm]"
},{
  "Name": "__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_70",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_65",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_72",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_0xfa7ba13c29e2d38c8ae25093f835ab14",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/norm1/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye154385_myl88_71",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 11,
  "Metadata": ""
},{
  "Name": "__myl_FcCastAdd_myl88_72",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_73",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add]"
},{
  "Name": "__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_73",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_62",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_73",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_76",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_75",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_74",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_0x166f11fca798ea25bbab70ff7c539643",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Sub]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_1]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Split]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8]"
},{
  "Name": "__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_74",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_76",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_75",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_74",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye150630",
    "Dimensions": [8400,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_79",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_78",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_77",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_0xc71bbed5e42c2906a2f6f45ea1d7a78c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_7]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_8]"
},{
  "Name": "__mye154387_myl88_75",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 11,
  "Metadata": ""
},{
  "Name": "__myl_FcCastAdd_myl88_76",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_80",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add]"
},{
  "Name": "__myl_ReshMaxrSubExpSum_myl88_77",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_80",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_82",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_81",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_ReshMaxrSubExpSum_0xba6a237155991369f77bdf11d50a3c03",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]"
},{
  "Name": "__mye154389_myl88_78",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 12,
  "Metadata": ""
},{
  "Name": "__mye154391_myl88_79",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 12,
  "Metadata": ""
},{
  "Name": "__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_80",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_81",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_77",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_79",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_78",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_82",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__mye147559_q8",
    "Dimensions": [8,32,300,1],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_0x8497f2d8c2f5630da07536b4f9cc18f0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_2]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_9]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Concat_10]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/ReduceSum]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_Move_myl88_81",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye147559_q8",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_84",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_Move_0xe44b2845ee5a2c900106157eaed1d520",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]"
},{
  "Name": "__myl_FcCastAddAdd_myl88_82",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_72",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_84",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_85",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/Add_3]"
},{
  "Name": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_83",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_85",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_87",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_86",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0xcc497afe211f479634492d5ba512e7ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/norm2/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_1/linear1/MatMul_myl88_84",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_86",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_88",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/linear1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/activation/Relu]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/Add]"
},{
  "Name": "__myl_FcCastAddAdd_myl88_85",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_87",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_88",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_89",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/linear2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/Add_4]"
},{
  "Name": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_86",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_89",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_91",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0xf06434bfbed1dc027cac0cf6800444ba",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye154393_myl88_87",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 13,
  "Metadata": ""
},{
  "Name": "__mye154395_myl88_88",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 13,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl88_89",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Add_2_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_2]"
},{
  "Name": "__mye154397_myl88_90",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 14,
  "Metadata": ""
},{
  "Name": "__myl_MaxMinSubMaxMinMaxMinDivLog_myl88_91",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_62",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_93",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_MaxMinSubMaxMinMaxMinDivLog_0x564e12beef03d2192684faee0d1f2dc4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/Log_1]\u001f[ONNX Layer: /model/decoder/decoder/Div_1]\u001f[ONNX Layer: /model/decoder/decoder/Sub_1]\u001f[ONNX Layer: /model/decoder/decoder/Clip_3]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl88_92",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_91",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/input_quantizer/QuantizeLinear_output_0'.1_94",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl88_93",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/input_quantizer/QuantizeLinear_output_0'.1_94",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_95",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add]"
},{
  "Name": "__myl_FcCastAddAddSigm_myl88_94",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_93",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_95",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_96",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add]\u001f[ONNX Layer: /model/decoder/decoder/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid_2]"
},{
  "Name": "__myl_MulMinMaxRounConcCast_myl88_95",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_96",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/input_quantizer_2/QuantizeLinear_output_0'.1_97",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRounConcCast_0x675a534c6ff964b95c70b269e3fd48e9",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl88_96",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/input_quantizer_2/QuantizeLinear_output_0'.1_97",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_98",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act_2/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/Add]"
},{
  "Name": "__myl_FcCastAdd_myl88_97",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_98",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_99",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/Add]"
},{
  "Name": "__myl_Add_myl88_98",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_99",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_Add_0xdde52a3a8d7160d5661d1cdb3767660f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/Add]"
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl88_99",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__mye150465",
    "Dimensions": [2,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add]"
},{
  "Name": "__mye154399_myl88_100",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 14,
  "Metadata": ""
},{
  "Name": "_gemm_mha_v2_myl88_101",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye150465",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye150465",
    "Dimensions": [8,32,300],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_102",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Half"
  }],
  "TacticName": "_gemm_mha_v2_0x742379e0e620f0cf024dbdbe86bf6611",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Mul_1]"
},{
  "Name": "__myl_Tran_myl88_102",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_102",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Transpose_5 _ /model/decoder/decoder/layers_2/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,8,32],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_Tran_0x068242bad4efe24d77461cc051df5e82",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Transpose_5]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Reshape_3]"
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/Gemm_myl88_103",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Transpose_5 _ /model/decoder/decoder/layers_2/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Gemm_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Gemm]"
},{
  "Name": "__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_104",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_99",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_106",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/decoder/decoder/layers_2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_0xfa7ba13c29e2d38c8ae25093f835ab14",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/norm1/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye154401_myl88_105",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 15,
  "Metadata": ""
},{
  "Name": "__myl_FcCastAdd_myl88_106",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_107",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add]"
},{
  "Name": "__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_107",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_96",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_107",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_110",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_109",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_108",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_0x166f11fca798ea25bbab70ff7c539643",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Sub]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_1]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Split]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8]"
},{
  "Name": "__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_108",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_110",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_109",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_108",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye150630",
    "Dimensions": [8400,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_113",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_112",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_111",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_0xc71bbed5e42c2906a2f6f45ea1d7a78c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_7]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_8]"
},{
  "Name": "__mye154403_myl88_109",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 15,
  "Metadata": ""
},{
  "Name": "__myl_FcCastAdd_myl88_110",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_114",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add]"
},{
  "Name": "__myl_ReshMaxrSubExpSum_myl88_111",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_114",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_116",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_115",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_ReshMaxrSubExpSum_0xba6a237155991369f77bdf11d50a3c03",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]"
},{
  "Name": "__mye154405_myl88_112",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 16,
  "Metadata": ""
},{
  "Name": "__mye154407_myl88_113",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 16,
  "Metadata": ""
},{
  "Name": "__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_114",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_115",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_111",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_113",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_112",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_116",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__mye147565_q8",
    "Dimensions": [8,32,300,1],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_0x8497f2d8c2f5630da07536b4f9cc18f0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_2]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_9]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Concat_10]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/ReduceSum]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_Move_myl88_115",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye147565_q8",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_118",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_Move_0xe44b2845ee5a2c900106157eaed1d520",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]"
},{
  "Name": "__myl_FcCastAddAdd_myl88_116",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_106",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_118",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_119",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/Add_3]"
},{
  "Name": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_117",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_119",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_121",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_120",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0xcc497afe211f479634492d5ba512e7ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/norm2/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_2/linear1/MatMul_myl88_118",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_120",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_122",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/linear1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/activation/Relu]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/Add]"
},{
  "Name": "__myl_FcCastAddAdd_myl88_119",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_121",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_122",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_123",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/linear2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/Add_4]"
},{
  "Name": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_120",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_123",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_1/input_quantizer/QuantizeLinear_output_0'.1_124",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0x80487bca91ee48a7b2ecd6f40baf47b3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye154409_myl88_121",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 17,
  "Metadata": ""
},{
  "Name": "__mye154411_myl88_122",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 17,
  "Metadata": ""
},{
  "Name": "__myl_FcCastAdd_myl88_123",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_1/input_quantizer/QuantizeLinear_output_0'.1_124",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_125",
    "Dimensions": [1,300,80],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_score_head.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_score_head.2/Add]"
},{
  "Name": "__myl_ReshGathSigmResh_myl88_124",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_125",
    "Dimensions": [1,300,80],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_126",
    "Dimensions": [1,24000],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_ReshGathSigmResh_0xa09b04cf5faa645da19283c01b369215",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /postprocessor/Sigmoid]\u001f[ONNX Layer: /postprocessor/Flatten]\u001f[ONNX Layer: /model/decoder/Gather_8]\u001f[ONNX Layer: /model/decoder/decoder/Unsqueeze_4]"
},{
  "Name": "__myl_Topk_myl88_125",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_126",
    "Dimensions": [1,24000],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Output Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
    "Dimensions": [1,300],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_128",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  }],
  "TacticName": "__myl_Topk_0xeff68fcd6e2ece445095c9d09d03e940",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /postprocessor/TopK]"
},{
  "Name": "__mye154413_myl88_126",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 18,
  "Metadata": ""
},{
  "Name": "__myl_MaxMinSubMaxMinMaxMinDivLog_myl88_127",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_96",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_129",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_MaxMinSubMaxMinMaxMinDivLog_0x564e12beef03d2192684faee0d1f2dc4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/Log_2]\u001f[ONNX Layer: /model/decoder/decoder/Div_2]\u001f[ONNX Layer: /model/decoder/decoder/Sub_2]\u001f[ONNX Layer: /model/decoder/decoder/Clip_6]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl88_128",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_1/input_quantizer/QuantizeLinear_output_0'.1_124",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/input_quantizer/QuantizeLinear_output_0'.1_130",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl88_129",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/input_quantizer/QuantizeLinear_output_0'.1_130",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_131",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add]"
},{
  "Name": "__myl_FcCastAddAddSigm_myl88_130",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_129",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_131",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_132",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add]\u001f[ONNX Layer: /model/decoder/decoder/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid_3]"
},{
  "Name": "__mye154415_myl88_131",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 18,
  "Metadata": ""
},{
  "Name": "__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl88_132",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_132",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_128",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "orig_target_sizes",
    "Dimensions": [1,2],
    "Format/Datatype": "Int64"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Output Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Half"
  },
  {
    "Name": "labels",
    "Dimensions": [1,300],
    "Format/Datatype": "Int64"
  }],
  "TacticName": "__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_0x10d3a9474b513eaf9fc3d1150e6c455f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /postprocessor/Tile]\u001f[ONNX Layer: /postprocessor/Unsqueeze_4]\u001f[ONNX Layer: /postprocessor/Div]\u001f[ONNX Layer: /postprocessor/Sub_2]\u001f[ONNX Layer: /postprocessor/Mul_3]\u001f[ONNX Layer: /postprocessor/Squeeze_3]\u001f[ONNX Layer: /postprocessor/Mul_1]\u001f[ONNX Layer: /postprocessor/Sub_1]\u001f[ONNX Layer: /postprocessor/Unsqueeze_1]\u001f[ONNX Layer: /postprocessor/Squeeze]\u001f[ONNX Layer: /postprocessor/Add_1]\u001f[ONNX Layer: /postprocessor/Unsqueeze_3]\u001f[ONNX Layer: /postprocessor/Unsqueeze_5]\u001f[ONNX Layer: /postprocessor/GatherElements]\u001f[ONNX Layer: /postprocessor/Mul_2]\u001f[ONNX Layer: /postprocessor/Concat]\u001f[ONNX Layer: /postprocessor/Unsqueeze]\u001f[ONNX Layer: /postprocessor/Sub]\u001f[ONNX Layer: /postprocessor/Unsqueeze_2]\u001f[ONNX Layer: /postprocessor/Add]\u001f[ONNX Layer: /postprocessor/Mul]\u001f[ONNX Layer: /postprocessor/Squeeze_2]\u001f[ONNX Layer: /postprocessor/Squeeze_1]\u001f[ONNX Layer: /postprocessor/Split]\u001f[ONNX Layer: /model/decoder/Gather_9]\u001f[ONNX Layer: /model/decoder/decoder/Unsqueeze_3]\u001f[ONNX Layer: Cast_3039]"
},{
  "Name": "Reformatting CopyNode for Output Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Reformatted Output Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
    "Location": "Device",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "Outputs": [
  {
    "Name": "boxes",
    "Location": "Device",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Reformatting CopyNode for Output Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Reformatted Output Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}",
    "Location": "Device",
    "Dimensions": [1,300],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "Outputs": [
  {
    "Name": "scores",
    "Location": "Device",
    "Dimensions": [1,300],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
}],
"Bindings": ["images"
,"orig_target_sizes"
,"labels"
,"boxes"
,"scores"
]}
