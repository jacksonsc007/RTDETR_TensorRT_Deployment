digraph {
	images [label="images
[1, 3, 640, 640]\nFP32 NCHW" color=red fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=images]
	"__myln_k_arg__bb1_7.0" [label="[1, 6400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_7]
	"__myln_k_arg__bb1_7.1" [label="[1, 6400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_7]
	"__myln_k_arg__bb1_11.0" [label="[1, 8400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_11]
	"__myln_k_arg__bb1_11.1" [label="[1, 8400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_11]
	"__myln_k_arg__bb1_10.0" [label="[1, 1600, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_10]
	"__myln_k_arg__bb1_10.1" [label="[1, 1600, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_10]
	"__myln_k_arg__bb1_15.0" [label="[1, 8400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_15]
	"__myln_k_arg__bb1_15.1" [label="[1, 8400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_15]
	"__myln_k_arg__bb1_14.0" [label="[1, 8400, 256]\nHalf" color=orange fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_14]
	"__myln_k_arg__bb1_14.1" [label="[1, 8400, 256]\nHalf" color=orange fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_14]
	orig_target_sizes [label="orig_target_sizes
[1, 2]\nInt64" color=gray fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=orig_target_sizes]
	labels [label="labels
[1, 300]\nInt64" color=gray fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=labels]
	boxes [label="boxes
[1, 300, 4]\nFP32 NCHW" color=red fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=boxes]
	scores [label="scores
[1, 300]\nFP32 NCHW" color=red fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=scores]
	"/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.0055757 ms</TD></TR><TR><TD>/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00599129 ms</TD></TR><TR><TD>model.backbone.conv1.conv1_1.conv.weight </TD></TR><TR><TD> /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/conv1/conv1_1/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 32}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_1/conv/Conv]+[ONNX Layer: /model/backbone/conv1/conv1_1/norm/BatchNormalization]+[ONNX Layer: /model/backbone/conv1/conv1_1/act/Relu]+[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv\nOutMaps:32\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_first_layer_i8i8_i8i32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_vect_c_32_tilesize8x16x32x32_stage1_warpsize4x1x1_tensor16x8x16_r3s3_u2v2_aligna4_alignc8\nTacticValue:0x5cc792a989a1d1a6\nWeights:{'Type': 'Int8', 'Count': 864}\n"]
	"model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0117975 ms</TD></TR><TR><TD>model.backbone.conv1.conv1_2.conv.weight </TD></TR><TR><TD> /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/conv1/conv1_2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 32}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_2/conv/Conv]+[ONNX Layer: /model/backbone/conv1/conv1_2/norm/BatchNormalization]+[ONNX Layer: /model/backbone/conv1/conv1_2/act/Relu]+[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv\nOutMaps:32\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3\nTacticValue:0x13463e9bf9ae0d73\nWeights:{'Type': 'Int8', 'Count': 9216}\n"]
	"model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0124206 ms</TD></TR><TR><TD>model.backbone.conv1.conv1_3.conv.weight </TD></TR><TR><TD> /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/conv1/conv1_3/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_3/conv/Conv]+[ONNX Layer: /model/backbone/conv1/conv1_3/norm/BatchNormalization]+[ONNX Layer: /model/backbone/conv1/conv1_3/act/Relu]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x9dafb2758560cc1d\nWeights:{'Type': 'Int8', 'Count': 18432}\n"]
	"/model/backbone/MaxPool" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Pooling</b></TD></TR><TR><TD>0.00744225 ms</TD></TR><TR><TD>/model/backbone/MaxPool</TD></TR><TR><TD>[ONNX Layer: /model/backbone/MaxPool]</TD></TR></TABLE>> color=lightgray fillcolor="#3CB371" fontname=Helvetica shape=Mrecord style=filled tooltip="AverageCountExcludesPadding:1\nBlendFactor:0\nLayerType:CaskPooling\nMetadata:[ONNX Layer: /model/backbone/MaxPool]\nName:/model/backbone/MaxPool\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPoolingType:MAX\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nStreamId:0\nStride:[2, 2]\nTacticName:sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX\nTacticValue:0x94215b398b8eb3ba\nWindowSize:[3, 3]\n"]
	"model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0078594 ms</TD></TR><TR><TD>model.backbone.res_layers.0.blocks.0.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x9dafb2758560cc1d\nWeights:{'Type': 'Int8', 'Count': 36864}\n"]
	"model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0109269 ms</TD></TR><TR><TD>model.backbone.res_layers.0.blocks.0.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xe2bc5a4963d23ad0\nWeights:{'Type': 'Int8', 'Count': 36864}\n"]
	"model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00782121 ms</TD></TR><TR><TD>model.backbone.res_layers.0.blocks.0.short.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/short/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/Add </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/Add]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/act/Relu]\nName:model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x1cfa820c55616892\nWeights:{'Type': 'Int8', 'Count': 4096}\n"]
	"/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00572185 ms</TD></TR><TR><TD>/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00790957 ms</TD></TR><TR><TD>model.backbone.res_layers.0.blocks.1.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x9dafb2758560cc1d\nWeights:{'Type': 'Int8', 'Count': 36864}\n"]
	"model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0111848 ms</TD></TR><TR><TD>model.backbone.res_layers.0.blocks.1.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.1/Add </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.1/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/Add]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/act/Relu]\nName:model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xe2bc5a4963d23ad0\nWeights:{'Type': 'Int8', 'Count': 36864}\n"]
	"/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00578659 ms</TD></TR><TR><TD>/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Pooling</b></TD></TR><TR><TD>0.00409532 ms</TD></TR><TR><TD>/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#3CB371" fontname=Helvetica shape=Mrecord style=filled tooltip="AverageCountExcludesPadding:0\nBlendFactor:0\nLayerType:CaskPooling\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool\nPaddingMode:kEXPLICIT_ROUND_UP\nPoolingType:AVERAGE\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nStreamId:0\nStride:[2, 2]\nTacticName:sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE\nTacticValue:0xd9375d43b61ffbcb\nWindowSize:[2, 2]\n"]
	"model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00748056 ms</TD></TR><TR><TD>model.backbone.res_layers.1.blocks.0.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x705baf38e41eee0b\nWeights:{'Type': 'Int8', 'Count': 73728}\n"]
	"model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00941549 ms</TD></TR><TR><TD>model.backbone.res_layers.1.blocks.0.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x4133eb8759ee0d6d\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00560833 ms</TD></TR><TR><TD>model.backbone.res_layers.1.blocks.0.short.conv.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/Add </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/Add]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/act/Relu]\nName:model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x8e1dd2962c589dd4\nWeights:{'Type': 'Int8', 'Count': 8192}\n"]
	"/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00498876 ms</TD></TR><TR><TD>/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00801198 ms</TD></TR><TR><TD>model.backbone.res_layers.1.blocks.1.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x128x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x214f03e23f252333\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00993854 ms</TD></TR><TR><TD>model.backbone.res_layers.1.blocks.1.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.1/Add </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.1/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/Add]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/act/Relu]\nName:model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x4133eb8759ee0d6d\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00546673 ms</TD></TR><TR><TD>/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Pooling</b></TD></TR><TR><TD>0.00487035 ms</TD></TR><TR><TD>/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#3CB371" fontname=Helvetica shape=Mrecord style=filled tooltip="AverageCountExcludesPadding:0\nBlendFactor:0\nLayerType:CaskPooling\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool\nPaddingMode:kEXPLICIT_ROUND_UP\nPoolingType:AVERAGE\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nStreamId:0\nStride:[2, 2]\nTacticName:sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE\nTacticValue:0xd9375d43b61ffbcb\nWindowSize:[2, 2]\n"]
	"model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00812662 ms</TD></TR><TR><TD>model.backbone.res_layers.2.blocks.0.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xbb88763c3b0e94d4\nWeights:{'Type': 'Int8', 'Count': 294912}\n"]
	"model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00971492 ms</TD></TR><TR><TD>model.backbone.res_layers.2.blocks.0.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xad6872a374321f7e\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00628606 ms</TD></TR><TR><TD>model.backbone.res_layers.2.blocks.0.short.conv.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/Add </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/Add]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/act/Relu]\nName:model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x8e1dd2962c589dd4\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00519844 ms</TD></TR><TR><TD>/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00965525 ms</TD></TR><TR><TD>model.backbone.res_layers.2.blocks.1.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xbb88763c3b0e94d4\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00955027 ms</TD></TR><TR><TD>model.backbone.res_layers.2.blocks.1.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.1/Add </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.1/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/Add]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/act/Relu]\nName:model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xad6872a374321f7e\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00501828 ms</TD></TR><TR><TD>/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Pooling</b></TD></TR><TR><TD>0.00509609 ms</TD></TR><TR><TD>/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#3CB371" fontname=Helvetica shape=Mrecord style=filled tooltip="AverageCountExcludesPadding:0\nBlendFactor:0\nLayerType:CaskPooling\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool\nPaddingMode:kEXPLICIT_ROUND_UP\nPoolingType:AVERAGE\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nStreamId:0\nStride:[2, 2]\nTacticName:sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE\nTacticValue:0xd9375d43b61ffbcb\nWindowSize:[2, 2]\n"]
	"model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00960214 ms</TD></TR><TR><TD>model.backbone.res_layers.3.blocks.0.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32\nTacticValue:0x322f337abc345152\nWeights:{'Type': 'Int8', 'Count': 1179648}\n"]
	"model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0126051 ms</TD></TR><TR><TD>model.backbone.res_layers.3.blocks.0.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32\nTacticValue:0xccdb99df0646c7b3\nWeights:{'Type': 'Int8', 'Count': 2359296}\n"]
	"model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00616766 ms</TD></TR><TR><TD>model.backbone.res_layers.3.blocks.0.short.conv.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/Add </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/Add]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/act/Relu]\nName:model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x7de8ad674a85e82a\nWeights:{'Type': 'Int8', 'Count': 131072}\n"]
	"/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00645586 ms</TD></TR><TR><TD>/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003e8\n"]
	"model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0125503 ms</TD></TR><TR><TD>model.backbone.res_layers.3.blocks.1.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x64x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x1d53511430a5d47e\nWeights:{'Type': 'Int8', 'Count': 2359296}\n"]
	"model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0127551 ms</TD></TR><TR><TD>model.backbone.res_layers.3.blocks.1.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.1/Add </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.1/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/Add]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/act/Relu]\nName:model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xc5159665a920f22c\nWeights:{'Type': 'Int8', 'Count': 2359296}\n"]
	"/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00645837 ms</TD></TR><TR><TD>/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear]\nName:/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003e8\n"]
	"model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00627181 ms</TD></TR><TR><TD>model.encoder.input_proj.2.conv.weight </TD></TR><TR><TD> /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/input_proj.2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 0}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:0\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/input_proj.2/conv/Conv]+[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x7524377e24bc511f\nWeights:{'Type': 'Int8', 'Count': 131072}\n"]
	"Reformatting CopyNode for Input Tensor 0 to {ForeignNode[onnx######MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00488265 ms</TD></TR><TR><TD>Reformatting CopyNode for Input Tensor 0 to ForeignNode[onnx::MatMul_3620 </TD></TR><TR><TD> ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 </TD></TR><TR><TD> /model/encoder/Reshape_1]</TD></TR><TR><TD></TD></TR><TR><TD>REFORMAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:\nName:Reformatting CopyNode for Input Tensor 0 to {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}\nOrigin:REFORMAT\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	__myl_MulAddReshMoveTranAddTran_myl38_0 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409562 ms</TD></TR><TR><TD>__myl_MulAddReshMoveTranAddTran_myl38_0</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Transpose]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/input_proj.2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/Reshape]+[ONNX Layer: /model/encoder/encoder.0/layers.0/Add]+[ONNX Layer: /model/encoder/Transpose]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1]\nName:__myl_MulAddReshMoveTranAddTran_myl38_0\nStreamId:0\nTacticName:__myl_MulAddReshMoveTranAddTran_0xe457aa15a1457e4d9ada1b8a9ac84074\n"]
	__mye8858_myl38_2 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye8858_myl38_2</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:1\nLayerType:wait\nMetadata:\nName:__mye8858_myl38_2\nStreamId:1\nTacticName:\n"]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl38_3" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00716746 ms</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl38_3</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_2]\nName:/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl38_3\nStreamId:1\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16\n"]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_5" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00716746 ms</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/self_attn/MatMul_1</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_5</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_1]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add]\nName:/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_5\nStreamId:0\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16\n"]
	_gemm_mha_v2_myl38_7 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00819191 ms</TD></TR><TR><TD>_gemm_mha_v2_myl38_7</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Mul_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Softmax]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Mul_1]\nName:_gemm_mha_v2_myl38_7\nStreamId:0\nTacticName:_gemm_mha_v2_0x4b3d43298bdfabe601b05a79fbfdf8c8\n"]
	__myl_Tran_myl38_8 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409521 ms</TD></TR><TR><TD>__myl_Tran_myl38_8</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3]\nName:__myl_Tran_myl38_8\nStreamId:0\nTacticName:__myl_Tran_0x15e794fcfc5aadd50d4214509ec23820\n"]
	"/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl38_9" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.006143 ms</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl38_9</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Gemm]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Gemm]\nName:/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl38_9\nStreamId:0\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16\n"]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl38_10 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl38_10</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_1]+[ONNX Layer: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear]\nName:__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl38_10\nStreamId:0\nTacticName:__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0x6fe4e7c4010102ac41311fb055daac74\n"]
	"/model/encoder/encoder_0/layers_0/linear1/MatMul_myl38_11" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00716746 ms</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/linear1/MatMul_myl38_11</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Div]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Erf]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/MatMul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul_1]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Add]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Div]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Erf]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/Add]\nName:/model/encoder/encoder_0/layers_0/linear1/MatMul_myl38_11\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_gelu_erf\n"]
	"/model/encoder/encoder_0/layers_0/linear2/MatMul_myl38_12" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614343 ms</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/linear2/MatMul_myl38_12</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]\nName:/model/encoder/encoder_0/layers_0/linear2/MatMul_myl38_12\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_CastAddAddCastMeanSubMulMean_myl38_13 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_CastAddAddCastMeanSubMulMean_myl38_13</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]+[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]+[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_2]\nName:__myl_CastAddAddCastMeanSubMulMean_myl38_13\nStreamId:0\nTacticName:__myl_CastAddAddCastMeanSubMulMean_0xc644c0fa4f3484d88e9acca381e2d8a8\n"]
	__myl_AddSqrtDivMulCastMulAddTranResh_myl38_14 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511923 ms</TD></TR><TR><TD>__myl_AddSqrtDivMulCastMulAddTranResh_myl38_14</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Transpose_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Reshape_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]+[ONNX Layer: /model/encoder/Transpose_1]+[ONNX Layer: /model/encoder/Reshape_1]\nName:__myl_AddSqrtDivMulCastMulAddTranResh_myl38_14\nStreamId:0\nTacticName:__myl_AddSqrtDivMulCastMulAddTranResh_0x18e715b50f8bff9f493fb3c5e3266869\n"]
	"model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00709138 ms</TD></TR><TR><TD>model.encoder.input_proj.0.conv.weight </TD></TR><TR><TD> /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/input_proj.0/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.0/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/input_proj.0/conv/Conv]+[ONNX Layer: /model/encoder/input_proj.0/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x483ad1560c6e5e27\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00632502 ms</TD></TR><TR><TD>model.encoder.input_proj.1.conv.weight </TD></TR><TR><TD> /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/input_proj.1/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/input_proj.1/conv/Conv]+[ONNX Layer: /model/encoder/input_proj.1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x483ad1560c6e5e27\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00748639 ms</TD></TR><TR><TD>/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear]\nName:/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003e8\n"]
	"model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00525512 ms</TD></TR><TR><TD>model.encoder.lateral_convs.0.conv.weight </TD></TR><TR><TD> /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/lateral_convs.0/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.0/conv/Conv]+[ONNX Layer: /model/encoder/lateral_convs.0/norm/BatchNormalization]+[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x6d377e4222886190\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00381925 ms</TD></TR><TR><TD>PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/act/Mul]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/lateral_convs.0/act/Sigmoid]+[ONNX Layer: /model/encoder/lateral_convs.0/act/Mul]\nName:PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)\nNbInputArgs:1\nNbLiterals:5\nNbOperations:5\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);']\nOutputVars:['var4']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x000000000000001f\n"]
	"/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00507295 ms</TD></TR><TR><TD>/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\nName:/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003e8\n"]
	"/model/encoder/Resize" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Resize</b></TD></TR><TR><TD>0.00434271 ms</TD></TR><TR><TD>/model/encoder/Resize</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Resize]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="CoordTransform:kASYMMETRIC\nCubicCoeff:-0.75\nExcludeOutside:0\nInterpolationMode:NEAREST\nLayerType:Resize\nMetadata:[ONNX Layer: /model/encoder/Resize]\nNNRounding:kFLOOR\nName:/model/encoder/Resize\nResizeScales:[1, 1, 2, 2, 0, 0, 0, 0]\nResizeSelector:kFORMULA\nStreamId:0\nTacticValue:0x0000000000000005\n"]
	"/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00479692 ms</TD></TR><TR><TD>/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Concat_2]</TD></TR><TR><TD>CONCAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/Concat_2]\nName:/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy\nOrigin:CONCAT\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00643621 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.0.conv2.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/conv2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x8e1dd2962c589dd4\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00638386 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.0.conv1.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/conv1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00786504 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc722efd60bc6ea84\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00779274 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc722efd60bc6ea84\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00784987 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xad6872a374321f7e\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00483083 ms</TD></TR><TR><TD>PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0', 'arg1']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f', '0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/Add]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]\nName:PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))\nNbInputArgs:2\nNbLiterals:10\nNbOperations:11\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);', 'auto const var5 = pwgen::iMul(literal9, arg1);', 'auto const var6 = pwgen::iTanh(var5);', 'auto const var7 = pwgen::iMul(var6, literal9);', 'auto const var8 = pwgen::iPlus(var7, literal9);', 'auto const var9 = pwgen::iMul(arg1, var8);', 'auto const var10 = pwgen::iPlus(var4, var9);']\nOutputVars:['var10']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x0000000000000018\n"]
	"model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00513551 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.0.conv3.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/conv3/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Mul]+[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00576386 ms</TD></TR><TR><TD>model.encoder.lateral_convs.1.conv.weight </TD></TR><TR><TD> /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/lateral_convs.1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.1/conv/Conv]+[ONNX Layer: /model/encoder/lateral_convs.1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/lateral_convs.1/act/Sigmoid]+[ONNX Layer: /model/encoder/lateral_convs.1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"/model/encoder/Resize_1" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Resize</b></TD></TR><TR><TD>0.00493794 ms</TD></TR><TR><TD>/model/encoder/Resize_1</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Resize_1]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="CoordTransform:kASYMMETRIC\nCubicCoeff:-0.75\nExcludeOutside:0\nInterpolationMode:NEAREST\nLayerType:Resize\nMetadata:[ONNX Layer: /model/encoder/Resize_1]\nNNRounding:kFLOOR\nName:/model/encoder/Resize_1\nResizeScales:[1, 1, 2, 2, 0, 0, 0, 0]\nResizeSelector:kFORMULA\nStreamId:0\nTacticValue:0x0000000000000005\n"]
	"/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00506741 ms</TD></TR><TR><TD>/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Concat_3]</TD></TR><TR><TD>CONCAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/Concat_3]\nName:/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy\nOrigin:CONCAT\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00802327 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.1.conv2.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/conv2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x758f8b2079a95b2e\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00841025 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.1.conv1.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/conv1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x458f02d2b10db57c\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00949283 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xfdf7509af98902e0\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00931181 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xfdf7509af98902e0\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00960123 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x4133eb8759ee0d6d\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00640159 ms</TD></TR><TR><TD>PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0', 'arg1']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f', '0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/Add]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]\nName:PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))\nNbInputArgs:2\nNbLiterals:10\nNbOperations:11\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);', 'auto const var5 = pwgen::iMul(literal9, arg1);', 'auto const var6 = pwgen::iTanh(var5);', 'auto const var7 = pwgen::iMul(var6, literal9);', 'auto const var8 = pwgen::iPlus(var7, literal9);', 'auto const var9 = pwgen::iMul(arg1, var8);', 'auto const var10 = pwgen::iPlus(var4, var9);']\nOutputVars:['var10']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x0000000000000019\n"]
	"model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00930389 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.1.conv3.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/conv3/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Mul]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x65a38dbc9e991257\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00912076 ms</TD></TR><TR><TD>model.decoder.input_proj.0.conv.weight </TD></TR><TR><TD> /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/decoder/input_proj.0/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 0}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:0\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/input_proj.0/conv/Conv]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]\nName:model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x8486adb55ae0ca6c\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0105572 ms</TD></TR><TR><TD>model.encoder.downsample_convs.0.conv.weight </TD></TR><TR><TD> /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/downsample_convs.0/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/Conv]+[ONNX Layer: /model/encoder/downsample_convs.0/norm/BatchNormalization]+[ONNX Layer: /model/encoder/downsample_convs.0/act/Sigmoid]+[ONNX Layer: /model/encoder/downsample_convs.0/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc722efd60bc6ea84\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"/model/encoder/Resize_1_output_0 copy" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00484382 ms</TD></TR><TR><TD>/model/encoder/Resize_1_output_0 copy</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Concat_4]</TD></TR><TR><TD>CONCAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/Concat_4]\nName:/model/encoder/Resize_1_output_0 copy\nOrigin:CONCAT\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00643596 ms</TD></TR><TR><TD>model.encoder.pan_blocks.0.conv2.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.0/conv2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x8e1dd2962c589dd4\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00636352 ms</TD></TR><TR><TD>model.encoder.pan_blocks.0.conv1.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.0/conv1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00704071 ms</TD></TR><TR><TD>model.encoder.pan_blocks.0.bottlenecks.0.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc722efd60bc6ea84\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00723351 ms</TD></TR><TR><TD>model.encoder.pan_blocks.0.bottlenecks.1.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc722efd60bc6ea84\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00771426 ms</TD></TR><TR><TD>model.encoder.pan_blocks.0.bottlenecks.2.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xad6872a374321f7e\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00486402 ms</TD></TR><TR><TD>PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0', 'arg1']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f', '0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/Add]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]\nName:PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))\nNbInputArgs:2\nNbLiterals:10\nNbOperations:11\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);', 'auto const var5 = pwgen::iMul(literal9, arg1);', 'auto const var6 = pwgen::iTanh(var5);', 'auto const var7 = pwgen::iMul(var6, literal9);', 'auto const var8 = pwgen::iPlus(var7, literal9);', 'auto const var9 = pwgen::iMul(arg1, var8);', 'auto const var10 = pwgen::iPlus(var4, var9);']\nOutputVars:['var10']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x0000000000000018\n"]
	"model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00497081 ms</TD></TR><TR><TD>model.encoder.pan_blocks.0.conv3.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.0/conv3/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Mul]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00655385 ms</TD></TR><TR><TD>model.decoder.input_proj.1.conv.weight </TD></TR><TR><TD> /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/decoder/input_proj.1/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 0}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:0\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/input_proj.1/conv/Conv]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]\nName:model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4\nTacticValue:0x733ba2a91a48d431\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00813832 ms</TD></TR><TR><TD>model.encoder.downsample_convs.1.conv.weight </TD></TR><TR><TD> /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/downsample_convs.1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/Conv]+[ONNX Layer: /model/encoder/downsample_convs.1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/downsample_convs.1/act/Sigmoid]+[ONNX Layer: /model/encoder/downsample_convs.1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc985777c89c6b3a4\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00496425 ms</TD></TR><TR><TD>/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\nName:/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003e8\n"]
	"model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00504744 ms</TD></TR><TR><TD>model.encoder.pan_blocks.1.conv2.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.1/conv2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x6d377e4222886190\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00509088 ms</TD></TR><TR><TD>model.encoder.pan_blocks.1.conv1.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.1/conv1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0xc6cdb1e47323bb01\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00640573 ms</TD></TR><TR><TD>model.encoder.pan_blocks.1.bottlenecks.0.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc985777c89c6b3a4\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00639747 ms</TD></TR><TR><TD>model.encoder.pan_blocks.1.bottlenecks.1.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc985777c89c6b3a4\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0067807 ms</TD></TR><TR><TD>model.encoder.pan_blocks.1.bottlenecks.2.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xd14bd6d95fefd45e\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00409446 ms</TD></TR><TR><TD>PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0', 'arg1']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f', '0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/Add]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]\nName:PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))\nNbInputArgs:2\nNbLiterals:10\nNbOperations:11\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);', 'auto const var5 = pwgen::iMul(literal9, arg1);', 'auto const var6 = pwgen::iTanh(var5);', 'auto const var7 = pwgen::iMul(var6, literal9);', 'auto const var8 = pwgen::iPlus(var7, literal9);', 'auto const var9 = pwgen::iMul(arg1, var8);', 'auto const var10 = pwgen::iPlus(var4, var9);']\nOutputVars:['var10']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x0000000000000018\n"]
	"model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00491946 ms</TD></TR><TR><TD>model.encoder.pan_blocks.1.conv3.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.1/conv3/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Mul]+[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0xc6cdb1e47323bb01\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0072201 ms</TD></TR><TR><TD>model.decoder.input_proj.2.conv.weight </TD></TR><TR><TD> /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/decoder/input_proj.2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 0}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:0\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/input_proj.2/conv/Conv]+[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]\nName:model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4\nTacticValue:0x5e4f6d7c83746fd6\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"Reformatting CopyNode for Input Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00646293 ms</TD></TR><TR><TD>Reformatting CopyNode for Input Tensor 1 to ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]</TD></TR><TR><TD></TD></TR><TR><TD>REFORMAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:\nName:Reformatting CopyNode for Input Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}\nOrigin:REFORMAT\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"Reformatting CopyNode for Input Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00488199 ms</TD></TR><TR><TD>Reformatting CopyNode for Input Tensor 2 to ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]</TD></TR><TR><TD></TD></TR><TR><TD>REFORMAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:\nName:Reformatting CopyNode for Input Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}\nOrigin:REFORMAT\nStreamId:0\nTacticValue:0x00000000000003e8\n"]
	"Reformatting CopyNode for Input Tensor 3 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00351178 ms</TD></TR><TR><TD>Reformatting CopyNode for Input Tensor 3 to ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]</TD></TR><TR><TD></TD></TR><TR><TD>REFORMAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:\nName:Reformatting CopyNode for Input Tensor 3 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}\nOrigin:REFORMAT\nStreamId:0\nTacticValue:0x00000000000003e8\n"]
	"entry^bb^wait^1_myl88_1" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>entry^bb^wait^1_myl88_1</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:19\nLayerType:wait\nMetadata:\nName:entry^bb^wait^1_myl88_1\nStreamId:1\nTacticName:\n"]
	__myl_MulAddReshMulMinMaxRounCastTran_myl88_2 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00921536 ms</TD></TR><TR><TD>__myl_MulAddReshMulMinMaxRounCastTran_myl88_2</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.0/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/input_proj.0/norm/BatchNormalization]+[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Reshape]+[ONNX Layer: /model/decoder/Transpose]\nName:__myl_MulAddReshMulMinMaxRounCastTran_myl88_2\nStreamId:0\nTacticName:__myl_MulAddReshMulMinMaxRounCastTran_0x5358adb630fbfcb554dd5ceff3cef1db\n"]
	__myl_MulMinMaxRounCastReshTran_myl88_3 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00716705 ms</TD></TR><TR><TD>__myl_MulMinMaxRounCastReshTran_myl88_3</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Reshape]+[ONNX Layer: /model/decoder/Transpose]\nName:__myl_MulMinMaxRounCastReshTran_myl88_3\nStreamId:0\nTacticName:__myl_MulMinMaxRounCastReshTran_0xf99f3d478a31416d3ca508b83f50f6cf\n"]
	__myl_MulAddReshMulMinMaxRounCastTran_myl88_4 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00921577 ms</TD></TR><TR><TD>__myl_MulAddReshMulMinMaxRounCastTran_myl88_4</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/input_proj.1/norm/BatchNormalization]+[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Reshape_1]+[ONNX Layer: /model/decoder/Transpose_1]\nName:__myl_MulAddReshMulMinMaxRounCastTran_myl88_4\nStreamId:1\nTacticName:__myl_MulAddReshMulMinMaxRounCastTran_0x3ce46b5387fb3712faa5ac5851c46aa2\n"]
	__myl_MulMinMaxRounCastReshTran_myl88_5 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_MulMinMaxRounCastReshTran_myl88_5</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Reshape_1]+[ONNX Layer: /model/decoder/Transpose_1]\nName:__myl_MulMinMaxRounCastReshTran_myl88_5\nStreamId:1\nTacticName:__myl_MulMinMaxRounCastReshTran_0x0289c18f1e1ff0d7a480407e8817adc8\n"]
	__mye154347_myl88_7 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye154347_myl88_7</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:1\nLayerType:wait\nMetadata:\nName:__mye154347_myl88_7\nStreamId:0\nTacticName:\n"]
	__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl88_8 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00921618 ms</TD></TR><TR><TD>__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl88_8</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Concat_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/input_proj.2/norm/BatchNormalization]+[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Concat_3]+[ONNX Layer: /model/decoder/Reshape_2]+[ONNX Layer: /model/decoder/Transpose_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]\nName:__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl88_8\nStreamId:0\nTacticName:__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_0xbf3c9a060b5f9802aa564f39e2f1f020\n"]
	__mye154351_myl88_10 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye154351_myl88_10</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:2\nLayerType:wait\nMetadata:\nName:__mye154351_myl88_10\nStreamId:1\nTacticName:\n"]
	__myl_FcMulCastAdd_myl88_11 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.0194563 ms</TD></TR><TR><TD>__myl_FcMulCastAdd_myl88_11</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add]\nName:__myl_FcMulCastAdd_myl88_11\nStreamId:1\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_FcCastAdd_myl88_12 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.013311 ms</TD></TR><TR><TD>__myl_FcCastAdd_myl88_12</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/enc_output/proj/MatMul]+[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_output/proj/Add]\nName:__myl_FcCastAdd_myl88_12\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_13 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00819164 ms</TD></TR><TR><TD>__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_13</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/norm/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/enc_output/norm/LayerNormalization]+[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear]\nName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_13\nStreamId:0\nTacticName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0xe2d727d35a85bd2c3cc2eb53c7452092\n"]
	__mye154355_myl88_15 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye154355_myl88_15</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:3\nLayerType:wait\nMetadata:\nName:__mye154355_myl88_15\nStreamId:1\nTacticName:\n"]
	"/model/decoder/enc_score_head/MatMul_myl88_16" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0143341 ms</TD></TR><TR><TD>/model/decoder/enc_score_head/MatMul_myl88_16</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/enc_score_head/MatMul]+[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_score_head/Add]\nName:/model/decoder/enc_score_head/MatMul_myl88_16\nStreamId:1\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32\n"]
	__myl_CastAddMaxr_myl88_17 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_CastAddMaxr_myl88_17</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/ReduceMax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/enc_score_head/MatMul]+[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_score_head/Add]+[ONNX Layer: /model/decoder/ReduceMax]\nName:__myl_CastAddMaxr_myl88_17\nStreamId:1\nTacticName:__myl_CastAddMaxr_0x19151a86595916c177b83b4afe8dd8e1\n"]
	__myl_Topk_myl88_18 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0204794 ms</TD></TR><TR><TD>__myl_Topk_myl88_18</TD></TR><TR><TD>[ONNX Layer: /model/decoder/TopK]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/TopK]\nName:__myl_Topk_myl88_18\nStreamId:1\nTacticName:__myl_Topk_0x3801d91b92fc69261d17a37dbf46b775\n"]
	"/model/decoder/enc_bbox_head/layers_0/MatMul_myl88_20" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0112635 ms</TD></TR><TR><TD>/model/decoder/enc_bbox_head/layers_0/MatMul_myl88_20</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/MatMul]+[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/act/Relu]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/Add]\nName:/model/decoder/enc_bbox_head/layers_0/MatMul_myl88_20\nStreamId:0\nTacticName:sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1\n"]
	"/model/decoder/enc_bbox_head/layers_1/MatMul_myl88_21" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0122872 ms</TD></TR><TR><TD>/model/decoder/enc_bbox_head/layers_1/MatMul_myl88_21</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/MatMul]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/act_1/Relu]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/Add]\nName:/model/decoder/enc_bbox_head/layers_1/MatMul_myl88_21\nStreamId:0\nTacticName:sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1\n"]
	__myl_FcCastAddAdd_myl88_22 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614341 ms</TD></TR><TR><TD>__myl_FcCastAddAdd_myl88_22</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/MatMul]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/Add]+[ONNX Layer: /model/decoder/Add]\nName:__myl_FcCastAddAdd_myl88_22\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x64x64_stage3_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl88_24 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511937 ms</TD></TR><TR><TD>__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl88_24</TD></TR><TR><TD>[ONNX Layer: /model/decoder/GatherElements]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Log]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Div]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sub]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Clip]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Unsqueeze]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/GatherElements]+[ONNX Layer: /model/decoder/decoder/Sigmoid]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/Log]+[ONNX Layer: /model/decoder/decoder/Div]+[ONNX Layer: /model/decoder/decoder/Sub]+[ONNX Layer: /model/decoder/decoder/Clip]+[ONNX Layer: /model/decoder/Unsqueeze]\nName:__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl88_24\nStreamId:0\nTacticName:__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_0x4e0b1a71403d082fda5d4916d8107860\n"]
	"/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl88_25" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511964 ms</TD></TR><TR><TD>/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl88_25</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]\nName:/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl88_25\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_FcCastAdd_myl88_26 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00512005 ms</TD></TR><TR><TD>__myl_FcCastAdd_myl88_26</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/Add]\nName:__myl_FcCastAdd_myl88_26\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReplGathReshReshAdd_myl88_27 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409539 ms</TD></TR><TR><TD>__myl_ReplGathReshReshAdd_myl88_27</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/GatherElements_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/Add]+[ONNX Layer: /model/decoder/GatherElements_1]\nName:__myl_ReplGathReshReshAdd_myl88_27\nStreamId:0\nTacticName:__myl_ReplGathReshReshAdd_0x53452db711fa8db38ccc9a01cdb12399\n"]
	__mye154363_myl88_29 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye154363_myl88_29</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:5\nLayerType:wait\nMetadata:\nName:__mye154363_myl88_29\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl88_30" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614341 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl88_30</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_2]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_2]\nName:/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl88_30\nStreamId:1\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16\n"]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl88_32" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00512005 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_0/self_attn/MatMul_1</TD></TR><TR><TD>/model/decoder/decoder/layers_0/self_attn/MatMul_myl88_32</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_1]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add]\nName:/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl88_32\nStreamId:0\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16\n"]
	_gemm_mha_v2_myl88_34 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00614373 ms</TD></TR><TR><TD>_gemm_mha_v2_myl88_34</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Mul_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_4]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Softmax]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_3]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Mul_1]\nName:_gemm_mha_v2_myl88_34\nStreamId:0\nTacticName:_gemm_mha_v2_0x742379e0e620f0cf024dbdbe86bf6611\n"]
	__myl_Tran_myl88_35 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00326389 ms</TD></TR><TR><TD>__myl_Tran_myl88_35</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Transpose_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Reshape_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Transpose_5]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Reshape_3]\nName:__myl_Tran_myl88_35\nStreamId:0\nTacticName:__myl_Tran_0x068242bad4efe24d77461cc051df5e82\n"]
	"/model/decoder/decoder/layers_0/self_attn/Gemm_myl88_36" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511964 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_0/self_attn/Gemm_myl88_36</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Gemm]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Gemm]\nName:/model/decoder/decoder/layers_0/self_attn/Gemm_myl88_36\nStreamId:0\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16\n"]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshAddMulMinMaxRounCast_myl88_37 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409577 ms</TD></TR><TR><TD>__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshAddMulMinMaxRounCast_myl88_37</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/norm1/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.0/norm1/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.0/Add_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]\nName:__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshAddMulMinMaxRounCast_myl88_37\nStreamId:0\nTacticName:__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshAddMulMinMaxRounCast_0x0e34c2b971ec15ffba3b5ab843fdf854\n"]
	__myl_FcCastAdd_myl88_39 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00511964 ms</TD></TR><TR><TD>__myl_FcCastAdd_myl88_39</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add]\nName:__myl_FcCastAdd_myl88_39\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_40 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307191 ms</TD></TR><TR><TD>__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_40</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Sub]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Split]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Sub]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_5]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_6]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Split]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8]\nName:__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_40\nStreamId:0\nTacticName:__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_0x166f11fca798ea25bbab70ff7c539643\n"]
	__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_41 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00921661 ms</TD></TR><TR><TD>__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_41</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_7]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_4]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_6]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_5]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_4]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_6]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_7]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_8]\nName:__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_41\nStreamId:0\nTacticName:__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_0xc71bbed5e42c2906a2f6f45ea1d7a78c\n"]
	__myl_FcCastAdd_myl88_43 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00512005 ms</TD></TR><TR><TD>__myl_FcCastAdd_myl88_43</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add]\nName:__myl_FcCastAdd_myl88_43\nStreamId:1\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshMaxrSubExpSum_myl88_44 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_ReshMaxrSubExpSum_myl88_44</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]\nName:__myl_ReshMaxrSubExpSum_myl88_44\nStreamId:1\nTacticName:__myl_ReshMaxrSubExpSum_0xba6a237155991369f77bdf11d50a3c03\n"]
	__mye154375_myl88_46 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye154375_myl88_46</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:8\nLayerType:wait\nMetadata:\nName:__mye154375_myl88_46\nStreamId:0\nTacticName:\n"]
	__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_47 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0153594 ms</TD></TR><TR><TD>__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_47</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_9]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Concat_10]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/ReduceSum]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_8]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_9]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Concat_10]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/ReduceSum]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_8]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear]\nName:__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_47\nStreamId:0\nTacticName:__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_0x8497f2d8c2f5630da07536b4f9cc18f0\n"]
	__myl_Move_myl88_48 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409577 ms</TD></TR><TR><TD>__myl_Move_myl88_48</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]\nName:__myl_Move_myl88_48\nStreamId:0\nTacticName:__myl_Move_0xe44b2845ee5a2c900106157eaed1d520\n"]
	__myl_FcCastAddAdd_myl88_49 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00428768 ms</TD></TR><TR><TD>__myl_FcCastAddAdd_myl88_49</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add_3]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/Add_3]\nName:__myl_FcCastAddAdd_myl88_49\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_50 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0032 ms</TD></TR><TR><TD>__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_50</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/norm2/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear]\nName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_50\nStreamId:0\nTacticName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0xcc497afe211f479634492d5ba512e7ea\n"]
	"/model/decoder/decoder/layers_0/linear1/MatMul_myl88_51" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00409613 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_0/linear1/MatMul_myl88_51</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/activation/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/linear1/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/activation/Relu]+[ONNX Layer: /model/decoder/decoder/layers.0/linear1/Add]\nName:/model/decoder/decoder/layers_0/linear1/MatMul_myl88_51\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	__myl_FcCastAddAdd_myl88_52 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614381 ms</TD></TR><TR><TD>__myl_FcCastAddAdd_myl88_52</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add_4]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/linear2/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/linear2/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/Add_4]\nName:__myl_FcCastAddAdd_myl88_52\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_53 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409562 ms</TD></TR><TR><TD>__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_53</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear]\nName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_53\nStreamId:0\nTacticName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0xf06434bfbed1dc027cac0cf6800444ba\n"]
	__mye154379_myl88_55 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye154379_myl88_55</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:9\nLayerType:wait\nMetadata:\nName:__mye154379_myl88_55\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl88_56" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00819083 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl88_56</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_2]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_2]\nName:/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl88_56\nStreamId:1\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16\n"]
	"/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl88_58" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.006143 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl88_58</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add]\nName:/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl88_58\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1\n"]
	"/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl88_59" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511964 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl88_59</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add]\nName:/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl88_59\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1\n"]
	__myl_FcCastAddAddSigm_myl88_60 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614341 ms</TD></TR><TR><TD>__myl_FcCastAddAddSigm_myl88_60</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sigmoid_1]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add]+[ONNX Layer: /model/decoder/decoder/Add]+[ONNX Layer: /model/decoder/decoder/Sigmoid_1]\nName:__myl_FcCastAddAddSigm_myl88_60\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_MulMinMaxRounConcCast_myl88_61 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307191 ms</TD></TR><TR><TD>__myl_MulMinMaxRounConcCast_myl88_61</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear]\nName:__myl_MulMinMaxRounConcCast_myl88_61\nStreamId:0\nTacticName:__myl_MulMinMaxRounConcCast_0x675a534c6ff964b95c70b269e3fd48e9\n"]
	"/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl88_62" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00412809 ms</TD></TR><TR><TD>/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl88_62</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/act_1/Relu]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/Add]\nName:/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl88_62\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_FcCastAdd_myl88_63 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.006143 ms</TD></TR><TR><TD>__myl_FcCastAdd_myl88_63</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/Add]\nName:__myl_FcCastAdd_myl88_63\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_Add_myl88_64 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00313563 ms</TD></TR><TR><TD>__myl_Add_myl88_64</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/Add]\nName:__myl_Add_myl88_64\nStreamId:0\nTacticName:__myl_Add_0xdde52a3a8d7160d5661d1cdb3767660f\n"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl88_65" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00512005 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_1/self_attn/MatMul_1</TD></TR><TR><TD>/model/decoder/decoder/layers_1/self_attn/MatMul_myl88_65</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_1]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add]\nName:/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl88_65\nStreamId:0\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16\n"]
	_gemm_mha_v2_myl88_67 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00614381 ms</TD></TR><TR><TD>_gemm_mha_v2_myl88_67</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Mul_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_4]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Softmax]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_3]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Mul_1]\nName:_gemm_mha_v2_myl88_67\nStreamId:0\nTacticName:_gemm_mha_v2_0x742379e0e620f0cf024dbdbe86bf6611\n"]
	__myl_Tran_myl88_68 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307163 ms</TD></TR><TR><TD>__myl_Tran_myl88_68</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Transpose_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Reshape_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Transpose_5]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Reshape_3]\nName:__myl_Tran_myl88_68\nStreamId:0\nTacticName:__myl_Tran_0x068242bad4efe24d77461cc051df5e82\n"]
	"/model/decoder/decoder/layers_1/self_attn/Gemm_myl88_69" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00512005 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_1/self_attn/Gemm_myl88_69</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Gemm]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Gemm]\nName:/model/decoder/decoder/layers_1/self_attn/Gemm_myl88_69\nStreamId:0\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16\n"]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_70 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00431958 ms</TD></TR><TR><TD>__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_70</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/norm1/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.1/norm1/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.1/Add_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]\nName:__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_70\nStreamId:0\nTacticName:__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_0xfa7ba13c29e2d38c8ae25093f835ab14\n"]
	__myl_FcCastAdd_myl88_72 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_FcCastAdd_myl88_72</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add]\nName:__myl_FcCastAdd_myl88_72\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_73 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_73</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Sub]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Split]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Sub]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_5]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_3]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Split]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8]\nName:__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_73\nStreamId:0\nTacticName:__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_0x166f11fca798ea25bbab70ff7c539643\n"]
	__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_74 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0112636 ms</TD></TR><TR><TD>__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_74</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_7]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_4]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_6]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_5]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_4]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_6]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_7]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_8]\nName:__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_74\nStreamId:0\nTacticName:__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_0xc71bbed5e42c2906a2f6f45ea1d7a78c\n"]
	__myl_FcCastAdd_myl88_76 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614381 ms</TD></TR><TR><TD>__myl_FcCastAdd_myl88_76</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add]\nName:__myl_FcCastAdd_myl88_76\nStreamId:1\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshMaxrSubExpSum_myl88_77 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409562 ms</TD></TR><TR><TD>__myl_ReshMaxrSubExpSum_myl88_77</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]\nName:__myl_ReshMaxrSubExpSum_myl88_77\nStreamId:1\nTacticName:__myl_ReshMaxrSubExpSum_0xba6a237155991369f77bdf11d50a3c03\n"]
	__mye154391_myl88_79 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye154391_myl88_79</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:12\nLayerType:wait\nMetadata:\nName:__mye154391_myl88_79\nStreamId:0\nTacticName:\n"]
	__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_80 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0153595 ms</TD></TR><TR><TD>__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_80</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_9]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Concat_10]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/ReduceSum]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_9]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Concat_10]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/ReduceSum]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_5]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear]\nName:__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_80\nStreamId:0\nTacticName:__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_0x8497f2d8c2f5630da07536b4f9cc18f0\n"]
	__myl_Move_myl88_81 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_Move_myl88_81</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]\nName:__myl_Move_myl88_81\nStreamId:0\nTacticName:__myl_Move_0xe44b2845ee5a2c900106157eaed1d520\n"]
	__myl_FcCastAddAdd_myl88_82 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00511964 ms</TD></TR><TR><TD>__myl_FcCastAddAdd_myl88_82</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add_3]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/Add_3]\nName:__myl_FcCastAddAdd_myl88_82\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_83 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00310408 ms</TD></TR><TR><TD>__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_83</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/norm2/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear]\nName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_83\nStreamId:0\nTacticName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0xcc497afe211f479634492d5ba512e7ea\n"]
	"/model/decoder/decoder/layers_1/linear1/MatMul_myl88_84" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614305 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_1/linear1/MatMul_myl88_84</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/activation/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/linear1/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/activation/Relu]+[ONNX Layer: /model/decoder/decoder/layers.1/linear1/Add]\nName:/model/decoder/decoder/layers_1/linear1/MatMul_myl88_84\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	__myl_FcCastAddAdd_myl88_85 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614381 ms</TD></TR><TR><TD>__myl_FcCastAddAdd_myl88_85</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add_4]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/linear2/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/linear2/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/Add_4]\nName:__myl_FcCastAddAdd_myl88_85\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_86 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409562 ms</TD></TR><TR><TD>__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_86</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear]\nName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_86\nStreamId:0\nTacticName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0xf06434bfbed1dc027cac0cf6800444ba\n"]
	__mye154395_myl88_88 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye154395_myl88_88</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:13\nLayerType:wait\nMetadata:\nName:__mye154395_myl88_88\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl88_89" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511964 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl88_89</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_2]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_2]\nName:/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl88_89\nStreamId:1\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16\n"]
	__myl_MaxMinSubMaxMinMaxMinDivLog_myl88_91 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409562 ms</TD></TR><TR><TD>__myl_MaxMinSubMaxMinMaxMinDivLog_myl88_91</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Log_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Div_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sub_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Clip_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/Log_1]+[ONNX Layer: /model/decoder/decoder/Div_1]+[ONNX Layer: /model/decoder/decoder/Sub_1]+[ONNX Layer: /model/decoder/decoder/Clip_3]\nName:__myl_MaxMinSubMaxMinMaxMinDivLog_myl88_91\nStreamId:0\nTacticName:__myl_MaxMinSubMaxMinMaxMinDivLog_0x564e12beef03d2192684faee0d1f2dc4\n"]
	"/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl88_92" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614341 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl88_92</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add]\nName:/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl88_92\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1\n"]
	"/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl88_93" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511964 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl88_93</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add]\nName:/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl88_93\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1\n"]
	__myl_FcCastAddAddSigm_myl88_94 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614381 ms</TD></TR><TR><TD>__myl_FcCastAddAddSigm_myl88_94</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sigmoid_2]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add]+[ONNX Layer: /model/decoder/decoder/Add_1]+[ONNX Layer: /model/decoder/decoder/Sigmoid_2]\nName:__myl_FcCastAddAddSigm_myl88_94\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_MulMinMaxRounConcCast_myl88_95 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00329584 ms</TD></TR><TR><TD>__myl_MulMinMaxRounConcCast_myl88_95</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear]\nName:__myl_MulMinMaxRounConcCast_myl88_95\nStreamId:0\nTacticName:__myl_MulMinMaxRounConcCast_0x675a534c6ff964b95c70b269e3fd48e9\n"]
	"/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl88_96" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511964 ms</TD></TR><TR><TD>/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl88_96</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/act_2/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/act_2/Relu]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/Add]\nName:/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl88_96\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_FcCastAdd_myl88_97 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00511964 ms</TD></TR><TR><TD>__myl_FcCastAdd_myl88_97</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/Add]\nName:__myl_FcCastAdd_myl88_97\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_Add_myl88_98 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307191 ms</TD></TR><TR><TD>__myl_Add_myl88_98</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/Add]\nName:__myl_Add_myl88_98\nStreamId:0\nTacticName:__myl_Add_0xdde52a3a8d7160d5661d1cdb3767660f\n"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl88_99" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00633567 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_2/self_attn/MatMul_1</TD></TR><TR><TD>/model/decoder/decoder/layers_2/self_attn/MatMul_myl88_99</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_1]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add]\nName:/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl88_99\nStreamId:0\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16\n"]
	_gemm_mha_v2_myl88_101 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00614381 ms</TD></TR><TR><TD>_gemm_mha_v2_myl88_101</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Mul_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_4]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Softmax]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_3]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Mul_1]\nName:_gemm_mha_v2_myl88_101\nStreamId:0\nTacticName:_gemm_mha_v2_0x742379e0e620f0cf024dbdbe86bf6611\n"]
	__myl_Tran_myl88_102 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307161 ms</TD></TR><TR><TD>__myl_Tran_myl88_102</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Transpose_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Reshape_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Transpose_5]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Reshape_3]\nName:__myl_Tran_myl88_102\nStreamId:0\nTacticName:__myl_Tran_0x068242bad4efe24d77461cc051df5e82\n"]
	"/model/decoder/decoder/layers_2/self_attn/Gemm_myl88_103" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00409644 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_2/self_attn/Gemm_myl88_103</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Gemm]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Gemm]\nName:/model/decoder/decoder/layers_2/self_attn/Gemm_myl88_103\nStreamId:0\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16\n"]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_104 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_104</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/norm1/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.2/norm1/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.2/Add_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]\nName:__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_104\nStreamId:0\nTacticName:__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_0xfa7ba13c29e2d38c8ae25093f835ab14\n"]
	__myl_FcCastAdd_myl88_106 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_FcCastAdd_myl88_106</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add]\nName:__myl_FcCastAdd_myl88_106\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_107 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307191 ms</TD></TR><TR><TD>__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_107</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Sub]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Split]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Sub]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_5]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_3]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Add]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Split]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8]\nName:__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_107\nStreamId:0\nTacticName:__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_0x166f11fca798ea25bbab70ff7c539643\n"]
	__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_108 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00921618 ms</TD></TR><TR><TD>__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_108</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_7]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_4]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_6]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_5]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_4]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_6]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_7]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_8]\nName:__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_108\nStreamId:0\nTacticName:__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_0xc71bbed5e42c2906a2f6f45ea1d7a78c\n"]
	__myl_FcCastAdd_myl88_110 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00512005 ms</TD></TR><TR><TD>__myl_FcCastAdd_myl88_110</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add]\nName:__myl_FcCastAdd_myl88_110\nStreamId:1\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshMaxrSubExpSum_myl88_111 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_ReshMaxrSubExpSum_myl88_111</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]\nName:__myl_ReshMaxrSubExpSum_myl88_111\nStreamId:1\nTacticName:__myl_ReshMaxrSubExpSum_0xba6a237155991369f77bdf11d50a3c03\n"]
	__mye154407_myl88_113 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye154407_myl88_113</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:16\nLayerType:wait\nMetadata:\nName:__mye154407_myl88_113\nStreamId:0\nTacticName:\n"]
	__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_114 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0143357 ms</TD></TR><TR><TD>__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_114</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_9]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Concat_10]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/ReduceSum]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_9]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Concat_10]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/ReduceSum]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_5]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear]\nName:__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_114\nStreamId:0\nTacticName:__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_0x8497f2d8c2f5630da07536b4f9cc18f0\n"]
	__myl_Move_myl88_115 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_Move_myl88_115</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]\nName:__myl_Move_myl88_115\nStreamId:0\nTacticName:__myl_Move_0xe44b2845ee5a2c900106157eaed1d520\n"]
	__myl_FcCastAddAdd_myl88_116 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00511964 ms</TD></TR><TR><TD>__myl_FcCastAddAdd_myl88_116</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add_3]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.2/Add_3]\nName:__myl_FcCastAddAdd_myl88_116\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_117 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307191 ms</TD></TR><TR><TD>__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_117</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/norm2/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear]\nName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_117\nStreamId:0\nTacticName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0xcc497afe211f479634492d5ba512e7ea\n"]
	"/model/decoder/decoder/layers_2/linear1/MatMul_myl88_118" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511982 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_2/linear1/MatMul_myl88_118</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/activation/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/linear1/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/activation/Relu]+[ONNX Layer: /model/decoder/decoder/layers.2/linear1/Add]\nName:/model/decoder/decoder/layers_2/linear1/MatMul_myl88_118\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	__myl_FcCastAddAdd_myl88_119 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614341 ms</TD></TR><TR><TD>__myl_FcCastAddAdd_myl88_119</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add_4]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/linear2/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/linear2/Add]+[ONNX Layer: /model/decoder/decoder/layers.2/Add_4]\nName:__myl_FcCastAddAdd_myl88_119\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_120 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409562 ms</TD></TR><TR><TD>__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_120</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear]\nName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_120\nStreamId:0\nTacticName:__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_0x80487bca91ee48a7b2ecd6f40baf47b3\n"]
	__mye154411_myl88_122 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye154411_myl88_122</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:17\nLayerType:wait\nMetadata:\nName:__mye154411_myl88_122\nStreamId:1\nTacticName:\n"]
	__myl_FcCastAdd_myl88_123 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00511964 ms</TD></TR><TR><TD>__myl_FcCastAdd_myl88_123</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_score_head.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_score_head.2/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_score_head.2/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_score_head.2/Add]\nName:__myl_FcCastAdd_myl88_123\nStreamId:1\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshGathSigmResh_myl88_124 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_ReshGathSigmResh_myl88_124</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Flatten]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Gather_8]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Unsqueeze_4]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /postprocessor/Sigmoid]+[ONNX Layer: /postprocessor/Flatten]+[ONNX Layer: /model/decoder/Gather_8]+[ONNX Layer: /model/decoder/decoder/Unsqueeze_4]\nName:__myl_ReshGathSigmResh_myl88_124\nStreamId:1\nTacticName:__myl_ReshGathSigmResh_0xa09b04cf5faa645da19283c01b369215\n"]
	__myl_Topk_myl88_125 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0434246 ms</TD></TR><TR><TD>__myl_Topk_myl88_125</TD></TR><TR><TD>[ONNX Layer: /postprocessor/TopK]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /postprocessor/TopK]\nName:__myl_Topk_myl88_125\nStreamId:1\nTacticName:__myl_Topk_0xeff68fcd6e2ece445095c9d09d03e940\n"]
	__myl_MaxMinSubMaxMinMaxMinDivLog_myl88_127 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00204842 ms</TD></TR><TR><TD>__myl_MaxMinSubMaxMinMaxMinDivLog_myl88_127</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Log_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Div_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sub_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Clip_6]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/Log_2]+[ONNX Layer: /model/decoder/decoder/Div_2]+[ONNX Layer: /model/decoder/decoder/Sub_2]+[ONNX Layer: /model/decoder/decoder/Clip_6]\nName:__myl_MaxMinSubMaxMinMaxMinDivLog_myl88_127\nStreamId:0\nTacticName:__myl_MaxMinSubMaxMinMaxMinDivLog_0x564e12beef03d2192684faee0d1f2dc4\n"]
	"/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl88_128" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl88_128</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add]\nName:/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl88_128\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1\n"]
	"/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl88_129" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl88_129</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add]\nName:/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl88_129\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1\n"]
	__myl_FcCastAddAddSigm_myl88_130 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614381 ms</TD></TR><TR><TD>__myl_FcCastAddAddSigm_myl88_130</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Add_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sigmoid_3]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add]+[ONNX Layer: /model/decoder/decoder/Add_2]+[ONNX Layer: /model/decoder/decoder/Sigmoid_3]\nName:__myl_FcCastAddAddSigm_myl88_130\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl88_132 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307191 ms</TD></TR><TR><TD>__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl88_132</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Tile]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_4]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Div]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Sub_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Mul_3]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Squeeze_3]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Sub_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Squeeze]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Add_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_3]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_5]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/GatherElements]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Mul_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Concat]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Sub]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Add]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Mul]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Squeeze_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Squeeze_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Split]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Gather_9]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Unsqueeze_3]</TD></TR><TR><TD>[ONNX Layer: Cast_3039]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /postprocessor/Tile]+[ONNX Layer: /postprocessor/Unsqueeze_4]+[ONNX Layer: /postprocessor/Div]+[ONNX Layer: /postprocessor/Sub_2]+[ONNX Layer: /postprocessor/Mul_3]+[ONNX Layer: /postprocessor/Squeeze_3]+[ONNX Layer: /postprocessor/Mul_1]+[ONNX Layer: /postprocessor/Sub_1]+[ONNX Layer: /postprocessor/Unsqueeze_1]+[ONNX Layer: /postprocessor/Squeeze]+[ONNX Layer: /postprocessor/Add_1]+[ONNX Layer: /postprocessor/Unsqueeze_3]+[ONNX Layer: /postprocessor/Unsqueeze_5]+[ONNX Layer: /postprocessor/GatherElements]+[ONNX Layer: /postprocessor/Mul_2]+[ONNX Layer: /postprocessor/Concat]+[ONNX Layer: /postprocessor/Unsqueeze]+[ONNX Layer: /postprocessor/Sub]+[ONNX Layer: /postprocessor/Unsqueeze_2]+[ONNX Layer: /postprocessor/Add]+[ONNX Layer: /postprocessor/Mul]+[ONNX Layer: /postprocessor/Squeeze_2]+[ONNX Layer: /postprocessor/Squeeze_1]+[ONNX Layer: /postprocessor/Split]+[ONNX Layer: /model/decoder/Gather_9]+[ONNX Layer: /model/decoder/decoder/Unsqueeze_3]+[ONNX Layer: Cast_3039]\nName:__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl88_132\nStreamId:0\nTacticName:__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_0x10d3a9474b513eaf9fc3d1150e6c455f\n"]
	"Reformatting CopyNode for Output Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00262524 ms</TD></TR><TR><TD>Reformatting CopyNode for Output Tensor 1 to ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]</TD></TR><TR><TD></TD></TR><TR><TD>REFORMAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:\nName:Reformatting CopyNode for Output Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}\nOrigin:REFORMAT\nStreamId:0\nTacticValue:0x00000000000003e8\n"]
	"Reformatting CopyNode for Output Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00270604 ms</TD></TR><TR><TD>Reformatting CopyNode for Output Tensor 2 to ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]</TD></TR><TR><TD></TD></TR><TR><TD>REFORMAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:\nName:Reformatting CopyNode for Output Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}\nOrigin:REFORMAT\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	images -> "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear" [label="[1, 3, 640, 640]\nFP32 NCHW" color=red]
	"/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear" -> "model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv" [label="[1, 3, 640, 640]\nInt8 NC/4HW4" color="#76b900"]
	"model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv" -> "model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv" [label="[1, 32, 320, 320]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv" -> "model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv" [label="[1, 32, 320, 320]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv" -> "/model/backbone/MaxPool" [label="[1, 64, 320, 320]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/MaxPool" -> "model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/MaxPool" -> "model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv" -> "model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv" -> "model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" [label="[1, 64, 160, 160]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" -> "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 64, 160, 160]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" -> "model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu" [label="[1, 64, 160, 160]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv" -> "model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu" -> "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 64, 160, 160]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool" -> "model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" [label="[1, 64, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv" -> "model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv" -> "model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" [label="[1, 128, 80, 80]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" -> "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 128, 80, 80]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" -> "model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu" [label="[1, 128, 80, 80]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv" -> "model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu" -> "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 128, 80, 80]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool" -> "model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv" -> "model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv" -> "model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" [label="[1, 256, 40, 40]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" -> "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 256, 40, 40]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" -> "model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu" [label="[1, 256, 40, 40]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv" -> "model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu" -> "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 256, 40, 40]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool" -> "model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" [label="[1, 256, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv" -> "model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv" -> "model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" [label="[1, 512, 20, 20]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" -> "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 512, 20, 20]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" -> "model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu" [label="[1, 512, 20, 20]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv" -> "model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu" -> "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear" [label="[1, 512, 20, 20]\nFP16 NC/32HW32" color=orange]
	"/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear" -> "model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv" -> "Reformatting CopyNode for Input Tensor 0 to {ForeignNode[onnx######MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}" [label="[1, 256, 20, 20]\nFP16 NC/32HW32" color=orange]
	"Reformatting CopyNode for Input Tensor 0 to {ForeignNode[onnx######MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}" -> __myl_MulAddReshMoveTranAddTran_myl38_0 [label="[1, 256, 20, 20]\nFP16 NHWC8" color=orange]
	__myl_MulAddReshMoveTranAddTran_myl38_0 -> "/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl38_3" [label="[400, 1, 256]\nHalf" color=orange]
	__myl_MulAddReshMoveTranAddTran_myl38_0 -> __myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl38_10 [label="[1, 400, 256]\nHalf" color=orange]
	__myl_MulAddReshMoveTranAddTran_myl38_0 -> "/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_5" [label="[1, 400, 256]\nHalf" color=orange]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl38_3" -> _gemm_mha_v2_myl38_7 [label="[400, 256]\nHalf" color=orange]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_5" -> _gemm_mha_v2_myl38_7 [label="[2, 400, 256]\nHalf" color=orange]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_5" -> _gemm_mha_v2_myl38_7 [label="[2, 400, 256]\nHalf" color=orange]
	_gemm_mha_v2_myl38_7 -> "__myln_k_arg__bb1_7.0" [label="[1, 6400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_7.0" -> __myl_Tran_myl38_8 [label="[1, 6400, 256]\nInt8" color="#76b900"]
	__myl_MulMinMaxRounCastReshTran_myl88_3 -> "__myln_k_arg__bb1_7.1" [label="[1, 6400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_7.1" -> __myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl88_8 [label="[1, 6400, 256]\nInt8" color="#76b900"]
	__myl_Tran_myl38_8 -> "/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl38_9" [label="[400, 8, 32]\nHalf" color=orange]
	"/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl38_9" -> __myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl38_10 [label="[400, 256]\nHalf" color=orange]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl38_10 -> "__myln_k_arg__bb1_11.0" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_11.0" -> __myl_CastAddAddCastMeanSubMulMean_myl38_13 [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl88_8 -> "__myln_k_arg__bb1_11.1" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_11.1" -> __myl_FcCastAdd_myl88_12 [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl38_10 -> "__myln_k_arg__bb1_10.0" [label="[1, 1600, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_10.0" -> "/model/encoder/encoder_0/layers_0/linear1/MatMul_myl38_11" [label="[1, 1600, 256]\nInt8" color="#76b900"]
	__myl_MulMinMaxRounCastReshTran_myl88_5 -> "__myln_k_arg__bb1_10.1" [label="[1, 1600, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_10.1" -> __myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl88_8 [label="[1, 1600, 256]\nInt8" color="#76b900"]
	"/model/encoder/encoder_0/layers_0/linear1/MatMul_myl38_11" -> "/model/encoder/encoder_0/layers_0/linear2/MatMul_myl38_12" [label="[1, 400, 1024]\nInt8" color="#76b900"]
	"/model/encoder/encoder_0/layers_0/linear2/MatMul_myl38_12" -> __myl_CastAddAddCastMeanSubMulMean_myl38_13 [label="[1, 400, 256]\nFloat" color=red]
	__myl_CastAddAddCastMeanSubMulMean_myl38_13 -> "__myln_k_arg__bb1_15.0" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_15.0" -> __myl_AddSqrtDivMulCastMulAddTranResh_myl38_14 [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_13 -> "__myln_k_arg__bb1_15.1" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_15.1" -> "/model/decoder/enc_score_head/MatMul_myl88_16" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_15.1" -> "/model/decoder/enc_bbox_head/layers_0/MatMul_myl88_20" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_CastAddAddCastMeanSubMulMean_myl38_13 -> "__myln_k_arg__bb1_14.0" [label="[1, 8400, 256]\nHalf" color=orange]
	"__myln_k_arg__bb1_14.0" -> __myl_AddSqrtDivMulCastMulAddTranResh_myl38_14 [label="[1, 8400, 256]\nHalf" color=orange]
	__myl_FcCastAdd_myl88_12 -> "__myln_k_arg__bb1_14.1" [label="[1, 8400, 256]\nHalf" color=orange]
	"__myln_k_arg__bb1_14.1" -> __myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_13 [label="[1, 8400, 256]\nHalf" color=orange]
	__myl_AddSqrtDivMulCastMulAddTranResh_myl38_14 -> "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear" [label="[1, 256, 20, 20]\nHalf" color=orange]
	"model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv" -> "model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv" [label="[1, 512, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv" -> "model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)" [label="[1, 512, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy" -> "model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv" [label="[1, 512, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy" -> "model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)" [label="[1, 512, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv" -> "model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv" -> "model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy" -> "model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy" -> "model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear" -> "model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv" [label="[1, 256, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv" -> "PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)" [label="[1, 256, 20, 20]\nFP32 NC/32HW32" color=red]
	"PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)" -> "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0" [label="[1, 256, 20, 20]\nFP16 NC/32HW32" color=orange]
	"PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)" -> "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1" [label="[1, 256, 20, 20]\nFP16 NC/32HW32" color=orange]
	"/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0" -> "/model/encoder/Resize" [label="[1, 256, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Resize" -> "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv" -> "PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))" [label="[1, 128, 40, 40]\nFP16 NC/32HW32" color=orange]
	"model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)" -> "model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" -> "model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" -> "model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" -> "PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))" [label="[1, 128, 40, 40]\nFP16 NC/32HW32" color=orange]
	"PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))" -> "model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)" -> "model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)" -> "/model/encoder/Resize_1" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)" -> "/model/encoder/Resize_1_output_0 copy" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Resize_1" -> "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy" [label="[1, 256, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv" -> "PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))" [label="[1, 128, 80, 80]\nFP16 NC/32HW32" color=orange]
	"model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)" -> "model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" -> "model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" -> "model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" -> "PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))" [label="[1, 128, 80, 80]\nFP16 NC/32HW32" color=orange]
	"PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))" -> "model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)" -> "model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv" [label="[1, 256, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)" -> "model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)" [label="[1, 256, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv" -> "Reformatting CopyNode for Input Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" [label="[1, 256, 80, 80]\nFP16 NC/32HW32" color=orange]
	"model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)" -> "model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)" -> "model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Resize_1_output_0 copy" -> "model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Resize_1_output_0 copy" -> "model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv" -> "PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))" [label="[1, 128, 40, 40]\nFP16 NC/32HW32" color=orange]
	"model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)" -> "model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" -> "model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" -> "model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" -> "PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))" [label="[1, 128, 40, 40]\nFP16 NC/32HW32" color=orange]
	"PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))" -> "model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)" -> "model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)" -> "model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv" -> "Reformatting CopyNode for Input Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" [label="[1, 256, 40, 40]\nFP32 NCHW" color=red]
	"model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)" -> "model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)" -> "model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1" -> "model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1" -> "model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv" -> "PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))" [label="[1, 128, 20, 20]\nFP32 NC/32HW32" color=red]
	"model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)" -> "model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" [label="[1, 128, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" -> "model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" [label="[1, 128, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" -> "model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" [label="[1, 128, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" -> "PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))" [label="[1, 128, 20, 20]\nFP32 NC/32HW32" color=red]
	"PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))" -> "model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)" [label="[1, 128, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)" -> "model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv" [label="[1, 256, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv" -> "Reformatting CopyNode for Input Tensor 3 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" [label="[1, 256, 20, 20]\nFP32 NCHW" color=red]
	"Reformatting CopyNode for Input Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" -> __myl_MulAddReshMulMinMaxRounCastTran_myl88_2 [label="[1, 256, 80, 80]\nFP16 NCHW" color=orange]
	"Reformatting CopyNode for Input Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" -> __myl_MulAddReshMulMinMaxRounCastTran_myl88_4 [label="[1, 256, 40, 40]\nFP16 NCHW" color=orange]
	"Reformatting CopyNode for Input Tensor 3 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" -> __myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl88_8 [label="[1, 256, 20, 20]\nFP16 NCHW" color=orange]
	__myl_MulAddReshMulMinMaxRounCastTran_myl88_2 -> __myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl88_8 [label="[1, 6400, 256]\nInt8" color="#76b900"]
	__myl_MulAddReshMulMinMaxRounCastTran_myl88_2 -> __myl_MulMinMaxRounCastReshTran_myl88_3 [label="[1, 256, 80, 80]\nHalf" color=orange]
	__myl_MulAddReshMulMinMaxRounCastTran_myl88_4 -> __myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl88_8 [label="[1, 1600, 256]\nInt8" color="#76b900"]
	__myl_MulAddReshMulMinMaxRounCastTran_myl88_4 -> __myl_MulMinMaxRounCastReshTran_myl88_5 [label="[1, 256, 40, 40]\nHalf" color=orange]
	__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl88_8 -> __myl_FcMulCastAdd_myl88_11 [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_FcMulCastAdd_myl88_11 -> __myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_41 [label="[3, 8400, 256]\nHalf" color=orange]
	__myl_FcMulCastAdd_myl88_11 -> __myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_74 [label="[3, 8400, 256]\nHalf" color=orange]
	__myl_FcMulCastAdd_myl88_11 -> __myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_108 [label="[3, 8400, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_13 -> __myl_ReplGathReshReshAdd_myl88_27 [label="[1, 8400, 256]\nHalf" color=orange]
	"/model/decoder/enc_score_head/MatMul_myl88_16" -> __myl_CastAddMaxr_myl88_17 [label="[1, 8400, 80]\nFloat" color=red]
	__myl_CastAddMaxr_myl88_17 -> __myl_Topk_myl88_18 [label="[1, 8400, 1]\nHalf" color=orange]
	__myl_Topk_myl88_18 -> __myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl88_24 [label="[1, 300]\nInt32" color=lightgray]
	"/model/decoder/enc_bbox_head/layers_0/MatMul_myl88_20" -> "/model/decoder/enc_bbox_head/layers_1/MatMul_myl88_21" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"/model/decoder/enc_bbox_head/layers_1/MatMul_myl88_21" -> __myl_FcCastAddAdd_myl88_22 [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_FcCastAddAdd_myl88_22 -> __myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl88_24 [label="[1, 8400, 4]\nHalf" color=orange]
	__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl88_24 -> __myl_ReplGathReshReshAdd_myl88_27 [label="[1, 300, 1]\nInt32" color=lightgray]
	__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl88_24 -> __myl_FcCastAddAddSigm_myl88_60 [label="[1, 300, 4]\nHalf" color=orange]
	__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl88_24 -> "/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl88_25" [label="[1, 300, 16]\nInt8" color="#76b900"]
	__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl88_24 -> __myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_40 [label="[1, 300, 4]\nHalf" color=orange]
	"/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl88_25" -> __myl_FcCastAdd_myl88_26 [label="[1, 300, 512]\nInt8" color="#76b900"]
	__myl_FcCastAdd_myl88_26 -> __myl_ReplGathReshReshAdd_myl88_27 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_ReplGathReshReshAdd_myl88_27 -> "/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl88_30" [label="[1, 300, 256]\nHalf" color=orange]
	__myl_ReplGathReshReshAdd_myl88_27 -> __myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshAddMulMinMaxRounCast_myl88_37 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_ReplGathReshReshAdd_myl88_27 -> "/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl88_32" [label="[300, 256]\nHalf" color=orange]
	__myl_ReplGathReshReshAdd_myl88_27 -> __myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshAddMulMinMaxRounCast_myl88_37 [label="[300, 256]\nHalf" color=orange]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl88_30" -> _gemm_mha_v2_myl88_34 [label="[300, 256]\nHalf" color=orange]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl88_32" -> _gemm_mha_v2_myl88_34 [label="[2, 300, 256]\nHalf" color=orange]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl88_32" -> _gemm_mha_v2_myl88_34 [label="[2, 300, 256]\nHalf" color=orange]
	_gemm_mha_v2_myl88_34 -> __myl_Tran_myl88_35 [label="[8, 300, 32]\nHalf" color=orange]
	__myl_Tran_myl88_35 -> "/model/decoder/decoder/layers_0/self_attn/Gemm_myl88_36" [label="[300, 8, 32]\nHalf" color=orange]
	"/model/decoder/decoder/layers_0/self_attn/Gemm_myl88_36" -> __myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshAddMulMinMaxRounCast_myl88_37 [label="[300, 256]\nHalf" color=orange]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshAddMulMinMaxRounCast_myl88_37 -> __myl_FcCastAddAdd_myl88_49 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshAddMulMinMaxRounCast_myl88_37 -> __myl_FcCastAdd_myl88_39 [label="[300, 256]\nInt8" color="#76b900"]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshAddMulMinMaxRounCast_myl88_37 -> __myl_FcCastAdd_myl88_43 [label="[300, 256]\nInt8" color="#76b900"]
	__myl_FcCastAdd_myl88_39 -> __myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_40 [label="[1, 300, 192]\nHalf" color=orange]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_40 -> __myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_41 [label="[8, 300, 4, 2]\nHalf" color=orange]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_40 -> __myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_41 [label="[8, 300, 4, 2]\nHalf" color=orange]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_40 -> __myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_41 [label="[8, 300, 4, 2]\nHalf" color=orange]
	__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_41 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_47 [label="[8, 32, 300, 4]\nHalf" color=orange]
	__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_41 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_47 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_41 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_47 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_FcCastAdd_myl88_43 -> __myl_ReshMaxrSubExpSum_myl88_44 [label="[1, 300, 96]\nHalf" color=orange]
	__myl_ReshMaxrSubExpSum_myl88_44 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_47 [label="[1, 300, 8, 12]\nHalf" color=orange]
	__myl_ReshMaxrSubExpSum_myl88_44 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_47 [label="[1, 300, 8, 1]\nHalf" color=orange]
	__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_47 -> __myl_Move_myl88_48 [label="[8, 32, 300, 1]\nInt8" color="#76b900"]
	__myl_Move_myl88_48 -> __myl_FcCastAddAdd_myl88_49 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcCastAddAdd_myl88_49 -> __myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_50 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_50 -> __myl_FcCastAddAdd_myl88_52 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_50 -> "/model/decoder/decoder/layers_0/linear1/MatMul_myl88_51" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/layers_0/linear1/MatMul_myl88_51" -> __myl_FcCastAddAdd_myl88_52 [label="[1, 300, 1024]\nInt8" color="#76b900"]
	__myl_FcCastAddAdd_myl88_52 -> __myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_53 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_53 -> "/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl88_56" [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_53 -> __myl_Add_myl88_64 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_53 -> __myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_70 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_53 -> "/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl88_58" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl88_56" -> _gemm_mha_v2_myl88_67 [label="[300, 256]\nHalf" color=orange]
	"/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl88_58" -> "/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl88_59" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl88_59" -> __myl_FcCastAddAddSigm_myl88_60 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcCastAddAddSigm_myl88_60 -> __myl_MulMinMaxRounConcCast_myl88_61 [label="[1, 300, 4]\nHalf" color=orange]
	__myl_FcCastAddAddSigm_myl88_60 -> __myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_73 [label="[1, 300, 4]\nHalf" color=orange]
	__myl_FcCastAddAddSigm_myl88_60 -> __myl_MaxMinSubMaxMinMaxMinDivLog_myl88_91 [label="[1, 300, 4]\nHalf" color=orange]
	__myl_MulMinMaxRounConcCast_myl88_61 -> "/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl88_62" [label="[1, 300, 16]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl88_62" -> __myl_FcCastAdd_myl88_63 [label="[1, 300, 512]\nInt8" color="#76b900"]
	__myl_FcCastAdd_myl88_63 -> __myl_Add_myl88_64 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_FcCastAdd_myl88_63 -> __myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_70 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_Add_myl88_64 -> "/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl88_65" [label="[1, 300, 256]\nHalf" color=orange]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl88_65" -> _gemm_mha_v2_myl88_67 [label="[2, 300, 256]\nHalf" color=orange]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl88_65" -> _gemm_mha_v2_myl88_67 [label="[2, 300, 256]\nHalf" color=orange]
	_gemm_mha_v2_myl88_67 -> __myl_Tran_myl88_68 [label="[8, 300, 32]\nHalf" color=orange]
	__myl_Tran_myl88_68 -> "/model/decoder/decoder/layers_1/self_attn/Gemm_myl88_69" [label="[300, 8, 32]\nHalf" color=orange]
	"/model/decoder/decoder/layers_1/self_attn/Gemm_myl88_69" -> __myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_70 [label="[300, 256]\nHalf" color=orange]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_70 -> __myl_FcCastAddAdd_myl88_82 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_70 -> __myl_FcCastAdd_myl88_72 [label="[300, 256]\nInt8" color="#76b900"]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_70 -> __myl_FcCastAdd_myl88_76 [label="[300, 256]\nInt8" color="#76b900"]
	__myl_FcCastAdd_myl88_72 -> __myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_73 [label="[1, 300, 192]\nHalf" color=orange]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_73 -> __myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_74 [label="[8, 300, 4, 2]\nHalf" color=orange]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_73 -> __myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_74 [label="[8, 300, 4, 2]\nHalf" color=orange]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_73 -> __myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_74 [label="[8, 300, 4, 2]\nHalf" color=orange]
	__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_74 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_80 [label="[8, 32, 300, 4]\nHalf" color=orange]
	__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_74 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_80 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_74 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_80 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_FcCastAdd_myl88_76 -> __myl_ReshMaxrSubExpSum_myl88_77 [label="[1, 300, 96]\nHalf" color=orange]
	__myl_ReshMaxrSubExpSum_myl88_77 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_80 [label="[1, 300, 8, 12]\nHalf" color=orange]
	__myl_ReshMaxrSubExpSum_myl88_77 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_80 [label="[1, 300, 8, 1]\nHalf" color=orange]
	__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_80 -> __myl_Move_myl88_81 [label="[8, 32, 300, 1]\nInt8" color="#76b900"]
	__myl_Move_myl88_81 -> __myl_FcCastAddAdd_myl88_82 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcCastAddAdd_myl88_82 -> __myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_83 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_83 -> __myl_FcCastAddAdd_myl88_85 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_83 -> "/model/decoder/decoder/layers_1/linear1/MatMul_myl88_84" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/layers_1/linear1/MatMul_myl88_84" -> __myl_FcCastAddAdd_myl88_85 [label="[1, 300, 1024]\nInt8" color="#76b900"]
	__myl_FcCastAddAdd_myl88_85 -> __myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_86 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_86 -> "/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl88_89" [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_86 -> __myl_Add_myl88_98 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_86 -> __myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_104 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_86 -> "/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl88_92" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl88_89" -> _gemm_mha_v2_myl88_101 [label="[300, 256]\nHalf" color=orange]
	__myl_MaxMinSubMaxMinMaxMinDivLog_myl88_91 -> __myl_FcCastAddAddSigm_myl88_94 [label="[1, 300, 4]\nHalf" color=orange]
	"/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl88_92" -> "/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl88_93" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl88_93" -> __myl_FcCastAddAddSigm_myl88_94 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcCastAddAddSigm_myl88_94 -> __myl_MulMinMaxRounConcCast_myl88_95 [label="[1, 300, 4]\nHalf" color=orange]
	__myl_FcCastAddAddSigm_myl88_94 -> __myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_107 [label="[1, 300, 4]\nHalf" color=orange]
	__myl_FcCastAddAddSigm_myl88_94 -> __myl_MaxMinSubMaxMinMaxMinDivLog_myl88_127 [label="[1, 300, 4]\nHalf" color=orange]
	__myl_MulMinMaxRounConcCast_myl88_95 -> "/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl88_96" [label="[1, 300, 16]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl88_96" -> __myl_FcCastAdd_myl88_97 [label="[1, 300, 512]\nInt8" color="#76b900"]
	__myl_FcCastAdd_myl88_97 -> __myl_Add_myl88_98 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_FcCastAdd_myl88_97 -> __myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_104 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_Add_myl88_98 -> "/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl88_99" [label="[1, 300, 256]\nHalf" color=orange]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl88_99" -> _gemm_mha_v2_myl88_101 [label="[2, 300, 256]\nHalf" color=orange]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl88_99" -> _gemm_mha_v2_myl88_101 [label="[2, 300, 256]\nHalf" color=orange]
	_gemm_mha_v2_myl88_101 -> __myl_Tran_myl88_102 [label="[8, 300, 32]\nHalf" color=orange]
	__myl_Tran_myl88_102 -> "/model/decoder/decoder/layers_2/self_attn/Gemm_myl88_103" [label="[300, 8, 32]\nHalf" color=orange]
	"/model/decoder/decoder/layers_2/self_attn/Gemm_myl88_103" -> __myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_104 [label="[300, 256]\nHalf" color=orange]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_104 -> __myl_FcCastAddAdd_myl88_116 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_104 -> __myl_FcCastAdd_myl88_106 [label="[300, 256]\nInt8" color="#76b900"]
	__myl_AddCastMeanSubMulMeanAddSqrtDivMulCastMulAddReshReshAddMulMinMaxRounCast_myl88_104 -> __myl_FcCastAdd_myl88_110 [label="[300, 256]\nInt8" color="#76b900"]
	__myl_FcCastAdd_myl88_106 -> __myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_107 [label="[1, 300, 192]\nHalf" color=orange]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_107 -> __myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_108 [label="[8, 300, 4, 2]\nHalf" color=orange]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_107 -> __myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_108 [label="[8, 300, 4, 2]\nHalf" color=orange]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl88_107 -> __myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_108 [label="[8, 300, 4, 2]\nHalf" color=orange]
	__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_108 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_114 [label="[8, 32, 300, 4]\nHalf" color=orange]
	__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_108 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_114 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_ReshTranReshMoveSlicReshSlicReshSlicReshGridCastGridGrid_myl88_108 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_114 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_FcCastAdd_myl88_110 -> __myl_ReshMaxrSubExpSum_myl88_111 [label="[1, 300, 96]\nHalf" color=orange]
	__myl_ReshMaxrSubExpSum_myl88_111 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_114 [label="[1, 300, 8, 12]\nHalf" color=orange]
	__myl_ReshMaxrSubExpSum_myl88_111 -> __myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_114 [label="[1, 300, 8, 1]\nHalf" color=orange]
	__myl_DivMulTranReshCastCastConcMulSumMulMinMaxRounCast_myl88_114 -> __myl_Move_myl88_115 [label="[8, 32, 300, 1]\nInt8" color="#76b900"]
	__myl_Move_myl88_115 -> __myl_FcCastAddAdd_myl88_116 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcCastAddAdd_myl88_116 -> __myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_117 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_117 -> __myl_FcCastAddAdd_myl88_119 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_117 -> "/model/decoder/decoder/layers_2/linear1/MatMul_myl88_118" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/layers_2/linear1/MatMul_myl88_118" -> __myl_FcCastAddAdd_myl88_119 [label="[1, 300, 1024]\nInt8" color="#76b900"]
	__myl_FcCastAddAdd_myl88_119 -> __myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_120 [label="[1, 300, 256]\nHalf" color=orange]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_120 -> __myl_FcCastAdd_myl88_123 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_CastMeanSubMulMeanAddSqrtDivMulCastMulAddMulMinMaxRounCast_myl88_120 -> "/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl88_128" [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcCastAdd_myl88_123 -> __myl_ReshGathSigmResh_myl88_124 [label="[1, 300, 80]\nHalf" color=orange]
	__myl_ReshGathSigmResh_myl88_124 -> __myl_Topk_myl88_125 [label="[1, 24000]\nHalf" color=orange]
	__myl_Topk_myl88_125 -> "Reformatting CopyNode for Output Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" [label="[1, 300]\nHalf" color=orange]
	__myl_Topk_myl88_125 -> __myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl88_132 [label="[1, 300]\nInt32" color=lightgray]
	__myl_MaxMinSubMaxMinMaxMinDivLog_myl88_127 -> __myl_FcCastAddAddSigm_myl88_130 [label="[1, 300, 4]\nHalf" color=orange]
	"/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl88_128" -> "/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl88_129" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl88_129" -> __myl_FcCastAddAddSigm_myl88_130 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcCastAddAddSigm_myl88_130 -> __myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl88_132 [label="[1, 300, 4]\nHalf" color=orange]
	orig_target_sizes -> __myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl88_132 [label="[1, 2]\nInt64" color=gray]
	__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl88_132 -> "Reformatting CopyNode for Output Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" [label="[1, 300, 4]\nHalf" color=orange]
	__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl88_132 -> labels [label="[1, 300]\nInt64" color=gray]
	"Reformatting CopyNode for Output Tensor 1 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" -> boxes [label="[1, 300, 4]\nFP32 NCHW" color=red]
	"Reformatting CopyNode for Output Tensor 2 to {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}" -> scores [label="[1, 300]\nFP32 NCHW" color=red]
	"__myln_k_arg__bb1_7.0" -> "__myln_k_arg__bb1_7.1" [label="[1, 6400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_11.0" -> "__myln_k_arg__bb1_11.1" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_10.0" -> "__myln_k_arg__bb1_10.1" [label="[1, 1600, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_15.0" -> "__myln_k_arg__bb1_15.1" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_14.0" -> "__myln_k_arg__bb1_14.1" [label="[1, 8400, 256]\nHalf" color=orange]
}
