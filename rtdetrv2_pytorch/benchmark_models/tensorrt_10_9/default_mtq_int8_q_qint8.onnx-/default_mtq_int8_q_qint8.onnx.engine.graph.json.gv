digraph {
	images [label="images
[1, 3, 640, 640]\nFP32 NCHW" color=red fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=images]
	"__myln_k_arg__bb1_5.0" [label="[1, 256, 80, 80]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_5]
	"__myln_k_arg__bb1_5.1" [label="[1, 256, 80, 80]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_5]
	"__myln_k_arg__bb1_8.0" [label="[8, 400, 400]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_8]
	"__myln_k_arg__bb1_8.1" [label="[1, 256, 40, 40]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_8]
	"__myln_k_arg__bb1_10.0" [label="[8, 400, 32]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_10]
	"__myln_k_arg__bb1_10.1" [label="[1, 1600, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_10]
	"__myln_k_arg__bb1_14.0" [label="[1, 8400, 256]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_14]
	"__myln_k_arg__bb1_14.1" [label="[1, 8400, 256]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_14]
	"__myln_k_arg__bb1_15.0" [label="[1, 8400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_15]
	"__myln_k_arg__bb1_15.1" [label="[1, 8400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_15]
	"__myln_k_arg__bb1_16.0" [label="[1, 8400, 256]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_16]
	"__myln_k_arg__bb1_16.1" [label="[1, 8400, 256]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_16]
	"__myln_k_arg__bb1_17.0" [label="[1, 8400, 80]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_17]
	"__myln_k_arg__bb1_17.1" [label="[1, 8400, 80]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_17]
	scores [label="scores
[1, 300]\nFloat" color=red fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=scores]
	orig_target_sizes [label="orig_target_sizes
[1, 2]\nInt64" color=gray fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=orig_target_sizes]
	boxes [label="boxes
[1, 300, 4]\nFloat" color=red fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=boxes]
	labels [label="labels
[1, 300]\nInt64" color=gray fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=labels]
	"/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00888037 ms</TD></TR><TR><TD>/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00633527 ms</TD></TR><TR><TD>model.backbone.conv1.conv1_1.conv.weight </TD></TR><TR><TD> /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/conv1/conv1_1/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 32}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_1/conv/Conv]+[ONNX Layer: /model/backbone/conv1/conv1_1/norm/BatchNormalization]+[ONNX Layer: /model/backbone/conv1/conv1_1/act/Relu]+[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv\nOutMaps:32\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_first_layer_i8i8_i8i32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_vect_c_32_tilesize8x16x32x32_stage1_warpsize4x1x1_tensor16x8x16_r3s3_u2v2_aligna4_alignc8\nTacticValue:0x5cc792a989a1d1a6\nWeights:{'Type': 'Int8', 'Count': 864}\n"]
	"model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0120818 ms</TD></TR><TR><TD>model.backbone.conv1.conv1_2.conv.weight </TD></TR><TR><TD> /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/conv1/conv1_2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 32}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_2/conv/Conv]+[ONNX Layer: /model/backbone/conv1/conv1_2/norm/BatchNormalization]+[ONNX Layer: /model/backbone/conv1/conv1_2/act/Relu]+[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv\nOutMaps:32\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3\nTacticValue:0x13463e9bf9ae0d73\nWeights:{'Type': 'Int8', 'Count': 9216}\n"]
	"model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0130286 ms</TD></TR><TR><TD>model.backbone.conv1.conv1_3.conv.weight </TD></TR><TR><TD> /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/conv1/conv1_3/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_3/conv/Conv]+[ONNX Layer: /model/backbone/conv1/conv1_3/norm/BatchNormalization]+[ONNX Layer: /model/backbone/conv1/conv1_3/act/Relu]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x9dafb2758560cc1d\nWeights:{'Type': 'Int8', 'Count': 18432}\n"]
	"/model/backbone/MaxPool" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Pooling</b></TD></TR><TR><TD>0.00761525 ms</TD></TR><TR><TD>/model/backbone/MaxPool</TD></TR><TR><TD>[ONNX Layer: /model/backbone/MaxPool]</TD></TR></TABLE>> color=lightgray fillcolor="#3CB371" fontname=Helvetica shape=Mrecord style=filled tooltip="AverageCountExcludesPadding:1\nBlendFactor:0\nLayerType:CaskPooling\nMetadata:[ONNX Layer: /model/backbone/MaxPool]\nName:/model/backbone/MaxPool\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPoolingType:MAX\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nStreamId:0\nStride:[2, 2]\nTacticName:sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX\nTacticValue:0x94215b398b8eb3ba\nWindowSize:[3, 3]\n"]
	"model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00794786 ms</TD></TR><TR><TD>model.backbone.res_layers.0.blocks.0.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x9dafb2758560cc1d\nWeights:{'Type': 'Int8', 'Count': 36864}\n"]
	"model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0142962 ms</TD></TR><TR><TD>model.backbone.res_layers.0.blocks.0.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xb936321f82fd390c\nWeights:{'Type': 'Int8', 'Count': 36864}\n"]
	"model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00959164 ms</TD></TR><TR><TD>model.backbone.res_layers.0.blocks.0.short.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/short/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/Add </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.0/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/Add]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/act/Relu]\nName:model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x6d377e4222886190\nWeights:{'Type': 'Int8', 'Count': 4096}\n"]
	"/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00769827 ms</TD></TR><TR><TD>/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00771981 ms</TD></TR><TR><TD>model.backbone.res_layers.0.blocks.1.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x9dafb2758560cc1d\nWeights:{'Type': 'Int8', 'Count': 36864}\n"]
	"model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0133462 ms</TD></TR><TR><TD>model.backbone.res_layers.0.blocks.1.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.1/Add </TD></TR><TR><TD> /model/backbone/res_layers.0/blocks.1/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/Add]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/act/Relu]\nName:model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x0e07dc8353bf7e9f\nWeights:{'Type': 'Int8', 'Count': 36864}\n"]
	"/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00783397 ms</TD></TR><TR><TD>/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Pooling</b></TD></TR><TR><TD>0.0051037 ms</TD></TR><TR><TD>/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#3CB371" fontname=Helvetica shape=Mrecord style=filled tooltip="AverageCountExcludesPadding:0\nBlendFactor:0\nLayerType:CaskPooling\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool\nPaddingMode:kEXPLICIT_ROUND_UP\nPoolingType:AVERAGE\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nStreamId:0\nStride:[2, 2]\nTacticName:sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE\nTacticValue:0xd9375d43b61ffbcb\nWindowSize:[2, 2]\n"]
	"model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00807823 ms</TD></TR><TR><TD>model.backbone.res_layers.1.blocks.0.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x705baf38e41eee0b\nWeights:{'Type': 'Int8', 'Count': 73728}\n"]
	"model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0122207 ms</TD></TR><TR><TD>model.backbone.res_layers.1.blocks.0.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x2d8ab2aa0639fda9\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00730813 ms</TD></TR><TR><TD>model.backbone.res_layers.1.blocks.0.short.conv.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/Add </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.0/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/Add]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/act/Relu]\nName:model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x6d377e4222886190\nWeights:{'Type': 'Int8', 'Count': 8192}\n"]
	"/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00666656 ms</TD></TR><TR><TD>/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00848689 ms</TD></TR><TR><TD>model.backbone.res_layers.1.blocks.1.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x128x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x214f03e23f252333\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0112862 ms</TD></TR><TR><TD>model.backbone.res_layers.1.blocks.1.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.1/Add </TD></TR><TR><TD> /model/backbone/res_layers.1/blocks.1/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/Add]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/act/Relu]\nName:model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xad886d4d69834922\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.0067602 ms</TD></TR><TR><TD>/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Pooling</b></TD></TR><TR><TD>0.00457928 ms</TD></TR><TR><TD>/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#3CB371" fontname=Helvetica shape=Mrecord style=filled tooltip="AverageCountExcludesPadding:0\nBlendFactor:0\nLayerType:CaskPooling\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool\nPaddingMode:kEXPLICIT_ROUND_UP\nPoolingType:AVERAGE\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nStreamId:0\nStride:[2, 2]\nTacticName:sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE\nTacticValue:0xd9375d43b61ffbcb\nWindowSize:[2, 2]\n"]
	"model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00831321 ms</TD></TR><TR><TD>model.backbone.res_layers.2.blocks.0.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xbb88763c3b0e94d4\nWeights:{'Type': 'Int8', 'Count': 294912}\n"]
	"model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0114056 ms</TD></TR><TR><TD>model.backbone.res_layers.2.blocks.0.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x2d8ab2aa0639fda9\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00620413 ms</TD></TR><TR><TD>model.backbone.res_layers.2.blocks.0.short.conv.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/Add </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.0/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/Add]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/act/Relu]\nName:model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x6d377e4222886190\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00635212 ms</TD></TR><TR><TD>/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00983207 ms</TD></TR><TR><TD>model.backbone.res_layers.2.blocks.1.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xbb88763c3b0e94d4\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0107276 ms</TD></TR><TR><TD>model.backbone.res_layers.2.blocks.1.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.1/Add </TD></TR><TR><TD> /model/backbone/res_layers.2/blocks.1/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/Add]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/act/Relu]\nName:model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x2d8ab2aa0639fda9\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00607163 ms</TD></TR><TR><TD>/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Pooling</b></TD></TR><TR><TD>0.00437271 ms</TD></TR><TR><TD>/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#3CB371" fontname=Helvetica shape=Mrecord style=filled tooltip="AverageCountExcludesPadding:0\nBlendFactor:0\nLayerType:CaskPooling\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool\nPaddingMode:kEXPLICIT_ROUND_UP\nPoolingType:AVERAGE\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nStreamId:0\nStride:[2, 2]\nTacticName:sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE\nTacticValue:0xd9375d43b61ffbcb\nWindowSize:[2, 2]\n"]
	"model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00941967 ms</TD></TR><TR><TD>model.backbone.res_layers.3.blocks.0.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32\nTacticValue:0x322f337abc345152\nWeights:{'Type': 'Int8', 'Count': 1179648}\n"]
	"model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0132265 ms</TD></TR><TR><TD>model.backbone.res_layers.3.blocks.0.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x45f7566cdb2b10fb\nWeights:{'Type': 'Int8', 'Count': 2359296}\n"]
	"model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00592674 ms</TD></TR><TR><TD>model.backbone.res_layers.3.blocks.0.short.conv.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/Add </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.0/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/Add]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/act/Relu]\nName:model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x65fbe45b4cb1d8a5\nWeights:{'Type': 'Int8', 'Count': 131072}\n"]
	"/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00609364 ms</TD></TR><TR><TD>/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0138389 ms</TD></TR><TR><TD>model.backbone.res_layers.3.blocks.1.branch2a.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x64x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x1d53511430a5d47e\nWeights:{'Type': 'Int8', 'Count': 2359296}\n"]
	"model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0130626 ms</TD></TR><TR><TD>model.backbone.res_layers.3.blocks.1.branch2b.conv.weight </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.1/Add </TD></TR><TR><TD> /model/backbone/res_layers.3/blocks.1/act/Relu</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/Add]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/act/Relu]\nName:model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x45f7566cdb2b10fb\nWeights:{'Type': 'Int8', 'Count': 2359296}\n"]
	"/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00590066 ms</TD></TR><TR><TD>/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear]\nName:/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00827164 ms</TD></TR><TR><TD>model.encoder.input_proj.2.conv.weight </TD></TR><TR><TD> /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/input_proj.2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 0}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:0\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/input_proj.2/conv/Conv]+[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4\nTacticValue:0x5e4f6d7c83746fd6\nWeights:{'Type': 'Int8', 'Count': 131072}\n"]
	__myl_MulAddReshTran_myl37_0 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409568 ms</TD></TR><TR><TD>__myl_MulAddReshTran_myl37_0</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/input_proj.2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/Reshape]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1]\nName:__myl_MulAddReshTran_myl37_0\nStreamId:0\nTacticName:__myl_MulAddReshTran_0xd7f3d1e2cc547844932d70a8482ece2b\n"]
	__myl_TranAdd_myl37_2 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307242 ms</TD></TR><TR><TD>__myl_TranAdd_myl37_2</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Transpose]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/Transpose]+[ONNX Layer: /model/encoder/encoder.0/layers.0/Add]\nName:__myl_TranAdd_myl37_2\nStreamId:0\nTacticName:__myl_TranAdd_0x1978cdfef91c73468af87ff188a514d1\n"]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl37_4" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00819108 ms</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl37_4</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_2]\nName:/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl37_4\nStreamId:1\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl37_6" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00921518 ms</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/self_attn/MatMul_1</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl37_6</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_1]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add]\nName:/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl37_6\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8\n"]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_3_myl37_7" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00819205 ms</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/self_attn/MatMul_3_myl37_7</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Mul_1]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Mul_1]\nName:/model/encoder/encoder_0/layers_0/self_attn/MatMul_3_myl37_7\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8\n"]
	__myl_MaxrSubExpSumDivMul_myl37_8 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00646336 ms</TD></TR><TR><TD>__myl_MaxrSubExpSumDivMul_myl37_8</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Softmax]\nName:__myl_MaxrSubExpSumDivMul_myl37_8\nStreamId:0\nTacticName:__myl_MaxrSubExpSumDivMul_0x954ecab20dc21ebdd768d1792fae06d0\n"]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_myl37_10" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00716788 ms</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_myl37_10</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4]\nName:/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_myl37_10\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	__myl_Tran_myl37_11 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>__myl_Tran_myl37_11</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3]\nName:__myl_Tran_myl37_11\nStreamId:0\nTacticName:__myl_Tran_0xa9ca448ca989e446f5b6e9b30bb6066d\n"]
	"/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl37_12" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614386 ms</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl37_12</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Gemm]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Gemm]\nName:/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl37_12\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl37_13 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00531139 ms</TD></TR><TR><TD>__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl37_13</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_1]+[ONNX Layer: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear]\nName:__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl37_13\nStreamId:0\nTacticName:__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_0x2246f3c023a9f5ff447ed70eb8e74db6\n"]
	"/model/encoder/encoder_0/layers_0/linear1/MatMul_myl37_14" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00819108 ms</TD></TR><TR><TD>/model/encoder/encoder_0/layers_0/linear1/MatMul_myl37_14</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Div]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Erf]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/MatMul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul_1]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Add]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Div]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Erf]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/Add]\nName:/model/encoder/encoder_0/layers_0/linear1/MatMul_myl37_14\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_gelu_erf\n"]
	__myl_FcAdd_myl37_15 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614354 ms</TD></TR><TR><TD>__myl_FcAdd_myl37_15</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]+[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_2]\nName:__myl_FcAdd_myl37_15\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshMeanSubMulMean_myl37_16 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_ReshMeanSubMulMean_myl37_16</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]\nName:__myl_ReshMeanSubMulMean_myl37_16\nStreamId:0\nTacticName:__myl_ReshMeanSubMulMean_0x026cdf70f904432fa7f9c6571177934a\n"]
	__myl_AddSqrtDivMulMulAddReshTran_myl37_17 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511903 ms</TD></TR><TR><TD>__myl_AddSqrtDivMulMulAddReshTran_myl37_17</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Transpose_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Reshape_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]+[ONNX Layer: /model/encoder/Transpose_1]+[ONNX Layer: /model/encoder/Reshape_1]\nName:__myl_AddSqrtDivMulMulAddReshTran_myl37_17\nStreamId:0\nTacticName:__myl_AddSqrtDivMulMulAddReshTran_0xce5ab2216ddcc262589c56ed29409629\n"]
	"model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00738722 ms</TD></TR><TR><TD>model.encoder.input_proj.0.conv.weight </TD></TR><TR><TD> /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/input_proj.0/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.0/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/input_proj.0/conv/Conv]+[ONNX Layer: /model/encoder/input_proj.0/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x483ad1560c6e5e27\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00668254 ms</TD></TR><TR><TD>model.encoder.input_proj.1.conv.weight </TD></TR><TR><TD> /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/input_proj.1/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/input_proj.1/conv/Conv]+[ONNX Layer: /model/encoder/input_proj.1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x483ad1560c6e5e27\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00638361 ms</TD></TR><TR><TD>/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear]\nName:/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003e8\n"]
	"model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00785948 ms</TD></TR><TR><TD>model.encoder.lateral_convs.0.conv.weight </TD></TR><TR><TD> /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/lateral_convs.0/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.0/conv/Conv]+[ONNX Layer: /model/encoder/lateral_convs.0/norm/BatchNormalization]+[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4\nTacticValue:0x5e4f6d7c83746fd6\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00376179 ms</TD></TR><TR><TD>PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/act/Mul]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/lateral_convs.0/act/Sigmoid]+[ONNX Layer: /model/encoder/lateral_convs.0/act/Mul]\nName:PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)\nNbInputArgs:1\nNbLiterals:5\nNbOperations:5\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);']\nOutputVars:['var4']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x0000000000000005\n"]
	"/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00620616 ms</TD></TR><TR><TD>/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\nName:/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003e8\n"]
	"/model/encoder/Resize" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Resize</b></TD></TR><TR><TD>0.00478053 ms</TD></TR><TR><TD>/model/encoder/Resize</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Resize]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="CoordTransform:kASYMMETRIC\nCubicCoeff:-0.75\nExcludeOutside:0\nInterpolationMode:NEAREST\nLayerType:Resize\nMetadata:[ONNX Layer: /model/encoder/Resize]\nNNRounding:kFLOOR\nName:/model/encoder/Resize\nResizeScales:[1, 1, 2, 2, 0, 0, 0, 0]\nResizeSelector:kFORMULA\nStreamId:0\nTacticValue:0x0000000000000005\n"]
	"/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00492161 ms</TD></TR><TR><TD>/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Concat_2]</TD></TR><TR><TD>CONCAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/Concat_2]\nName:/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy\nOrigin:CONCAT\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00646469 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.0.conv2.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/conv2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x9ec201b34455146e\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00677405 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.0.conv1.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/conv1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00802399 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc722efd60bc6ea84\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00782252 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc722efd60bc6ea84\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00822373 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x45f7566cdb2b10fb\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00536775 ms</TD></TR><TR><TD>PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0', 'arg1']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f', '0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/Add]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]\nName:PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))\nNbInputArgs:2\nNbLiterals:10\nNbOperations:11\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);', 'auto const var5 = pwgen::iMul(literal9, arg1);', 'auto const var6 = pwgen::iTanh(var5);', 'auto const var7 = pwgen::iMul(var6, literal9);', 'auto const var8 = pwgen::iPlus(var7, literal9);', 'auto const var9 = pwgen::iMul(arg1, var8);', 'auto const var10 = pwgen::iPlus(var4, var9);']\nOutputVars:['var10']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x0000000000000018\n"]
	"model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0063325 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.0.conv3.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.0/conv3/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Mul]+[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00642281 ms</TD></TR><TR><TD>model.encoder.lateral_convs.1.conv.weight </TD></TR><TR><TD> /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/lateral_convs.1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.1/conv/Conv]+[ONNX Layer: /model/encoder/lateral_convs.1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/lateral_convs.1/act/Sigmoid]+[ONNX Layer: /model/encoder/lateral_convs.1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"/model/encoder/Resize_1" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Resize</b></TD></TR><TR><TD>0.00498823 ms</TD></TR><TR><TD>/model/encoder/Resize_1</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Resize_1]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="CoordTransform:kASYMMETRIC\nCubicCoeff:-0.75\nExcludeOutside:0\nInterpolationMode:NEAREST\nLayerType:Resize\nMetadata:[ONNX Layer: /model/encoder/Resize_1]\nNNRounding:kFLOOR\nName:/model/encoder/Resize_1\nResizeScales:[1, 1, 2, 2, 0, 0, 0, 0]\nResizeSelector:kFORMULA\nStreamId:0\nTacticValue:0x0000000000000005\n"]
	"/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.0053912 ms</TD></TR><TR><TD>/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Concat_3]</TD></TR><TR><TD>CONCAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/Concat_3]\nName:/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy\nOrigin:CONCAT\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0113035 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.1.conv2.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/conv2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x7720f198395e7d3d\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00839933 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.1.conv1.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/conv1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x458f02d2b10db57c\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0108345 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xfdf7509af98902e0\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00979162 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xfdf7509af98902e0\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0125327 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x2d8ab2aa0639fda9\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00791044 ms</TD></TR><TR><TD>PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0', 'arg1']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f', '0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/Add]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]\nName:PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))\nNbInputArgs:2\nNbLiterals:10\nNbOperations:11\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);', 'auto const var5 = pwgen::iMul(literal9, arg1);', 'auto const var6 = pwgen::iTanh(var5);', 'auto const var7 = pwgen::iMul(var6, literal9);', 'auto const var8 = pwgen::iPlus(var7, literal9);', 'auto const var9 = pwgen::iMul(arg1, var8);', 'auto const var10 = pwgen::iPlus(var4, var9);']\nOutputVars:['var10']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x000000000000001a\n"]
	"model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0120854 ms</TD></TR><TR><TD>model.encoder.fpn_blocks.1.conv3.conv.weight </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/fpn_blocks.1/conv3/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Mul]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x65a38dbc9e991257\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0128832 ms</TD></TR><TR><TD>model.decoder.input_proj.0.conv.weight </TD></TR><TR><TD> /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/decoder/input_proj.0/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 0}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:0\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/input_proj.0/conv/Conv]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]\nName:model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4\nTacticValue:0x733ba2a91a48d431\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0108467 ms</TD></TR><TR><TD>model.encoder.downsample_convs.0.conv.weight </TD></TR><TR><TD> /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/downsample_convs.0/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/Conv]+[ONNX Layer: /model/encoder/downsample_convs.0/norm/BatchNormalization]+[ONNX Layer: /model/encoder/downsample_convs.0/act/Sigmoid]+[ONNX Layer: /model/encoder/downsample_convs.0/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc722efd60bc6ea84\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"/model/encoder/Resize_1_output_0 copy" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00490638 ms</TD></TR><TR><TD>/model/encoder/Resize_1_output_0 copy</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Concat_4]</TD></TR><TR><TD>CONCAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/Concat_4]\nName:/model/encoder/Resize_1_output_0 copy\nOrigin:CONCAT\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00654659 ms</TD></TR><TR><TD>model.encoder.pan_blocks.0.conv2.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.0/conv2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x9ec201b34455146e\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00676042 ms</TD></TR><TR><TD>model.encoder.pan_blocks.0.conv1.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.0/conv1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00780884 ms</TD></TR><TR><TD>model.encoder.pan_blocks.0.bottlenecks.0.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc722efd60bc6ea84\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00781706 ms</TD></TR><TR><TD>model.encoder.pan_blocks.0.bottlenecks.1.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc722efd60bc6ea84\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00810635 ms</TD></TR><TR><TD>model.encoder.pan_blocks.0.bottlenecks.2.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x45f7566cdb2b10fb\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00531127 ms</TD></TR><TR><TD>PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0', 'arg1']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f', '0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/Add]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]\nName:PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))\nNbInputArgs:2\nNbLiterals:10\nNbOperations:11\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);', 'auto const var5 = pwgen::iMul(literal9, arg1);', 'auto const var6 = pwgen::iTanh(var5);', 'auto const var7 = pwgen::iMul(var6, literal9);', 'auto const var8 = pwgen::iPlus(var7, literal9);', 'auto const var9 = pwgen::iMul(arg1, var8);', 'auto const var10 = pwgen::iPlus(var4, var9);']\nOutputVars:['var10']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x0000000000000018\n"]
	"model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00623643 ms</TD></TR><TR><TD>model.encoder.pan_blocks.0.conv3.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.0/conv3/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Mul]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00779285 ms</TD></TR><TR><TD>model.decoder.input_proj.1.conv.weight </TD></TR><TR><TD> /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/decoder/input_proj.1/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 0}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:0\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/input_proj.1/conv/Conv]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]\nName:model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4\nTacticValue:0x733ba2a91a48d431\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00914593 ms</TD></TR><TR><TD>model.encoder.downsample_convs.1.conv.weight </TD></TR><TR><TD> /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/downsample_convs.1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/Conv]+[ONNX Layer: /model/encoder/downsample_convs.1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/downsample_convs.1/act/Sigmoid]+[ONNX Layer: /model/encoder/downsample_convs.1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc985777c89c6b3a4\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00664004 ms</TD></TR><TR><TD>/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\nName:/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003e8\n"]
	"model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00627669 ms</TD></TR><TR><TD>model.encoder.pan_blocks.1.conv2.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.1/conv2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x6d377e4222886190\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00622698 ms</TD></TR><TR><TD>model.encoder.pan_blocks.1.conv1.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.1/conv1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0xc6cdb1e47323bb01\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00673319 ms</TD></TR><TR><TD>model.encoder.pan_blocks.1.bottlenecks.0.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc985777c89c6b3a4\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0067089 ms</TD></TR><TR><TD>model.encoder.pan_blocks.1.bottlenecks.1.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc985777c89c6b3a4\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00730545 ms</TD></TR><TR><TD>model.encoder.pan_blocks.1.bottlenecks.2.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xd14bd6d95fefd45e\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00429604 ms</TD></TR><TR><TD>PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0', 'arg1']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f', '0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/Add]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]\nName:PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))\nNbInputArgs:2\nNbLiterals:10\nNbOperations:11\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);', 'auto const var5 = pwgen::iMul(literal9, arg1);', 'auto const var6 = pwgen::iTanh(var5);', 'auto const var7 = pwgen::iMul(var6, literal9);', 'auto const var8 = pwgen::iPlus(var7, literal9);', 'auto const var9 = pwgen::iMul(arg1, var8);', 'auto const var10 = pwgen::iPlus(var4, var9);']\nOutputVars:['var10']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x0000000000000018\n"]
	"model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0054075 ms</TD></TR><TR><TD>model.encoder.pan_blocks.1.conv3.conv.weight </TD></TR><TR><TD> /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/encoder/pan_blocks.1/conv3/conv/Conv </TD></TR><TR><TD> PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Mul]+[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0xc6cdb1e47323bb01\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00714089 ms</TD></TR><TR><TD>model.decoder.input_proj.2.conv.weight </TD></TR><TR><TD> /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear </TD></TR><TR><TD> /model/decoder/input_proj.2/conv/Conv</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 0}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:0\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/input_proj.2/conv/Conv]+[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]\nName:model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4\nTacticValue:0x5e4f6d7c83746fd6\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"entry^bb^wait^1_myl85_1" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>entry^bb^wait^1_myl85_1</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:19\nLayerType:wait\nMetadata:\nName:entry^bb^wait^1_myl85_1\nStreamId:1\nTacticName:\n"]
	__myl_MulAddReshMulMinMaxRounCastTran_myl85_2 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0122858 ms</TD></TR><TR><TD>__myl_MulAddReshMulMinMaxRounCastTran_myl85_2</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.0/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/input_proj.0/norm/BatchNormalization]+[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Reshape]+[ONNX Layer: /model/decoder/Transpose]\nName:__myl_MulAddReshMulMinMaxRounCastTran_myl85_2\nStreamId:0\nTacticName:__myl_MulAddReshMulMinMaxRounCastTran_0x459d65282c25a1537bcc80e4552f8190\n"]
	__myl_MulMinMaxRounCastReshTran_myl85_3 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0071669 ms</TD></TR><TR><TD>__myl_MulMinMaxRounCastReshTran_myl85_3</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Reshape]+[ONNX Layer: /model/decoder/Transpose]\nName:__myl_MulMinMaxRounCastReshTran_myl85_3\nStreamId:0\nTacticName:__myl_MulMinMaxRounCastReshTran_0x783660148271f95371b9bc4f4d2bb040\n"]
	__myl_MulAddReshMulMinMaxRounCastTran_myl85_4 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00819254 ms</TD></TR><TR><TD>__myl_MulAddReshMulMinMaxRounCastTran_myl85_4</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/input_proj.1/norm/BatchNormalization]+[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Reshape_1]+[ONNX Layer: /model/decoder/Transpose_1]\nName:__myl_MulAddReshMulMinMaxRounCastTran_myl85_4\nStreamId:1\nTacticName:__myl_MulAddReshMulMinMaxRounCastTran_0x3ce367effa63c510276f5de98da8e392\n"]
	__myl_MulMinMaxRounCastReshTran_myl85_5 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>__myl_MulMinMaxRounCastReshTran_myl85_5</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Reshape_1]+[ONNX Layer: /model/decoder/Transpose_1]\nName:__myl_MulMinMaxRounCastReshTran_myl85_5\nStreamId:1\nTacticName:__myl_MulMinMaxRounCastReshTran_0xfe5454bfee8c5d0486ec8f4142dd2b5d\n"]
	__mye153330_myl85_7 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye153330_myl85_7</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:1\nLayerType:wait\nMetadata:\nName:__mye153330_myl85_7\nStreamId:0\nTacticName:\n"]
	__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl85_8 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0112632 ms</TD></TR><TR><TD>__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl85_8</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Concat_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/input_proj.2/norm/BatchNormalization]+[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Concat_3]+[ONNX Layer: /model/decoder/Reshape_2]+[ONNX Layer: /model/decoder/Transpose_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]\nName:__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl85_8\nStreamId:0\nTacticName:__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_0xc0b1b0b8ff66928228e54fb74ec8a45e\n"]
	__mye153334_myl85_10 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye153334_myl85_10</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:2\nLayerType:wait\nMetadata:\nName:__mye153334_myl85_10\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_11" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0276492 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul</TD></TR><TR><TD>/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul</TD></TR><TR><TD>/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_11</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add]\nName:/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_11\nStreamId:1\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32\n"]
	"/model/decoder/enc_output/proj/MatMul_myl85_12" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0194541 ms</TD></TR><TR><TD>/model/decoder/enc_output/proj/MatMul_myl85_12</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/enc_output/proj/MatMul]+[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_output/proj/Add]\nName:/model/decoder/enc_output/proj/MatMul_myl85_12\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32\n"]
	__myl_MeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_13 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0133125 ms</TD></TR><TR><TD>__myl_MeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_13</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/norm/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/enc_output/norm/LayerNormalization]+[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear]\nName:__myl_MeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_13\nStreamId:0\nTacticName:__myl_MeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_0x2f9cc7962385301203cd2db1b02ed7ec\n"]
	__mye153338_myl85_15 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye153338_myl85_15</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:3\nLayerType:wait\nMetadata:\nName:__mye153338_myl85_15\nStreamId:1\nTacticName:\n"]
	"/model/decoder/enc_score_head/MatMul_myl85_16" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0194551 ms</TD></TR><TR><TD>/model/decoder/enc_score_head/MatMul_myl85_16</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/enc_score_head/MatMul]+[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_score_head/Add]\nName:/model/decoder/enc_score_head/MatMul_myl85_16\nStreamId:1\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32\n"]
	__myl_Maxr_myl85_17 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>__myl_Maxr_myl85_17</TD></TR><TR><TD>[ONNX Layer: /model/decoder/ReduceMax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/ReduceMax]\nName:__myl_Maxr_myl85_17\nStreamId:1\nTacticName:__myl_Maxr_0x45757ac352af2ed0058c336edc12ba60\n"]
	__myl_Topk_myl85_18 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0348161 ms</TD></TR><TR><TD>__myl_Topk_myl85_18</TD></TR><TR><TD>[ONNX Layer: /model/decoder/TopK]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/TopK]\nName:__myl_Topk_myl85_18\nStreamId:1\nTacticName:__myl_Topk_0x2bbfb8ea621d6367d9edfe76c21438e4\n"]
	"/model/decoder/enc_bbox_head/layers_0/MatMul_myl85_20" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0143343 ms</TD></TR><TR><TD>/model/decoder/enc_bbox_head/layers_0/MatMul_myl85_20</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/MatMul]+[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/act/Relu]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/Add]\nName:/model/decoder/enc_bbox_head/layers_0/MatMul_myl85_20\nStreamId:0\nTacticName:sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1\n"]
	"/model/decoder/enc_bbox_head/layers_1/MatMul_myl85_21" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0102395 ms</TD></TR><TR><TD>/model/decoder/enc_bbox_head/layers_1/MatMul_myl85_21</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/MatMul]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/act_1/Relu]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/Add]\nName:/model/decoder/enc_bbox_head/layers_1/MatMul_myl85_21\nStreamId:0\nTacticName:sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1\n"]
	__myl_FcAdd_myl85_22 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00921469 ms</TD></TR><TR><TD>__myl_FcAdd_myl85_22</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/MatMul]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/Add]+[ONNX Layer: /model/decoder/Add]\nName:__myl_FcAdd_myl85_22\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl85_24 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl85_24</TD></TR><TR><TD>[ONNX Layer: /model/decoder/GatherElements]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Log]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Div]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sub]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Clip]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Unsqueeze]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/GatherElements]+[ONNX Layer: /model/decoder/decoder/Sigmoid]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/Log]+[ONNX Layer: /model/decoder/decoder/Div]+[ONNX Layer: /model/decoder/decoder/Sub]+[ONNX Layer: /model/decoder/decoder/Clip]+[ONNX Layer: /model/decoder/Unsqueeze]\nName:__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl85_24\nStreamId:0\nTacticName:__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_0x87091167bd6c2281e86f5f452041128e\n"]
	"/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl85_25" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00716657 ms</TD></TR><TR><TD>/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl85_25</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]\nName:/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl85_25\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	"/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_26" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614348 ms</TD></TR><TR><TD>/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_26</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/Add]\nName:/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_26\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_ReplGathReshAdd_myl85_27 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00319998 ms</TD></TR><TR><TD>__myl_ReplGathReshAdd_myl85_27</TD></TR><TR><TD>[ONNX Layer: /model/decoder/GatherElements_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/GatherElements_1]+[ONNX Layer: /model/decoder/decoder/layers.0/Add]\nName:__myl_ReplGathReshAdd_myl85_27\nStreamId:0\nTacticName:__myl_ReplGathReshAdd_0x177016a333c1e0c029a20cc81ca838c0\n"]
	__mye153346_myl85_29 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye153346_myl85_29</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:5\nLayerType:wait\nMetadata:\nName:__mye153346_myl85_29\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl85_30" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00921615 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl85_30</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_2]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_2]\nName:/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl85_30\nStreamId:1\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8\n"]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_32" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00921518 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_0/self_attn/MatMul_1</TD></TR><TR><TD>/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_32</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_1]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add]\nName:/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_32\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8\n"]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_33" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00643172 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_33</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Mul_1]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_3]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Mul_1]\nName:/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_33\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8\n"]
	__myl_MaxrSubExpSumDivMul_myl85_34 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.005152 ms</TD></TR><TR><TD>__myl_MaxrSubExpSumDivMul_myl85_34</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Softmax]\nName:__myl_MaxrSubExpSumDivMul_myl85_34\nStreamId:0\nTacticName:__myl_MaxrSubExpSumDivMul_0xe7d314cc73dbf705f429f8278ab30c57\n"]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_36" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00704008 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_36</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_4]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_4]\nName:/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_36\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	__myl_Tran_myl85_37 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307198 ms</TD></TR><TR><TD>__myl_Tran_myl85_37</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Transpose_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Reshape_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Transpose_5]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Reshape_3]\nName:__myl_Tran_myl85_37\nStreamId:0\nTacticName:__myl_Tran_0x812a618d2f6da6e0d008691c870cb2b7\n"]
	"/model/decoder/decoder/layers_0/self_attn/Gemm_myl85_38" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_0/self_attn/Gemm_myl85_38</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Gemm]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Gemm]\nName:/model/decoder/decoder/layers_0/self_attn/Gemm_myl85_38\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8\n"]
	__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_39 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0040956 ms</TD></TR><TR><TD>__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_39</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/norm1/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.0/norm1/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.0/Add_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]\nName:__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_39\nStreamId:0\nTacticName:__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_0x69dd74bed63b6785a6f736aca73a15a6\n"]
	__myl_FcMulAdd_myl85_40 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>__myl_FcMulAdd_myl85_40</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add]\nName:__myl_FcMulAdd_myl85_40\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_42 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_42</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Sub]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Split]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Sub]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_5]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_6]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Split]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8]\nName:__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_42\nStreamId:0\nTacticName:__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_0x1ba079c73dc7098ecd7f49a50270a387\n"]
	__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_43 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00921585 ms</TD></TR><TR><TD>__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_43</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_7]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_4]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_4]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_5]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_6]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_6]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_7]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_8]\nName:__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_43\nStreamId:0\nTacticName:__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_0x4671ed411a6bb6a8da5e34e92e03761d\n"]
	__myl_ReshMaxrSubExpSum_myl85_45 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00614289 ms</TD></TR><TR><TD>__myl_ReshMaxrSubExpSum_myl85_45</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]\nName:__myl_ReshMaxrSubExpSum_myl85_45\nStreamId:1\nTacticName:__myl_ReshMaxrSubExpSum_0xf2da65babbfdba9319fb6fef7954bb4f\n"]
	__mye153358_myl85_47 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye153358_myl85_47</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:8\nLayerType:wait\nMetadata:\nName:__mye153358_myl85_47\nStreamId:0\nTacticName:\n"]
	__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_48 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0166077 ms</TD></TR><TR><TD>__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_48</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_9]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Concat_10]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/ReduceSum]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_8]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_9]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Concat_10]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/ReduceSum]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_8]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear]\nName:__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_48\nStreamId:0\nTacticName:__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_0xf0d0ce15ea4ff3463060538d679df965\n"]
	__myl_Move_myl85_49 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>__myl_Move_myl85_49</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]\nName:__myl_Move_myl85_49\nStreamId:0\nTacticName:__myl_Move_0xe44b2845ee5a2c900106157eaed1d520\n"]
	__myl_FcAdd_myl85_50 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00512001 ms</TD></TR><TR><TD>__myl_FcAdd_myl85_50</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add_3]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/Add_3]\nName:__myl_FcAdd_myl85_50\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_51 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_51</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/norm2/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear]\nName:__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_51\nStreamId:0\nTacticName:__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_0x9a04d543e7c3b3f716fb221e2f203132\n"]
	"/model/decoder/decoder/layers_0/linear1/MatMul_myl85_52" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_0/linear1/MatMul_myl85_52</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/activation/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/linear1/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/activation/Relu]+[ONNX Layer: /model/decoder/decoder/layers.0/linear1/Add]\nName:/model/decoder/decoder/layers_0/linear1/MatMul_myl85_52\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	__myl_FcAdd_myl85_53 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00630378 ms</TD></TR><TR><TD>__myl_FcAdd_myl85_53</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add_4]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/linear2/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/linear2/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/Add_4]\nName:__myl_FcAdd_myl85_53\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_54 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511903 ms</TD></TR><TR><TD>__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_54</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear]\nName:__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_54\nStreamId:0\nTacticName:__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_0x1b4b77686f41c45144fdfff1c09c0d9b\n"]
	__mye153362_myl85_56 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye153362_myl85_56</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:9\nLayerType:wait\nMetadata:\nName:__mye153362_myl85_56\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl85_57" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00819108 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl85_57</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_2]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_2]\nName:/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl85_57\nStreamId:1\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8\n"]
	"/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl85_59" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl85_59</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add]\nName:/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl85_59\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1\n"]
	"/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl85_60" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl85_60</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add]\nName:/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl85_60\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1\n"]
	__myl_FcAddSigm_myl85_61 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>__myl_FcAddSigm_myl85_61</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sigmoid_1]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add]+[ONNX Layer: /model/decoder/decoder/Add]+[ONNX Layer: /model/decoder/decoder/Sigmoid_1]\nName:__myl_FcAddSigm_myl85_61\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_MulMinMaxRounConcCast_myl85_62 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409519 ms</TD></TR><TR><TD>__myl_MulMinMaxRounConcCast_myl85_62</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear]\nName:__myl_MulMinMaxRounConcCast_myl85_62\nStreamId:0\nTacticName:__myl_MulMinMaxRounConcCast_0x7ef7115f49fa122439bd1412238d61ca\n"]
	"/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl85_63" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00425634 ms</TD></TR><TR><TD>/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl85_63</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/act_1/Relu]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/Add]\nName:/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl85_63\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	"/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_64" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511964 ms</TD></TR><TR><TD>/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_64</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/Add]\nName:/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_64\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_Add_myl85_65 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00348789 ms</TD></TR><TR><TD>__myl_Add_myl85_65</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/Add]\nName:__myl_Add_myl85_65\nStreamId:0\nTacticName:__myl_Add_0xb0206d942e687a41bd32a2b95ff44f68\n"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_66" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00655991 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_1/self_attn/MatMul_1</TD></TR><TR><TD>/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_66</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_1]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add]\nName:/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_66\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8\n"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_67" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614386 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_67</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Mul_1]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_3]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Mul_1]\nName:/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_67\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8\n"]
	__myl_MaxrSubExpSumDivMul_myl85_68 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00540741 ms</TD></TR><TR><TD>__myl_MaxrSubExpSumDivMul_myl85_68</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Softmax]\nName:__myl_MaxrSubExpSumDivMul_myl85_68\nStreamId:0\nTacticName:__myl_MaxrSubExpSumDivMul_0xe7d314cc73dbf705f429f8278ab30c57\n"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_70" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614345 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_70</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_4]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_4]\nName:/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_70\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	__myl_Tran_myl85_71 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409505 ms</TD></TR><TR><TD>__myl_Tran_myl85_71</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Transpose_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Reshape_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Transpose_5]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Reshape_3]\nName:__myl_Tran_myl85_71\nStreamId:0\nTacticName:__myl_Tran_0x812a618d2f6da6e0d008691c870cb2b7\n"]
	"/model/decoder/decoder/layers_1/self_attn/Gemm_myl85_72" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614386 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_1/self_attn/Gemm_myl85_72</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Gemm]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Gemm]\nName:/model/decoder/decoder/layers_1/self_attn/Gemm_myl85_72\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8\n"]
	__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_73 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511903 ms</TD></TR><TR><TD>__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_73</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/norm1/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.1/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.1/norm1/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.1/Add_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]\nName:__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_73\nStreamId:0\nTacticName:__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_0x2bacafd8f052a09e462b3d296a6b34c7\n"]
	__myl_FcMulAdd_myl85_74 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00511963 ms</TD></TR><TR><TD>__myl_FcMulAdd_myl85_74</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add]\nName:__myl_FcMulAdd_myl85_74\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_76 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_76</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Sub]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Split]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Sub]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_5]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_3]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Split]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8]\nName:__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_76\nStreamId:0\nTacticName:__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_0x1ba079c73dc7098ecd7f49a50270a387\n"]
	__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_77 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00937538 ms</TD></TR><TR><TD>__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_77</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_7]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_4]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_4]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_5]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_6]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_6]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_7]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_8]\nName:__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_77\nStreamId:0\nTacticName:__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_0x4671ed411a6bb6a8da5e34e92e03761d\n"]
	__myl_ReshMaxrSubExpSum_myl85_79 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>__myl_ReshMaxrSubExpSum_myl85_79</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]\nName:__myl_ReshMaxrSubExpSum_myl85_79\nStreamId:1\nTacticName:__myl_ReshMaxrSubExpSum_0xf2da65babbfdba9319fb6fef7954bb4f\n"]
	__mye153374_myl85_81 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye153374_myl85_81</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:12\nLayerType:wait\nMetadata:\nName:__mye153374_myl85_81\nStreamId:0\nTacticName:\n"]
	__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_82 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0163841 ms</TD></TR><TR><TD>__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_82</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_9]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Concat_10]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/ReduceSum]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_9]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Concat_10]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/ReduceSum]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_5]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear]\nName:__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_82\nStreamId:0\nTacticName:__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_0xf0d0ce15ea4ff3463060538d679df965\n"]
	__myl_Move_myl85_83 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_Move_myl85_83</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]\nName:__myl_Move_myl85_83\nStreamId:0\nTacticName:__myl_Move_0xe44b2845ee5a2c900106157eaed1d520\n"]
	__myl_FcAdd_myl85_84 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.004128 ms</TD></TR><TR><TD>__myl_FcAdd_myl85_84</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add_3]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/Add_3]\nName:__myl_FcAdd_myl85_84\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_85 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_85</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/norm2/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear]\nName:__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_85\nStreamId:0\nTacticName:__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_0x9a04d543e7c3b3f716fb221e2f203132\n"]
	"/model/decoder/decoder/layers_1/linear1/MatMul_myl85_86" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.005152 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_1/linear1/MatMul_myl85_86</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/activation/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/linear1/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/activation/Relu]+[ONNX Layer: /model/decoder/decoder/layers.1/linear1/Add]\nName:/model/decoder/decoder/layers_1/linear1/MatMul_myl85_86\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	__myl_FcAdd_myl85_87 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00512005 ms</TD></TR><TR><TD>__myl_FcAdd_myl85_87</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add_4]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/linear2/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/linear2/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/Add_4]\nName:__myl_FcAdd_myl85_87\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_88 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_88</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear]\nName:__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_88\nStreamId:0\nTacticName:__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_0x1b4b77686f41c45144fdfff1c09c0d9b\n"]
	__mye153378_myl85_90 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye153378_myl85_90</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:13\nLayerType:wait\nMetadata:\nName:__mye153378_myl85_90\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl85_91" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl85_91</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_2]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_2]\nName:/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl85_91\nStreamId:1\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8\n"]
	__myl_MaxMinSubMaxMinMaxMinDivLog_myl85_93 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>__myl_MaxMinSubMaxMinMaxMinDivLog_myl85_93</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Log_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Div_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sub_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Clip_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/Log_1]+[ONNX Layer: /model/decoder/decoder/Div_1]+[ONNX Layer: /model/decoder/decoder/Sub_1]+[ONNX Layer: /model/decoder/decoder/Clip_3]\nName:__myl_MaxMinSubMaxMinMaxMinDivLog_myl85_93\nStreamId:0\nTacticName:__myl_MaxMinSubMaxMinMaxMinDivLog_0x0fb4f0d98d09dda9f624bf65aecc1fdd\n"]
	"/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl85_94" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00512001 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl85_94</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add]\nName:/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl85_94\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1\n"]
	"/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl85_95" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl85_95</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add]\nName:/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl85_95\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1\n"]
	__myl_FcAddSigm_myl85_96 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614298 ms</TD></TR><TR><TD>__myl_FcAddSigm_myl85_96</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sigmoid_2]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add]+[ONNX Layer: /model/decoder/decoder/Add_1]+[ONNX Layer: /model/decoder/decoder/Sigmoid_2]\nName:__myl_FcAddSigm_myl85_96\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_MulMinMaxRounConcCast_myl85_97 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307193 ms</TD></TR><TR><TD>__myl_MulMinMaxRounConcCast_myl85_97</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear]\nName:__myl_MulMinMaxRounConcCast_myl85_97\nStreamId:0\nTacticName:__myl_MulMinMaxRounConcCast_0x7ef7115f49fa122439bd1412238d61ca\n"]
	"/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl85_98" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00409651 ms</TD></TR><TR><TD>/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl85_98</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/act_2/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/act_2/Relu]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/Add]\nName:/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl85_98\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	"/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_99" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00512001 ms</TD></TR><TR><TD>/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_99</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/Add]\nName:/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_99\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_Add_myl85_100 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00316754 ms</TD></TR><TR><TD>__myl_Add_myl85_100</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/Add]\nName:__myl_Add_myl85_100\nStreamId:0\nTacticName:__myl_Add_0xb0206d942e687a41bd32a2b95ff44f68\n"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_101" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00755192 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_2/self_attn/MatMul_1</TD></TR><TR><TD>/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_101</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_1]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add]\nName:/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_101\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8\n"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_102" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00819156 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_102</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Mul_1]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_3]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Mul_1]\nName:/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_102\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8\n"]
	__myl_MaxrSubExpSumDivMul_myl85_103 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0052475 ms</TD></TR><TR><TD>__myl_MaxrSubExpSumDivMul_myl85_103</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Softmax]\nName:__myl_MaxrSubExpSumDivMul_myl85_103\nStreamId:0\nTacticName:__myl_MaxrSubExpSumDivMul_0xe7d314cc73dbf705f429f8278ab30c57\n"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_105" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00716788 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_105</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_4]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_4]\nName:/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_105\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	__myl_Tran_myl85_106 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409523 ms</TD></TR><TR><TD>__myl_Tran_myl85_106</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Transpose_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Reshape_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Transpose_5]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Reshape_3]\nName:__myl_Tran_myl85_106\nStreamId:0\nTacticName:__myl_Tran_0x812a618d2f6da6e0d008691c870cb2b7\n"]
	"/model/decoder/decoder/layers_2/self_attn/Gemm_myl85_107" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00540789 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_2/self_attn/Gemm_myl85_107</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Gemm]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Gemm]\nName:/model/decoder/decoder/layers_2/self_attn/Gemm_myl85_107\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8\n"]
	__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_108 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_108</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/norm1/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.2/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.2/norm1/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.2/Add_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]\nName:__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_108\nStreamId:0\nTacticName:__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_0x2bacafd8f052a09e462b3d296a6b34c7\n"]
	__myl_FcMulAdd_myl85_109 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>__myl_FcMulAdd_myl85_109</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add]\nName:__myl_FcMulAdd_myl85_109\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_111 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307193 ms</TD></TR><TR><TD>__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_111</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Sub]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Split]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Sub]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_5]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_3]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Add]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Split]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8]\nName:__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_111\nStreamId:0\nTacticName:__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_0x1ba079c73dc7098ecd7f49a50270a387\n"]
	__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_112 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00950354 ms</TD></TR><TR><TD>__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_112</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_7]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_4]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_4]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_5]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_6]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_6]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_7]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_8]\nName:__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_112\nStreamId:0\nTacticName:__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_0x4671ed411a6bb6a8da5e34e92e03761d\n"]
	__myl_ReshMaxrSubExpSum_myl85_114 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>__myl_ReshMaxrSubExpSum_myl85_114</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]\nName:__myl_ReshMaxrSubExpSum_myl85_114\nStreamId:1\nTacticName:__myl_ReshMaxrSubExpSum_0xf2da65babbfdba9319fb6fef7954bb4f\n"]
	__mye153390_myl85_116 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye153390_myl85_116</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:16\nLayerType:wait\nMetadata:\nName:__mye153390_myl85_116\nStreamId:0\nTacticName:\n"]
	__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_117 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0174075 ms</TD></TR><TR><TD>__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_117</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_9]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Concat_10]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/ReduceSum]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_9]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Concat_10]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/ReduceSum]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_5]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear]\nName:__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_117\nStreamId:0\nTacticName:__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_0xf0d0ce15ea4ff3463060538d679df965\n"]
	__myl_Move_myl85_118 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>__myl_Move_myl85_118</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]\nName:__myl_Move_myl85_118\nStreamId:0\nTacticName:__myl_Move_0xe44b2845ee5a2c900106157eaed1d520\n"]
	__myl_FcAdd_myl85_119 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>__myl_FcAdd_myl85_119</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add_3]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.2/Add_3]\nName:__myl_FcAdd_myl85_119\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_120 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00412767 ms</TD></TR><TR><TD>__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_120</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/norm2/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear]\nName:__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_120\nStreamId:0\nTacticName:__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_0x9a04d543e7c3b3f716fb221e2f203132\n"]
	"/model/decoder/decoder/layers_2/linear1/MatMul_myl85_121" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>/model/decoder/decoder/layers_2/linear1/MatMul_myl85_121</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/activation/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/linear1/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/activation/Relu]+[ONNX Layer: /model/decoder/decoder/layers.2/linear1/Add]\nName:/model/decoder/decoder/layers_2/linear1/MatMul_myl85_121\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	__myl_FcAdd_myl85_122 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>__myl_FcAdd_myl85_122</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add_4]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/linear2/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/linear2/Add]+[ONNX Layer: /model/decoder/decoder/layers.2/Add_4]\nName:__myl_FcAdd_myl85_122\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_123 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409571 ms</TD></TR><TR><TD>__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_123</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear]\nName:__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_123\nStreamId:0\nTacticName:__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_0xdbf5fe7187fbdeb24bfb2dcd48012c78\n"]
	__mye153394_myl85_125 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye153394_myl85_125</TD></TR><TR><TD></TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="EventId:17\nLayerType:wait\nMetadata:\nName:__mye153394_myl85_125\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/dec_score_head_2/MatMul_myl85_126" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_score_head_2/MatMul_myl85_126</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_score_head.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_score_head.2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_score_head.2/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_score_head.2/Add]\nName:/model/decoder/decoder/dec_score_head_2/MatMul_myl85_126\nStreamId:1\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_GathSigmResh_myl85_127 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_GathSigmResh_myl85_127</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Flatten]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Gather_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /postprocessor/Flatten]+[ONNX Layer: /postprocessor/Sigmoid]+[ONNX Layer: /model/decoder/Gather_8]\nName:__myl_GathSigmResh_myl85_127\nStreamId:1\nTacticName:__myl_GathSigmResh_0x983551a631bdccd1905654f55e50a7e4\n"]
	__myl_Topk_myl85_128 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0788477 ms</TD></TR><TR><TD>__myl_Topk_myl85_128</TD></TR><TR><TD>[ONNX Layer: /postprocessor/TopK]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /postprocessor/TopK]\nName:__myl_Topk_myl85_128\nStreamId:1\nTacticName:__myl_Topk_0x46004755f860a677c07469a83ee8bc45\n"]
	__myl_MaxMinSubMaxMinMaxMinDivLog_myl85_130 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409505 ms</TD></TR><TR><TD>__myl_MaxMinSubMaxMinMaxMinDivLog_myl85_130</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Log_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Div_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sub_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Clip_6]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/Log_2]+[ONNX Layer: /model/decoder/decoder/Div_2]+[ONNX Layer: /model/decoder/decoder/Sub_2]+[ONNX Layer: /model/decoder/decoder/Clip_6]\nName:__myl_MaxMinSubMaxMinMaxMinDivLog_myl85_130\nStreamId:0\nTacticName:__myl_MaxMinSubMaxMinMaxMinDivLog_0x0fb4f0d98d09dda9f624bf65aecc1fdd\n"]
	"/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl85_131" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00409651 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl85_131</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add]\nName:/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl85_131\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1\n"]
	"/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl85_132" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl85_132</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add]\nName:/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl85_132\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1\n"]
	__myl_FcAddSigm_myl85_133 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>__myl_FcAddSigm_myl85_133</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Add_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sigmoid_3]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add]+[ONNX Layer: /model/decoder/decoder/Add_2]+[ONNX Layer: /model/decoder/decoder/Sigmoid_3]\nName:__myl_FcAddSigm_myl85_133\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl85_135 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0031365 ms</TD></TR><TR><TD>__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl85_135</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Tile]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_4]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Div]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Sub_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Mul_3]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Squeeze_3]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Sub_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Squeeze]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Add_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_3]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_5]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/GatherElements]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Mul_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Concat]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Sub]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Add]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Mul]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Squeeze_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Squeeze_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Split]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Gather_9]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Unsqueeze_3]</TD></TR><TR><TD>[ONNX Layer: Cast_3039]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /postprocessor/Tile]+[ONNX Layer: /postprocessor/Unsqueeze_4]+[ONNX Layer: /postprocessor/Div]+[ONNX Layer: /postprocessor/Sub_2]+[ONNX Layer: /postprocessor/Mul_3]+[ONNX Layer: /postprocessor/Squeeze_3]+[ONNX Layer: /postprocessor/Mul_1]+[ONNX Layer: /postprocessor/Sub_1]+[ONNX Layer: /postprocessor/Unsqueeze_1]+[ONNX Layer: /postprocessor/Squeeze]+[ONNX Layer: /postprocessor/Add_1]+[ONNX Layer: /postprocessor/Unsqueeze_3]+[ONNX Layer: /postprocessor/Unsqueeze_5]+[ONNX Layer: /postprocessor/GatherElements]+[ONNX Layer: /postprocessor/Mul_2]+[ONNX Layer: /postprocessor/Concat]+[ONNX Layer: /postprocessor/Unsqueeze]+[ONNX Layer: /postprocessor/Sub]+[ONNX Layer: /postprocessor/Unsqueeze_2]+[ONNX Layer: /postprocessor/Add]+[ONNX Layer: /postprocessor/Mul]+[ONNX Layer: /postprocessor/Squeeze_2]+[ONNX Layer: /postprocessor/Squeeze_1]+[ONNX Layer: /postprocessor/Split]+[ONNX Layer: /model/decoder/Gather_9]+[ONNX Layer: /model/decoder/decoder/Unsqueeze_3]+[ONNX Layer: Cast_3039]\nName:__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl85_135\nStreamId:0\nTacticName:__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_0x1e340078e2dfe6c4366f77078054d7f7\n"]
	images -> "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear" [label="[1, 3, 640, 640]\nFP32 NCHW" color=red]
	"/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear" -> "model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv" [label="[1, 3, 640, 640]\nInt8 NC/4HW4" color="#76b900"]
	"model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv" -> "model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv" [label="[1, 32, 320, 320]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv" -> "model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv" [label="[1, 32, 320, 320]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv" -> "/model/backbone/MaxPool" [label="[1, 64, 320, 320]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/MaxPool" -> "model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/MaxPool" -> "model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv" -> "model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv" -> "model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" [label="[1, 64, 160, 160]\nFP32 NC/32HW32" color=red]
	"model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" -> "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 64, 160, 160]\nFP32 NC/32HW32" color=red]
	"model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" -> "model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu" [label="[1, 64, 160, 160]\nFP32 NC/32HW32" color=red]
	"/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv" -> "model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu" -> "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 64, 160, 160]\nFP32 NC/32HW32" color=red]
	"/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool" -> "model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" [label="[1, 64, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv" -> "model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv" -> "model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" [label="[1, 128, 80, 80]\nFP32 NC/32HW32" color=red]
	"model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" -> "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 128, 80, 80]\nFP32 NC/32HW32" color=red]
	"model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" -> "model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu" [label="[1, 128, 80, 80]\nFP32 NC/32HW32" color=red]
	"/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv" -> "model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu" -> "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 128, 80, 80]\nFP32 NC/32HW32" color=red]
	"/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool" -> "model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv" -> "model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv" -> "model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" [label="[1, 256, 40, 40]\nFP32 NC/32HW32" color=red]
	"model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" -> "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 256, 40, 40]\nFP32 NC/32HW32" color=red]
	"model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" -> "model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu" [label="[1, 256, 40, 40]\nFP32 NC/32HW32" color=red]
	"/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv" -> "model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu" -> "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 256, 40, 40]\nFP32 NC/32HW32" color=red]
	"/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool" -> "model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" [label="[1, 256, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv" -> "model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv" -> "model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" [label="[1, 512, 20, 20]\nFP32 NC/32HW32" color=red]
	"model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" -> "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 512, 20, 20]\nFP32 NC/32HW32" color=red]
	"model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" -> "model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu" [label="[1, 512, 20, 20]\nFP32 NC/32HW32" color=red]
	"/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv" -> "model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu" -> "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear" [label="[1, 512, 20, 20]\nFP32 NC/32HW32" color=red]
	"/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear" -> "model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv" -> __myl_MulAddReshTran_myl37_0 [label="[1, 256, 20, 20]\nFP32 NCHW" color=red]
	__myl_MulAddReshTran_myl37_0 -> "/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl37_4" [label="[400, 1, 256]\nFloat" color=red]
	__myl_MulAddReshTran_myl37_0 -> __myl_TranAdd_myl37_2 [label="[1, 256, 400]\nFloat" color=red]
	__myl_TranAdd_myl37_2 -> "/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl37_6" [label="[1, 400, 256]\nFloat" color=red]
	__myl_TranAdd_myl37_2 -> "__myln_k_arg__bb1_5.0" [label="[1, 256, 80, 80]\nFloat" color=red]
	"__myln_k_arg__bb1_5.0" -> __myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl37_13 [label="[1, 256, 80, 80]\nFloat" color=red]
	__myl_MulAddReshMulMinMaxRounCastTran_myl85_2 -> "__myln_k_arg__bb1_5.1" [label="[1, 256, 80, 80]\nFloat" color=red]
	"__myln_k_arg__bb1_5.1" -> __myl_MulMinMaxRounCastReshTran_myl85_3 [label="[1, 256, 80, 80]\nFloat" color=red]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl37_4" -> "/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_myl37_10" [label="[400, 256]\nFloat" color=red]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl37_6" -> "/model/encoder/encoder_0/layers_0/self_attn/MatMul_3_myl37_7" [label="[2, 400, 256]\nFloat" color=red]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl37_6" -> "/model/encoder/encoder_0/layers_0/self_attn/MatMul_3_myl37_7" [label="[2, 400, 256]\nFloat" color=red]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_3_myl37_7" -> "__myln_k_arg__bb1_8.0" [label="[8, 400, 400]\nFloat" color=red]
	"__myln_k_arg__bb1_8.0" -> __myl_MaxrSubExpSumDivMul_myl37_8 [label="[8, 400, 400]\nFloat" color=red]
	"__myln_k_arg__bb1_8.0" -> __myl_MaxrSubExpSumDivMul_myl37_8 [label="[8, 400, 400]\nFloat" color=red]
	__myl_MulAddReshMulMinMaxRounCastTran_myl85_4 -> "__myln_k_arg__bb1_8.1" [label="[1, 256, 40, 40]\nFloat" color=red]
	"__myln_k_arg__bb1_8.1" -> __myl_MulMinMaxRounCastReshTran_myl85_5 [label="[1, 256, 40, 40]\nFloat" color=red]
	__myl_MaxrSubExpSumDivMul_myl37_8 -> "/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_myl37_10" [label="[8, 400, 400]\nFloat" color=red]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_myl37_10" -> "__myln_k_arg__bb1_10.0" [label="[8, 400, 32]\nFloat" color=red]
	"__myln_k_arg__bb1_10.0" -> __myl_Tran_myl37_11 [label="[8, 400, 32]\nFloat" color=red]
	__myl_MulMinMaxRounCastReshTran_myl85_5 -> "__myln_k_arg__bb1_10.1" [label="[1, 1600, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_10.1" -> __myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl85_8 [label="[1, 1600, 256]\nInt8" color="#76b900"]
	__myl_Tran_myl37_11 -> "/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl37_12" [label="[400, 8, 32]\nFloat" color=red]
	"/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl37_12" -> __myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl37_13 [label="[400, 256]\nFloat" color=red]
	__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl37_13 -> "/model/encoder/encoder_0/layers_0/linear1/MatMul_myl37_14" [label="[400, 256]\nInt8" color="#76b900"]
	__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl37_13 -> "__myln_k_arg__bb1_14.0" [label="[1, 8400, 256]\nFloat" color=red]
	"__myln_k_arg__bb1_14.0" -> __myl_FcAdd_myl37_15 [label="[1, 8400, 256]\nFloat" color=red]
	"/model/decoder/enc_output/proj/MatMul_myl85_12" -> "__myln_k_arg__bb1_14.1" [label="[1, 8400, 256]\nFloat" color=red]
	"__myln_k_arg__bb1_14.1" -> __myl_MeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_13 [label="[1, 8400, 256]\nFloat" color=red]
	"__myln_k_arg__bb1_14.1" -> __myl_MeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_13 [label="[1, 8400, 256]\nFloat" color=red]
	"/model/encoder/encoder_0/layers_0/linear1/MatMul_myl37_14" -> "__myln_k_arg__bb1_15.0" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_15.0" -> __myl_FcAdd_myl37_15 [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_MeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_13 -> "__myln_k_arg__bb1_15.1" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_15.1" -> "/model/decoder/enc_score_head/MatMul_myl85_16" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_15.1" -> "/model/decoder/enc_bbox_head/layers_0/MatMul_myl85_20" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_FcAdd_myl37_15 -> "__myln_k_arg__bb1_16.0" [label="[1, 8400, 256]\nFloat" color=red]
	"__myln_k_arg__bb1_16.0" -> __myl_ReshMeanSubMulMean_myl37_16 [label="[1, 8400, 256]\nFloat" color=red]
	__myl_MeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_13 -> "__myln_k_arg__bb1_16.1" [label="[1, 8400, 256]\nFloat" color=red]
	"__myln_k_arg__bb1_16.1" -> __myl_ReplGathReshAdd_myl85_27 [label="[1, 8400, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMean_myl37_16 -> __myl_AddSqrtDivMulMulAddReshTran_myl37_17 [label="[400, 1]\nFloat" color=red]
	__myl_ReshMeanSubMulMean_myl37_16 -> "__myln_k_arg__bb1_17.0" [label="[1, 8400, 80]\nFloat" color=red]
	"__myln_k_arg__bb1_17.0" -> __myl_AddSqrtDivMulMulAddReshTran_myl37_17 [label="[1, 8400, 80]\nFloat" color=red]
	"/model/decoder/enc_score_head/MatMul_myl85_16" -> "__myln_k_arg__bb1_17.1" [label="[1, 8400, 80]\nFloat" color=red]
	"__myln_k_arg__bb1_17.1" -> __myl_Maxr_myl85_17 [label="[1, 8400, 80]\nFloat" color=red]
	__myl_AddSqrtDivMulMulAddReshTran_myl37_17 -> "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear" [label="[1, 256, 400]\nFloat" color=red]
	"model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv" -> "model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv" [label="[1, 512, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv" -> "model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)" [label="[1, 512, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy" -> "model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv" [label="[1, 512, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy" -> "model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)" [label="[1, 512, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv" -> "model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv" -> "model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy" -> "model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy" -> "model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear" -> "model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv" [label="[1, 256, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv" -> "PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)" [label="[1, 256, 20, 20]\nFP32 NCHW" color=red]
	"PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)" -> "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0" [label="[1, 256, 20, 20]\nFP32 NCHW" color=red]
	"PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)" -> "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1" [label="[1, 256, 20, 20]\nFP32 NCHW" color=red]
	"/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0" -> "/model/encoder/Resize" [label="[1, 256, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Resize" -> "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv" -> "PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))" [label="[1, 128, 40, 40]\nFP32 NC/32HW32" color=red]
	"model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)" -> "model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" -> "model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" -> "model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" -> "PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))" [label="[1, 128, 40, 40]\nFP32 NC/32HW32" color=red]
	"PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))" -> "model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)" -> "model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)" -> "/model/encoder/Resize_1" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)" -> "/model/encoder/Resize_1_output_0 copy" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Resize_1" -> "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy" [label="[1, 256, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv" -> "PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))" [label="[1, 128, 80, 80]\nFP32 NC/32HW32" color=red]
	"model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)" -> "model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" -> "model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" -> "model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" -> "PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))" [label="[1, 128, 80, 80]\nFP32 NC/32HW32" color=red]
	"PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))" -> "model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)" -> "model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv" [label="[1, 256, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)" -> "model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)" [label="[1, 256, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv" -> __myl_MulAddReshMulMinMaxRounCastTran_myl85_2 [label="[1, 256, 80, 80]\nFP32 NCHW" color=red]
	"model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)" -> "model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)" -> "model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Resize_1_output_0 copy" -> "model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Resize_1_output_0 copy" -> "model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv" -> "PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))" [label="[1, 128, 40, 40]\nFP32 NC/32HW32" color=red]
	"model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)" -> "model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" -> "model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" -> "model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" -> "PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))" [label="[1, 128, 40, 40]\nFP32 NC/32HW32" color=red]
	"PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))" -> "model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)" -> "model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)" -> "model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv" -> __myl_MulAddReshMulMinMaxRounCastTran_myl85_4 [label="[1, 256, 40, 40]\nFP32 NCHW" color=red]
	"model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)" -> "model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)" -> "model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1" -> "model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1" -> "model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv" -> "PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))" [label="[1, 128, 20, 20]\nFP32 NC/32HW32" color=red]
	"model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)" -> "model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" [label="[1, 128, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" -> "model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" [label="[1, 128, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" -> "model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" [label="[1, 128, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" -> "PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))" [label="[1, 128, 20, 20]\nFP32 NC/32HW32" color=red]
	"PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))" -> "model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)" [label="[1, 128, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)" -> "model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv" [label="[1, 256, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv" -> __myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl85_8 [label="[1, 256, 20, 20]\nFP32 NCHW" color=red]
	__myl_MulAddReshMulMinMaxRounCastTran_myl85_2 -> __myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl85_8 [label="[1, 6400, 256]\nInt8" color="#76b900"]
	__myl_MulMinMaxRounCastReshTran_myl85_3 -> __myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl85_8 [label="[1, 6400, 256]\nInt8" color="#76b900"]
	__myl_MulAddReshMulMinMaxRounCastTran_myl85_4 -> __myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl85_8 [label="[1, 1600, 256]\nInt8" color="#76b900"]
	__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl85_8 -> "/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_11" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl85_8 -> "/model/decoder/enc_output/proj/MatMul_myl85_12" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_11" -> __myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_43 [label="[3, 8400, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_11" -> __myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_77 [label="[3, 8400, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_11" -> __myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_112 [label="[3, 8400, 256]\nFloat" color=red]
	__myl_Maxr_myl85_17 -> __myl_Topk_myl85_18 [label="[1, 8400, 1]\nFloat" color=red]
	__myl_Topk_myl85_18 -> __myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl85_24 [label="[1, 300]\nInt32" color=lightgray]
	"/model/decoder/enc_bbox_head/layers_0/MatMul_myl85_20" -> "/model/decoder/enc_bbox_head/layers_1/MatMul_myl85_21" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"/model/decoder/enc_bbox_head/layers_1/MatMul_myl85_21" -> __myl_FcAdd_myl85_22 [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_22 -> __myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl85_24 [label="[1, 8400, 4]\nFloat" color=red]
	__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl85_24 -> __myl_ReplGathReshAdd_myl85_27 [label="[1, 300, 1]\nInt32" color=lightgray]
	__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl85_24 -> __myl_FcAddSigm_myl85_61 [label="[1, 300, 4]\nFloat" color=red]
	__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl85_24 -> "/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl85_25" [label="[1, 300, 16]\nInt8" color="#76b900"]
	__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl85_24 -> __myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_42 [label="[1, 300, 4]\nFloat" color=red]
	"/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl85_25" -> "/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_26" [label="[1, 300, 512]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_26" -> __myl_ReplGathReshAdd_myl85_27 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_26" -> __myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_39 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ReplGathReshAdd_myl85_27 -> "/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_32" [label="[300, 256]\nFloat" color=red]
	__myl_ReplGathReshAdd_myl85_27 -> "/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl85_30" [label="[1, 300, 256]\nFloat" color=red]
	__myl_ReplGathReshAdd_myl85_27 -> __myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_39 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl85_30" -> "/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_36" [label="[300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_32" -> "/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_33" [label="[2, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_32" -> "/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_33" [label="[2, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_33" -> __myl_MaxrSubExpSumDivMul_myl85_34 [label="[8, 300, 300]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_33" -> __myl_MaxrSubExpSumDivMul_myl85_34 [label="[8, 300, 300]\nFloat" color=red]
	__myl_MaxrSubExpSumDivMul_myl85_34 -> "/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_36" [label="[8, 300, 300]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_36" -> __myl_Tran_myl85_37 [label="[8, 300, 32]\nFloat" color=red]
	__myl_Tran_myl85_37 -> "/model/decoder/decoder/layers_0/self_attn/Gemm_myl85_38" [label="[300, 8, 32]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/Gemm_myl85_38" -> __myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_39 [label="[300, 256]\nFloat" color=red]
	__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_39 -> __myl_FcMulAdd_myl85_40 [label="[300, 256]\nInt8" color="#76b900"]
	__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_39 -> __myl_FcAdd_myl85_50 [label="[1, 300, 256]\nFloat" color=red]
	__myl_FcMulAdd_myl85_40 -> __myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_42 [label="[1, 300, 288]\nFloat" color=red]
	__myl_FcMulAdd_myl85_40 -> __myl_ReshMaxrSubExpSum_myl85_45 [label="[1, 300, 288]\nFloat" color=red]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_42 -> __myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_43 [label="[8, 300, 4, 2]\nFloat" color=red]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_42 -> __myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_43 [label="[8, 300, 4, 2]\nFloat" color=red]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_42 -> __myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_43 [label="[8, 300, 4, 2]\nFloat" color=red]
	__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_43 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_48 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_43 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_48 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_43 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_48 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_ReshMaxrSubExpSum_myl85_45 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_48 [label="[1, 300, 8, 12]\nFloat" color=red]
	__myl_ReshMaxrSubExpSum_myl85_45 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_48 [label="[1, 300, 8, 1]\nFloat" color=red]
	__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_48 -> __myl_Move_myl85_49 [label="[8, 32, 300, 1]\nInt8" color="#76b900"]
	__myl_Move_myl85_49 -> __myl_FcAdd_myl85_50 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_50 -> __myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_51 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_51 -> "/model/decoder/decoder/layers_0/linear1/MatMul_myl85_52" [label="[300, 256]\nInt8" color="#76b900"]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_51 -> __myl_FcAdd_myl85_53 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/linear1/MatMul_myl85_52" -> __myl_FcAdd_myl85_53 [label="[1, 300, 1024]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_53 -> __myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_54 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_54 -> "/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl85_57" [label="[300, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_54 -> __myl_Add_myl85_65 [label="[300, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_54 -> __myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_73 [label="[300, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_54 -> "/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl85_59" [label="[300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl85_57" -> "/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_70" [label="[300, 256]\nFloat" color=red]
	"/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl85_59" -> "/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl85_60" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl85_60" -> __myl_FcAddSigm_myl85_61 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcAddSigm_myl85_61 -> __myl_MulMinMaxRounConcCast_myl85_62 [label="[1, 300, 4]\nFloat" color=red]
	__myl_FcAddSigm_myl85_61 -> __myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_76 [label="[1, 300, 4]\nFloat" color=red]
	__myl_FcAddSigm_myl85_61 -> __myl_MaxMinSubMaxMinMaxMinDivLog_myl85_93 [label="[1, 300, 4]\nFloat" color=red]
	__myl_MulMinMaxRounConcCast_myl85_62 -> "/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl85_63" [label="[1, 300, 16]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl85_63" -> "/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_64" [label="[1, 300, 512]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_64" -> __myl_Add_myl85_65 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_64" -> __myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_73 [label="[1, 300, 256]\nFloat" color=red]
	__myl_Add_myl85_65 -> "/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_66" [label="[300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_66" -> "/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_67" [label="[2, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_66" -> "/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_67" [label="[2, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_67" -> __myl_MaxrSubExpSumDivMul_myl85_68 [label="[8, 300, 300]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_67" -> __myl_MaxrSubExpSumDivMul_myl85_68 [label="[8, 300, 300]\nFloat" color=red]
	__myl_MaxrSubExpSumDivMul_myl85_68 -> "/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_70" [label="[8, 300, 300]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_70" -> __myl_Tran_myl85_71 [label="[8, 300, 32]\nFloat" color=red]
	__myl_Tran_myl85_71 -> "/model/decoder/decoder/layers_1/self_attn/Gemm_myl85_72" [label="[300, 8, 32]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/self_attn/Gemm_myl85_72" -> __myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_73 [label="[300, 256]\nFloat" color=red]
	__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_73 -> __myl_FcMulAdd_myl85_74 [label="[300, 256]\nInt8" color="#76b900"]
	__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_73 -> __myl_FcAdd_myl85_84 [label="[1, 300, 256]\nFloat" color=red]
	__myl_FcMulAdd_myl85_74 -> __myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_76 [label="[1, 300, 288]\nFloat" color=red]
	__myl_FcMulAdd_myl85_74 -> __myl_ReshMaxrSubExpSum_myl85_79 [label="[1, 300, 288]\nFloat" color=red]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_76 -> __myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_77 [label="[8, 300, 4, 2]\nFloat" color=red]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_76 -> __myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_77 [label="[8, 300, 4, 2]\nFloat" color=red]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_76 -> __myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_77 [label="[8, 300, 4, 2]\nFloat" color=red]
	__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_77 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_82 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_77 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_82 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_77 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_82 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_ReshMaxrSubExpSum_myl85_79 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_82 [label="[1, 300, 8, 12]\nFloat" color=red]
	__myl_ReshMaxrSubExpSum_myl85_79 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_82 [label="[1, 300, 8, 1]\nFloat" color=red]
	__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_82 -> __myl_Move_myl85_83 [label="[8, 32, 300, 1]\nInt8" color="#76b900"]
	__myl_Move_myl85_83 -> __myl_FcAdd_myl85_84 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_84 -> __myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_85 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_85 -> "/model/decoder/decoder/layers_1/linear1/MatMul_myl85_86" [label="[300, 256]\nInt8" color="#76b900"]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_85 -> __myl_FcAdd_myl85_87 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/linear1/MatMul_myl85_86" -> __myl_FcAdd_myl85_87 [label="[1, 300, 1024]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_87 -> __myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_88 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_88 -> "/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl85_91" [label="[300, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_88 -> __myl_Add_myl85_100 [label="[300, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_88 -> __myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_108 [label="[300, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_88 -> "/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl85_94" [label="[300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl85_91" -> "/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_105" [label="[300, 256]\nFloat" color=red]
	__myl_MaxMinSubMaxMinMaxMinDivLog_myl85_93 -> __myl_FcAddSigm_myl85_96 [label="[1, 300, 4]\nFloat" color=red]
	"/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl85_94" -> "/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl85_95" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl85_95" -> __myl_FcAddSigm_myl85_96 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcAddSigm_myl85_96 -> __myl_MulMinMaxRounConcCast_myl85_97 [label="[1, 300, 4]\nFloat" color=red]
	__myl_FcAddSigm_myl85_96 -> __myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_111 [label="[1, 300, 4]\nFloat" color=red]
	__myl_FcAddSigm_myl85_96 -> __myl_MaxMinSubMaxMinMaxMinDivLog_myl85_130 [label="[1, 300, 4]\nFloat" color=red]
	__myl_MulMinMaxRounConcCast_myl85_97 -> "/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl85_98" [label="[1, 300, 16]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl85_98" -> "/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_99" [label="[1, 300, 512]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_99" -> __myl_Add_myl85_100 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_99" -> __myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_108 [label="[1, 300, 256]\nFloat" color=red]
	__myl_Add_myl85_100 -> "/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_101" [label="[300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_101" -> "/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_102" [label="[2, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_101" -> "/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_102" [label="[2, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_102" -> __myl_MaxrSubExpSumDivMul_myl85_103 [label="[8, 300, 300]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_102" -> __myl_MaxrSubExpSumDivMul_myl85_103 [label="[8, 300, 300]\nFloat" color=red]
	__myl_MaxrSubExpSumDivMul_myl85_103 -> "/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_105" [label="[8, 300, 300]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_105" -> __myl_Tran_myl85_106 [label="[8, 300, 32]\nFloat" color=red]
	__myl_Tran_myl85_106 -> "/model/decoder/decoder/layers_2/self_attn/Gemm_myl85_107" [label="[300, 8, 32]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/self_attn/Gemm_myl85_107" -> __myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_108 [label="[300, 256]\nFloat" color=red]
	__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_108 -> __myl_FcMulAdd_myl85_109 [label="[300, 256]\nInt8" color="#76b900"]
	__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_108 -> __myl_FcAdd_myl85_119 [label="[1, 300, 256]\nFloat" color=red]
	__myl_FcMulAdd_myl85_109 -> __myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_111 [label="[1, 300, 288]\nFloat" color=red]
	__myl_FcMulAdd_myl85_109 -> __myl_ReshMaxrSubExpSum_myl85_114 [label="[1, 300, 288]\nFloat" color=red]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_111 -> __myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_112 [label="[8, 300, 4, 2]\nFloat" color=red]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_111 -> __myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_112 [label="[8, 300, 4, 2]\nFloat" color=red]
	__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_111 -> __myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_112 [label="[8, 300, 4, 2]\nFloat" color=red]
	__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_112 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_117 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_112 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_117 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_112 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_117 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_ReshMaxrSubExpSum_myl85_114 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_117 [label="[1, 300, 8, 12]\nFloat" color=red]
	__myl_ReshMaxrSubExpSum_myl85_114 -> __myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_117 [label="[1, 300, 8, 1]\nFloat" color=red]
	__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_117 -> __myl_Move_myl85_118 [label="[8, 32, 300, 1]\nInt8" color="#76b900"]
	__myl_Move_myl85_118 -> __myl_FcAdd_myl85_119 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_119 -> __myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_120 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_120 -> "/model/decoder/decoder/layers_2/linear1/MatMul_myl85_121" [label="[300, 256]\nInt8" color="#76b900"]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_120 -> __myl_FcAdd_myl85_122 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/linear1/MatMul_myl85_121" -> __myl_FcAdd_myl85_122 [label="[1, 300, 1024]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_122 -> __myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_123 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_123 -> "/model/decoder/decoder/dec_score_head_2/MatMul_myl85_126" [label="[300, 256]\nInt8" color="#76b900"]
	__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_123 -> "/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl85_131" [label="[300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_score_head_2/MatMul_myl85_126" -> __myl_GathSigmResh_myl85_127 [label="[1, 300, 80]\nFloat" color=red]
	__myl_GathSigmResh_myl85_127 -> __myl_Topk_myl85_128 [label="[1, 24000]\nFloat" color=red]
	__myl_Topk_myl85_128 -> scores [label="[1, 300]\nFloat" color=red]
	__myl_Topk_myl85_128 -> __myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl85_135 [label="[1, 300]\nInt32" color=lightgray]
	__myl_MaxMinSubMaxMinMaxMinDivLog_myl85_130 -> __myl_FcAddSigm_myl85_133 [label="[1, 300, 4]\nFloat" color=red]
	"/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl85_131" -> "/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl85_132" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl85_132" -> __myl_FcAddSigm_myl85_133 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcAddSigm_myl85_133 -> __myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl85_135 [label="[1, 300, 4]\nFloat" color=red]
	orig_target_sizes -> __myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl85_135 [label="[1, 2]\nInt64" color=gray]
	__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl85_135 -> boxes [label="[1, 300, 4]\nFloat" color=red]
	__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl85_135 -> labels [label="[1, 300]\nInt64" color=gray]
	"__myln_k_arg__bb1_5.0" -> "__myln_k_arg__bb1_5.1" [label="[1, 256, 80, 80]\nFloat" color=red]
	"__myln_k_arg__bb1_8.0" -> "__myln_k_arg__bb1_8.1" [label="[1, 256, 40, 40]\nFloat" color=red]
	"__myln_k_arg__bb1_10.0" -> "__myln_k_arg__bb1_10.1" [label="[1, 1600, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_14.0" -> "__myln_k_arg__bb1_14.1" [label="[1, 8400, 256]\nFloat" color=red]
	"__myln_k_arg__bb1_15.0" -> "__myln_k_arg__bb1_15.1" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_16.0" -> "__myln_k_arg__bb1_16.1" [label="[1, 8400, 256]\nFloat" color=red]
	"__myln_k_arg__bb1_17.0" -> "__myln_k_arg__bb1_17.1" [label="[1, 8400, 80]\nFloat" color=red]
}
