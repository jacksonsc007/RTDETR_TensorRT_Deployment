{"Layers": [{
  "Name": "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "images",
    "Location": "Device",
    "Dimensions": [1,3,640,640],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,3,640,640],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,3,640,640],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 864},
  "Bias": {"Type": "Float", "Count": 32},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_first_layer_i8i8_i8i32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_vect_c_32_tilesize8x16x32x32_stage1_warpsize4x1x1_tensor16x8x16_r3s3_u2v2_aligna4_alignc8",
  "TacticValue": "0x5cc792a989a1d1a6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/conv/Conv]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/act/Relu]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 9216},
  "Bias": {"Type": "Float", "Count": 32},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3",
  "TacticValue": "0x13463e9bf9ae0d73",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/Conv]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/act/Relu]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/MaxPool_output_0",
    "Location": "Device",
    "Dimensions": [1,64,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 18432},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x9dafb2758560cc1d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/Conv]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/backbone/MaxPool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/MaxPool_output_0",
    "Location": "Device",
    "Dimensions": [1,64,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/MaxPool]"
},{
  "Name": "model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x9dafb2758560cc1d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xb936321f82fd390c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 4096},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x9dafb2758560cc1d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x0e07dc8353bf7e9f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_UP",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 0,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE",
  "TacticValue": "0xd9375d43b61ffbcb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x705baf38e41eee0b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x2d8ab2aa0639fda9",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 8192},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x128x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x214f03e23f252333",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xad886d4d69834922",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_UP",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 0,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE",
  "TacticValue": "0xd9375d43b61ffbcb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 294912},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xbb88763c3b0e94d4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x2d8ab2aa0639fda9",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xbb88763c3b0e94d4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x2d8ab2aa0639fda9",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_UP",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 0,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE",
  "TacticValue": "0xd9375d43b61ffbcb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1179648},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32",
  "TacticValue": "0x322f337abc345152",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x45f7566cdb2b10fb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 131072},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x65fbe45b4cb1d8a5",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x64x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x1d53511430a5d47e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x45f7566cdb2b10fb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/act/Relu]"
},{
  "Name": "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 131072},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x5e4f6d7c83746fd6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "__myl_MulAddReshTran_myl37_0",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/Conv_output_0",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_1_first_transpose_output.1",
    "Dimensions": [400,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_3",
    "Dimensions": [1,256,400],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MulAddReshTran_0xd7f3d1e2cc547844932d70a8482ece2b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.2/norm/BatchNormalization]\u001f[ONNX Layer: /model/encoder/Reshape]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1]"
},{
  "Name": "__mye8928_myl37_1",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 1,
  "Metadata": ""
},{
  "Name": "__myl_TranAdd_myl37_2",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_3",
    "Dimensions": [1,256,400],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/Add_output_0'.1",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_5",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_TranAdd_0x1978cdfef91c73468af87ff188a514d1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Transpose]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/Add]"
},{
  "Name": "__mye8930_myl37_3",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 1,
  "Metadata": ""
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl37_4",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_1_first_transpose_output.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_2]"
},{
  "Name": "__mye8932_myl37_5",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 2,
  "Metadata": ""
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl37_6",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/Add_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye8674",
    "Dimensions": [2,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add]"
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_3_myl37_7",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye8674",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8674",
    "Dimensions": [8,32,400],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [8,400,400],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Mul_1]"
},{
  "Name": "__myl_MaxrSubExpSumDivMul_myl37_8",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [8,400,400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [8,400,400],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_output_0'.1_9",
    "Dimensions": [8,400,400],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxrSubExpSumDivMul_0x954ecab20dc21ebdd768d1792fae06d0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Softmax]"
},{
  "Name": "__mye8934_myl37_9",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 2,
  "Metadata": ""
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_myl37_10",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_output_0'.1_9",
    "Dimensions": [8,400,400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4]"
},{
  "Name": "__myl_Tran_myl37_11",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_5 _ /model/encoder/encoder_0/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [400,8,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Tran_0xa9ca448ca989e446f5b6e9b30bb6066d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5]\u001e[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3]"
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl37_12",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_5 _ /model/encoder/encoder_0/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Gemm]"
},{
  "Name": "__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl37_13",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_5",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_0x2246f3c023a9f5ff447ed70eb8e74db6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/encoder/encoder_0/layers_0/linear1/MatMul_myl37_14",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,400,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_gelu_erf",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Add]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Div]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Erf]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/Add]"
},{
  "Name": "__myl_FcAdd_myl37_15",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,400,1024],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_16",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_2]"
},{
  "Name": "__myl_ReshMeanSubMulMean_myl37_16",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_16",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_18",
    "Dimensions": [400,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshMeanSubMulMean_0x026cdf70f904432fa7f9c6571177934a",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]"
},{
  "Name": "__myl_AddSqrtDivMulMulAddReshTran_myl37_17",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_18",
    "Dimensions": [400,1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Reshape_1_output_0",
    "Dimensions": [1,256,400],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddSqrtDivMulMulAddReshTran_0xce5ab2216ddcc262589c56ed29409629",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]\u001f[ONNX Layer: /model/encoder/Transpose_1]\u001e[ONNX Layer: /model/encoder/Reshape_1]"
},{
  "Name": "model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x483ad1560c6e5e27",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/input_proj.0/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x483ad1560c6e5e27",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/input_proj.1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Reshape_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x5e4f6d7c83746fd6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Output Tensor 0 to PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);"],
  "TacticValue": "0x0000000000000005",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/act/Mul]"
},{
  "Name": "Reformatting CopyNode for Output Tensor 0 to PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Output Tensor 0 to PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/act/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/act/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Resize_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/encoder/Resize",
  "LayerType": "Resize",
  "Inputs": [
  {
    "Name": "/model/encoder/Resize_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Resize",
  "InterpolationMode": "NEAREST",
  "ResizeScales": [1, 1, 2, 2, 0, 0, 0, 0],
  "ExcludeOutside": 0,
  "CubicCoeff": -0.75,
  "CoordTransform": "kASYMMETRIC",
  "ResizeSelector": "kFORMULA",
  "NNRounding": "kFLOOR",
  "TacticValue": "0x0000000000000005",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Resize]"
},{
  "Name": "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Concat_2]"
},{
  "Name": "model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x9ec201b34455146e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc722efd60bc6ea84",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc722efd60bc6ea84",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x45f7566cdb2b10fb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  },
  {
    "Name": "/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/Add]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Mul]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Resize_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/Resize_1",
  "LayerType": "Resize",
  "Inputs": [
  {
    "Name": "/model/encoder/Resize_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Resize",
  "InterpolationMode": "NEAREST",
  "ResizeScales": [1, 1, 2, 2, 0, 0, 0, 0],
  "ExcludeOutside": 0,
  "CubicCoeff": -0.75,
  "CoordTransform": "kASYMMETRIC",
  "ResizeSelector": "kFORMULA",
  "NNRounding": "kFLOOR",
  "TacticValue": "0x0000000000000005",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Resize_1]"
},{
  "Name": "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Concat_3]"
},{
  "Name": "model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x7720f198395e7d3d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x458f02d2b10db57c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xfdf7509af98902e0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xfdf7509af98902e0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x2d8ab2aa0639fda9",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  },
  {
    "Name": "/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x000000000000001a",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/Add]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x65a38dbc9e991257",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Mul]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.0/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x733ba2a91a48d431",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc722efd60bc6ea84",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/Resize_1_output_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Resize_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Concat_4]"
},{
  "Name": "model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x9ec201b34455146e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc722efd60bc6ea84",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc722efd60bc6ea84",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x45f7566cdb2b10fb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  },
  {
    "Name": "/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/Add]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Mul]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.1/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x733ba2a91a48d431",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc985777c89c6b3a4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/act/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0xc6cdb1e47323bb01",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc985777c89c6b3a4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc985777c89c6b3a4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xd14bd6d95fefd45e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  },
  {
    "Name": "/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/Add]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0xc6cdb1e47323bb01",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Mul]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x5e4f6d7c83746fd6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/Conv]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "entry^bb^signal^1_myl85_0",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 19,
  "Metadata": ""
},{
  "Name": "entry^bb^wait^1_myl85_1",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 19,
  "Metadata": ""
},{
  "Name": "__myl_MulAddReshMulMinMaxRounCastTran_myl85_2",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/input_proj.0/conv/Conv_output_0",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_6",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_5",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MulAddReshMulMinMaxRounCastTran_0x459d65282c25a1537bcc80e4552f8190",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.0/norm/BatchNormalization]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape]\u001e[ONNX Layer: /model/decoder/Transpose]"
},{
  "Name": "__myl_MulMinMaxRounCastReshTran_myl85_3",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_5",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_7",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRounCastReshTran_0x783660148271f95371b9bc4f4d2bb040",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape]\u001e[ONNX Layer: /model/decoder/Transpose]"
},{
  "Name": "__myl_MulAddReshMulMinMaxRounCastTran_myl85_4",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/input_proj.1/conv/Conv_output_0",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MulAddReshMulMinMaxRounCastTran_0x3ce367effa63c510276f5de98da8e392",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.1/norm/BatchNormalization]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape_1]\u001e[ONNX Layer: /model/decoder/Transpose_1]"
},{
  "Name": "__myl_MulMinMaxRounCastReshTran_myl85_5",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRounCastReshTran_0xfe5454bfee8c5d0486ec8f4142dd2b5d",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape_1]\u001e[ONNX Layer: /model/decoder/Transpose_1]"
},{
  "Name": "__mye153328_myl85_6",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 1,
  "Metadata": ""
},{
  "Name": "__mye153330_myl85_7",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 1,
  "Metadata": ""
},{
  "Name": "__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_myl85_8",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_7",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_6",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "/model/decoder/input_proj.2/conv/Conv_output_0",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye150462_12",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulAddMulMinMaxRounCastReshReshTranMulMinMaxRounCastTranConcConc_0xc0b1b0b8ff66928228e54fb74ec8a45e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.2/norm/BatchNormalization]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Concat_3]\u001f[ONNX Layer: /model/decoder/Reshape_2]\u001e[ONNX Layer: /model/decoder/Transpose_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye153332_myl85_9",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 2,
  "Metadata": ""
},{
  "Name": "__mye153334_myl85_10",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 2,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_11",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye150462_12",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__mye150462",
    "Dimensions": [3,8400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add]"
},{
  "Name": "/model/decoder/enc_output/proj/MatMul_myl85_12",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_output/proj/MatMul]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_output/proj/Add]"
},{
  "Name": "__myl_MeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_13",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_16",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_0x2f9cc7962385301203cd2db1b02ed7ec",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_output/norm/LayerNormalization]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye153336_myl85_14",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 3,
  "Metadata": ""
},{
  "Name": "__mye153338_myl85_15",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 3,
  "Metadata": ""
},{
  "Name": "/model/decoder/enc_score_head/MatMul_myl85_16",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [1,8400,80],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/enc_score_head/MatMul]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_score_head/Add]"
},{
  "Name": "__myl_Maxr_myl85_17",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [1,8400,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/ReduceMax_output_0'_unsqueezed0.1",
    "Dimensions": [1,8400,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Maxr_0x45757ac352af2ed0058c336edc12ba60",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/ReduceMax]"
},{
  "Name": "__myl_Topk_myl85_18",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/ReduceMax_output_0'_unsqueezed0.1",
    "Dimensions": [1,8400],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/TopK_output_0'.1",
    "Dimensions": [1,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_20",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  }],
  "TacticName": "__myl_Topk_0x2bbfb8ea621d6367d9edfe76c21438e4",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/TopK]"
},{
  "Name": "__mye153340_myl85_19",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 4,
  "Metadata": ""
},{
  "Name": "/model/decoder/enc_bbox_head/layers_0/MatMul_myl85_20",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/enc_bbox_head/layers_2/input_quantizer/QuantizeLinear_output_0'.1_21",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/act/Relu]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/Add]"
},{
  "Name": "/model/decoder/enc_bbox_head/layers_1/MatMul_myl85_21",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/enc_bbox_head/layers_2/input_quantizer/QuantizeLinear_output_0'.1_21",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_22",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/act_1/Relu]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/Add]"
},{
  "Name": "__myl_FcAdd_myl85_22",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_22",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_23",
    "Dimensions": [1,8400,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/Add]\u001f[ONNX Layer: /model/decoder/Add]"
},{
  "Name": "__mye153342_myl85_23",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 4,
  "Metadata": ""
},{
  "Name": "__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_myl85_24",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_20",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_23",
    "Dimensions": [1,8400,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_24",
    "Dimensions": [1,300,1],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_27",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_26",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_25",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_CastReshCastReplGathSigmMaxMinMulMinMaxRounConcCastMaxSubMinMaxMinDivLog_0x87091167bd6c2281e86f5f452041128e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/GatherElements]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/Log]\u001f[ONNX Layer: /model/decoder/decoder/Div]\u001f[ONNX Layer: /model/decoder/decoder/Sub]\u001f[ONNX Layer: /model/decoder/decoder/Clip]\u001f[ONNX Layer: /model/decoder/Unsqueeze]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl85_25",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_26",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1_28",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_26",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1_28",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/Add]"
},{
  "Name": "__myl_ReplGathReshAdd_myl85_27",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_16",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_24",
    "Dimensions": [1,300,1],
    "Format/Datatype": "Int32"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/GatherElements_1_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReplGathReshAdd_0x177016a333c1e0c029a20cc81ca838c0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/GatherElements_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/Add]"
},{
  "Name": "__mye153344_myl85_28",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 5,
  "Metadata": ""
},{
  "Name": "__mye153346_myl85_29",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 5,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl85_30",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/GatherElements_1_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_2]"
},{
  "Name": "__mye153348_myl85_31",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 6,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_32",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye150447",
    "Dimensions": [2,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add]"
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_33",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye150447",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150447",
    "Dimensions": [8,32,300],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_34",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Mul_1]"
},{
  "Name": "__myl_MaxrSubExpSumDivMul_myl85_34",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_34",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_34",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_4_output_0'.1_35",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxrSubExpSumDivMul_0xe7d314cc73dbf705f429f8278ab30c57",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Softmax]"
},{
  "Name": "__mye153350_myl85_35",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 6,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_36",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_4_output_0'.1_35",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_36",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_4]"
},{
  "Name": "__myl_Tran_myl85_37",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_36",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Transpose_5 _ /model/decoder/decoder/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,8,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Tran_0x812a618d2f6da6e0d008691c870cb2b7",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Transpose_5]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Reshape_3]"
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/Gemm_myl85_38",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Transpose_5 _ /model/decoder/decoder/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Gemm]"
},{
  "Name": "__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_39",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/GatherElements_1_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_40",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_0x69dd74bed63b6785a6f736aca73a15a6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/norm1/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_FcMulAdd_myl85_40",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__mye150423mul_beta",
    "Dimensions": [1,300,288],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add]"
},{
  "Name": "__mye153352_myl85_41",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 7,
  "Metadata": ""
},{
  "Name": "__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_42",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_25",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150423mul_beta",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_44",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_43",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_42",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_0x1ba079c73dc7098ecd7f49a50270a387",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Sub]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_1]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Split]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8]"
},{
  "Name": "__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_43",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_44",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_43",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_42",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150462",
    "Dimensions": [1,8400,8,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_47",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_46",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_45",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_0x4671ed411a6bb6a8da5e34e92e03761d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_7]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_8]"
},{
  "Name": "__mye153354_myl85_44",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 7,
  "Metadata": ""
},{
  "Name": "__myl_ReshMaxrSubExpSum_myl85_45",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye150423mul_beta",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_49",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_48",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshMaxrSubExpSum_0xf2da65babbfdba9319fb6fef7954bb4f",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]"
},{
  "Name": "__mye153356_myl85_46",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 8,
  "Metadata": ""
},{
  "Name": "__mye153358_myl85_47",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 8,
  "Metadata": ""
},{
  "Name": "__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_48",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_48",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_45",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_46",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_47",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_49",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye147331_q8",
    "Dimensions": [8,32,300,1],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_0xf0d0ce15ea4ff3463060538d679df965",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_2]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_9]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Concat_10]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/ReduceSum]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_8]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_Move_myl85_49",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye147331_q8",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_51",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_Move_0xe44b2845ee5a2c900106157eaed1d520",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]"
},{
  "Name": "__myl_FcAdd_myl85_50",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_40",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_51",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_52",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/Add_3]"
},{
  "Name": "__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_51",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_52",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_54",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_0x9a04d543e7c3b3f716fb221e2f203132",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/norm2/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_0/linear1/MatMul_myl85_52",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_55",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/linear1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/activation/Relu]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/Add]"
},{
  "Name": "__myl_FcAdd_myl85_53",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_54",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_55",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_56",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/linear2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/Add_4]"
},{
  "Name": "__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_54",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_56",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_0x1b4b77686f41c45144fdfff1c09c0d9b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye153360_myl85_55",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 9,
  "Metadata": ""
},{
  "Name": "__mye153362_myl85_56",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 9,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl85_57",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Add_2_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_2]"
},{
  "Name": "__mye153364_myl85_58",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 10,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl85_59",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/input_quantizer/QuantizeLinear_output_0'.1_60",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl85_60",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/input_quantizer/QuantizeLinear_output_0'.1_60",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_61",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add]"
},{
  "Name": "__myl_FcAddSigm_myl85_61",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_27",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_61",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_62",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add]\u001f[ONNX Layer: /model/decoder/decoder/Add]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid_1]"
},{
  "Name": "__myl_MulMinMaxRounConcCast_myl85_62",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_62",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/input_quantizer_1/QuantizeLinear_output_0'.1_63",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRounConcCast_0x7ef7115f49fa122439bd1412238d61ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl85_63",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/input_quantizer_1/QuantizeLinear_output_0'.1_63",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1_64",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/Add]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_64",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1_64",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/Add]"
},{
  "Name": "__myl_Add_myl85_65",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Add_0xb0206d942e687a41bd32a2b95ff44f68",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/Add]"
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_66",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye150360",
    "Dimensions": [2,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add]"
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_67",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye150360",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150360",
    "Dimensions": [8,32,300],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_68",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Mul_1]"
},{
  "Name": "__myl_MaxrSubExpSumDivMul_myl85_68",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_68",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_68",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_4_output_0'.1_69",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxrSubExpSumDivMul_0xe7d314cc73dbf705f429f8278ab30c57",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Softmax]"
},{
  "Name": "__mye153366_myl85_69",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 10,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_70",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_4_output_0'.1_69",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_70",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_4]"
},{
  "Name": "__myl_Tran_myl85_71",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_70",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Transpose_5 _ /model/decoder/decoder/layers_1/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,8,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Tran_0x812a618d2f6da6e0d008691c870cb2b7",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Transpose_5]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Reshape_3]"
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/Gemm_myl85_72",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Transpose_5 _ /model/decoder/decoder/layers_1/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Gemm_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Gemm]"
},{
  "Name": "__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_73",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_74",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_0x2bacafd8f052a09e462b3d296a6b34c7",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/norm1/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_FcMulAdd_myl85_74",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__mye150336mul_beta",
    "Dimensions": [1,300,288],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add]"
},{
  "Name": "__mye153368_myl85_75",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 11,
  "Metadata": ""
},{
  "Name": "__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_76",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_62",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150336mul_beta",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_78",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_77",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_76",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_0x1ba079c73dc7098ecd7f49a50270a387",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Sub]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_1]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Split]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8]"
},{
  "Name": "__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_77",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_78",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_77",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_76",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150462",
    "Dimensions": [1,8400,8,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_81",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_80",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_79",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_0x4671ed411a6bb6a8da5e34e92e03761d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_7]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_8]"
},{
  "Name": "__mye153370_myl85_78",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 11,
  "Metadata": ""
},{
  "Name": "__myl_ReshMaxrSubExpSum_myl85_79",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye150336mul_beta",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_83",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_82",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshMaxrSubExpSum_0xf2da65babbfdba9319fb6fef7954bb4f",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]"
},{
  "Name": "__mye153372_myl85_80",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 12,
  "Metadata": ""
},{
  "Name": "__mye153374_myl85_81",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 12,
  "Metadata": ""
},{
  "Name": "__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_82",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_82",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_79",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_80",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_81",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_83",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye147337_q8",
    "Dimensions": [8,32,300,1],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_0xf0d0ce15ea4ff3463060538d679df965",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_2]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_9]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Concat_10]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/ReduceSum]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_Move_myl85_83",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye147337_q8",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_85",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_Move_0xe44b2845ee5a2c900106157eaed1d520",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]"
},{
  "Name": "__myl_FcAdd_myl85_84",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_74",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_85",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_86",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/Add_3]"
},{
  "Name": "__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_85",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_86",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_88",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_0x9a04d543e7c3b3f716fb221e2f203132",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/norm2/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_1/linear1/MatMul_myl85_86",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_89",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/linear1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/activation/Relu]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/Add]"
},{
  "Name": "__myl_FcAdd_myl85_87",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_88",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_89",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_90",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/linear2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/Add_4]"
},{
  "Name": "__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_88",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_90",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_0x1b4b77686f41c45144fdfff1c09c0d9b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye153376_myl85_89",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 13,
  "Metadata": ""
},{
  "Name": "__mye153378_myl85_90",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 13,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl85_91",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Add_2_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_2]"
},{
  "Name": "__mye153380_myl85_92",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 14,
  "Metadata": ""
},{
  "Name": "__myl_MaxMinSubMaxMinMaxMinDivLog_myl85_93",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_62",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_94",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxMinSubMaxMinMaxMinDivLog_0x0fb4f0d98d09dda9f624bf65aecc1fdd",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/Log_1]\u001f[ONNX Layer: /model/decoder/decoder/Div_1]\u001f[ONNX Layer: /model/decoder/decoder/Sub_1]\u001f[ONNX Layer: /model/decoder/decoder/Clip_3]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl85_94",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/input_quantizer/QuantizeLinear_output_0'.1_95",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl85_95",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/input_quantizer/QuantizeLinear_output_0'.1_95",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_96",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add]"
},{
  "Name": "__myl_FcAddSigm_myl85_96",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_94",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_96",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_97",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add]\u001f[ONNX Layer: /model/decoder/decoder/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid_2]"
},{
  "Name": "__myl_MulMinMaxRounConcCast_myl85_97",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_97",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/input_quantizer_2/QuantizeLinear_output_0'.1_98",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRounConcCast_0x7ef7115f49fa122439bd1412238d61ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl85_98",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/input_quantizer_2/QuantizeLinear_output_0'.1_98",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1_99",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act_2/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/Add]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_99",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1_99",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/Add]"
},{
  "Name": "__myl_Add_myl85_100",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Add_0xb0206d942e687a41bd32a2b95ff44f68",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/Add]"
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_101",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye150273",
    "Dimensions": [2,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add]"
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_102",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye150273",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150273",
    "Dimensions": [8,32,300],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_103",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Mul_1]"
},{
  "Name": "__myl_MaxrSubExpSumDivMul_myl85_103",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_103",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_103",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_4_output_0'.1_104",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxrSubExpSumDivMul_0xe7d314cc73dbf705f429f8278ab30c57",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Softmax]"
},{
  "Name": "__mye153382_myl85_104",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 14,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_105",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_4_output_0'.1_104",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_105",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_4]"
},{
  "Name": "__myl_Tran_myl85_106",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_105",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Transpose_5 _ /model/decoder/decoder/layers_2/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,8,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Tran_0x812a618d2f6da6e0d008691c870cb2b7",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Transpose_5]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Reshape_3]"
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/Gemm_myl85_107",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Transpose_5 _ /model/decoder/decoder/layers_2/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Gemm_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Gemm]"
},{
  "Name": "__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_myl85_108",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_109",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshAddReshMeanSubMulMeanAddSqrtDivMulMulAddReshAddMulMinMaxRounCast_0x2bacafd8f052a09e462b3d296a6b34c7",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/norm1/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_FcMulAdd_myl85_109",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__mye150249mul_beta",
    "Dimensions": [1,300,288],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add]"
},{
  "Name": "__mye153384_myl85_110",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 15,
  "Metadata": ""
},{
  "Name": "__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_myl85_111",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_97",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150249mul_beta",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_113",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_112",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_111",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshSlicSlicReshMulMulMulAddMulAddTranReshSlicSlicSlic_0x1ba079c73dc7098ecd7f49a50270a387",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Sub]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_1]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Split]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8]"
},{
  "Name": "__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_myl85_112",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_113",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_112",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_111",
    "Dimensions": [8,300,4,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150462",
    "Dimensions": [1,8400,8,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_116",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_115",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_114",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_TranReshMoveSlicReshSlicReshSlicReshGridGridGrid_0x4671ed411a6bb6a8da5e34e92e03761d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_7]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_8]"
},{
  "Name": "__mye153386_myl85_113",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 15,
  "Metadata": ""
},{
  "Name": "__myl_ReshMaxrSubExpSum_myl85_114",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye150249mul_beta",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_118",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_117",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshMaxrSubExpSum_0xf2da65babbfdba9319fb6fef7954bb4f",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]"
},{
  "Name": "__mye153388_myl85_115",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 16,
  "Metadata": ""
},{
  "Name": "__mye153390_myl85_116",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 16,
  "Metadata": ""
},{
  "Name": "__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_myl85_117",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_117",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_114",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_115",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_116",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_118",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye147343_q8",
    "Dimensions": [8,32,300,1],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_DivMulTranReshConcMulSumMulMinMaxRounCast_0xf0d0ce15ea4ff3463060538d679df965",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_2]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_9]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Concat_10]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/ReduceSum]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_Move_myl85_118",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye147343_q8",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_120",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_Move_0xe44b2845ee5a2c900106157eaed1d520",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]"
},{
  "Name": "__myl_FcAdd_myl85_119",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_109",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_120",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_121",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/Add_3]"
},{
  "Name": "__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_myl85_120",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_121",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_123",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddReshMulMinMaxRounCast_0x9a04d543e7c3b3f716fb221e2f203132",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/norm2/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_2/linear1/MatMul_myl85_121",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_124",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/linear1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/activation/Relu]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/Add]"
},{
  "Name": "__myl_FcAdd_myl85_122",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_123",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_124",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_125",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/linear2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/Add_4]"
},{
  "Name": "__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_myl85_123",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_125",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_ReshMeanSubMulMeanAddSqrtDivMulMulAddMulMinMaxRounCast_0xdbf5fe7187fbdeb24bfb2dcd48012c78",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye153392_myl85_124",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 17,
  "Metadata": ""
},{
  "Name": "__mye153394_myl85_125",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 17,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/dec_score_head_2/MatMul_myl85_126",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_score_head_2/Add_output_0'.1",
    "Dimensions": [1,300,80],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_score_head.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_score_head.2/Add]"
},{
  "Name": "__myl_GathSigmResh_myl85_127",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_score_head_2/Add_output_0'.1",
    "Dimensions": [1,1,300,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_128",
    "Dimensions": [1,24000],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_GathSigmResh_0x983551a631bdccd1905654f55e50a7e4",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /postprocessor/Flatten]\u001f[ONNX Layer: /postprocessor/Sigmoid]\u001f[ONNX Layer: /model/decoder/Gather_8]"
},{
  "Name": "__myl_Topk_myl85_128",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_128",
    "Dimensions": [1,24000],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "scores",
    "Dimensions": [1,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_130",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  }],
  "TacticName": "__myl_Topk_0x46004755f860a677c07469a83ee8bc45",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /postprocessor/TopK]"
},{
  "Name": "__mye153396_myl85_129",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "EventId": 18,
  "Metadata": ""
},{
  "Name": "__myl_MaxMinSubMaxMinMaxMinDivLog_myl85_130",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_97",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_131",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxMinSubMaxMinMaxMinDivLog_0x0fb4f0d98d09dda9f624bf65aecc1fdd",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/Log_2]\u001f[ONNX Layer: /model/decoder/decoder/Div_2]\u001f[ONNX Layer: /model/decoder/decoder/Sub_2]\u001f[ONNX Layer: /model/decoder/decoder/Clip_6]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl85_131",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/input_quantizer/QuantizeLinear_output_0'.1_132",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl85_132",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/input_quantizer/QuantizeLinear_output_0'.1_132",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_133",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add]"
},{
  "Name": "__myl_FcAddSigm_myl85_133",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_131",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_133",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_134",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add]\u001f[ONNX Layer: /model/decoder/decoder/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid_3]"
},{
  "Name": "__mye153398_myl85_134",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "EventId": 18,
  "Metadata": ""
},{
  "Name": "__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_myl85_135",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_134",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_130",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "orig_target_sizes",
    "Dimensions": [1,2],
    "Format/Datatype": "Int64"
  }],
  "Outputs": [
  {
    "Name": "boxes",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "labels",
    "Dimensions": [1,300],
    "Format/Datatype": "Int64"
  }],
  "TacticName": "__myl_ReplReshCastCastDivReshCastReplMulSubReshGathSlicReshSlicReshSlicReshSlicReshMulAddReshSubEtc_0x1e340078e2dfe6c4366f77078054d7f7",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /postprocessor/Tile]\u001f[ONNX Layer: /postprocessor/Unsqueeze_4]\u001f[ONNX Layer: /postprocessor/Div]\u001f[ONNX Layer: /postprocessor/Sub_2]\u001f[ONNX Layer: /postprocessor/Mul_3]\u001f[ONNX Layer: /postprocessor/Squeeze_3]\u001f[ONNX Layer: /postprocessor/Mul_1]\u001f[ONNX Layer: /postprocessor/Sub_1]\u001f[ONNX Layer: /postprocessor/Unsqueeze_1]\u001f[ONNX Layer: /postprocessor/Squeeze]\u001f[ONNX Layer: /postprocessor/Add_1]\u001f[ONNX Layer: /postprocessor/Unsqueeze_3]\u001f[ONNX Layer: /postprocessor/Unsqueeze_5]\u001f[ONNX Layer: /postprocessor/GatherElements]\u001f[ONNX Layer: /postprocessor/Mul_2]\u001f[ONNX Layer: /postprocessor/Concat]\u001f[ONNX Layer: /postprocessor/Unsqueeze]\u001f[ONNX Layer: /postprocessor/Sub]\u001f[ONNX Layer: /postprocessor/Unsqueeze_2]\u001f[ONNX Layer: /postprocessor/Add]\u001f[ONNX Layer: /postprocessor/Mul]\u001f[ONNX Layer: /postprocessor/Squeeze_2]\u001f[ONNX Layer: /postprocessor/Squeeze_1]\u001f[ONNX Layer: /postprocessor/Split]\u001f[ONNX Layer: /model/decoder/Gather_9]\u001f[ONNX Layer: /model/decoder/decoder/Unsqueeze_3]\u001f[ONNX Layer: Cast_3039]"
}],
"Bindings": ["images"
,"orig_target_sizes"
,"labels"
,"boxes"
,"scores"
]}
