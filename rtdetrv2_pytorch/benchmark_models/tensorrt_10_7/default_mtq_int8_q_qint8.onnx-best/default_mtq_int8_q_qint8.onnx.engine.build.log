&&&& RUNNING TensorRT.trtexec [TensorRT v100700] [b23] # trtexec --verbose --onnx=default_mtq_int8_q_qint8.onnx --saveEngine=tensorrt_10_7/default_mtq_int8_q_qint8.onnx-best/default_mtq_int8_q_qint8.onnx.engine --exportLayerInfo=tensorrt_10_7/default_mtq_int8_q_qint8.onnx-best/default_mtq_int8_q_qint8.onnx.engine.graph.json --timingCacheFile=./timing.cache --profilingVerbosity=detailed --best
[05/21/2025-09:28:07] [I] === Model Options ===
[05/21/2025-09:28:07] [I] Format: ONNX
[05/21/2025-09:28:07] [I] Model: default_mtq_int8_q_qint8.onnx
[05/21/2025-09:28:07] [I] Output:
[05/21/2025-09:28:07] [I] === Build Options ===
[05/21/2025-09:28:07] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default
[05/21/2025-09:28:07] [I] avgTiming: 8
[05/21/2025-09:28:07] [I] Precision: FP32+FP16+BF16+INT8
[05/21/2025-09:28:07] [I] LayerPrecisions: 
[05/21/2025-09:28:07] [I] Layer Device Types: 
[05/21/2025-09:28:07] [I] Calibration: Dynamic
[05/21/2025-09:28:07] [I] Refit: Disabled
[05/21/2025-09:28:07] [I] Strip weights: Disabled
[05/21/2025-09:28:07] [I] Version Compatible: Disabled
[05/21/2025-09:28:07] [I] ONNX Plugin InstanceNorm: Disabled
[05/21/2025-09:28:07] [I] TensorRT runtime: full
[05/21/2025-09:28:07] [I] Lean DLL Path: 
[05/21/2025-09:28:07] [I] Tempfile Controls: { in_memory: allow, temporary: allow }
[05/21/2025-09:28:07] [I] Exclude Lean Runtime: Disabled
[05/21/2025-09:28:07] [I] Sparsity: Disabled
[05/21/2025-09:28:07] [I] Safe mode: Disabled
[05/21/2025-09:28:07] [I] Build DLA standalone loadable: Disabled
[05/21/2025-09:28:07] [I] Allow GPU fallback for DLA: Disabled
[05/21/2025-09:28:07] [I] DirectIO mode: Disabled
[05/21/2025-09:28:07] [I] Restricted mode: Disabled
[05/21/2025-09:28:07] [I] Skip inference: Disabled
[05/21/2025-09:28:07] [I] Save engine: tensorrt_10_7/default_mtq_int8_q_qint8.onnx-best/default_mtq_int8_q_qint8.onnx.engine
[05/21/2025-09:28:07] [I] Load engine: 
[05/21/2025-09:28:07] [I] Profiling verbosity: 2
[05/21/2025-09:28:07] [I] Tactic sources: Using default tactic sources
[05/21/2025-09:28:07] [I] timingCacheMode: global
[05/21/2025-09:28:07] [I] timingCacheFile: ./timing.cache
[05/21/2025-09:28:07] [I] Enable Compilation Cache: Enabled
[05/21/2025-09:28:07] [I] Enable Monitor Memory: Disabled
[05/21/2025-09:28:07] [I] errorOnTimingCacheMiss: Disabled
[05/21/2025-09:28:07] [I] Preview Features: Use default preview flags.
[05/21/2025-09:28:07] [I] MaxAuxStreams: -1
[05/21/2025-09:28:07] [I] BuilderOptimizationLevel: -1
[05/21/2025-09:28:07] [I] MaxTactics: -1
[05/21/2025-09:28:07] [I] Calibration Profile Index: 0
[05/21/2025-09:28:07] [I] Weight Streaming: Disabled
[05/21/2025-09:28:07] [I] Runtime Platform: Same As Build
[05/21/2025-09:28:07] [I] Debug Tensors: 
[05/21/2025-09:28:07] [I] Input(s)s format: fp32:CHW
[05/21/2025-09:28:07] [I] Output(s)s format: fp32:CHW
[05/21/2025-09:28:07] [I] Input build shapes: model
[05/21/2025-09:28:07] [I] Input calibration shapes: model
[05/21/2025-09:28:07] [I] === System Options ===
[05/21/2025-09:28:07] [I] Device: 0
[05/21/2025-09:28:07] [I] DLACore: 
[05/21/2025-09:28:07] [I] Plugins:
[05/21/2025-09:28:07] [I] setPluginsToSerialize:
[05/21/2025-09:28:07] [I] dynamicPlugins:
[05/21/2025-09:28:07] [I] ignoreParsedPluginLibs: 0
[05/21/2025-09:28:07] [I] 
[05/21/2025-09:28:07] [I] === Inference Options ===
[05/21/2025-09:28:07] [I] Batch: Explicit
[05/21/2025-09:28:07] [I] Input inference shapes: model
[05/21/2025-09:28:07] [I] Iterations: 10
[05/21/2025-09:28:07] [I] Duration: 3s (+ 200ms warm up)
[05/21/2025-09:28:07] [I] Sleep time: 0ms
[05/21/2025-09:28:07] [I] Idle time: 0ms
[05/21/2025-09:28:07] [I] Inference Streams: 1
[05/21/2025-09:28:07] [I] ExposeDMA: Disabled
[05/21/2025-09:28:07] [I] Data transfers: Enabled
[05/21/2025-09:28:07] [I] Spin-wait: Disabled
[05/21/2025-09:28:07] [I] Multithreading: Disabled
[05/21/2025-09:28:07] [I] CUDA Graph: Disabled
[05/21/2025-09:28:07] [I] Separate profiling: Disabled
[05/21/2025-09:28:07] [I] Time Deserialize: Disabled
[05/21/2025-09:28:07] [I] Time Refit: Disabled
[05/21/2025-09:28:07] [I] NVTX verbosity: 2
[05/21/2025-09:28:07] [I] Persistent Cache Ratio: 0
[05/21/2025-09:28:07] [I] Optimization Profile Index: 0
[05/21/2025-09:28:07] [I] Weight Streaming Budget: 100.000000%
[05/21/2025-09:28:07] [I] Inputs:
[05/21/2025-09:28:07] [I] Debug Tensor Save Destinations:
[05/21/2025-09:28:07] [I] === Reporting Options ===
[05/21/2025-09:28:07] [I] Verbose: Enabled
[05/21/2025-09:28:07] [I] Averages: 10 inferences
[05/21/2025-09:28:07] [I] Percentiles: 90,95,99
[05/21/2025-09:28:07] [I] Dump refittable layers:Disabled
[05/21/2025-09:28:07] [I] Dump output: Disabled
[05/21/2025-09:28:07] [I] Profile: Disabled
[05/21/2025-09:28:07] [I] Export timing to JSON file: 
[05/21/2025-09:28:07] [I] Export output to JSON file: 
[05/21/2025-09:28:07] [I] Export profile to JSON file: 
[05/21/2025-09:28:07] [I] 
[05/21/2025-09:28:07] [I] === Device Information ===
[05/21/2025-09:28:07] [I] Available Devices: 
[05/21/2025-09:28:07] [I]   Device 0: "NVIDIA GeForce RTX 4090" UUID: GPU-117c6cfa-7ace-5107-bd8e-0405fabb6962
[05/21/2025-09:28:07] [I] Selected Device: NVIDIA GeForce RTX 4090
[05/21/2025-09:28:07] [I] Selected Device ID: 0
[05/21/2025-09:28:07] [I] Selected Device UUID: GPU-117c6cfa-7ace-5107-bd8e-0405fabb6962
[05/21/2025-09:28:07] [I] Compute Capability: 8.9
[05/21/2025-09:28:07] [I] SMs: 128
[05/21/2025-09:28:07] [I] Device Global Memory: 24105 MiB
[05/21/2025-09:28:07] [I] Shared Memory per SM: 100 KiB
[05/21/2025-09:28:07] [I] Memory Bus Width: 384 bits (ECC disabled)
[05/21/2025-09:28:07] [I] Application Compute Clock Rate: 2.52 GHz
[05/21/2025-09:28:07] [I] Application Memory Clock Rate: 10.501 GHz
[05/21/2025-09:28:07] [I] 
[05/21/2025-09:28:07] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.
[05/21/2025-09:28:07] [I] 
[05/21/2025-09:28:07] [I] TensorRT version: 10.7.0
[05/21/2025-09:28:07] [I] Loading standard plugins
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::ROIAlign_TRT version 2
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 2
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 3
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::ModulatedDeformConv2d version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::Proposal version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 2
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::ROIAlign_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::ScatterElements version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::ScatterElements version 2
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::Split version 1
[05/21/2025-09:28:07] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1
[05/21/2025-09:28:07] [I] [TRT] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 21, GPU 393 (MiB)
[05/21/2025-09:28:08] [V] [TRT] Trying to load shared library libnvinfer_builder_resource.so.10.7.0
[05/21/2025-09:28:08] [V] [TRT] Loaded shared library libnvinfer_builder_resource.so.10.7.0
[05/21/2025-09:28:09] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +2284, GPU +440, now: CPU 2461, GPU 833 (MiB)
[05/21/2025-09:28:09] [V] [TRT] CUDA lazy loading is enabled.
[05/21/2025-09:28:09] [I] Start parsing network model.
[05/21/2025-09:28:09] [I] [TRT] ----------------------------------------------------------------
[05/21/2025-09:28:09] [I] [TRT] Input filename:   default_mtq_int8_q_qint8.onnx
[05/21/2025-09:28:09] [I] [TRT] ONNX IR version:  0.0.8
[05/21/2025-09:28:09] [I] [TRT] Opset version:    17
[05/21/2025-09:28:09] [I] [TRT] Producer name:    pytorch
[05/21/2025-09:28:09] [I] [TRT] Producer version: 2.5.0
[05/21/2025-09:28:09] [I] [TRT] Domain:           
[05/21/2025-09:28:09] [I] [TRT] Model version:    0
[05/21/2025-09:28:09] [I] [TRT] Doc string:       
[05/21/2025-09:28:09] [I] [TRT] ----------------------------------------------------------------
[05/21/2025-09:28:09] [V] [TRT] Adding network input: images with dtype: float32, dimensions: (1, 3, 640, 640)
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: images for ONNX tensor: images
[05/21/2025-09:28:09] [V] [TRT] Adding network input: orig_target_sizes with dtype: int64, dimensions: (1, 2)
[05/21/2025-09:28:09] [W] [TRT] ModelImporter.cpp:459: Make sure input orig_target_sizes has Int64 binding.
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: orig_target_sizes for ONNX tensor: orig_target_sizes
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_3.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_3.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_3.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.conv1.conv1_3.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.short.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.short.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.short.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.short.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.short.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.0.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.1.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.1.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.1.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.1.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.1.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.1.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.1.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.1.branch2b.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.1.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.0.blocks.1.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.short.conv.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.short.conv.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.short.conv.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.short.conv.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.short.conv.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.branch2b.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.0.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.1.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.1.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.1.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.1.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.1.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.1.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.1.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.1.branch2b.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.1.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.1.blocks.1.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.short.conv.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.short.conv.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.short.conv.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.short.conv.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.short.conv.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.branch2b.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.0.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.1.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.1.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.1.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.1.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.1.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.1.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.1.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.1.branch2b.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.1.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.2.blocks.1.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.short.conv.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.short.conv.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.short.conv.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.short.conv.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.short.conv.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.0.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.1.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.1.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.1.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.1.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.1.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.1.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.1.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.1.branch2b.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.1.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.backbone.res_layers.3.blocks.1.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.anchors
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.0.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.0.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.0.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.0.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.input_proj.2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.self_attn.out_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.self_attn.out_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.norm1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.norm1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.cross_attn.sampling_offsets.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.cross_attn.sampling_offsets.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.cross_attn.attention_weights.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.cross_attn.attention_weights.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.cross_attn.value_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.cross_attn.value_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.cross_attn.output_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.cross_attn.output_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.norm2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.norm2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.linear1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.linear1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.linear2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.linear2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.norm3.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.0.norm3.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.self_attn.out_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.self_attn.out_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.norm1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.norm1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.cross_attn.sampling_offsets.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.cross_attn.sampling_offsets.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.cross_attn.attention_weights.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.cross_attn.attention_weights.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.cross_attn.value_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.cross_attn.value_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.cross_attn.output_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.cross_attn.output_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.norm2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.norm2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.linear1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.linear1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.linear2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.linear2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.norm3.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.1.norm3.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.self_attn.out_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.self_attn.out_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.norm1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.norm1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.cross_attn.sampling_offsets.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.cross_attn.sampling_offsets.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.cross_attn.attention_weights.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.cross_attn.attention_weights.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.cross_attn.value_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.cross_attn.value_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.cross_attn.output_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.cross_attn.output_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.norm2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.norm2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.linear1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.linear1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.linear2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.linear2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.norm3.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.decoder.layers.2.norm3.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.query_pos_head.layers.0.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.query_pos_head.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.query_pos_head.layers.1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.query_pos_head.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.enc_output.proj.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.enc_output.proj.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.enc_output.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.enc_output.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.enc_score_head.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.enc_score_head.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.enc_bbox_head.layers.0.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.enc_bbox_head.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.enc_bbox_head.layers.1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.enc_bbox_head.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.enc_bbox_head.layers.2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.enc_bbox_head.layers.2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_score_head.2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_score_head.2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.0.layers.0.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.0.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.0.layers.1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.0.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.0.layers.2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.0.layers.2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.1.layers.0.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.1.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.1.layers.1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.1.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.1.layers.2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.1.layers.2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.2.layers.0.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.2.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.2.layers.1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.2.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.2.layers.2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.decoder.dec_bbox_head.2.layers.2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.0.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.0.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.0.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.0.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.input_proj.2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.encoder.0.layers.0.self_attn.out_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.encoder.0.layers.0.self_attn.out_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.encoder.0.layers.0.linear1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.encoder.0.layers.0.linear1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.encoder.0.layers.0.linear2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.encoder.0.layers.0.linear2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.encoder.0.layers.0.norm1.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.encoder.0.layers.0.norm1.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.encoder.0.layers.0.norm2.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.encoder.0.layers.0.norm2.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.lateral_convs.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.lateral_convs.0.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.lateral_convs.0.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.lateral_convs.0.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.lateral_convs.0.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.lateral_convs.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.lateral_convs.1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.lateral_convs.1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.lateral_convs.1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.lateral_convs.1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.bottlenecks.0.conv.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.bottlenecks.1.conv.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.bottlenecks.2.conv.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv3.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv3.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv3.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.0.conv3.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.bottlenecks.0.conv.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.bottlenecks.1.conv.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.bottlenecks.2.conv.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv3.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv3.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv3.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.fpn_blocks.1.conv3.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.downsample_convs.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.downsample_convs.0.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.downsample_convs.0.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.downsample_convs.0.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.downsample_convs.0.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.downsample_convs.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.downsample_convs.1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.downsample_convs.1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.downsample_convs.1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.downsample_convs.1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.bottlenecks.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.bottlenecks.0.conv.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.bottlenecks.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.bottlenecks.1.conv.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.bottlenecks.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.bottlenecks.2.conv.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv3.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv3.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv3.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.0.conv3.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.bottlenecks.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.bottlenecks.0.conv.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.bottlenecks.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.bottlenecks.1.conv.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.bottlenecks.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.bottlenecks.2.conv.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv3.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv3.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv3.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: model.encoder.pan_blocks.1.conv3.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Add_3614
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Add_3616
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Add_3618
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::MatMul_3619
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::MatMul_3620
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::MatMul_3621
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Mul_3692
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Add_3731
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Add_3733
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Add_3735
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::MatMul_3736
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::MatMul_3737
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::MatMul_3738
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Mul_3755
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Add_3803
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Add_3805
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Add_3807
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::MatMul_3808
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::MatMul_3809
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::MatMul_3810
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Add_3875
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Add_3877
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Add_3879
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::MatMul_3880
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::MatMul_3881
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::MatMul_3882
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/conv1/conv1_2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/conv1/conv1_3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/input_proj.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/Constant_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Unsqueeze_1255
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/self_attn/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/activation/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/activation/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/activation/Constant_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/lateral_convs.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/lateral_convs.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/Constant_9_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/lateral_convs.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/lateral_convs.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/downsample_convs.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/downsample_convs.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/downsample_convs.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/downsample_convs.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/input_proj.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/enc_output/proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/enc_output/proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/enc_score_head/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/enc_score_head/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/enc_score_head/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/Constant_18_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/Constant_21_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/Constant_15_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/Constant_39_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Split_2305
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/Constant_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.1/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.1/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.2/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.2/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /postprocessor/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: onnx::Tile_3498
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /postprocessor/Constant_14_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: _v_4326
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: _v_1997
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/self_attn/Concat_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/self_attn/Concat_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/encoder.0/layers.0/self_attn/Concat_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/encoder/Concat_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/Concat_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/Concat_7_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/Add_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: _v_1846
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: _v_1848
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: _v_1850
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: _v_1749
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/self_attn/Concat_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/self_attn/Concat_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/Concat_6_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/Concat_7_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/Concat_8_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/Concat_9_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: /model/decoder/decoder/layers.0/cross_attn/Concat_11_output_0
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: _v_1663
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: _v_1665
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: _v_1669
[05/21/2025-09:28:09] [V] [TRT] Importing initializer: _v_1675
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: images
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [images -> (1, 3, 640, 640)[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight for ONNX node: tmp_weight
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 3, 640, 640)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 3, 640, 640)[INT8]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_0 for ONNX node: tmp_weight_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 3, 640, 640)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.conv1.conv1_1.conv.weight -> (32, 3, 3, 3)[FLOAT]], [/model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_1_output_0 -> (32)[FLOAT]], [/model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_output_0 -> (32)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.conv1.conv1_1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1 for ONNX node: tmp_weight_1
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear_output_0 -> (32, 3, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear_output_0 -> (32, 3, 3, 3)[INT8]], [/model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_1_output_0 -> (32)[FLOAT]], [/model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_output_0 -> (32)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_2 for ONNX node: tmp_weight_2
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear_output_0 -> (32, 3, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/conv/Conv [Conv] inputs: [/model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 3, 640, 640)[FLOAT]], [/model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear_output_0 -> (32, 3, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_1/conv/Conv for ONNX node: /model/backbone/conv1/conv1_1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_1/conv/Conv_output_0 for ONNX tensor: /model/backbone/conv1/conv1_1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/conv/Conv [Conv] outputs: [/model/backbone/conv1/conv1_1/conv/Conv_output_0 -> (1, 32, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/conv1/conv1_1/conv/Conv_output_0 -> (1, 32, 320, 320)[FLOAT]], [model.backbone.conv1.conv1_1.norm.weight -> (32)[FLOAT]], [model.backbone.conv1.conv1_1.norm.bias -> (32)[FLOAT]], [model.backbone.conv1.conv1_1.norm.running_mean -> (32)[FLOAT]], [model.backbone.conv1.conv1_1.norm.running_var -> (32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_1/norm/BatchNormalization for ONNX node: /model/backbone/conv1/conv1_1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_1/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/conv1/conv1_1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/conv1/conv1_1/norm/BatchNormalization_output_0 -> (1, 32, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_1/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_1/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/act/Relu [Relu] inputs: [/model/backbone/conv1/conv1_1/norm/BatchNormalization_output_0 -> (1, 32, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_1/act/Relu for ONNX node: /model/backbone/conv1/conv1_1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_1/act/Relu_output_0 for ONNX tensor: /model/backbone/conv1/conv1_1/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_1/act/Relu [Relu] outputs: [/model/backbone/conv1/conv1_1/act/Relu_output_0 -> (1, 32, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/conv1/conv1_1/act/Relu_output_0 -> (1, 32, 320, 320)[FLOAT]], [/model/backbone/conv1/conv1_2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/conv1/conv1_2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_3 for ONNX node: tmp_weight_3
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 32, 320, 320)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 32, 320, 320)[INT8]], [/model/backbone/conv1/conv1_2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_4 for ONNX node: tmp_weight_4
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 32, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.conv1.conv1_2.conv.weight -> (32, 32, 3, 3)[FLOAT]], [/model/backbone/conv1/conv1_2/conv/weight_quantizer/Constant_1_output_0 -> (32)[FLOAT]], [/model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_output_0 -> (32)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.conv1.conv1_2.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/conv1/conv1_2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_5 for ONNX node: tmp_weight_5
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear_output_0 -> (32, 32, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear_output_0 -> (32, 32, 3, 3)[INT8]], [/model/backbone/conv1/conv1_2/conv/weight_quantizer/Constant_1_output_0 -> (32)[FLOAT]], [/model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_output_0 -> (32)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_6 for ONNX node: tmp_weight_6
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear_output_0 -> (32, 32, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/conv/Conv [Conv] inputs: [/model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 32, 320, 320)[FLOAT]], [/model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear_output_0 -> (32, 32, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_2/conv/Conv for ONNX node: /model/backbone/conv1/conv1_2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_2/conv/Conv_output_0 for ONNX tensor: /model/backbone/conv1/conv1_2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/conv/Conv [Conv] outputs: [/model/backbone/conv1/conv1_2/conv/Conv_output_0 -> (1, 32, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/conv1/conv1_2/conv/Conv_output_0 -> (1, 32, 320, 320)[FLOAT]], [model.backbone.conv1.conv1_2.norm.weight -> (32)[FLOAT]], [model.backbone.conv1.conv1_2.norm.bias -> (32)[FLOAT]], [model.backbone.conv1.conv1_2.norm.running_mean -> (32)[FLOAT]], [model.backbone.conv1.conv1_2.norm.running_var -> (32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_2/norm/BatchNormalization for ONNX node: /model/backbone/conv1/conv1_2/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_2/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/conv1/conv1_2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/conv1/conv1_2/norm/BatchNormalization_output_0 -> (1, 32, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_2/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_2/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/act/Relu [Relu] inputs: [/model/backbone/conv1/conv1_2/norm/BatchNormalization_output_0 -> (1, 32, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_2/act/Relu for ONNX node: /model/backbone/conv1/conv1_2/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_2/act/Relu_output_0 for ONNX tensor: /model/backbone/conv1/conv1_2/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_2/act/Relu [Relu] outputs: [/model/backbone/conv1/conv1_2/act/Relu_output_0 -> (1, 32, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_2/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/conv1/conv1_2/act/Relu_output_0 -> (1, 32, 320, 320)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/conv1/conv1_3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_7 for ONNX node: tmp_weight_7
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 32, 320, 320)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 32, 320, 320)[INT8]], [/model/backbone/conv1/conv1_3/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_8 for ONNX node: tmp_weight_8
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 32, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.conv1.conv1_3.conv.weight -> (64, 32, 3, 3)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_1_output_0 -> (64)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0 -> (64)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.conv1.conv1_3.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_9 for ONNX node: tmp_weight_9
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear_output_0 -> (64, 32, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear_output_0 -> (64, 32, 3, 3)[INT8]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_1_output_0 -> (64)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0 -> (64)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_10 for ONNX node: tmp_weight_10
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear_output_0 -> (64, 32, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_3/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_3/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/conv/Conv [Conv] inputs: [/model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 32, 320, 320)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear_output_0 -> (64, 32, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_3/conv/Conv for ONNX node: /model/backbone/conv1/conv1_3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_3/conv/Conv_output_0 for ONNX tensor: /model/backbone/conv1/conv1_3/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/conv/Conv [Conv] outputs: [/model/backbone/conv1/conv1_3/conv/Conv_output_0 -> (1, 64, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_3/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_3/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_3.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_3.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_3.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.conv1.conv1_3.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/conv1/conv1_3/conv/Conv_output_0 -> (1, 64, 320, 320)[FLOAT]], [model.backbone.conv1.conv1_3.norm.weight -> (64)[FLOAT]], [model.backbone.conv1.conv1_3.norm.bias -> (64)[FLOAT]], [model.backbone.conv1.conv1_3.norm.running_mean -> (64)[FLOAT]], [model.backbone.conv1.conv1_3.norm.running_var -> (64)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_3/norm/BatchNormalization for ONNX node: /model/backbone/conv1/conv1_3/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_3/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/conv1/conv1_3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/conv1/conv1_3/norm/BatchNormalization_output_0 -> (1, 64, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/conv1/conv1_3/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/conv1/conv1_3/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/act/Relu [Relu] inputs: [/model/backbone/conv1/conv1_3/norm/BatchNormalization_output_0 -> (1, 64, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/conv1/conv1_3/act/Relu for ONNX node: /model/backbone/conv1/conv1_3/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/conv1/conv1_3/act/Relu_output_0 for ONNX tensor: /model/backbone/conv1/conv1_3/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/conv1/conv1_3/act/Relu [Relu] outputs: [/model/backbone/conv1/conv1_3/act/Relu_output_0 -> (1, 64, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/MaxPool [MaxPool]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/MaxPool [MaxPool]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/MaxPool [MaxPool] inputs: [/model/backbone/conv1/conv1_3/act/Relu_output_0 -> (1, 64, 320, 320)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/MaxPool for ONNX node: /model/backbone/MaxPool
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/MaxPool_output_0 for ONNX tensor: /model/backbone/MaxPool_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/MaxPool [MaxPool] outputs: [/model/backbone/MaxPool_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/MaxPool_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/MaxPool_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_11 for ONNX node: tmp_weight_11
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 64, 160, 160)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 64, 160, 160)[INT8]], [/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_12 for ONNX node: tmp_weight_12
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.0.blocks.0.branch2a.conv.weight -> (64, 64, 3, 3)[FLOAT]], [/model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (64)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0 -> (64)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.0.blocks.0.branch2a.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_13 for ONNX node: tmp_weight_13
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (64, 64, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (64, 64, 3, 3)[INT8]], [/model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (64)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0 -> (64)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_14 for ONNX node: tmp_weight_14
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (64, 64, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv [Conv] inputs: [/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (64, 64, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv [Conv] outputs: [/model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv_output_0 -> (1, 64, 160, 160)[FLOAT]], [model.backbone.res_layers.0.blocks.0.branch2a.norm.weight -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.0.branch2a.norm.bias -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.0.branch2a.norm.running_mean -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.0.branch2a.norm.running_var -> (64)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu [Relu] inputs: [/model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu [Relu] outputs: [/model/backbone/res_layers.0/blocks.0/branch2a/act/Relu_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.0/branch2a/act/Relu_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_15 for ONNX node: tmp_weight_15
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 64, 160, 160)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 64, 160, 160)[INT8]], [/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_16 for ONNX node: tmp_weight_16
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.0.blocks.0.branch2b.conv.weight -> (64, 64, 3, 3)[FLOAT]], [/model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (64)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0 -> (64)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.0.blocks.0.branch2b.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_17 for ONNX node: tmp_weight_17
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (64, 64, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (64, 64, 3, 3)[INT8]], [/model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (64)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0 -> (64)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_18 for ONNX node: tmp_weight_18
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (64, 64, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv [Conv] inputs: [/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (64, 64, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv [Conv] outputs: [/model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.short.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv_output_0 -> (1, 64, 160, 160)[FLOAT]], [model.backbone.res_layers.0.blocks.0.branch2b.norm.weight -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.0.short.norm.bias -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.0.branch2b.norm.running_mean -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.0.branch2b.norm.running_var -> (64)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.short.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.0.blocks.0.short.conv.weight -> (64, 64, 1, 1)[FLOAT]], [/model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/Constant_1_output_0 -> (64)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0 -> (64)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.0.blocks.0.short.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_19 for ONNX node: tmp_weight_19
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear_output_0 -> (64, 64, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear_output_0 -> (64, 64, 1, 1)[INT8]], [/model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/Constant_1_output_0 -> (64)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0 -> (64)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_20 for ONNX node: tmp_weight_20
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear_output_0 -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/short/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/short/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/short/conv/Conv [Conv] inputs: [/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear_output_0 -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/short/conv/Conv for ONNX node: /model/backbone/res_layers.0/blocks.0/short/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/short/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/short/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/short/conv/Conv [Conv] outputs: [/model/backbone/res_layers.0/blocks.0/short/conv/Conv_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/short/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.short.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.short.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.short.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.0.short.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.0/blocks.0/short/conv/Conv_output_0 -> (1, 64, 160, 160)[FLOAT]], [model.backbone.res_layers.0.blocks.0.short.norm.weight -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.0.short.norm.bias -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.0.short.norm.running_mean -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.0.short.norm.running_var -> (64)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/Add [Add] inputs: [/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/Add for ONNX node: /model/backbone/res_layers.0/blocks.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/Add_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/Add [Add] outputs: [/model/backbone/res_layers.0/blocks.0/Add_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.0/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.0/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/act/Relu [Relu] inputs: [/model/backbone/res_layers.0/blocks.0/Add_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.0/act/Relu for ONNX node: /model/backbone/res_layers.0/blocks.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.0/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.0/act/Relu [Relu] outputs: [/model/backbone/res_layers.0/blocks.0/act/Relu_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.0/act/Relu_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_21 for ONNX node: tmp_weight_21
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 64, 160, 160)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 64, 160, 160)[INT8]], [/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_22 for ONNX node: tmp_weight_22
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.1.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.0.blocks.1.branch2a.conv.weight -> (64, 64, 3, 3)[FLOAT]], [/model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (64)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0 -> (64)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.0.blocks.1.branch2a.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_23 for ONNX node: tmp_weight_23
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (64, 64, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (64, 64, 3, 3)[INT8]], [/model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (64)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0 -> (64)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_24 for ONNX node: tmp_weight_24
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (64, 64, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv [Conv] inputs: [/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (64, 64, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv [Conv] outputs: [/model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.1.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.1.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.1.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.1.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv_output_0 -> (1, 64, 160, 160)[FLOAT]], [model.backbone.res_layers.0.blocks.1.branch2a.norm.weight -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.1.branch2a.norm.bias -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.1.branch2a.norm.running_mean -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.1.branch2a.norm.running_var -> (64)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu [Relu] inputs: [/model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu [Relu] outputs: [/model/backbone/res_layers.0/blocks.1/branch2a/act/Relu_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.1/branch2a/act/Relu_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_25 for ONNX node: tmp_weight_25
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 64, 160, 160)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 64, 160, 160)[INT8]], [/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_26 for ONNX node: tmp_weight_26
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.1.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.0.blocks.1.branch2b.conv.weight -> (64, 64, 3, 3)[FLOAT]], [/model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (64)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0 -> (64)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.0.blocks.1.branch2b.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_27 for ONNX node: tmp_weight_27
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (64, 64, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (64, 64, 3, 3)[INT8]], [/model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (64)[FLOAT]], [/model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_output_0 -> (64)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_28 for ONNX node: tmp_weight_28
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (64, 64, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv [Conv] inputs: [/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (64, 64, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv [Conv] outputs: [/model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.1.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.1.branch2b.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.1.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.0.blocks.1.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv_output_0 -> (1, 64, 160, 160)[FLOAT]], [model.backbone.res_layers.0.blocks.1.branch2b.norm.weight -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.1.branch2b.norm.bias -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.1.branch2b.norm.running_mean -> (64)[FLOAT]], [model.backbone.res_layers.0.blocks.1.branch2b.norm.running_var -> (64)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/Add [Add] inputs: [/model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.0/blocks.0/act/Relu_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/Add for ONNX node: /model/backbone/res_layers.0/blocks.1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/Add_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/Add [Add] outputs: [/model/backbone/res_layers.0/blocks.1/Add_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.0/blocks.1/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.0/blocks.1/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/act/Relu [Relu] inputs: [/model/backbone/res_layers.0/blocks.1/Add_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.0/blocks.1/act/Relu for ONNX node: /model/backbone/res_layers.0/blocks.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.0/blocks.1/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.0/blocks.1/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.0/blocks.1/act/Relu [Relu] outputs: [/model/backbone/res_layers.0/blocks.1/act/Relu_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.0/blocks.1/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.0/blocks.1/act/Relu_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_29 for ONNX node: tmp_weight_29
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 64, 160, 160)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 64, 160, 160)[INT8]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_30 for ONNX node: tmp_weight_30
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.1.blocks.0.branch2a.conv.weight -> (128, 64, 3, 3)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.1.blocks.0.branch2a.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_31 for ONNX node: tmp_weight_31
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 64, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 64, 3, 3)[INT8]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_32 for ONNX node: tmp_weight_32
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 64, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv [Conv] inputs: [/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 160, 160)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 64, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv [Conv] outputs: [/model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], [model.backbone.res_layers.1.blocks.0.branch2a.norm.weight -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.0.branch2a.norm.bias -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.0.branch2a.norm.running_mean -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.0.branch2a.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu [Relu] inputs: [/model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu [Relu] outputs: [/model/backbone/res_layers.1/blocks.0/branch2a/act/Relu_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.0/branch2a/act/Relu_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_33 for ONNX node: tmp_weight_33
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], [/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_34 for ONNX node: tmp_weight_34
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.1.blocks.0.branch2b.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.1.blocks.0.branch2b.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_35 for ONNX node: tmp_weight_35
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_36 for ONNX node: tmp_weight_36
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv [Conv] inputs: [/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv [Conv] outputs: [/model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.branch2b.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], [model.backbone.res_layers.1.blocks.0.branch2b.norm.weight -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.0.branch2b.norm.bias -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.0.branch2b.norm.running_mean -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.0.branch2b.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool [AveragePool]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool [AveragePool]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool [AveragePool] inputs: [/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 160, 160)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool for ONNX node: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool [AveragePool] outputs: [/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool_output_0 -> (1, 64, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool_output_0 -> (1, 64, 80, 80)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_37 for ONNX node: tmp_weight_37
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 64, 80, 80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 64, 80, 80)[INT8]], [/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_38 for ONNX node: tmp_weight_38
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.short.conv.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.1.blocks.0.short.conv.conv.weight -> (128, 64, 1, 1)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.1.blocks.0.short.conv.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_39 for ONNX node: tmp_weight_39
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 64, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 64, 1, 1)[INT8]], [/model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_40 for ONNX node: tmp_weight_40
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 64, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv [Conv] inputs: [/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 64, 80, 80)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 64, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv for ONNX node: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv [Conv] outputs: [/model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.short.conv.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.short.conv.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.short.conv.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.0.short.conv.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], [model.backbone.res_layers.1.blocks.0.short.conv.norm.weight -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.0.short.conv.norm.bias -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.0.short.conv.norm.running_mean -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.0.short.conv.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/Add [Add] inputs: [/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/Add for ONNX node: /model/backbone/res_layers.1/blocks.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/Add_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/Add [Add] outputs: [/model/backbone/res_layers.1/blocks.0/Add_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.0/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.0/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/act/Relu [Relu] inputs: [/model/backbone/res_layers.1/blocks.0/Add_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.0/act/Relu for ONNX node: /model/backbone/res_layers.1/blocks.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.0/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.0/act/Relu [Relu] outputs: [/model/backbone/res_layers.1/blocks.0/act/Relu_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.0/act/Relu_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_41 for ONNX node: tmp_weight_41
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], [/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_42 for ONNX node: tmp_weight_42
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.1.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.1.blocks.1.branch2a.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.1.blocks.1.branch2a.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_43 for ONNX node: tmp_weight_43
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_44 for ONNX node: tmp_weight_44
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv [Conv] inputs: [/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv [Conv] outputs: [/model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.1.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.1.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.1.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.1.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], [model.backbone.res_layers.1.blocks.1.branch2a.norm.weight -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.1.branch2a.norm.bias -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.1.branch2a.norm.running_mean -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.1.branch2a.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu [Relu] inputs: [/model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu [Relu] outputs: [/model/backbone/res_layers.1/blocks.1/branch2a/act/Relu_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.1/branch2a/act/Relu_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_45 for ONNX node: tmp_weight_45
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], [/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_46 for ONNX node: tmp_weight_46
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.1.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.1.blocks.1.branch2b.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.1.blocks.1.branch2b.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_47 for ONNX node: tmp_weight_47
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_48 for ONNX node: tmp_weight_48
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv [Conv] inputs: [/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv [Conv] outputs: [/model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.1.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.1.branch2b.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.1.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.1.blocks.1.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], [model.backbone.res_layers.1.blocks.1.branch2b.norm.weight -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.1.branch2b.norm.bias -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.1.branch2b.norm.running_mean -> (128)[FLOAT]], [model.backbone.res_layers.1.blocks.1.branch2b.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/Add [Add] inputs: [/model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/act/Relu_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/Add for ONNX node: /model/backbone/res_layers.1/blocks.1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/Add_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/Add [Add] outputs: [/model/backbone/res_layers.1/blocks.1/Add_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.1/blocks.1/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.1/blocks.1/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/act/Relu [Relu] inputs: [/model/backbone/res_layers.1/blocks.1/Add_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.1/blocks.1/act/Relu for ONNX node: /model/backbone/res_layers.1/blocks.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.1/blocks.1/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.1/blocks.1/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.1/blocks.1/act/Relu [Relu] outputs: [/model/backbone/res_layers.1/blocks.1/act/Relu_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.1/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.1/blocks.1/act/Relu_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_49 for ONNX node: tmp_weight_49
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_50 for ONNX node: tmp_weight_50
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.2.blocks.0.branch2a.conv.weight -> (256, 128, 3, 3)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.2.blocks.0.branch2a.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_51 for ONNX node: tmp_weight_51
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 3, 3)[INT8]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_52 for ONNX node: tmp_weight_52
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv [Conv] inputs: [/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv [Conv] outputs: [/model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], [model.backbone.res_layers.2.blocks.0.branch2a.norm.weight -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.0.branch2a.norm.bias -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.0.branch2a.norm.running_mean -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.0.branch2a.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu [Relu] inputs: [/model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu [Relu] outputs: [/model/backbone/res_layers.2/blocks.0/branch2a/act/Relu_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.0/branch2a/act/Relu_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_53 for ONNX node: tmp_weight_53
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 40, 40)[INT8]], [/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_54 for ONNX node: tmp_weight_54
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.2.blocks.0.branch2b.conv.weight -> (256, 256, 3, 3)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.2.blocks.0.branch2b.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_55 for ONNX node: tmp_weight_55
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 3, 3)[INT8]], [/model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_56 for ONNX node: tmp_weight_56
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv [Conv] inputs: [/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv [Conv] outputs: [/model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.branch2b.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], [model.backbone.res_layers.2.blocks.0.branch2b.norm.weight -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.0.branch2b.norm.bias -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.0.branch2b.norm.running_mean -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.0.branch2b.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool [AveragePool]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool [AveragePool]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool [AveragePool] inputs: [/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool for ONNX node: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool [AveragePool] outputs: [/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_57 for ONNX node: tmp_weight_57
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], [/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_58 for ONNX node: tmp_weight_58
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.short.conv.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.2.blocks.0.short.conv.conv.weight -> (256, 128, 1, 1)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.2.blocks.0.short.conv.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_59 for ONNX node: tmp_weight_59
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 1, 1)[INT8]], [/model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_60 for ONNX node: tmp_weight_60
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv [Conv] inputs: [/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv for ONNX node: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv [Conv] outputs: [/model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.short.conv.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.short.conv.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.short.conv.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.0.short.conv.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], [model.backbone.res_layers.2.blocks.0.short.conv.norm.weight -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.0.short.conv.norm.bias -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.0.short.conv.norm.running_mean -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.0.short.conv.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/Add [Add] inputs: [/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/Add for ONNX node: /model/backbone/res_layers.2/blocks.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/Add_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/Add [Add] outputs: [/model/backbone/res_layers.2/blocks.0/Add_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.0/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.0/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/act/Relu [Relu] inputs: [/model/backbone/res_layers.2/blocks.0/Add_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.0/act/Relu for ONNX node: /model/backbone/res_layers.2/blocks.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.0/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.0/act/Relu [Relu] outputs: [/model/backbone/res_layers.2/blocks.0/act/Relu_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.0/act/Relu_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_61 for ONNX node: tmp_weight_61
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 40, 40)[INT8]], [/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_62 for ONNX node: tmp_weight_62
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.1.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.2.blocks.1.branch2a.conv.weight -> (256, 256, 3, 3)[FLOAT]], [/model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.2.blocks.1.branch2a.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_63 for ONNX node: tmp_weight_63
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 3, 3)[INT8]], [/model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_64 for ONNX node: tmp_weight_64
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv [Conv] inputs: [/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv [Conv] outputs: [/model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.1.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.1.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.1.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.1.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], [model.backbone.res_layers.2.blocks.1.branch2a.norm.weight -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.1.branch2a.norm.bias -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.1.branch2a.norm.running_mean -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.1.branch2a.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu [Relu] inputs: [/model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu [Relu] outputs: [/model/backbone/res_layers.2/blocks.1/branch2a/act/Relu_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.1/branch2a/act/Relu_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_65 for ONNX node: tmp_weight_65
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 40, 40)[INT8]], [/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_66 for ONNX node: tmp_weight_66
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.1.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.2.blocks.1.branch2b.conv.weight -> (256, 256, 3, 3)[FLOAT]], [/model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.2.blocks.1.branch2b.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_67 for ONNX node: tmp_weight_67
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 3, 3)[INT8]], [/model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_68 for ONNX node: tmp_weight_68
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv [Conv] inputs: [/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv [Conv] outputs: [/model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.1.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.1.branch2b.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.1.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.2.blocks.1.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], [model.backbone.res_layers.2.blocks.1.branch2b.norm.weight -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.1.branch2b.norm.bias -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.1.branch2b.norm.running_mean -> (256)[FLOAT]], [model.backbone.res_layers.2.blocks.1.branch2b.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/Add [Add] inputs: [/model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/act/Relu_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/Add for ONNX node: /model/backbone/res_layers.2/blocks.1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/Add_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/Add [Add] outputs: [/model/backbone/res_layers.2/blocks.1/Add_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.2/blocks.1/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.2/blocks.1/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/act/Relu [Relu] inputs: [/model/backbone/res_layers.2/blocks.1/Add_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.2/blocks.1/act/Relu for ONNX node: /model/backbone/res_layers.2/blocks.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.2/blocks.1/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.2/blocks.1/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.2/blocks.1/act/Relu [Relu] outputs: [/model/backbone/res_layers.2/blocks.1/act/Relu_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.1/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.2/blocks.1/act/Relu_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_69 for ONNX node: tmp_weight_69
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 40, 40)[INT8]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_70 for ONNX node: tmp_weight_70
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.3.blocks.0.branch2a.conv.weight -> (512, 256, 3, 3)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (512)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.3.blocks.0.branch2a.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_71 for ONNX node: tmp_weight_71
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (512, 256, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (512, 256, 3, 3)[INT8]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (512)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_72 for ONNX node: tmp_weight_72
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv [Conv] inputs: [/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv [Conv] outputs: [/model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv_output_0 -> (1, 512, 20, 20)[FLOAT]], [model.backbone.res_layers.3.blocks.0.branch2a.norm.weight -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.0.branch2a.norm.bias -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.0.branch2a.norm.running_mean -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.0.branch2a.norm.running_var -> (512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu [Relu] inputs: [/model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu [Relu] outputs: [/model/backbone/res_layers.3/blocks.0/branch2a/act/Relu_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.0/branch2a/act/Relu_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_73 for ONNX node: tmp_weight_73
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 20, 20)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 20, 20)[INT8]], [/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_74 for ONNX node: tmp_weight_74
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.3.blocks.0.branch2b.conv.weight -> (512, 512, 3, 3)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (512)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.3.blocks.0.branch2b.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_75 for ONNX node: tmp_weight_75
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (512, 512, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (512, 512, 3, 3)[INT8]], [/model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (512)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_76 for ONNX node: tmp_weight_76
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv [Conv] inputs: [/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv [Conv] outputs: [/model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.short.conv.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv_output_0 -> (1, 512, 20, 20)[FLOAT]], [model.backbone.res_layers.3.blocks.0.branch2b.norm.weight -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.0.short.conv.norm.bias -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.0.branch2b.norm.running_mean -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.0.branch2b.norm.running_var -> (512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool [AveragePool]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool [AveragePool]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool [AveragePool] inputs: [/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool for ONNX node: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool [AveragePool] outputs: [/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool_output_0 -> (1, 256, 20, 20)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_77 for ONNX node: tmp_weight_77
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 20, 20)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 20, 20)[INT8]], [/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_78 for ONNX node: tmp_weight_78
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.short.conv.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.3.blocks.0.short.conv.conv.weight -> (512, 256, 1, 1)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0 -> (512)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.3.blocks.0.short.conv.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_79 for ONNX node: tmp_weight_79
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0 -> (512, 256, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear_output_0 -> (512, 256, 1, 1)[INT8]], [/model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0 -> (512)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_80 for ONNX node: tmp_weight_80
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0 -> (512, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv [Conv] inputs: [/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 20, 20)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear_output_0 -> (512, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv for ONNX node: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv [Conv] outputs: [/model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.short.conv.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.short.conv.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.short.conv.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.0.short.conv.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv_output_0 -> (1, 512, 20, 20)[FLOAT]], [model.backbone.res_layers.3.blocks.0.short.conv.norm.weight -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.0.short.conv.norm.bias -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.0.short.conv.norm.running_mean -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.0.short.conv.norm.running_var -> (512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/Add [Add] inputs: [/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/Add for ONNX node: /model/backbone/res_layers.3/blocks.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/Add_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/Add [Add] outputs: [/model/backbone/res_layers.3/blocks.0/Add_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.0/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.0/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/act/Relu [Relu] inputs: [/model/backbone/res_layers.3/blocks.0/Add_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.0/act/Relu for ONNX node: /model/backbone/res_layers.3/blocks.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.0/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.0/act/Relu [Relu] outputs: [/model/backbone/res_layers.3/blocks.0/act/Relu_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.0/act/Relu_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_81 for ONNX node: tmp_weight_81
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 20, 20)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 20, 20)[INT8]], [/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_82 for ONNX node: tmp_weight_82
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.1.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.3.blocks.1.branch2a.conv.weight -> (512, 512, 3, 3)[FLOAT]], [/model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (512)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.3.blocks.1.branch2a.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_83 for ONNX node: tmp_weight_83
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (512, 512, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear_output_0 -> (512, 512, 3, 3)[INT8]], [/model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0 -> (512)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_84 for ONNX node: tmp_weight_84
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv [Conv] inputs: [/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear_output_0 -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv [Conv] outputs: [/model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.1.branch2a.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.1.branch2a.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.1.branch2a.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.1.branch2a.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv_output_0 -> (1, 512, 20, 20)[FLOAT]], [model.backbone.res_layers.3.blocks.1.branch2a.norm.weight -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.1.branch2a.norm.bias -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.1.branch2a.norm.running_mean -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.1.branch2a.norm.running_var -> (512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu [Relu] inputs: [/model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu [Relu] outputs: [/model/backbone/res_layers.3/blocks.1/branch2a/act/Relu_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.1/branch2a/act/Relu_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_85 for ONNX node: tmp_weight_85
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 20, 20)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 20, 20)[INT8]], [/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_86 for ONNX node: tmp_weight_86
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.1.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.backbone.res_layers.3.blocks.1.branch2b.conv.weight -> (512, 512, 3, 3)[FLOAT]], [/model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (512)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.backbone.res_layers.3.blocks.1.branch2b.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_87 for ONNX node: tmp_weight_87
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (512, 512, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear_output_0 -> (512, 512, 3, 3)[INT8]], [/model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0 -> (512)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_88 for ONNX node: tmp_weight_88
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv [Conv] inputs: [/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear_output_0 -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv [Conv] outputs: [/model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.1.branch2b.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.1.branch2b.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.1.branch2b.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.backbone.res_layers.3.blocks.1.branch2b.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization] inputs: [/model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv_output_0 -> (1, 512, 20, 20)[FLOAT]], [model.backbone.res_layers.3.blocks.1.branch2b.norm.weight -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.1.branch2b.norm.bias -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.1.branch2b.norm.running_mean -> (512)[FLOAT]], [model.backbone.res_layers.3.blocks.1.branch2b.norm.running_var -> (512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization for ONNX node: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization [BatchNormalization] outputs: [/model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/Add [Add] inputs: [/model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/act/Relu_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/Add for ONNX node: /model/backbone/res_layers.3/blocks.1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/Add_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/Add [Add] outputs: [/model/backbone/res_layers.3/blocks.1/Add_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/backbone/res_layers.3/blocks.1/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/backbone/res_layers.3/blocks.1/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/act/Relu [Relu] inputs: [/model/backbone/res_layers.3/blocks.1/Add_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/backbone/res_layers.3/blocks.1/act/Relu for ONNX node: /model/backbone/res_layers.3/blocks.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/backbone/res_layers.3/blocks.1/act/Relu_output_0 for ONNX tensor: /model/backbone/res_layers.3/blocks.1/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/backbone/res_layers.3/blocks.1/act/Relu [Relu] outputs: [/model/backbone/res_layers.3/blocks.1/act/Relu_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.input_proj.0.conv.weight -> (256, 128, 1, 1)[FLOAT]], [/model/encoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.input_proj.0.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_89 for ONNX node: tmp_weight_89
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 1, 1)[INT8]], [/model/encoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_90 for ONNX node: tmp_weight_90
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.0/conv/Conv [Conv] inputs: [/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.0/conv/Conv for ONNX node: /model/encoder/input_proj.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.0/conv/Conv_output_0 for ONNX tensor: /model/encoder/input_proj.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.0/conv/Conv [Conv] outputs: [/model/encoder/input_proj.0/conv/Conv_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.0/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.0/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.0.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.0.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.0.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.0.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.0/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/input_proj.0/conv/Conv_output_0 -> (1, 256, 80, 80)[FLOAT]], [model.encoder.input_proj.0.norm.weight -> (256)[FLOAT]], [model.encoder.input_proj.0.norm.bias -> (256)[FLOAT]], [model.encoder.input_proj.0.norm.running_mean -> (256)[FLOAT]], [model.encoder.input_proj.0.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.0/norm/BatchNormalization for ONNX node: /model/encoder/input_proj.0/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.0/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/input_proj.0/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.0/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/input_proj.0/norm/BatchNormalization_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.input_proj.1.conv.weight -> (256, 256, 1, 1)[FLOAT]], [/model/encoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.input_proj.1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_91 for ONNX node: tmp_weight_91
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 1, 1)[INT8]], [/model/encoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_92 for ONNX node: tmp_weight_92
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.1/conv/Conv [Conv] inputs: [/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.1/conv/Conv for ONNX node: /model/encoder/input_proj.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.1/conv/Conv_output_0 for ONNX tensor: /model/encoder/input_proj.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.1/conv/Conv [Conv] outputs: [/model/encoder/input_proj.1/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.1/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/input_proj.1/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], [model.encoder.input_proj.1.norm.weight -> (256)[FLOAT]], [model.encoder.input_proj.1.norm.bias -> (256)[FLOAT]], [model.encoder.input_proj.1.norm.running_mean -> (256)[FLOAT]], [model.encoder.input_proj.1.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.1/norm/BatchNormalization for ONNX node: /model/encoder/input_proj.1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.1/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/input_proj.1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.1/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/input_proj.1/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.1/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/backbone/res_layers.3/blocks.1/act/Relu_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/encoder/input_proj.2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.2/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/input_proj.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_93 for ONNX node: tmp_weight_93
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 20, 20)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 20, 20)[INT8]], [/model/encoder/input_proj.2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_94 for ONNX node: tmp_weight_94
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.input_proj.2.conv.weight -> (256, 512, 1, 1)[FLOAT]], [/model/encoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.input_proj.2.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_95 for ONNX node: tmp_weight_95
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 512, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 512, 1, 1)[INT8]], [/model/encoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_96 for ONNX node: tmp_weight_96
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.2/conv/Conv [Conv] inputs: [/model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.2/conv/Conv for ONNX node: /model/encoder/input_proj.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.2/conv/Conv_output_0 for ONNX tensor: /model/encoder/input_proj.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.2/conv/Conv [Conv] outputs: [/model/encoder/input_proj.2/conv/Conv_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/input_proj.2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/input_proj.2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.input_proj.2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.2/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/input_proj.2/conv/Conv_output_0 -> (1, 256, 20, 20)[FLOAT]], [model.encoder.input_proj.2.norm.weight -> (256)[FLOAT]], [model.encoder.input_proj.2.norm.bias -> (256)[FLOAT]], [model.encoder.input_proj.2.norm.running_mean -> (256)[FLOAT]], [model.encoder.input_proj.2.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/input_proj.2/norm/BatchNormalization for ONNX node: /model/encoder/input_proj.2/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/input_proj.2/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/input_proj.2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/input_proj.2/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/input_proj.2/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_4326
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Reshape [Reshape] inputs: [/model/encoder/input_proj.2/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], [_v_4326 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/Reshape for ONNX node: /model/encoder/Reshape
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/Reshape_output_0 for ONNX tensor: /model/encoder/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Reshape [Reshape] outputs: [/model/encoder/Reshape_output_0 -> (1, 256, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Transpose [Transpose] inputs: [/model/encoder/Reshape_output_0 -> (1, 256, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/Transpose for ONNX node: /model/encoder/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/Transpose_output_0 for ONNX tensor: /model/encoder/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Transpose [Transpose] outputs: [/model/encoder/Transpose_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/Add [Add] inputs: [/model/encoder/Transpose_output_0 -> (1, 400, 256)[FLOAT]], [/model/encoder/encoder.0/layers.0/Constant_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/Constant_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/Add for ONNX node: /model/encoder/encoder.0/layers.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/Add_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/Add [Add] outputs: [/model/encoder/encoder.0/layers.0/Add_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose [Transpose] inputs: [/model/encoder/encoder.0/layers.0/Add_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose [Transpose] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Transpose_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose_1 [Transpose] inputs: [/model/encoder/Reshape_output_0 -> (1, 256, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose_1 [Transpose] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Transpose_1_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::MatMul_3619
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul [MatMul] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Transpose_output_0 -> (400, 1, 256)[FLOAT]], [onnx::MatMul_3619 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::MatMul_3619 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_97 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/MatMul
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul: broadcasting input1 to make tensors conform, dims(input0)=[400,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/MatMul_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul [MatMul] outputs: [/model/encoder/encoder.0/layers.0/self_attn/MatMul_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Add_3614
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Add [Add] inputs: [onnx::Add_3614 -> (256)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/MatMul_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Add_3614 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_98 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_99 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Add for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Add_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Add [Add] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Add_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::MatMul_3620
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul_1 [MatMul] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Transpose_output_0 -> (400, 1, 256)[FLOAT]], [onnx::MatMul_3620 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::MatMul_3620 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_100 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_101 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul_1: broadcasting input1 to make tensors conform, dims(input0)=[400,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul_1 [MatMul] outputs: [/model/encoder/encoder.0/layers.0/self_attn/MatMul_1_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Add_3616
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Add_1 [Add] inputs: [onnx::Add_3616 -> (256)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/MatMul_1_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Add_3616 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_102 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_103 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Add_1 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Add_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Add_1_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Add_1 [Add] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Add_1_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::MatMul_3621
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul_2 [MatMul] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Transpose_1_output_0 -> (400, 1, 256)[FLOAT]], [onnx::MatMul_3621 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::MatMul_3621 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_104 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_105 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul_2: broadcasting input1 to make tensors conform, dims(input0)=[400,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul_2 [MatMul] outputs: [/model/encoder/encoder.0/layers.0/self_attn/MatMul_2_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Add_3618
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Add_2 [Add] inputs: [onnx::Add_3618 -> (256)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/MatMul_2_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Add_3618 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_106 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_107 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Add_2 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Add_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Add_2_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Add_2 [Add] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Add_2_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Concat_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Reshape [Reshape] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Add_output_0 -> (400, 1, 256)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/Concat_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_108 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Reshape_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Reshape [Reshape] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Reshape_output_0 -> (400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose_2 [Transpose] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Reshape_output_0 -> (400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_2 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_2_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose_2 [Transpose] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Transpose_2_output_0 -> (8, 400, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Concat_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Reshape_1 [Reshape] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Add_1_output_0 -> (400, 1, 256)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/Concat_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_109 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_1 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Reshape_1_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Reshape_1 [Reshape] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Reshape_1_output_0 -> (400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Concat_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Reshape_2 [Reshape] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Add_2_output_0 -> (400, 1, 256)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/Concat_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_110 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_2 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Reshape_2_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Reshape_2 [Reshape] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Reshape_2_output_0 -> (400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose_3 [Transpose] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Reshape_2_output_0 -> (400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_3 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_3_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose_3 [Transpose] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Transpose_3_output_0 -> (8, 400, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Mul_1 [Mul] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Transpose_2_output_0 -> (8, 400, 32)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/Constant_7_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Constant_7_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_111 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_112 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Mul_1 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Mul_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Mul_1_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Mul_1 [Mul] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Mul_1_output_0 -> (8, 400, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_4 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_4 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose_4 [Transpose] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Reshape_1_output_0 -> (400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_4 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_4_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose_4 [Transpose] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Transpose_4_output_0 -> (8, 32, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Transpose_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul_3 [MatMul] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Mul_1_output_0 -> (8, 400, 32)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/Transpose_4_output_0 -> (8, 32, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul_3 [MatMul] outputs: [/model/encoder/encoder.0/layers.0/self_attn/MatMul_3_output_0 -> (8, 400, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Softmax [Softmax] inputs: [/model/encoder/encoder.0/layers.0/self_attn/MatMul_3_output_0 -> (8, 400, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Softmax for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Softmax
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_113 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Softmax_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Softmax [Softmax] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Softmax_output_0 -> (8, 400, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul_4 [MatMul] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Softmax_output_0 -> (8, 400, 400)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/Transpose_3_output_0 -> (8, 400, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul_4 [MatMul] outputs: [/model/encoder/encoder.0/layers.0/self_attn/MatMul_4_output_0 -> (8, 400, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose_5 [Transpose] inputs: [/model/encoder/encoder.0/layers.0/self_attn/MatMul_4_output_0 -> (8, 400, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose_5 [Transpose] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Transpose_5_output_0 -> (400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Concat_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Reshape_3 [Reshape] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Transpose_5_output_0 -> (400, 8, 32)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/Concat_3_output_0 -> (2)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_114 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Reshape_3 [Reshape] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Reshape_3_output_0 -> (400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Gemm [Gemm]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Gemm [Gemm]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.encoder.0.layers.0.self_attn.out_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.encoder.0.layers.0.self_attn.out_proj.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Gemm [Gemm] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Reshape_3_output_0 -> (400, 256)[FLOAT]], [model.encoder.encoder.0.layers.0.self_attn.out_proj.weight -> (256, 256)[FLOAT]], [model.encoder.encoder.0.layers.0.self_attn.out_proj.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.encoder.0.layers.0.self_attn.out_proj.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Using opA: 0 opB: 1
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Gemm for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Gemm
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.encoder.0.layers.0.self_attn.out_proj.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_115 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_116 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Gemm_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Gemm_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Gemm [Gemm] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Gemm_output_0 -> (400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Gemm_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Concat_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Reshape_4 [Reshape] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Gemm_output_0 -> (400, 256)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/Concat_4_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_117 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_4 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Reshape_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Reshape_4_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Reshape_4 [Reshape] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Reshape_4_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_6 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_6 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose_6 [Transpose] inputs: [/model/encoder/encoder.0/layers.0/self_attn/Reshape_4_output_0 -> (400, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_6 for ONNX node: /model/encoder/encoder.0/layers.0/self_attn/Transpose_6
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_6_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/self_attn/Transpose_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/Transpose_6 [Transpose] outputs: [/model/encoder/encoder.0/layers.0/self_attn/Transpose_6_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Transpose_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/Add_1 [Add] inputs: [/model/encoder/Transpose_output_0 -> (1, 400, 256)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/Transpose_6_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/Add_1 for ONNX node: /model/encoder/encoder.0/layers.0/Add_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/Add_1_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/Add_1 [Add] outputs: [/model/encoder/encoder.0/layers.0/Add_1_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.encoder.0.layers.0.norm1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.encoder.0.layers.0.norm1.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/norm1/LayerNormalization [LayerNormalization] inputs: [/model/encoder/encoder.0/layers.0/Add_1_output_0 -> (1, 400, 256)[FLOAT]], [model.encoder.encoder.0.layers.0.norm1.weight -> (256)[FLOAT]], [model.encoder.encoder.0.layers.0.norm1.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.encoder.0.layers.0.norm1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.encoder.0.layers.0.norm1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_120 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_121 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_122 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_123 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization for ONNX node: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/norm1/LayerNormalization [LayerNormalization] outputs: [/model/encoder/encoder.0/layers.0/norm1/LayerNormalization_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/encoder.0/layers.0/norm1/LayerNormalization_output_0 -> (1, 400, 256)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_124 for ONNX node: tmp_weight_124
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear_output_0 -> (1, 400, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear_output_0 -> (1, 400, 256)[INT8]], [/model/encoder/encoder.0/layers.0/linear1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_125 for ONNX node: tmp_weight_125
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.encoder.0.layers.0.linear1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.encoder.0.layers.0.linear1.weight -> (1024, 256)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_1_output_0 -> (1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0 -> (1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.encoder.0.layers.0.linear1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_126 for ONNX node: tmp_weight_126
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/QuantizeLinear_output_0 -> (1024, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/QuantizeLinear_output_0 -> (1024, 256)[INT8]], [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_1_output_0 -> (1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0 -> (1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_127 for ONNX node: tmp_weight_127
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/Transpose [Transpose] inputs: [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear1/Transpose for ONNX node: /model/encoder/encoder.0/layers.0/linear1/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear1/Transpose_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/Transpose [Transpose] outputs: [/model/encoder/encoder.0/layers.0/linear1/Transpose_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/MatMul [MatMul] inputs: [/model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear_output_0 -> (1, 400, 256)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear1/Transpose_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_128 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_129 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear1/MatMul for ONNX node: /model/encoder/encoder.0/layers.0/linear1/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear1/MatMul_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/MatMul [MatMul] outputs: [/model/encoder/encoder.0/layers.0/linear1/MatMul_output_0 -> (1, 400, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.encoder.0.layers.0.linear1.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/Add [Add] inputs: [model.encoder.encoder.0.layers.0.linear1.bias -> (1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear1/MatMul_output_0 -> (1, 400, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.encoder.0.layers.0.linear1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_130 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_131 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear1/Add for ONNX node: /model/encoder/encoder.0/layers.0/linear1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear1/Add_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear1/Add [Add] outputs: [/model/encoder/encoder.0/layers.0/linear1/Add_output_0 -> (1, 400, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/activation/Div [Div]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/activation/Div [Div]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/activation/Div [Div] inputs: [/model/encoder/encoder.0/layers.0/linear1/Add_output_0 -> (1, 400, 1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/activation/Constant_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_132 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_133 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/activation/Div for ONNX node: /model/encoder/encoder.0/layers.0/activation/Div
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/activation/Div_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/activation/Div_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/activation/Div [Div] outputs: [/model/encoder/encoder.0/layers.0/activation/Div_output_0 -> (1, 400, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/activation/Erf [Erf]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/activation/Erf [Erf]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Div_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/activation/Erf [Erf] inputs: [/model/encoder/encoder.0/layers.0/activation/Div_output_0 -> (1, 400, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/activation/Erf for ONNX node: /model/encoder/encoder.0/layers.0/activation/Erf
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/activation/Erf_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/activation/Erf_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/activation/Erf [Erf] outputs: [/model/encoder/encoder.0/layers.0/activation/Erf_output_0 -> (1, 400, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/activation/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/activation/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Erf_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/activation/Add [Add] inputs: [/model/encoder/encoder.0/layers.0/activation/Erf_output_0 -> (1, 400, 1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_1_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/activation/Constant_1_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_134 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_135 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/activation/Add for ONNX node: /model/encoder/encoder.0/layers.0/activation/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/activation/Add_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/activation/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/activation/Add [Add] outputs: [/model/encoder/encoder.0/layers.0/activation/Add_output_0 -> (1, 400, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/activation/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/activation/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/activation/Mul [Mul] inputs: [/model/encoder/encoder.0/layers.0/linear1/Add_output_0 -> (1, 400, 1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Add_output_0 -> (1, 400, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/activation/Mul for ONNX node: /model/encoder/encoder.0/layers.0/activation/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/activation/Mul_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/activation/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/activation/Mul [Mul] outputs: [/model/encoder/encoder.0/layers.0/activation/Mul_output_0 -> (1, 400, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/activation/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/activation/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/activation/Mul_1 [Mul] inputs: [/model/encoder/encoder.0/layers.0/activation/Mul_output_0 -> (1, 400, 1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_2_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/activation/Constant_2_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_136 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_137 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/activation/Mul_1 for ONNX node: /model/encoder/encoder.0/layers.0/activation/Mul_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/activation/Mul_1_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/activation/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/activation/Mul_1 [Mul] outputs: [/model/encoder/encoder.0/layers.0/activation/Mul_1_output_0 -> (1, 400, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/encoder.0/layers.0/activation/Mul_1_output_0 -> (1, 400, 1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_138 for ONNX node: tmp_weight_138
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear_output_0 -> (1, 400, 1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear_output_0 -> (1, 400, 1024)[INT8]], [/model/encoder/encoder.0/layers.0/linear2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_139 for ONNX node: tmp_weight_139
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear_output_0 -> (1, 400, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.encoder.0.layers.0.linear2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.encoder.0.layers.0.linear2.weight -> (256, 1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear2/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.encoder.0.layers.0.linear2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_140 for ONNX node: tmp_weight_140
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/encoder.0/layers.0/linear2/weight_quantizer/QuantizeLinear_output_0 -> (256, 1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/encoder.0/layers.0/linear2/weight_quantizer/QuantizeLinear_output_0 -> (256, 1024)[INT8]], [/model/encoder/encoder.0/layers.0/linear2/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_141 for ONNX node: tmp_weight_141
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/Transpose [Transpose] inputs: [/model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear2/Transpose for ONNX node: /model/encoder/encoder.0/layers.0/linear2/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear2/Transpose_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/Transpose [Transpose] outputs: [/model/encoder/encoder.0/layers.0/linear2/Transpose_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/MatMul [MatMul] inputs: [/model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear_output_0 -> (1, 400, 1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear2/Transpose_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_142 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_143 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear2/MatMul for ONNX node: /model/encoder/encoder.0/layers.0/linear2/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear2/MatMul_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/MatMul [MatMul] outputs: [/model/encoder/encoder.0/layers.0/linear2/MatMul_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/linear2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/linear2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.encoder.0.layers.0.linear2.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/Add [Add] inputs: [model.encoder.encoder.0.layers.0.linear2.bias -> (256)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear2/MatMul_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.encoder.0.layers.0.linear2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_144 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_145 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/linear2/Add for ONNX node: /model/encoder/encoder.0/layers.0/linear2/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/linear2/Add_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/linear2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/linear2/Add [Add] outputs: [/model/encoder/encoder.0/layers.0/linear2/Add_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/Add_2 [Add] inputs: [/model/encoder/encoder.0/layers.0/norm1/LayerNormalization_output_0 -> (1, 400, 256)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear2/Add_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/Add_2 for ONNX node: /model/encoder/encoder.0/layers.0/Add_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/Add_2_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/Add_2 [Add] outputs: [/model/encoder/encoder.0/layers.0/Add_2_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.encoder.0.layers.0.norm2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.encoder.0.layers.0.norm2.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/norm2/LayerNormalization [LayerNormalization] inputs: [/model/encoder/encoder.0/layers.0/Add_2_output_0 -> (1, 400, 256)[FLOAT]], [model.encoder.encoder.0.layers.0.norm2.weight -> (256)[FLOAT]], [model.encoder.encoder.0.layers.0.norm2.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.encoder.0.layers.0.norm2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.encoder.0.layers.0.norm2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_148 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_149 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_150 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_151 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization for ONNX node: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization_output_0 for ONNX tensor: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/norm2/LayerNormalization [LayerNormalization] outputs: [/model/encoder/encoder.0/layers.0/norm2/LayerNormalization_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Transpose_1 [Transpose] inputs: [/model/encoder/encoder.0/layers.0/norm2/LayerNormalization_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/Transpose_1 for ONNX node: /model/encoder/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/Transpose_1_output_0 for ONNX tensor: /model/encoder/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Transpose_1 [Transpose] outputs: [/model/encoder/Transpose_1_output_0 -> (1, 256, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Concat_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Reshape_1 [Reshape] inputs: [/model/encoder/Transpose_1_output_0 -> (1, 256, 400)[FLOAT]], [/model/encoder/Concat_1_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_152 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/Reshape_1 for ONNX node: /model/encoder/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/Reshape_1_output_0 for ONNX tensor: /model/encoder/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Reshape_1 [Reshape] outputs: [/model/encoder/Reshape_1_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/Reshape_1_output_0 -> (1, 256, 20, 20)[FLOAT]], [/model/encoder/lateral_convs.0/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.0/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/lateral_convs.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_153 for ONNX node: tmp_weight_153
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 20, 20)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 20, 20)[INT8]], [/model/encoder/lateral_convs.0/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_154 for ONNX node: tmp_weight_154
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.lateral_convs.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.lateral_convs.0.conv.weight -> (256, 256, 1, 1)[FLOAT]], [/model/encoder/lateral_convs.0/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.lateral_convs.0.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/lateral_convs.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_155 for ONNX node: tmp_weight_155
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 1, 1)[INT8]], [/model/encoder/lateral_convs.0/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_156 for ONNX node: tmp_weight_156
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/conv/Conv [Conv] inputs: [/model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 20, 20)[FLOAT]], [/model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.0/conv/Conv for ONNX node: /model/encoder/lateral_convs.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.0/conv/Conv_output_0 for ONNX tensor: /model/encoder/lateral_convs.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/conv/Conv [Conv] outputs: [/model/encoder/lateral_convs.0/conv/Conv_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.0/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.0/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.lateral_convs.0.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.lateral_convs.0.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.lateral_convs.0.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.lateral_convs.0.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/lateral_convs.0/conv/Conv_output_0 -> (1, 256, 20, 20)[FLOAT]], [model.encoder.lateral_convs.0.norm.weight -> (256)[FLOAT]], [model.encoder.lateral_convs.0.norm.bias -> (256)[FLOAT]], [model.encoder.lateral_convs.0.norm.running_mean -> (256)[FLOAT]], [model.encoder.lateral_convs.0.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.0/norm/BatchNormalization for ONNX node: /model/encoder/lateral_convs.0/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/lateral_convs.0/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.0/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.0/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/act/Sigmoid [Sigmoid] inputs: [/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.0/act/Sigmoid for ONNX node: /model/encoder/lateral_convs.0/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.0/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/lateral_convs.0/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/act/Sigmoid [Sigmoid] outputs: [/model/encoder/lateral_convs.0/act/Sigmoid_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.0/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.0/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/act/Mul [Mul] inputs: [/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], [/model/encoder/lateral_convs.0/act/Sigmoid_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.0/act/Mul for ONNX node: /model/encoder/lateral_convs.0/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.0/act/Mul_output_0 for ONNX tensor: /model/encoder/lateral_convs.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.0/act/Mul [Mul] outputs: [/model/encoder/lateral_convs.0/act/Mul_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/Resize [Resize]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/Resize [Resize]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_9_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Resize [Resize] inputs: [/model/encoder/lateral_convs.0/act/Mul_output_0 -> (1, 256, 20, 20)[FLOAT]], [optional input, not set], [/model/encoder/Constant_9_output_0 -> (4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/Resize for ONNX node: /model/encoder/Resize
[05/21/2025-09:28:09] [V] [TRT] Running resize layer with: 
Transformation mode: asymmetric
Resize mode: nearest

[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/Resize_output_0 for ONNX tensor: /model/encoder/Resize_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Resize [Resize] outputs: [/model/encoder/Resize_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/Concat_2 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/Concat_2 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Resize_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Concat_2 [Concat] inputs: [/model/encoder/Resize_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/encoder/input_proj.1/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/Concat_2 for ONNX node: /model/encoder/Concat_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/Concat_2_output_0 for ONNX tensor: /model/encoder/Concat_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Concat_2 [Concat] outputs: [/model/encoder/Concat_2_output_0 -> (1, 512, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Concat_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/Concat_2_output_0 -> (1, 512, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_157 for ONNX node: tmp_weight_157
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 40, 40)[INT8]], [/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_158 for ONNX node: tmp_weight_158
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.fpn_blocks.0.conv1.conv.weight -> (128, 512, 1, 1)[FLOAT]], [/model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.fpn_blocks.0.conv1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_159 for ONNX node: tmp_weight_159
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], [/model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_160 for ONNX node: tmp_weight_160
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/Conv [Conv] inputs: [/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv1/conv/Conv for ONNX node: /model/encoder/fpn_blocks.0/conv1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv1/conv/Conv_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/Conv [Conv] outputs: [/model/encoder/fpn_blocks.0/conv1/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/fpn_blocks.0/conv1/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], [model.encoder.fpn_blocks.0.conv1.norm.weight -> (128)[FLOAT]], [model.encoder.fpn_blocks.0.conv1.norm.bias -> (128)[FLOAT]], [model.encoder.fpn_blocks.0.conv1.norm.running_mean -> (128)[FLOAT]], [model.encoder.fpn_blocks.0.conv1.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization for ONNX node: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/act/Sigmoid [Sigmoid] inputs: [/model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid for ONNX node: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/act/Sigmoid [Sigmoid] outputs: [/model/encoder/fpn_blocks.0/conv1/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/act/Mul [Mul] inputs: [/model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/conv1/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv1/act/Mul for ONNX node: /model/encoder/fpn_blocks.0/conv1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv1/act/Mul_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/act/Mul [Mul] outputs: [/model/encoder/fpn_blocks.0/conv1/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/fpn_blocks.0/conv1/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_161 for ONNX node: tmp_weight_161
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_162 for ONNX node: tmp_weight_162
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_163 for ONNX node: tmp_weight_163
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_164 for ONNX node: tmp_weight_164
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.bottlenecks.0.conv.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv [Conv] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], [model.encoder.fpn_blocks.0.bottlenecks.0.conv.bias -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv [Conv] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul [Mul] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul [Mul] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_165 for ONNX node: tmp_weight_165
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_166 for ONNX node: tmp_weight_166
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_167 for ONNX node: tmp_weight_167
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_168 for ONNX node: tmp_weight_168
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.bottlenecks.1.conv.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv [Conv] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], [model.encoder.fpn_blocks.0.bottlenecks.1.conv.bias -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv [Conv] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul [Mul] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul [Mul] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_169 for ONNX node: tmp_weight_169
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_170 for ONNX node: tmp_weight_170
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_171 for ONNX node: tmp_weight_171
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_172 for ONNX node: tmp_weight_172
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.bottlenecks.2.conv.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Conv] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], [model.encoder.fpn_blocks.0.bottlenecks.2.conv.bias -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Conv] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul [Mul] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul for ONNX node: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul [Mul] outputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.fpn_blocks.0.conv2.conv.weight -> (128, 512, 1, 1)[FLOAT]], [/model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.fpn_blocks.0.conv2.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_173 for ONNX node: tmp_weight_173
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], [/model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_174 for ONNX node: tmp_weight_174
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv2/conv/Conv [Conv] inputs: [/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv2/conv/Conv for ONNX node: /model/encoder/fpn_blocks.0/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv2/conv/Conv_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv2/conv/Conv [Conv] outputs: [/model/encoder/fpn_blocks.0/conv2/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/fpn_blocks.0/conv2/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], [model.encoder.fpn_blocks.0.conv2.norm.weight -> (128)[FLOAT]], [model.encoder.fpn_blocks.0.conv2.norm.bias -> (128)[FLOAT]], [model.encoder.fpn_blocks.0.conv2.norm.running_mean -> (128)[FLOAT]], [model.encoder.fpn_blocks.0.conv2.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization for ONNX node: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv2/act/Sigmoid [Sigmoid] inputs: [/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid for ONNX node: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv2/act/Sigmoid [Sigmoid] outputs: [/model/encoder/fpn_blocks.0/conv2/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv2/act/Mul [Mul] inputs: [/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/conv2/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv2/act/Mul for ONNX node: /model/encoder/fpn_blocks.0/conv2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv2/act/Mul_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv2/act/Mul [Mul] outputs: [/model/encoder/fpn_blocks.0/conv2/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/Add [Add] inputs: [/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/conv2/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/Add for ONNX node: /model/encoder/fpn_blocks.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/Add_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/Add [Add] outputs: [/model/encoder/fpn_blocks.0/Add_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/fpn_blocks.0/Add_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_175 for ONNX node: tmp_weight_175
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], [/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_176 for ONNX node: tmp_weight_176
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.fpn_blocks.0.conv3.conv.weight -> (256, 128, 1, 1)[FLOAT]], [/model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.fpn_blocks.0.conv3.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_177 for ONNX node: tmp_weight_177
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 1, 1)[INT8]], [/model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_178 for ONNX node: tmp_weight_178
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv3/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv3/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/conv/Conv [Conv] inputs: [/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv3/conv/Conv for ONNX node: /model/encoder/fpn_blocks.0/conv3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv3/conv/Conv_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv3/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/conv/Conv [Conv] outputs: [/model/encoder/fpn_blocks.0/conv3/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv3.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv3.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv3.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.0.conv3.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/fpn_blocks.0/conv3/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], [model.encoder.fpn_blocks.0.conv3.norm.weight -> (256)[FLOAT]], [model.encoder.fpn_blocks.0.conv3.norm.bias -> (256)[FLOAT]], [model.encoder.fpn_blocks.0.conv3.norm.running_mean -> (256)[FLOAT]], [model.encoder.fpn_blocks.0.conv3.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization for ONNX node: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/act/Sigmoid [Sigmoid] inputs: [/model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid for ONNX node: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/act/Sigmoid [Sigmoid] outputs: [/model/encoder/fpn_blocks.0/conv3/act/Sigmoid_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.0/conv3/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.0/conv3/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/act/Mul [Mul] inputs: [/model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.0/conv3/act/Sigmoid_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.0/conv3/act/Mul for ONNX node: /model/encoder/fpn_blocks.0/conv3/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.0/conv3/act/Mul_output_0 for ONNX tensor: /model/encoder/fpn_blocks.0/conv3/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.0/conv3/act/Mul [Mul] outputs: [/model/encoder/fpn_blocks.0/conv3/act/Mul_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.0/conv3/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/fpn_blocks.0/conv3/act/Mul_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/encoder/lateral_convs.1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.1/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/lateral_convs.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_179 for ONNX node: tmp_weight_179
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 40, 40)[INT8]], [/model/encoder/lateral_convs.1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_180 for ONNX node: tmp_weight_180
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.lateral_convs.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.lateral_convs.1.conv.weight -> (256, 256, 1, 1)[FLOAT]], [/model/encoder/lateral_convs.1/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.lateral_convs.1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/lateral_convs.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_181 for ONNX node: tmp_weight_181
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 1, 1)[INT8]], [/model/encoder/lateral_convs.1/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_182 for ONNX node: tmp_weight_182
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/conv/Conv [Conv] inputs: [/model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.1/conv/Conv for ONNX node: /model/encoder/lateral_convs.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.1/conv/Conv_output_0 for ONNX tensor: /model/encoder/lateral_convs.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/conv/Conv [Conv] outputs: [/model/encoder/lateral_convs.1/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.lateral_convs.1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.lateral_convs.1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.lateral_convs.1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.lateral_convs.1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/lateral_convs.1/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], [model.encoder.lateral_convs.1.norm.weight -> (256)[FLOAT]], [model.encoder.lateral_convs.1.norm.bias -> (256)[FLOAT]], [model.encoder.lateral_convs.1.norm.running_mean -> (256)[FLOAT]], [model.encoder.lateral_convs.1.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.1/norm/BatchNormalization for ONNX node: /model/encoder/lateral_convs.1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.1/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/lateral_convs.1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/lateral_convs.1/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/act/Sigmoid [Sigmoid] inputs: [/model/encoder/lateral_convs.1/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.1/act/Sigmoid for ONNX node: /model/encoder/lateral_convs.1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.1/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/lateral_convs.1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/act/Sigmoid [Sigmoid] outputs: [/model/encoder/lateral_convs.1/act/Sigmoid_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/lateral_convs.1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/lateral_convs.1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/act/Mul [Mul] inputs: [/model/encoder/lateral_convs.1/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/encoder/lateral_convs.1/act/Sigmoid_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/lateral_convs.1/act/Mul for ONNX node: /model/encoder/lateral_convs.1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/lateral_convs.1/act/Mul_output_0 for ONNX tensor: /model/encoder/lateral_convs.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/lateral_convs.1/act/Mul [Mul] outputs: [/model/encoder/lateral_convs.1/act/Mul_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/Resize_1 [Resize]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/Resize_1 [Resize]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_9_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Resize_1 [Resize] inputs: [/model/encoder/lateral_convs.1/act/Mul_output_0 -> (1, 256, 40, 40)[FLOAT]], [optional input, not set], [/model/encoder/Constant_9_output_0 -> (4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/Resize_1 for ONNX node: /model/encoder/Resize_1
[05/21/2025-09:28:09] [V] [TRT] Running resize layer with: 
Transformation mode: asymmetric
Resize mode: nearest

[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/Resize_1_output_0 for ONNX tensor: /model/encoder/Resize_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Resize_1 [Resize] outputs: [/model/encoder/Resize_1_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/Concat_3 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/Concat_3 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Resize_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/input_proj.0/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Concat_3 [Concat] inputs: [/model/encoder/Resize_1_output_0 -> (1, 256, 80, 80)[FLOAT]], [/model/encoder/input_proj.0/norm/BatchNormalization_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/Concat_3 for ONNX node: /model/encoder/Concat_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/Concat_3_output_0 for ONNX tensor: /model/encoder/Concat_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Concat_3 [Concat] outputs: [/model/encoder/Concat_3_output_0 -> (1, 512, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Concat_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/Concat_3_output_0 -> (1, 512, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_183 for ONNX node: tmp_weight_183
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 80, 80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 80, 80)[INT8]], [/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_184 for ONNX node: tmp_weight_184
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.fpn_blocks.1.conv1.conv.weight -> (128, 512, 1, 1)[FLOAT]], [/model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.fpn_blocks.1.conv1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_185 for ONNX node: tmp_weight_185
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], [/model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_186 for ONNX node: tmp_weight_186
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/conv/Conv [Conv] inputs: [/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv1/conv/Conv for ONNX node: /model/encoder/fpn_blocks.1/conv1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv1/conv/Conv_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/conv/Conv [Conv] outputs: [/model/encoder/fpn_blocks.1/conv1/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/fpn_blocks.1/conv1/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], [model.encoder.fpn_blocks.1.conv1.norm.weight -> (128)[FLOAT]], [model.encoder.fpn_blocks.1.conv1.norm.bias -> (128)[FLOAT]], [model.encoder.fpn_blocks.1.conv1.norm.running_mean -> (128)[FLOAT]], [model.encoder.fpn_blocks.1.conv1.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization for ONNX node: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/act/Sigmoid [Sigmoid] inputs: [/model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid for ONNX node: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/act/Sigmoid [Sigmoid] outputs: [/model/encoder/fpn_blocks.1/conv1/act/Sigmoid_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/act/Mul [Mul] inputs: [/model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/conv1/act/Sigmoid_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv1/act/Mul for ONNX node: /model/encoder/fpn_blocks.1/conv1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv1/act/Mul_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv1/act/Mul [Mul] outputs: [/model/encoder/fpn_blocks.1/conv1/act/Mul_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/fpn_blocks.1/conv1/act/Mul_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_187 for ONNX node: tmp_weight_187
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_188 for ONNX node: tmp_weight_188
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_189 for ONNX node: tmp_weight_189
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_190 for ONNX node: tmp_weight_190
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.bottlenecks.0.conv.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv [Conv] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], [model.encoder.fpn_blocks.1.bottlenecks.0.conv.bias -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv [Conv] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul [Mul] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul [Mul] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_191 for ONNX node: tmp_weight_191
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_192 for ONNX node: tmp_weight_192
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_193 for ONNX node: tmp_weight_193
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_194 for ONNX node: tmp_weight_194
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.bottlenecks.1.conv.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv [Conv] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], [model.encoder.fpn_blocks.1.bottlenecks.1.conv.bias -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv [Conv] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul [Mul] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul [Mul] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_195 for ONNX node: tmp_weight_195
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_196 for ONNX node: tmp_weight_196
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_197 for ONNX node: tmp_weight_197
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_198 for ONNX node: tmp_weight_198
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.bottlenecks.2.conv.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Conv] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], [model.encoder.fpn_blocks.1.bottlenecks.2.conv.bias -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Conv] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul [Mul] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul for ONNX node: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul [Mul] outputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.fpn_blocks.1.conv2.conv.weight -> (128, 512, 1, 1)[FLOAT]], [/model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.fpn_blocks.1.conv2.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_199 for ONNX node: tmp_weight_199
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], [/model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_200 for ONNX node: tmp_weight_200
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv2/conv/Conv [Conv] inputs: [/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv2/conv/Conv for ONNX node: /model/encoder/fpn_blocks.1/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv2/conv/Conv_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv2/conv/Conv [Conv] outputs: [/model/encoder/fpn_blocks.1/conv2/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/fpn_blocks.1/conv2/conv/Conv_output_0 -> (1, 128, 80, 80)[FLOAT]], [model.encoder.fpn_blocks.1.conv2.norm.weight -> (128)[FLOAT]], [model.encoder.fpn_blocks.1.conv2.norm.bias -> (128)[FLOAT]], [model.encoder.fpn_blocks.1.conv2.norm.running_mean -> (128)[FLOAT]], [model.encoder.fpn_blocks.1.conv2.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization for ONNX node: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv2/act/Sigmoid [Sigmoid] inputs: [/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid for ONNX node: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv2/act/Sigmoid [Sigmoid] outputs: [/model/encoder/fpn_blocks.1/conv2/act/Sigmoid_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv2/act/Mul [Mul] inputs: [/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/conv2/act/Sigmoid_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv2/act/Mul for ONNX node: /model/encoder/fpn_blocks.1/conv2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv2/act/Mul_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv2/act/Mul [Mul] outputs: [/model/encoder/fpn_blocks.1/conv2/act/Mul_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/Add [Add] inputs: [/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/conv2/act/Mul_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/Add for ONNX node: /model/encoder/fpn_blocks.1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/Add_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/Add [Add] outputs: [/model/encoder/fpn_blocks.1/Add_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/fpn_blocks.1/Add_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_201 for ONNX node: tmp_weight_201
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 80, 80)[INT8]], [/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_202 for ONNX node: tmp_weight_202
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.fpn_blocks.1.conv3.conv.weight -> (256, 128, 1, 1)[FLOAT]], [/model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.fpn_blocks.1.conv3.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_203 for ONNX node: tmp_weight_203
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 1, 1)[INT8]], [/model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_204 for ONNX node: tmp_weight_204
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv3/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv3/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/conv/Conv [Conv] inputs: [/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv3/conv/Conv for ONNX node: /model/encoder/fpn_blocks.1/conv3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv3/conv/Conv_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv3/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/conv/Conv [Conv] outputs: [/model/encoder/fpn_blocks.1/conv3/conv/Conv_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv3.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv3.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv3.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.fpn_blocks.1.conv3.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/fpn_blocks.1/conv3/conv/Conv_output_0 -> (1, 256, 80, 80)[FLOAT]], [model.encoder.fpn_blocks.1.conv3.norm.weight -> (256)[FLOAT]], [model.encoder.fpn_blocks.1.conv3.norm.bias -> (256)[FLOAT]], [model.encoder.fpn_blocks.1.conv3.norm.running_mean -> (256)[FLOAT]], [model.encoder.fpn_blocks.1.conv3.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization for ONNX node: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/act/Sigmoid [Sigmoid] inputs: [/model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid for ONNX node: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/act/Sigmoid [Sigmoid] outputs: [/model/encoder/fpn_blocks.1/conv3/act/Sigmoid_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/fpn_blocks.1/conv3/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/fpn_blocks.1/conv3/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/act/Mul [Mul] inputs: [/model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization_output_0 -> (1, 256, 80, 80)[FLOAT]], [/model/encoder/fpn_blocks.1/conv3/act/Sigmoid_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/fpn_blocks.1/conv3/act/Mul for ONNX node: /model/encoder/fpn_blocks.1/conv3/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/fpn_blocks.1/conv3/act/Mul_output_0 for ONNX tensor: /model/encoder/fpn_blocks.1/conv3/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/fpn_blocks.1/conv3/act/Mul [Mul] outputs: [/model/encoder/fpn_blocks.1/conv3/act/Mul_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv3/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/fpn_blocks.1/conv3/act/Mul_output_0 -> (1, 256, 80, 80)[FLOAT]], [/model/encoder/downsample_convs.0/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.0/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/downsample_convs.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_205 for ONNX node: tmp_weight_205
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 80, 80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 80, 80)[INT8]], [/model/encoder/downsample_convs.0/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_206 for ONNX node: tmp_weight_206
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.downsample_convs.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.downsample_convs.0.conv.weight -> (256, 256, 3, 3)[FLOAT]], [/model/encoder/downsample_convs.0/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.downsample_convs.0.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/downsample_convs.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_207 for ONNX node: tmp_weight_207
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 3, 3)[INT8]], [/model/encoder/downsample_convs.0/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_208 for ONNX node: tmp_weight_208
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/conv/Conv [Conv] inputs: [/model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 80, 80)[FLOAT]], [/model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.0/conv/Conv for ONNX node: /model/encoder/downsample_convs.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.0/conv/Conv_output_0 for ONNX tensor: /model/encoder/downsample_convs.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/conv/Conv [Conv] outputs: [/model/encoder/downsample_convs.0/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.0/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.0/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.downsample_convs.0.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.downsample_convs.0.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.downsample_convs.0.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.downsample_convs.0.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/downsample_convs.0/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], [model.encoder.downsample_convs.0.norm.weight -> (256)[FLOAT]], [model.encoder.downsample_convs.0.norm.bias -> (256)[FLOAT]], [model.encoder.downsample_convs.0.norm.running_mean -> (256)[FLOAT]], [model.encoder.downsample_convs.0.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.0/norm/BatchNormalization for ONNX node: /model/encoder/downsample_convs.0/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.0/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/downsample_convs.0/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/downsample_convs.0/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.0/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.0/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/act/Sigmoid [Sigmoid] inputs: [/model/encoder/downsample_convs.0/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.0/act/Sigmoid for ONNX node: /model/encoder/downsample_convs.0/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.0/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/downsample_convs.0/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/act/Sigmoid [Sigmoid] outputs: [/model/encoder/downsample_convs.0/act/Sigmoid_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.0/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.0/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/act/Mul [Mul] inputs: [/model/encoder/downsample_convs.0/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/encoder/downsample_convs.0/act/Sigmoid_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.0/act/Mul for ONNX node: /model/encoder/downsample_convs.0/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.0/act/Mul_output_0 for ONNX tensor: /model/encoder/downsample_convs.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.0/act/Mul [Mul] outputs: [/model/encoder/downsample_convs.0/act/Mul_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/Concat_4 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/Concat_4 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Concat_4 [Concat] inputs: [/model/encoder/downsample_convs.0/act/Mul_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/encoder/lateral_convs.1/act/Mul_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/Concat_4 for ONNX node: /model/encoder/Concat_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/Concat_4_output_0 for ONNX tensor: /model/encoder/Concat_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Concat_4 [Concat] outputs: [/model/encoder/Concat_4_output_0 -> (1, 512, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Concat_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/Concat_4_output_0 -> (1, 512, 40, 40)[FLOAT]], [/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_209 for ONNX node: tmp_weight_209
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 40, 40)[INT8]], [/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_210 for ONNX node: tmp_weight_210
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.pan_blocks.0.conv1.conv.weight -> (128, 512, 1, 1)[FLOAT]], [/model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.pan_blocks.0.conv1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_211 for ONNX node: tmp_weight_211
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], [/model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_212 for ONNX node: tmp_weight_212
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/conv/Conv [Conv] inputs: [/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv1/conv/Conv for ONNX node: /model/encoder/pan_blocks.0/conv1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv1/conv/Conv_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/conv/Conv [Conv] outputs: [/model/encoder/pan_blocks.0/conv1/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/pan_blocks.0/conv1/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], [model.encoder.pan_blocks.0.conv1.norm.weight -> (128)[FLOAT]], [model.encoder.pan_blocks.0.conv1.norm.bias -> (128)[FLOAT]], [model.encoder.pan_blocks.0.conv1.norm.running_mean -> (128)[FLOAT]], [model.encoder.pan_blocks.0.conv1.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization for ONNX node: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/pan_blocks.0/conv1/norm/BatchNormalization_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/act/Sigmoid [Sigmoid] inputs: [/model/encoder/pan_blocks.0/conv1/norm/BatchNormalization_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv1/act/Sigmoid for ONNX node: /model/encoder/pan_blocks.0/conv1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv1/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/act/Sigmoid [Sigmoid] outputs: [/model/encoder/pan_blocks.0/conv1/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/act/Mul [Mul] inputs: [/model/encoder/pan_blocks.0/conv1/norm/BatchNormalization_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/conv1/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv1/act/Mul for ONNX node: /model/encoder/pan_blocks.0/conv1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv1/act/Mul_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv1/act/Mul [Mul] outputs: [/model/encoder/pan_blocks.0/conv1/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/pan_blocks.0/conv1/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_213 for ONNX node: tmp_weight_213
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_214 for ONNX node: tmp_weight_214
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.bottlenecks.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.pan_blocks.0.bottlenecks.0.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.pan_blocks.0.bottlenecks.0.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_215 for ONNX node: tmp_weight_215
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_216 for ONNX node: tmp_weight_216
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.bottlenecks.0.conv.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv [Conv] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], [model.encoder.pan_blocks.0.bottlenecks.0.conv.bias -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv [Conv] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul [Mul] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul [Mul] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_217 for ONNX node: tmp_weight_217
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_218 for ONNX node: tmp_weight_218
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.bottlenecks.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.pan_blocks.0.bottlenecks.1.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.pan_blocks.0.bottlenecks.1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_219 for ONNX node: tmp_weight_219
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_220 for ONNX node: tmp_weight_220
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.bottlenecks.1.conv.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv [Conv] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], [model.encoder.pan_blocks.0.bottlenecks.1.conv.bias -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv [Conv] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul [Mul] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul [Mul] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_221 for ONNX node: tmp_weight_221
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_222 for ONNX node: tmp_weight_222
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.bottlenecks.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.pan_blocks.0.bottlenecks.2.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.pan_blocks.0.bottlenecks.2.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_223 for ONNX node: tmp_weight_223
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_224 for ONNX node: tmp_weight_224
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.bottlenecks.2.conv.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Conv] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], [model.encoder.pan_blocks.0.bottlenecks.2.conv.bias -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Conv] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul [Mul] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul for ONNX node: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul [Mul] outputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.pan_blocks.0.conv2.conv.weight -> (128, 512, 1, 1)[FLOAT]], [/model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.pan_blocks.0.conv2.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_225 for ONNX node: tmp_weight_225
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], [/model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_226 for ONNX node: tmp_weight_226
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv2/conv/Conv [Conv] inputs: [/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv2/conv/Conv for ONNX node: /model/encoder/pan_blocks.0/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv2/conv/Conv_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv2/conv/Conv [Conv] outputs: [/model/encoder/pan_blocks.0/conv2/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/pan_blocks.0/conv2/conv/Conv_output_0 -> (1, 128, 40, 40)[FLOAT]], [model.encoder.pan_blocks.0.conv2.norm.weight -> (128)[FLOAT]], [model.encoder.pan_blocks.0.conv2.norm.bias -> (128)[FLOAT]], [model.encoder.pan_blocks.0.conv2.norm.running_mean -> (128)[FLOAT]], [model.encoder.pan_blocks.0.conv2.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization for ONNX node: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv2/act/Sigmoid [Sigmoid] inputs: [/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv2/act/Sigmoid for ONNX node: /model/encoder/pan_blocks.0/conv2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv2/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv2/act/Sigmoid [Sigmoid] outputs: [/model/encoder/pan_blocks.0/conv2/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv2/act/Mul [Mul] inputs: [/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/conv2/act/Sigmoid_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv2/act/Mul for ONNX node: /model/encoder/pan_blocks.0/conv2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv2/act/Mul_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv2/act/Mul [Mul] outputs: [/model/encoder/pan_blocks.0/conv2/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/Add [Add] inputs: [/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/conv2/act/Mul_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/Add for ONNX node: /model/encoder/pan_blocks.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/Add_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/Add [Add] outputs: [/model/encoder/pan_blocks.0/Add_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/pan_blocks.0/Add_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_227 for ONNX node: tmp_weight_227
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 40, 40)[INT8]], [/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_228 for ONNX node: tmp_weight_228
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.pan_blocks.0.conv3.conv.weight -> (256, 128, 1, 1)[FLOAT]], [/model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.pan_blocks.0.conv3.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_229 for ONNX node: tmp_weight_229
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 1, 1)[INT8]], [/model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_230 for ONNX node: tmp_weight_230
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv3/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv3/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/conv/Conv [Conv] inputs: [/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv3/conv/Conv for ONNX node: /model/encoder/pan_blocks.0/conv3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv3/conv/Conv_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv3/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/conv/Conv [Conv] outputs: [/model/encoder/pan_blocks.0/conv3/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv3.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv3.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv3.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.0.conv3.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/pan_blocks.0/conv3/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], [model.encoder.pan_blocks.0.conv3.norm.weight -> (256)[FLOAT]], [model.encoder.pan_blocks.0.conv3.norm.bias -> (256)[FLOAT]], [model.encoder.pan_blocks.0.conv3.norm.running_mean -> (256)[FLOAT]], [model.encoder.pan_blocks.0.conv3.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization for ONNX node: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/pan_blocks.0/conv3/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv3/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv3/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/act/Sigmoid [Sigmoid] inputs: [/model/encoder/pan_blocks.0/conv3/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv3/act/Sigmoid for ONNX node: /model/encoder/pan_blocks.0/conv3/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv3/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv3/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/act/Sigmoid [Sigmoid] outputs: [/model/encoder/pan_blocks.0/conv3/act/Sigmoid_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.0/conv3/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.0/conv3/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/act/Mul [Mul] inputs: [/model/encoder/pan_blocks.0/conv3/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/encoder/pan_blocks.0/conv3/act/Sigmoid_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.0/conv3/act/Mul for ONNX node: /model/encoder/pan_blocks.0/conv3/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.0/conv3/act/Mul_output_0 for ONNX tensor: /model/encoder/pan_blocks.0/conv3/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.0/conv3/act/Mul [Mul] outputs: [/model/encoder/pan_blocks.0/conv3/act/Mul_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.0/conv3/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/pan_blocks.0/conv3/act/Mul_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/encoder/downsample_convs.1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.1/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/downsample_convs.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_231 for ONNX node: tmp_weight_231
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 40, 40)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 40, 40)[INT8]], [/model/encoder/downsample_convs.1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_232 for ONNX node: tmp_weight_232
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.downsample_convs.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.downsample_convs.1.conv.weight -> (256, 256, 3, 3)[FLOAT]], [/model/encoder/downsample_convs.1/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.downsample_convs.1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/downsample_convs.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_233 for ONNX node: tmp_weight_233
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 3, 3)[INT8]], [/model/encoder/downsample_convs.1/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_234 for ONNX node: tmp_weight_234
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/conv/Conv [Conv] inputs: [/model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.1/conv/Conv for ONNX node: /model/encoder/downsample_convs.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.1/conv/Conv_output_0 for ONNX tensor: /model/encoder/downsample_convs.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/conv/Conv [Conv] outputs: [/model/encoder/downsample_convs.1/conv/Conv_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.downsample_convs.1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.downsample_convs.1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.downsample_convs.1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.downsample_convs.1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/downsample_convs.1/conv/Conv_output_0 -> (1, 256, 20, 20)[FLOAT]], [model.encoder.downsample_convs.1.norm.weight -> (256)[FLOAT]], [model.encoder.downsample_convs.1.norm.bias -> (256)[FLOAT]], [model.encoder.downsample_convs.1.norm.running_mean -> (256)[FLOAT]], [model.encoder.downsample_convs.1.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.1/norm/BatchNormalization for ONNX node: /model/encoder/downsample_convs.1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.1/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/downsample_convs.1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/downsample_convs.1/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/act/Sigmoid [Sigmoid] inputs: [/model/encoder/downsample_convs.1/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.1/act/Sigmoid for ONNX node: /model/encoder/downsample_convs.1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.1/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/downsample_convs.1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/act/Sigmoid [Sigmoid] outputs: [/model/encoder/downsample_convs.1/act/Sigmoid_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/downsample_convs.1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/downsample_convs.1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/act/Mul [Mul] inputs: [/model/encoder/downsample_convs.1/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], [/model/encoder/downsample_convs.1/act/Sigmoid_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/downsample_convs.1/act/Mul for ONNX node: /model/encoder/downsample_convs.1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/downsample_convs.1/act/Mul_output_0 for ONNX tensor: /model/encoder/downsample_convs.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/downsample_convs.1/act/Mul [Mul] outputs: [/model/encoder/downsample_convs.1/act/Mul_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/Concat_5 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/Concat_5 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/lateral_convs.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Concat_5 [Concat] inputs: [/model/encoder/downsample_convs.1/act/Mul_output_0 -> (1, 256, 20, 20)[FLOAT]], [/model/encoder/lateral_convs.0/act/Mul_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/Concat_5 for ONNX node: /model/encoder/Concat_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/Concat_5_output_0 for ONNX tensor: /model/encoder/Concat_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/Concat_5 [Concat] outputs: [/model/encoder/Concat_5_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Concat_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/Concat_5_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_235 for ONNX node: tmp_weight_235
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 20, 20)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 512, 20, 20)[INT8]], [/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_236 for ONNX node: tmp_weight_236
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.pan_blocks.1.conv1.conv.weight -> (128, 512, 1, 1)[FLOAT]], [/model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.pan_blocks.1.conv1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_237 for ONNX node: tmp_weight_237
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], [/model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_238 for ONNX node: tmp_weight_238
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/Conv [Conv] inputs: [/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv1/conv/Conv for ONNX node: /model/encoder/pan_blocks.1/conv1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv1/conv/Conv_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/Conv [Conv] outputs: [/model/encoder/pan_blocks.1/conv1/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/pan_blocks.1/conv1/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], [model.encoder.pan_blocks.1.conv1.norm.weight -> (128)[FLOAT]], [model.encoder.pan_blocks.1.conv1.norm.bias -> (128)[FLOAT]], [model.encoder.pan_blocks.1.conv1.norm.running_mean -> (128)[FLOAT]], [model.encoder.pan_blocks.1.conv1.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization for ONNX node: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/pan_blocks.1/conv1/norm/BatchNormalization_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/act/Sigmoid [Sigmoid] inputs: [/model/encoder/pan_blocks.1/conv1/norm/BatchNormalization_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv1/act/Sigmoid for ONNX node: /model/encoder/pan_blocks.1/conv1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv1/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/act/Sigmoid [Sigmoid] outputs: [/model/encoder/pan_blocks.1/conv1/act/Sigmoid_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/act/Mul [Mul] inputs: [/model/encoder/pan_blocks.1/conv1/norm/BatchNormalization_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/conv1/act/Sigmoid_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv1/act/Mul for ONNX node: /model/encoder/pan_blocks.1/conv1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv1/act/Mul_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv1/act/Mul [Mul] outputs: [/model/encoder/pan_blocks.1/conv1/act/Mul_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/pan_blocks.1/conv1/act/Mul_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_239 for ONNX node: tmp_weight_239
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 20, 20)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 20, 20)[INT8]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_240 for ONNX node: tmp_weight_240
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.bottlenecks.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.pan_blocks.1.bottlenecks.0.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.pan_blocks.1.bottlenecks.0.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_241 for ONNX node: tmp_weight_241
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_242 for ONNX node: tmp_weight_242
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.bottlenecks.0.conv.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv [Conv] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], [model.encoder.pan_blocks.1.bottlenecks.0.conv.bias -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv [Conv] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid [Sigmoid] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul [Mul] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul [Mul] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_243 for ONNX node: tmp_weight_243
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 20, 20)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 20, 20)[INT8]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_244 for ONNX node: tmp_weight_244
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.bottlenecks.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.pan_blocks.1.bottlenecks.1.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.pan_blocks.1.bottlenecks.1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_245 for ONNX node: tmp_weight_245
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_246 for ONNX node: tmp_weight_246
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.bottlenecks.1.conv.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv [Conv] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], [model.encoder.pan_blocks.1.bottlenecks.1.conv.bias -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv [Conv] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid [Sigmoid] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul [Mul] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul [Mul] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_247 for ONNX node: tmp_weight_247
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 20, 20)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 20, 20)[INT8]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_248 for ONNX node: tmp_weight_248
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.bottlenecks.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.pan_blocks.1.bottlenecks.2.conv.weight -> (128, 128, 3, 3)[FLOAT]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.pan_blocks.1.bottlenecks.2.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_249 for ONNX node: tmp_weight_249
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 128, 3, 3)[INT8]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_250 for ONNX node: tmp_weight_250
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.bottlenecks.2.conv.bias
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Conv] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 128, 3, 3)[FLOAT]], [model.encoder.pan_blocks.1.bottlenecks.2.conv.bias -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Conv] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid [Sigmoid] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul [Mul] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul for ONNX node: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul [Mul] outputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.pan_blocks.1.conv2.conv.weight -> (128, 512, 1, 1)[FLOAT]], [/model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.pan_blocks.1.conv2.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_251 for ONNX node: tmp_weight_251
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear_output_0 -> (128, 512, 1, 1)[INT8]], [/model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0 -> (128)[FLOAT]], [/model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (128)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_252 for ONNX node: tmp_weight_252
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv2/conv/Conv [Conv] inputs: [/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 512, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear_output_0 -> (128, 512, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv2/conv/Conv for ONNX node: /model/encoder/pan_blocks.1/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv2/conv/Conv_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv2/conv/Conv [Conv] outputs: [/model/encoder/pan_blocks.1/conv2/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/pan_blocks.1/conv2/conv/Conv_output_0 -> (1, 128, 20, 20)[FLOAT]], [model.encoder.pan_blocks.1.conv2.norm.weight -> (128)[FLOAT]], [model.encoder.pan_blocks.1.conv2.norm.bias -> (128)[FLOAT]], [model.encoder.pan_blocks.1.conv2.norm.running_mean -> (128)[FLOAT]], [model.encoder.pan_blocks.1.conv2.norm.running_var -> (128)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization for ONNX node: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv2/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv2/act/Sigmoid [Sigmoid] inputs: [/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv2/act/Sigmoid for ONNX node: /model/encoder/pan_blocks.1/conv2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv2/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv2/act/Sigmoid [Sigmoid] outputs: [/model/encoder/pan_blocks.1/conv2/act/Sigmoid_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv2/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv2/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv2/act/Mul [Mul] inputs: [/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/conv2/act/Sigmoid_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv2/act/Mul for ONNX node: /model/encoder/pan_blocks.1/conv2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv2/act/Mul_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv2/act/Mul [Mul] outputs: [/model/encoder/pan_blocks.1/conv2/act/Mul_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv2/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/Add [Add] inputs: [/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/conv2/act/Mul_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/Add for ONNX node: /model/encoder/pan_blocks.1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/Add_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/Add [Add] outputs: [/model/encoder/pan_blocks.1/Add_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/pan_blocks.1/Add_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_253 for ONNX node: tmp_weight_253
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 20, 20)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 128, 20, 20)[INT8]], [/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_254 for ONNX node: tmp_weight_254
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.encoder.pan_blocks.1.conv3.conv.weight -> (256, 128, 1, 1)[FLOAT]], [/model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.encoder.pan_blocks.1.conv3.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_255 for ONNX node: tmp_weight_255
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 128, 1, 1)[INT8]], [/model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_256 for ONNX node: tmp_weight_256
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv3/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv3/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/conv/Conv [Conv] inputs: [/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 128, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 128, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv3/conv/Conv for ONNX node: /model/encoder/pan_blocks.1/conv3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv3/conv/Conv_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv3/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/conv/Conv [Conv] outputs: [/model/encoder/pan_blocks.1/conv3/conv/Conv_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv3.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv3.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv3.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.encoder.pan_blocks.1.conv3.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization [BatchNormalization] inputs: [/model/encoder/pan_blocks.1/conv3/conv/Conv_output_0 -> (1, 256, 20, 20)[FLOAT]], [model.encoder.pan_blocks.1.conv3.norm.weight -> (256)[FLOAT]], [model.encoder.pan_blocks.1.conv3.norm.bias -> (256)[FLOAT]], [model.encoder.pan_blocks.1.conv3.norm.running_mean -> (256)[FLOAT]], [model.encoder.pan_blocks.1.conv3.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization for ONNX node: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization [BatchNormalization] outputs: [/model/encoder/pan_blocks.1/conv3/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv3/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv3/act/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/act/Sigmoid [Sigmoid] inputs: [/model/encoder/pan_blocks.1/conv3/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv3/act/Sigmoid for ONNX node: /model/encoder/pan_blocks.1/conv3/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv3/act/Sigmoid_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv3/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/act/Sigmoid [Sigmoid] outputs: [/model/encoder/pan_blocks.1/conv3/act/Sigmoid_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/encoder/pan_blocks.1/conv3/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/encoder/pan_blocks.1/conv3/act/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/act/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/act/Mul [Mul] inputs: [/model/encoder/pan_blocks.1/conv3/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], [/model/encoder/pan_blocks.1/conv3/act/Sigmoid_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/pan_blocks.1/conv3/act/Mul for ONNX node: /model/encoder/pan_blocks.1/conv3/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/encoder/pan_blocks.1/conv3/act/Mul_output_0 for ONNX tensor: /model/encoder/pan_blocks.1/conv3/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/pan_blocks.1/conv3/act/Mul [Mul] outputs: [/model/encoder/pan_blocks.1/conv3/act/Mul_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.input_proj.0.conv.weight -> (256, 256, 1, 1)[FLOAT]], [/model/decoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.input_proj.0.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_257 for ONNX node: tmp_weight_257
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 1, 1)[INT8]], [/model/decoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_258 for ONNX node: tmp_weight_258
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.0/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.0/conv/Conv [Conv] inputs: [/model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 80, 80)[FLOAT]], [/model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.0/conv/Conv for ONNX node: /model/decoder/input_proj.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.0/conv/Conv_output_0 for ONNX tensor: /model/decoder/input_proj.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.0/conv/Conv [Conv] outputs: [/model/decoder/input_proj.0/conv/Conv_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.0/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.0/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.0/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.0.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.0.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.0.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.0.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.0/norm/BatchNormalization [BatchNormalization] inputs: [/model/decoder/input_proj.0/conv/Conv_output_0 -> (1, 256, 80, 80)[FLOAT]], [model.decoder.input_proj.0.norm.weight -> (256)[FLOAT]], [model.decoder.input_proj.0.norm.bias -> (256)[FLOAT]], [model.decoder.input_proj.0.norm.running_mean -> (256)[FLOAT]], [model.decoder.input_proj.0.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.0/norm/BatchNormalization for ONNX node: /model/decoder/input_proj.0/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.0/norm/BatchNormalization_output_0 for ONNX tensor: /model/decoder/input_proj.0/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.0/norm/BatchNormalization [BatchNormalization] outputs: [/model/decoder/input_proj.0/norm/BatchNormalization_output_0 -> (1, 256, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.input_proj.1.conv.weight -> (256, 256, 1, 1)[FLOAT]], [/model/decoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.input_proj.1.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_259 for ONNX node: tmp_weight_259
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 1, 1)[INT8]], [/model/decoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_260 for ONNX node: tmp_weight_260
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.1/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.1/conv/Conv [Conv] inputs: [/model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 40, 40)[FLOAT]], [/model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.1/conv/Conv for ONNX node: /model/decoder/input_proj.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.1/conv/Conv_output_0 for ONNX tensor: /model/decoder/input_proj.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.1/conv/Conv [Conv] outputs: [/model/decoder/input_proj.1/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.1/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.1/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.1.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.1.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.1.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.1.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.1/norm/BatchNormalization [BatchNormalization] inputs: [/model/decoder/input_proj.1/conv/Conv_output_0 -> (1, 256, 40, 40)[FLOAT]], [model.decoder.input_proj.1.norm.weight -> (256)[FLOAT]], [model.decoder.input_proj.1.norm.bias -> (256)[FLOAT]], [model.decoder.input_proj.1.norm.running_mean -> (256)[FLOAT]], [model.decoder.input_proj.1.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.1/norm/BatchNormalization for ONNX node: /model/decoder/input_proj.1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.1/norm/BatchNormalization_output_0 for ONNX tensor: /model/decoder/input_proj.1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.1/norm/BatchNormalization [BatchNormalization] outputs: [/model/decoder/input_proj.1/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/pan_blocks.1/conv3/act/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/encoder/pan_blocks.1/conv3/act/Mul_output_0 -> (1, 256, 20, 20)[FLOAT]], [/model/decoder/input_proj.2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.2/conv/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/input_proj.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_261 for ONNX node: tmp_weight_261
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 20, 20)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0 -> (1, 256, 20, 20)[INT8]], [/model/decoder/input_proj.2/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_262 for ONNX node: tmp_weight_262
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.input_proj.2.conv.weight -> (256, 256, 1, 1)[FLOAT]], [/model/decoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.input_proj.2.conv.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_263 for ONNX node: tmp_weight_263
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 1, 1)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear_output_0 -> (256, 256, 1, 1)[INT8]], [/model/decoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_264 for ONNX node: tmp_weight_264
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.2/conv/Conv [Conv]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.2/conv/Conv [Conv] inputs: [/model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear_output_0 -> (1, 256, 20, 20)[FLOAT]], [/model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear_output_0 -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.2/conv/Conv for ONNX node: /model/decoder/input_proj.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.2/conv/Conv_output_0 for ONNX tensor: /model/decoder/input_proj.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.2/conv/Conv [Conv] outputs: [/model/decoder/input_proj.2/conv/Conv_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/input_proj.2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/input_proj.2/norm/BatchNormalization [BatchNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.2/conv/Conv_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.2.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.2.norm.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.2.norm.running_mean
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.input_proj.2.norm.running_var
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.2/norm/BatchNormalization [BatchNormalization] inputs: [/model/decoder/input_proj.2/conv/Conv_output_0 -> (1, 256, 20, 20)[FLOAT]], [model.decoder.input_proj.2.norm.weight -> (256)[FLOAT]], [model.decoder.input_proj.2.norm.bias -> (256)[FLOAT]], [model.decoder.input_proj.2.norm.running_mean -> (256)[FLOAT]], [model.decoder.input_proj.2.norm.running_var -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Found BatchNormalization node with conforming initializer types. Combining into a single scale node.
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/input_proj.2/norm/BatchNormalization for ONNX node: /model/decoder/input_proj.2/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/input_proj.2/norm/BatchNormalization_output_0 for ONNX tensor: /model/decoder/input_proj.2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/input_proj.2/norm/BatchNormalization [BatchNormalization] outputs: [/model/decoder/input_proj.2/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.0/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_4326
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Reshape [Reshape] inputs: [/model/decoder/input_proj.0/norm/BatchNormalization_output_0 -> (1, 256, 80, 80)[FLOAT]], [_v_4326 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_265 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Reshape for ONNX node: /model/decoder/Reshape
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Reshape_output_0 for ONNX tensor: /model/decoder/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Reshape [Reshape] outputs: [/model/decoder/Reshape_output_0 -> (1, 256, 6400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Transpose [Transpose] inputs: [/model/decoder/Reshape_output_0 -> (1, 256, 6400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Transpose for ONNX node: /model/decoder/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Transpose_output_0 for ONNX tensor: /model/decoder/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Transpose [Transpose] outputs: [/model/decoder/Transpose_output_0 -> (1, 6400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.1/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_4326
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Reshape_1 [Reshape] inputs: [/model/decoder/input_proj.1/norm/BatchNormalization_output_0 -> (1, 256, 40, 40)[FLOAT]], [_v_4326 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_266 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Reshape_1 for ONNX node: /model/decoder/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Reshape_1_output_0 for ONNX tensor: /model/decoder/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Reshape_1 [Reshape] outputs: [/model/decoder/Reshape_1_output_0 -> (1, 256, 1600)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Transpose_1 [Transpose] inputs: [/model/decoder/Reshape_1_output_0 -> (1, 256, 1600)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Transpose_1 for ONNX node: /model/decoder/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Transpose_1_output_0 for ONNX tensor: /model/decoder/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Transpose_1 [Transpose] outputs: [/model/decoder/Transpose_1_output_0 -> (1, 1600, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/input_proj.2/norm/BatchNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_4326
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Reshape_2 [Reshape] inputs: [/model/decoder/input_proj.2/norm/BatchNormalization_output_0 -> (1, 256, 20, 20)[FLOAT]], [_v_4326 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_267 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Reshape_2 for ONNX node: /model/decoder/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Reshape_2_output_0 for ONNX tensor: /model/decoder/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Reshape_2 [Reshape] outputs: [/model/decoder/Reshape_2_output_0 -> (1, 256, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Transpose_2 [Transpose] inputs: [/model/decoder/Reshape_2_output_0 -> (1, 256, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Transpose_2 for ONNX node: /model/decoder/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Transpose_2_output_0 for ONNX tensor: /model/decoder/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Transpose_2 [Transpose] outputs: [/model/decoder/Transpose_2_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Concat_3 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Concat_3 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Concat_3 [Concat] inputs: [/model/decoder/Transpose_output_0 -> (1, 6400, 256)[FLOAT]], [/model/decoder/Transpose_1_output_0 -> (1, 1600, 256)[FLOAT]], [/model/decoder/Transpose_2_output_0 -> (1, 400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Concat_3 for ONNX node: /model/decoder/Concat_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Concat_3_output_0 for ONNX tensor: /model/decoder/Concat_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Concat_3 [Concat] outputs: [/model/decoder/Concat_3_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Mul_3692
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Concat_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Mul [Mul] inputs: [onnx::Mul_3692 -> (1, 8400, 1)[FLOAT]], [/model/decoder/Concat_3_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Mul_3692 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Mul for ONNX node: /model/decoder/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Mul_output_0 for ONNX tensor: /model/decoder/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Mul [Mul] outputs: [/model/decoder/Mul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/Mul_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/enc_output/proj/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_output/proj/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/enc_output/proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_268 for ONNX node: tmp_weight_268
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/enc_output/proj/input_quantizer/QuantizeLinear_output_0 -> (1, 8400, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/enc_output/proj/input_quantizer/QuantizeLinear_output_0 -> (1, 8400, 256)[INT8]], [/model/decoder/enc_output/proj/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_269 for ONNX node: tmp_weight_269
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/enc_output/proj/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_output/proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_output/proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.enc_output.proj.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.enc_output.proj.weight -> (256, 256)[FLOAT]], [/model/decoder/enc_output/proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.enc_output.proj.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_output/proj/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/enc_output/proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_270 for ONNX node: tmp_weight_270
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_output/proj/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/enc_output/proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_output/proj/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_output/proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/enc_output/proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/enc_output/proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/enc_output/proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_271 for ONNX node: tmp_weight_271
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_output/proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_output/proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/Transpose [Transpose] inputs: [/model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_output/proj/Transpose for ONNX node: /model/decoder/enc_output/proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_output/proj/Transpose_output_0 for ONNX tensor: /model/decoder/enc_output/proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/Transpose [Transpose] outputs: [/model/decoder/enc_output/proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_output/proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_output/proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/MatMul [MatMul] inputs: [/model/decoder/enc_output/proj/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/enc_output/proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_272 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_273 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_output/proj/MatMul for ONNX node: /model/decoder/enc_output/proj/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_output/proj/MatMul_output_0 for ONNX tensor: /model/decoder/enc_output/proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/MatMul [MatMul] outputs: [/model/decoder/enc_output/proj/MatMul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_output/proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_output/proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.enc_output.proj.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/Add [Add] inputs: [model.decoder.enc_output.proj.bias -> (256)[FLOAT]], [/model/decoder/enc_output/proj/MatMul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.enc_output.proj.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_274 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_275 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_output/proj/Add for ONNX node: /model/decoder/enc_output/proj/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_output/proj/Add_output_0 for ONNX tensor: /model/decoder/enc_output/proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/proj/Add [Add] outputs: [/model/decoder/enc_output/proj/Add_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_output/norm/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_output/norm/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.enc_output.norm.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.enc_output.norm.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/norm/LayerNormalization [LayerNormalization] inputs: [/model/decoder/enc_output/proj/Add_output_0 -> (1, 8400, 256)[FLOAT]], [model.decoder.enc_output.norm.weight -> (256)[FLOAT]], [model.decoder.enc_output.norm.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.enc_output.norm.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.enc_output.norm.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_278 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_279 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_280 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_281 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_output/norm/LayerNormalization for ONNX node: /model/decoder/enc_output/norm/LayerNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_output/norm/LayerNormalization_output_0 for ONNX tensor: /model/decoder/enc_output/norm/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_output/norm/LayerNormalization [LayerNormalization] outputs: [/model/decoder/enc_output/norm/LayerNormalization_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/norm/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/enc_output/norm/LayerNormalization_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/enc_score_head/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_score_head/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/enc_score_head/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_282 for ONNX node: tmp_weight_282
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/enc_score_head/input_quantizer/QuantizeLinear_output_0 -> (1, 8400, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/enc_score_head/input_quantizer/QuantizeLinear_output_0 -> (1, 8400, 256)[INT8]], [/model/decoder/enc_score_head/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_283 for ONNX node: tmp_weight_283
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/enc_score_head/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_score_head/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_score_head/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.enc_score_head.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.enc_score_head.weight -> (80, 256)[FLOAT]], [/model/decoder/enc_score_head/weight_quantizer/Constant_1_output_0 -> (80)[FLOAT]], [/model/decoder/enc_score_head/weight_quantizer/Constant_output_0 -> (80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.enc_score_head.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_score_head/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/enc_score_head/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_284 for ONNX node: tmp_weight_284
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_score_head/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/enc_score_head/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_score_head/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_score_head/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/enc_score_head/weight_quantizer/QuantizeLinear_output_0 -> (80, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/enc_score_head/weight_quantizer/QuantizeLinear_output_0 -> (80, 256)[INT8]], [/model/decoder/enc_score_head/weight_quantizer/Constant_1_output_0 -> (80)[FLOAT]], [/model/decoder/enc_score_head/weight_quantizer/Constant_output_0 -> (80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_285 for ONNX node: tmp_weight_285
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/enc_score_head/weight_quantizer/DequantizeLinear_output_0 -> (80, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_score_head/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_score_head/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/Transpose [Transpose] inputs: [/model/decoder/enc_score_head/weight_quantizer/DequantizeLinear_output_0 -> (80, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_score_head/Transpose for ONNX node: /model/decoder/enc_score_head/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_score_head/Transpose_output_0 for ONNX tensor: /model/decoder/enc_score_head/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/Transpose [Transpose] outputs: [/model/decoder/enc_score_head/Transpose_output_0 -> (256, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_score_head/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_score_head/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/MatMul [MatMul] inputs: [/model/decoder/enc_score_head/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/enc_score_head/Transpose_output_0 -> (256, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_286 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_287 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_score_head/MatMul for ONNX node: /model/decoder/enc_score_head/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_score_head/MatMul_output_0 for ONNX tensor: /model/decoder/enc_score_head/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/MatMul [MatMul] outputs: [/model/decoder/enc_score_head/MatMul_output_0 -> (1, 8400, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_score_head/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_score_head/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.enc_score_head.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/Add [Add] inputs: [model.decoder.enc_score_head.bias -> (80)[FLOAT]], [/model/decoder/enc_score_head/MatMul_output_0 -> (1, 8400, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.enc_score_head.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_288 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_289 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_score_head/Add for ONNX node: /model/decoder/enc_score_head/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_score_head/Add_output_0 for ONNX tensor: /model/decoder/enc_score_head/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_score_head/Add [Add] outputs: [/model/decoder/enc_score_head/Add_output_0 -> (1, 8400, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.enc_bbox_head.layers.0.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.enc_bbox_head.layers.0.weight -> (256, 256)[FLOAT]], [/model/decoder/enc_bbox_head/layers.0/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.enc_bbox_head.layers.0.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_290 for ONNX node: tmp_weight_290
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/enc_bbox_head/layers.0/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/enc_bbox_head/layers.0/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/enc_bbox_head/layers.0/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_291 for ONNX node: tmp_weight_291
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.0/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.0/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.0/Transpose [Transpose] inputs: [/model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.0/Transpose for ONNX node: /model/decoder/enc_bbox_head/layers.0/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.0/Transpose_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.0/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.0/Transpose [Transpose] outputs: [/model/decoder/enc_bbox_head/layers.0/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.0/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.0/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.0/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.0/MatMul [MatMul] inputs: [/model/decoder/enc_score_head/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/enc_bbox_head/layers.0/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_292 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_293 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.0/MatMul for ONNX node: /model/decoder/enc_bbox_head/layers.0/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.0/MatMul_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.0/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.0/MatMul [MatMul] outputs: [/model/decoder/enc_bbox_head/layers.0/MatMul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.enc_bbox_head.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.0/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.0/Add [Add] inputs: [model.decoder.enc_bbox_head.layers.0.bias -> (256)[FLOAT]], [/model/decoder/enc_bbox_head/layers.0/MatMul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.enc_bbox_head.layers.0.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_294 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_295 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.0/Add for ONNX node: /model/decoder/enc_bbox_head/layers.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.0/Add_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.0/Add [Add] outputs: [/model/decoder/enc_bbox_head/layers.0/Add_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/act/Relu [Relu] inputs: [/model/decoder/enc_bbox_head/layers.0/Add_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/act/Relu for ONNX node: /model/decoder/enc_bbox_head/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/act/Relu_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/act/Relu [Relu] outputs: [/model/decoder/enc_bbox_head/act/Relu_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/enc_bbox_head/act/Relu_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/enc_bbox_head/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/enc_bbox_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_296 for ONNX node: tmp_weight_296
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear_output_0 -> (1, 8400, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear_output_0 -> (1, 8400, 256)[INT8]], [/model/decoder/enc_bbox_head/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_297 for ONNX node: tmp_weight_297
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.enc_bbox_head.layers.1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.enc_bbox_head.layers.1.weight -> (256, 256)[FLOAT]], [/model/decoder/enc_bbox_head/layers.1/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.enc_bbox_head.layers.1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_298 for ONNX node: tmp_weight_298
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/enc_bbox_head/layers.1/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/enc_bbox_head/layers.1/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/enc_bbox_head/layers.1/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_299 for ONNX node: tmp_weight_299
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/Transpose [Transpose] inputs: [/model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.1/Transpose for ONNX node: /model/decoder/enc_bbox_head/layers.1/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.1/Transpose_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/Transpose [Transpose] outputs: [/model/decoder/enc_bbox_head/layers.1/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/MatMul [MatMul] inputs: [/model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/enc_bbox_head/layers.1/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_300 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_301 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.1/MatMul for ONNX node: /model/decoder/enc_bbox_head/layers.1/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.1/MatMul_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/MatMul [MatMul] outputs: [/model/decoder/enc_bbox_head/layers.1/MatMul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.enc_bbox_head.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/Add [Add] inputs: [model.decoder.enc_bbox_head.layers.1.bias -> (256)[FLOAT]], [/model/decoder/enc_bbox_head/layers.1/MatMul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.enc_bbox_head.layers.1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_302 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_303 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.1/Add for ONNX node: /model/decoder/enc_bbox_head/layers.1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.1/Add_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.1/Add [Add] outputs: [/model/decoder/enc_bbox_head/layers.1/Add_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/act_1/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/act_1/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/act_1/Relu [Relu] inputs: [/model/decoder/enc_bbox_head/layers.1/Add_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/act_1/Relu for ONNX node: /model/decoder/enc_bbox_head/act_1/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/act_1/Relu_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/act_1/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/act_1/Relu [Relu] outputs: [/model/decoder/enc_bbox_head/act_1/Relu_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/act_1/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/enc_bbox_head/act_1/Relu_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/enc_bbox_head/layers.2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/enc_bbox_head/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_304 for ONNX node: tmp_weight_304
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear_output_0 -> (1, 8400, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear_output_0 -> (1, 8400, 256)[INT8]], [/model/decoder/enc_bbox_head/layers.2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_305 for ONNX node: tmp_weight_305
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.enc_bbox_head.layers.2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.enc_bbox_head.layers.2.weight -> (4, 256)[FLOAT]], [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_1_output_0 -> (4)[FLOAT]], [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0 -> (4)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.enc_bbox_head.layers.2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_306 for ONNX node: tmp_weight_306
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/QuantizeLinear_output_0 -> (4, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/QuantizeLinear_output_0 -> (4, 256)[INT8]], [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_1_output_0 -> (4)[FLOAT]], [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0 -> (4)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_307 for ONNX node: tmp_weight_307
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear_output_0 -> (4, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/Transpose [Transpose] inputs: [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear_output_0 -> (4, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.2/Transpose for ONNX node: /model/decoder/enc_bbox_head/layers.2/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.2/Transpose_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/Transpose [Transpose] outputs: [/model/decoder/enc_bbox_head/layers.2/Transpose_output_0 -> (256, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/MatMul [MatMul] inputs: [/model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/enc_bbox_head/layers.2/Transpose_output_0 -> (256, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_308 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_309 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.2/MatMul for ONNX node: /model/decoder/enc_bbox_head/layers.2/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.2/MatMul_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/MatMul [MatMul] outputs: [/model/decoder/enc_bbox_head/layers.2/MatMul_output_0 -> (1, 8400, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/enc_bbox_head/layers.2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/enc_bbox_head/layers.2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.enc_bbox_head.layers.2.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/Add [Add] inputs: [model.decoder.enc_bbox_head.layers.2.bias -> (4)[FLOAT]], [/model/decoder/enc_bbox_head/layers.2/MatMul_output_0 -> (1, 8400, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.enc_bbox_head.layers.2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_310 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_311 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/enc_bbox_head/layers.2/Add for ONNX node: /model/decoder/enc_bbox_head/layers.2/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/enc_bbox_head/layers.2/Add_output_0 for ONNX tensor: /model/decoder/enc_bbox_head/layers.2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/enc_bbox_head/layers.2/Add [Add] outputs: [/model/decoder/enc_bbox_head/layers.2/Add_output_0 -> (1, 8400, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.anchors
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Add [Add] inputs: [/model/decoder/enc_bbox_head/layers.2/Add_output_0 -> (1, 8400, 4)[FLOAT]], [model.decoder.anchors -> (1, 8400, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.anchors required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Add for ONNX node: /model/decoder/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Add_output_0 for ONNX tensor: /model/decoder/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Add [Add] outputs: [/model/decoder/Add_output_0 -> (1, 8400, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/ReduceMax [ReduceMax]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/ReduceMax [ReduceMax]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/ReduceMax [ReduceMax] inputs: [/model/decoder/enc_score_head/Add_output_0 -> (1, 8400, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/ReduceMax for ONNX node: /model/decoder/ReduceMax
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/ReduceMax_output_0 for ONNX tensor: /model/decoder/ReduceMax_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/ReduceMax [ReduceMax] outputs: [/model/decoder/ReduceMax_output_0 -> (1, 8400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/TopK [TopK]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/TopK [TopK]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/ReduceMax_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Constant_18_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/TopK [TopK] inputs: [/model/decoder/ReduceMax_output_0 -> (1, 8400)[FLOAT]], [/model/decoder/Constant_18_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Constant_18_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_convertToScalar required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/TopK for ONNX node: /model/decoder/TopK
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/TopK_output_0 for ONNX tensor: /model/decoder/TopK_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/TopK_output_1 for ONNX tensor: /model/decoder/TopK_output_1
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/TopK [TopK] outputs: [/model/decoder/TopK_output_0 -> (1, 300)[FLOAT]], [/model/decoder/TopK_output_1 -> (1, 300)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Unsqueeze [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Unsqueeze [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/TopK_output_1
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Unsqueeze [Unsqueeze] inputs: [/model/decoder/TopK_output_1 -> (1, 300)[INT64]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/Constant_7_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Unsqueeze for ONNX node: /model/decoder/Unsqueeze
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Unsqueeze_output_0 for ONNX tensor: /model/decoder/Unsqueeze_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Unsqueeze [Unsqueeze] outputs: [/model/decoder/Unsqueeze_output_0 -> (1, 300, 1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Tile [Tile]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Tile [Tile]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Unsqueeze_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Concat_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Tile [Tile] inputs: [/model/decoder/Unsqueeze_output_0 -> (1, 300, 1)[INT64]], [/model/decoder/Concat_5_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Tile for ONNX node: /model/decoder/Tile
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Tile_output_0 for ONNX tensor: /model/decoder/Tile_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Tile [Tile] outputs: [/model/decoder/Tile_output_0 -> (1, 300, 4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/GatherElements [GatherElements]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/GatherElements [GatherElements]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Tile_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/GatherElements [GatherElements] inputs: [/model/decoder/Add_output_0 -> (1, 8400, 4)[FLOAT]], [/model/decoder/Tile_output_0 -> (1, 300, 4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Using Gather axis: 1
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_312 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/GatherElements for ONNX node: /model/decoder/GatherElements
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/GatherElements_output_0 for ONNX tensor: /model/decoder/GatherElements_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/GatherElements [GatherElements] outputs: [/model/decoder/GatherElements_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Tile_1 [Tile]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Tile_1 [Tile]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Unsqueeze_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Concat_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Tile_1 [Tile] inputs: [/model/decoder/Unsqueeze_output_0 -> (1, 300, 1)[INT64]], [/model/decoder/Concat_7_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_313 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Tile_1 for ONNX node: /model/decoder/Tile_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Tile_1_output_0 for ONNX tensor: /model/decoder/Tile_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Tile_1 [Tile] outputs: [/model/decoder/Tile_1_output_0 -> (1, 300, 256)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/GatherElements_1 [GatherElements]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/GatherElements_1 [GatherElements]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/norm/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Tile_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/GatherElements_1 [GatherElements] inputs: [/model/decoder/enc_output/norm/LayerNormalization_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/Tile_1_output_0 -> (1, 300, 256)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Using Gather axis: 1
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_314 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/GatherElements_1 for ONNX node: /model/decoder/GatherElements_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/GatherElements_1_output_0 for ONNX tensor: /model/decoder/GatherElements_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/GatherElements_1 [GatherElements] outputs: [/model/decoder/GatherElements_1_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/GatherElements_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sigmoid [Sigmoid] inputs: [/model/decoder/GatherElements_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Sigmoid for ONNX node: /model/decoder/decoder/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Sigmoid_output_0 for ONNX tensor: /model/decoder/decoder/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sigmoid [Sigmoid] outputs: [/model/decoder/decoder/Sigmoid_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/Sigmoid_output_0 -> (1, 300, 4)[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_315 for ONNX node: tmp_weight_315
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 4)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 4)[INT8]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_316 for ONNX node: tmp_weight_316
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.query_pos_head.layers.0.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.query_pos_head.layers.0.weight -> (512, 4)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/Constant_1_output_0 -> (512)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.query_pos_head.layers.0.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_317 for ONNX node: tmp_weight_317
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/QuantizeLinear_output_0 -> (512, 4)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/QuantizeLinear_output_0 -> (512, 4)[INT8]], [/model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/Constant_1_output_0 -> (512)[FLOAT]], [/model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_318 for ONNX node: tmp_weight_318
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear_output_0 -> (512, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/Transpose [Transpose] inputs: [/model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear_output_0 -> (512, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0/Transpose for ONNX node: /model/decoder/decoder/query_pos_head/layers.0/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/Transpose [Transpose] outputs: [/model/decoder/decoder/query_pos_head/layers.0/Transpose_output_0 -> (4, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/MatMul [MatMul] inputs: [/model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.0/Transpose_output_0 -> (4, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_319 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_320 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul for ONNX node: /model/decoder/decoder/query_pos_head/layers.0/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/MatMul [MatMul] outputs: [/model/decoder/decoder/query_pos_head/layers.0/MatMul_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.query_pos_head.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/Add [Add] inputs: [model.decoder.query_pos_head.layers.0.bias -> (512)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.0/MatMul_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.query_pos_head.layers.0.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_321 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_322 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0/Add for ONNX node: /model/decoder/decoder/query_pos_head/layers.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0/Add_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/Add [Add] outputs: [/model/decoder/decoder/query_pos_head/layers.0/Add_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/act/Relu [Relu] inputs: [/model/decoder/decoder/query_pos_head/layers.0/Add_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/act/Relu for ONNX node: /model/decoder/decoder/query_pos_head/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/act/Relu_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/act/Relu [Relu] outputs: [/model/decoder/decoder/query_pos_head/act/Relu_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/query_pos_head/act/Relu_output_0 -> (1, 300, 512)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_323 for ONNX node: tmp_weight_323
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 512)[INT8]], [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_324 for ONNX node: tmp_weight_324
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.query_pos_head.layers.1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.query_pos_head.layers.1.weight -> (256, 512)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.query_pos_head.layers.1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_325 for ONNX node: tmp_weight_325
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/QuantizeLinear_output_0 -> (256, 512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/QuantizeLinear_output_0 -> (256, 512)[INT8]], [/model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_326 for ONNX node: tmp_weight_326
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear_output_0 -> (256, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/Transpose [Transpose] inputs: [/model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear_output_0 -> (256, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/Transpose for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/Transpose [Transpose] outputs: [/model/decoder/decoder/query_pos_head/layers.1/Transpose_output_0 -> (512, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/MatMul [MatMul] inputs: [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 512)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1/Transpose_output_0 -> (512, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_327 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_328 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/MatMul for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/MatMul [MatMul] outputs: [/model/decoder/decoder/query_pos_head/layers.1/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.query_pos_head.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/Add [Add] inputs: [model.decoder.query_pos_head.layers.1.bias -> (256)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.query_pos_head.layers.1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_329 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_330 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/Add for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1/Add_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/Add [Add] outputs: [/model/decoder/decoder/query_pos_head/layers.1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/GatherElements_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/Add [Add] inputs: [/model/decoder/GatherElements_1_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/Add for ONNX node: /model/decoder/decoder/layers.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/Add [Add] outputs: [/model/decoder/decoder/layers.0/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.0/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Transpose for ONNX node: /model/decoder/decoder/layers.0/self_attn/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.0/self_attn/Transpose_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/GatherElements_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose_1 [Transpose] inputs: [/model/decoder/GatherElements_1_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Transpose_1 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose_1 [Transpose] outputs: [/model/decoder/decoder/layers.0/self_attn/Transpose_1_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::MatMul_3736
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.0/self_attn/Transpose_output_0 -> (300, 1, 256)[FLOAT]], [onnx::MatMul_3736 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::MatMul_3736 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_331 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_332 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/MatMul for ONNX node: /model/decoder/decoder/layers.0/self_attn/MatMul
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.0/self_attn/MatMul_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Add_3731
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Add [Add] inputs: [onnx::Add_3731 -> (256)[FLOAT]], [/model/decoder/decoder/layers.0/self_attn/MatMul_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Add_3731 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_333 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_334 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Add for ONNX node: /model/decoder/decoder/layers.0/self_attn/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Add [Add] outputs: [/model/decoder/decoder/layers.0/self_attn/Add_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/MatMul_1 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/MatMul_1 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::MatMul_3737
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul_1 [MatMul] inputs: [/model/decoder/decoder/layers.0/self_attn/Transpose_output_0 -> (300, 1, 256)[FLOAT]], [onnx::MatMul_3737 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::MatMul_3737 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_335 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_336 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/MatMul_1 for ONNX node: /model/decoder/decoder/layers.0/self_attn/MatMul_1
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul_1: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/MatMul_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/MatMul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul_1 [MatMul] outputs: [/model/decoder/decoder/layers.0/self_attn/MatMul_1_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Add_3733
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/MatMul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Add_1 [Add] inputs: [onnx::Add_3733 -> (256)[FLOAT]], [/model/decoder/decoder/layers.0/self_attn/MatMul_1_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Add_3733 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_337 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_338 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Add_1 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Add_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Add_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Add_1 [Add] outputs: [/model/decoder/decoder/layers.0/self_attn/Add_1_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/MatMul_2 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/MatMul_2 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::MatMul_3738
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul_2 [MatMul] inputs: [/model/decoder/decoder/layers.0/self_attn/Transpose_1_output_0 -> (300, 1, 256)[FLOAT]], [onnx::MatMul_3738 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::MatMul_3738 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_339 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_340 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/MatMul_2 for ONNX node: /model/decoder/decoder/layers.0/self_attn/MatMul_2
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul_2: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/MatMul_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/MatMul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul_2 [MatMul] outputs: [/model/decoder/decoder/layers.0/self_attn/MatMul_2_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Add_3735
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/MatMul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Add_2 [Add] inputs: [onnx::Add_3735 -> (256)[FLOAT]], [/model/decoder/decoder/layers.0/self_attn/MatMul_2_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Add_3735 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_341 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_342 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Add_2 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Add_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Add_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Add_2 [Add] outputs: [/model/decoder/decoder/layers.0/self_attn/Add_2_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Concat_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Reshape [Reshape] inputs: [/model/decoder/decoder/layers.0/self_attn/Add_output_0 -> (300, 1, 256)[FLOAT]], [/model/decoder/decoder/layers.0/self_attn/Concat_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_343 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Reshape for ONNX node: /model/decoder/decoder/layers.0/self_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Reshape_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Reshape [Reshape] outputs: [/model/decoder/decoder/layers.0/self_attn/Reshape_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose_2 [Transpose] inputs: [/model/decoder/decoder/layers.0/self_attn/Reshape_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Transpose_2 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose_2 [Transpose] outputs: [/model/decoder/decoder/layers.0/self_attn/Transpose_2_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Concat_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Reshape_1 [Reshape] inputs: [/model/decoder/decoder/layers.0/self_attn/Add_1_output_0 -> (300, 1, 256)[FLOAT]], [/model/decoder/decoder/layers.0/self_attn/Concat_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_344 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Reshape_1 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Reshape_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Reshape_1 [Reshape] outputs: [/model/decoder/decoder/layers.0/self_attn/Reshape_1_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Concat_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Reshape_2 [Reshape] inputs: [/model/decoder/decoder/layers.0/self_attn/Add_2_output_0 -> (300, 1, 256)[FLOAT]], [/model/decoder/decoder/layers.0/self_attn/Concat_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_345 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Reshape_2 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Reshape_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Reshape_2 [Reshape] outputs: [/model/decoder/decoder/layers.0/self_attn/Reshape_2_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose_3 [Transpose] inputs: [/model/decoder/decoder/layers.0/self_attn/Reshape_2_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Transpose_3 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose_3 [Transpose] outputs: [/model/decoder/decoder/layers.0/self_attn/Transpose_3_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Mul_1 [Mul] inputs: [/model/decoder/decoder/layers.0/self_attn/Transpose_2_output_0 -> (8, 300, 32)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/Constant_7_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_346 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_347 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Mul_1 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Mul_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Mul_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Mul_1 [Mul] outputs: [/model/decoder/decoder/layers.0/self_attn/Mul_1_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose_4 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose_4 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose_4 [Transpose] inputs: [/model/decoder/decoder/layers.0/self_attn/Reshape_1_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Transpose_4 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Transpose_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose_4 [Transpose] outputs: [/model/decoder/decoder/layers.0/self_attn/Transpose_4_output_0 -> (8, 32, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/MatMul_3 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/MatMul_3 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Transpose_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul_3 [MatMul] inputs: [/model/decoder/decoder/layers.0/self_attn/Mul_1_output_0 -> (8, 300, 32)[FLOAT]], [/model/decoder/decoder/layers.0/self_attn/Transpose_4_output_0 -> (8, 32, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/MatMul_3 for ONNX node: /model/decoder/decoder/layers.0/self_attn/MatMul_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/MatMul_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/MatMul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul_3 [MatMul] outputs: [/model/decoder/decoder/layers.0/self_attn/MatMul_3_output_0 -> (8, 300, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/MatMul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Softmax [Softmax] inputs: [/model/decoder/decoder/layers.0/self_attn/MatMul_3_output_0 -> (8, 300, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Softmax for ONNX node: /model/decoder/decoder/layers.0/self_attn/Softmax
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_348 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Softmax_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Softmax [Softmax] outputs: [/model/decoder/decoder/layers.0/self_attn/Softmax_output_0 -> (8, 300, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/MatMul_4 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/MatMul_4 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul_4 [MatMul] inputs: [/model/decoder/decoder/layers.0/self_attn/Softmax_output_0 -> (8, 300, 300)[FLOAT]], [/model/decoder/decoder/layers.0/self_attn/Transpose_3_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/MatMul_4 for ONNX node: /model/decoder/decoder/layers.0/self_attn/MatMul_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/MatMul_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/MatMul_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul_4 [MatMul] outputs: [/model/decoder/decoder/layers.0/self_attn/MatMul_4_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose_5 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose_5 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/MatMul_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose_5 [Transpose] inputs: [/model/decoder/decoder/layers.0/self_attn/MatMul_4_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Transpose_5 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Transpose_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_5_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose_5 [Transpose] outputs: [/model/decoder/decoder/layers.0/self_attn/Transpose_5_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Reshape_3 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Reshape_3 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Transpose_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1846
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Reshape_3 [Reshape] inputs: [/model/decoder/decoder/layers.0/self_attn/Transpose_5_output_0 -> (300, 8, 32)[FLOAT]], [_v_1846 -> (2)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_349 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Reshape_3 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Reshape_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Reshape_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Reshape_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Reshape_3 [Reshape] outputs: [/model/decoder/decoder/layers.0/self_attn/Reshape_3_output_0 -> (300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Gemm [Gemm]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Gemm [Gemm]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Reshape_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.self_attn.out_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.self_attn.out_proj.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Gemm [Gemm] inputs: [/model/decoder/decoder/layers.0/self_attn/Reshape_3_output_0 -> (300, 256)[FLOAT]], [model.decoder.decoder.layers.0.self_attn.out_proj.weight -> (256, 256)[FLOAT]], [model.decoder.decoder.layers.0.self_attn.out_proj.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.self_attn.out_proj.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Using opA: 0 opB: 1
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Gemm for ONNX node: /model/decoder/decoder/layers.0/self_attn/Gemm
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.self_attn.out_proj.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_350 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_351 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Gemm_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Gemm_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Gemm [Gemm] outputs: [/model/decoder/decoder/layers.0/self_attn/Gemm_output_0 -> (300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Gemm_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Concat_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Reshape_4 [Reshape] inputs: [/model/decoder/decoder/layers.0/self_attn/Gemm_output_0 -> (300, 256)[FLOAT]], [/model/decoder/decoder/layers.0/self_attn/Concat_4_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_352 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Reshape_4 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Reshape_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Reshape_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Reshape_4 [Reshape] outputs: [/model/decoder/decoder/layers.0/self_attn/Reshape_4_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose_6 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/self_attn/Transpose_6 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose_6 [Transpose] inputs: [/model/decoder/decoder/layers.0/self_attn/Reshape_4_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/self_attn/Transpose_6 for ONNX node: /model/decoder/decoder/layers.0/self_attn/Transpose_6
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_6_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/self_attn/Transpose_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/Transpose_6 [Transpose] outputs: [/model/decoder/decoder/layers.0/self_attn/Transpose_6_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/GatherElements_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/self_attn/Transpose_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/Add_1 [Add] inputs: [/model/decoder/GatherElements_1_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.0/self_attn/Transpose_6_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/Add_1 for ONNX node: /model/decoder/decoder/layers.0/Add_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/Add_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/Add_1 [Add] outputs: [/model/decoder/decoder/layers.0/Add_1_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/norm1/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/norm1/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.norm1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.norm1.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/norm1/LayerNormalization [LayerNormalization] inputs: [/model/decoder/decoder/layers.0/Add_1_output_0 -> (1, 300, 256)[FLOAT]], [model.decoder.decoder.layers.0.norm1.weight -> (256)[FLOAT]], [model.decoder.decoder.layers.0.norm1.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.norm1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.norm1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_355 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_356 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_357 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_358 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/norm1/LayerNormalization for ONNX node: /model/decoder/decoder/layers.0/norm1/LayerNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/norm1/LayerNormalization_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/norm1/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/norm1/LayerNormalization [LayerNormalization] outputs: [/model/decoder/decoder/layers.0/norm1/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/norm1/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/Add_2 [Add] inputs: [/model/decoder/decoder/layers.0/norm1/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/Add_2 for ONNX node: /model/decoder/decoder/layers.0/Add_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/Add_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/Add_2 [Add] outputs: [/model/decoder/decoder/layers.0/Add_2_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Concat_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/Concat_3_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/enc_output/proj/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_359 for ONNX node: tmp_weight_359
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear_output_0 -> (1, 8400, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_output/proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear_output_0 -> (1, 8400, 256)[INT8]], [/model/decoder/enc_output/proj/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_360 for ONNX node: tmp_weight_360
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.cross_attn.value_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.0.cross_attn.value_proj.weight -> (256, 256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.cross_attn.value_proj.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_361 for ONNX node: tmp_weight_361
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_362 for ONNX node: tmp_weight_362
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose for ONNX node: /model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_363 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_364 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul for ONNX node: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.cross_attn.value_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/Add [Add] inputs: [model.decoder.decoder.layers.0.cross_attn.value_proj.bias -> (256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.cross_attn.value_proj.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_365 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_366 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add for ONNX node: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/value_proj/Add [Add] outputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/Add_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1848
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape [Reshape] inputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/Add_output_0 -> (1, 8400, 256)[FLOAT]], [_v_1848 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_367 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Reshape for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape [Reshape] outputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_output_0 -> (1, 8400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.0/Add_2_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_368 for ONNX node: tmp_weight_368
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_369 for ONNX node: tmp_weight_369
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.cross_attn.sampling_offsets.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.0.cross_attn.sampling_offsets.weight -> (192, 256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0 -> (192)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0 -> (192)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.cross_attn.sampling_offsets.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_370 for ONNX node: tmp_weight_370
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0 -> (192, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0 -> (192, 256)[INT8]], [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0 -> (192)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0 -> (192)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_371 for ONNX node: tmp_weight_371
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0 -> (192, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0 -> (192, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose for ONNX node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose_output_0 -> (256, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose_output_0 -> (256, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_372 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_373 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul for ONNX node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul_output_0 -> (1, 300, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.cross_attn.sampling_offsets.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add [Add] inputs: [model.decoder.decoder.layers.0.cross_attn.sampling_offsets.bias -> (192)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul_output_0 -> (1, 300, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.cross_attn.sampling_offsets.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_374 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_375 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add for ONNX node: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add [Add] outputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add_output_0 -> (1, 300, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1663
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_1 [Reshape] inputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add_output_0 -> (1, 300, 192)[FLOAT]], [_v_1663 -> (5)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_376 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_1 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_1 [Reshape] outputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_1_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.cross_attn.attention_weights.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.0.cross_attn.attention_weights.weight -> (96, 256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0 -> (96)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0 -> (96)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.cross_attn.attention_weights.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_377 for ONNX node: tmp_weight_377
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0 -> (96, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0 -> (96, 256)[INT8]], [/model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0 -> (96)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0 -> (96)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_378 for ONNX node: tmp_weight_378
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0 -> (96, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0 -> (96, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose for ONNX node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose_output_0 -> (256, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose_output_0 -> (256, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_379 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_380 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul for ONNX node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul_output_0 -> (1, 300, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.cross_attn.attention_weights.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add [Add] inputs: [model.decoder.decoder.layers.0.cross_attn.attention_weights.bias -> (96)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul_output_0 -> (1, 300, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.cross_attn.attention_weights.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_381 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_382 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add for ONNX node: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add [Add] outputs: [/model/decoder/decoder/layers.0/cross_attn/attention_weights/Add_output_0 -> (1, 300, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1665
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_2 [Reshape] inputs: [/model/decoder/decoder/layers.0/cross_attn/attention_weights/Add_output_0 -> (1, 300, 96)[FLOAT]], [_v_1665 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_383 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_2 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_2 [Reshape] outputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_2_output_0 -> (1, 300, 8, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Softmax [Softmax] inputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_2_output_0 -> (1, 300, 8, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Softmax for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Softmax
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_384 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Softmax_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Softmax [Softmax] outputs: [/model/decoder/decoder/layers.0/cross_attn/Softmax_output_0 -> (1, 300, 8, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Mul_3755
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Mul [Mul] inputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_1_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [onnx::Mul_3755 -> (12, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Mul_3755 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_385 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_386 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Mul for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Mul_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Mul [Mul] outputs: [/model/decoder/decoder/layers.0/cross_attn/Mul_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1997
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8 [Unsqueeze] inputs: [/model/decoder/decoder/Sigmoid_output_0 -> (1, 300, 4)[FLOAT]], [_v_1997 -> (2)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: _v_1997 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8 [Unsqueeze] outputs: [/model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8_output_0 -> (1, 300, 1, 1, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Slice [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Slice [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Constant_15_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Constant_21_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Slice [Slice] inputs: [/model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8_output_0 -> (1, 300, 1, 1, 4)[FLOAT]], [/model/decoder/decoder/Constant_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Constant_15_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0 -> (1)[INT64]], [/model/decoder/Constant_21_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Constant_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_387 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Constant_15_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_388 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_391 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_392 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_394 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_395 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_396 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_398 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_399 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_400 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_402 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_403 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_405 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_406 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_407 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_408 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_410 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_411 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_412 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_413 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_415 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_416 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_417 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Slice for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Slice
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Slice_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Slice_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Slice [Slice] outputs: [/model/decoder/decoder/layers.0/cross_attn/Slice_output_0 -> (1, 300, 1, 1, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Slice_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Mul_1 [Mul] inputs: [/model/decoder/decoder/layers.0/cross_attn/Mul_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Slice_output_0 -> (1, 300, 1, 1, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Mul_1 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Mul_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Mul_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Mul_1 [Mul] outputs: [/model/decoder/decoder/layers.0/cross_attn/Mul_1_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Mul_2 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Mul_2 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Mul_2 [Mul] inputs: [/model/decoder/decoder/layers.0/cross_attn/Mul_1_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_2_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_418 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_419 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Mul_2 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Mul_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Mul_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Mul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Mul_2 [Mul] outputs: [/model/decoder/decoder/layers.0/cross_attn/Mul_2_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Slice_1 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Slice_1 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Unsqueeze_1255
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Constant_21_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Slice_1 [Slice] inputs: [/model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8_output_0 -> (1, 300, 1, 1, 4)[FLOAT]], [onnx::Unsqueeze_1255 -> (1)[INT64]], [/model/decoder/decoder/Constant_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0 -> (1)[INT64]], [/model/decoder/Constant_21_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Unsqueeze_1255 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_420 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_421 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_423 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_424 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_426 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_427 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_429 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_430 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_431 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_433 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_434 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_435 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_437 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_438 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_440 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_441 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_442 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_443 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_445 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_446 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_447 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_448 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_450 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_451 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_452 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Slice_1 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Slice_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Slice_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Slice_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Slice_1 [Slice] outputs: [/model/decoder/decoder/layers.0/cross_attn/Slice_1_output_0 -> (1, 300, 1, 1, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Slice_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Mul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Add [Add] inputs: [/model/decoder/decoder/layers.0/cross_attn/Slice_1_output_0 -> (1, 300, 1, 1, 2)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Mul_2_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Add for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Add [Add] outputs: [/model/decoder/decoder/layers.0/cross_attn/Add_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_output_0 -> (1, 8400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Transpose for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.0/cross_attn/Transpose_output_0 -> (1, 8, 32, 8400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1749
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_4 [Reshape] inputs: [/model/decoder/decoder/layers.0/cross_attn/Transpose_output_0 -> (1, 8, 32, 8400)[FLOAT]], [_v_1749 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_453 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_4 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Reshape_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_4 [Reshape] outputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_4_output_0 -> (8, 32, 8400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Slice_4 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Slice_4 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Unsqueeze_1255
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Slice_4 [Slice] inputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_4_output_0 -> (8, 32, 8400)[FLOAT]], [onnx::Unsqueeze_1255 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0 -> (1)[INT64]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_454 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_455 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_457 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_458 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_460 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_461 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_463 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_464 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_465 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_467 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_468 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_469 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_471 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_472 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_474 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_475 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_476 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_477 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_479 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_480 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_481 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_482 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_484 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_485 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_486 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Slice_4 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Slice_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Slice_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Slice_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Slice_4 [Slice] outputs: [/model/decoder/decoder/layers.0/cross_attn/Slice_4_output_0 -> (8, 32, 6400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Slice_5 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Slice_5 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Slice_5 [Slice] inputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_4_output_0 -> (8, 32, 8400)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Add_2_output_0 -> (1)[INT64]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_487 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Add_2_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_488 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_490 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_491 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_493 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_494 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_496 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_497 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_498 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_500 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_501 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_502 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_504 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_505 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_507 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_508 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_509 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_510 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_512 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_513 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_514 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_515 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_517 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_518 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_519 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Slice_5 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Slice_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Slice_5_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Slice_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Slice_5 [Slice] outputs: [/model/decoder/decoder/layers.0/cross_attn/Slice_5_output_0 -> (8, 32, 1600)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Slice_6 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Slice_6 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Add_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Slice_6 [Slice] inputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_4_output_0 -> (8, 32, 8400)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Add_2_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Add_3_output_0 -> (1)[INT64]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_520 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Add_3_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_521 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_523 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_524 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_526 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_527 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_529 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_530 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_531 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_533 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_534 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_535 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_537 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_538 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_540 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_541 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_542 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_543 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_545 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_546 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_547 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_548 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_550 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_551 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_552 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Slice_6 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Slice_6
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Slice_6_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Slice_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Slice_6 [Slice] outputs: [/model/decoder/decoder/layers.0/cross_attn/Slice_6_output_0 -> (8, 32, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Mul_6 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Mul_6 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Constant_39_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Mul_6 [Mul] inputs: [/model/decoder/decoder/layers.0/cross_attn/Add_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Constant_39_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Constant_39_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_553 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_554 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Mul_6 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Mul_6
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Mul_6_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Mul_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Mul_6 [Mul] outputs: [/model/decoder/decoder/layers.0/cross_attn/Mul_6_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Sub [Sub]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Sub [Sub]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Mul_6_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Sub [Sub] inputs: [/model/decoder/decoder/layers.0/cross_attn/Mul_6_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_1_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_555 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_556 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Sub for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Sub
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Sub_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Sub_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Sub [Sub] outputs: [/model/decoder/decoder/layers.0/cross_attn/Sub_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Sub_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Transpose_1 [Transpose] inputs: [/model/decoder/decoder/layers.0/cross_attn/Sub_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_1 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Transpose_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Transpose_1 [Transpose] outputs: [/model/decoder/decoder/layers.0/cross_attn/Transpose_1_output_0 -> (1, 8, 300, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_5 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_5 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1850
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_5 [Reshape] inputs: [/model/decoder/decoder/layers.0/cross_attn/Transpose_1_output_0 -> (1, 8, 300, 12, 2)[FLOAT]], [_v_1850 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_557 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_5 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Reshape_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_5_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_5 [Reshape] outputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_5_output_0 -> (8, 300, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Split [Split]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Split [Split]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Reshape_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Split_2305
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Split [Split] inputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_5_output_0 -> (8, 300, 12, 2)[FLOAT]], [onnx::Split_2305 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_558 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Split for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Split
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_559 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Split_560 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Split
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_561 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Split_562 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Split
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Split_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Split_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Split_output_1 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Split_output_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Split_output_2 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Split_output_2
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Split [Split] outputs: [/model/decoder/decoder/layers.0/cross_attn/Split_output_0 -> (8, 300, 4, 2)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Split_output_1 -> (8, 300, 4, 2)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Split_output_2 -> (8, 300, 4, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_6 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_6 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Slice_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_6 [Reshape] inputs: [/model/decoder/decoder/layers.0/cross_attn/Slice_4_output_0 -> (8, 32, 6400)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_6_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_563 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_6 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Reshape_6
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_6_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_6 [Reshape] outputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_6_output_0 -> (8, 32, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/GridSample [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/GridSample [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Reshape_6_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Split_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/GridSample [GridSample] inputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_6_output_0 -> (8, 32, 80, 80)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Split_output_0 -> (8, 300, 4, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/GridSample for ONNX node: /model/decoder/decoder/layers.0/cross_attn/GridSample
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/GridSample_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/GridSample_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/GridSample [GridSample] outputs: [/model/decoder/decoder/layers.0/cross_attn/GridSample_output_0 -> (8, 32, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_7 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_7 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Slice_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_7 [Reshape] inputs: [/model/decoder/decoder/layers.0/cross_attn/Slice_5_output_0 -> (8, 32, 1600)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_7_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_564 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_7 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Reshape_7
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_7_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_7 [Reshape] outputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_7_output_0 -> (8, 32, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/GridSample_1 [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/GridSample_1 [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Reshape_7_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Split_output_1
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/GridSample_1 [GridSample] inputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_7_output_0 -> (8, 32, 40, 40)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Split_output_1 -> (8, 300, 4, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/GridSample_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/GridSample_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/GridSample_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/GridSample_1 [GridSample] outputs: [/model/decoder/decoder/layers.0/cross_attn/GridSample_1_output_0 -> (8, 32, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_8 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_8 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Slice_6_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_8 [Reshape] inputs: [/model/decoder/decoder/layers.0/cross_attn/Slice_6_output_0 -> (8, 32, 400)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_8_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_565 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_8 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Reshape_8
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_8_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_8 [Reshape] outputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_8_output_0 -> (8, 32, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/GridSample_2 [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/GridSample_2 [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Reshape_8_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Split_output_2
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/GridSample_2 [GridSample] inputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_8_output_0 -> (8, 32, 20, 20)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Split_output_2 -> (8, 300, 4, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_2 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/GridSample_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/GridSample_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/GridSample_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/GridSample_2 [GridSample] outputs: [/model/decoder/decoder/layers.0/cross_attn/GridSample_2_output_0 -> (8, 32, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Transpose_2 [Transpose] inputs: [/model/decoder/decoder/layers.0/cross_attn/Softmax_output_0 -> (1, 300, 8, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_2 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Transpose_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Transpose_2 [Transpose] outputs: [/model/decoder/decoder/layers.0/cross_attn/Transpose_2_output_0 -> (1, 8, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_9 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_9 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_9_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_9 [Reshape] inputs: [/model/decoder/decoder/layers.0/cross_attn/Transpose_2_output_0 -> (1, 8, 300, 12)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_9_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_566 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_9 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Reshape_9
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_9_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_9_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_9 [Reshape] outputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_9_output_0 -> (8, 1, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Concat_10 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Concat_10 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/GridSample_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/GridSample_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/GridSample_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Concat_10 [Concat] inputs: [/model/decoder/decoder/layers.0/cross_attn/GridSample_output_0 -> (8, 32, 300, 4)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/GridSample_1_output_0 -> (8, 32, 300, 4)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/GridSample_2_output_0 -> (8, 32, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Concat_10 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Concat_10
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Concat_10_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Concat_10_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Concat_10 [Concat] outputs: [/model/decoder/decoder/layers.0/cross_attn/Concat_10_output_0 -> (8, 32, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Mul_8 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Mul_8 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_10_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Reshape_9_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Mul_8 [Mul] inputs: [/model/decoder/decoder/layers.0/cross_attn/Concat_10_output_0 -> (8, 32, 300, 12)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Reshape_9_output_0 -> (8, 1, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Mul_8 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Mul_8
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Mul_8_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Mul_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Mul_8 [Mul] outputs: [/model/decoder/decoder/layers.0/cross_attn/Mul_8_output_0 -> (8, 32, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/ReduceSum [ReduceSum]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/ReduceSum [ReduceSum]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Mul_8_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/ReduceSum [ReduceSum] inputs: [/model/decoder/decoder/layers.0/cross_attn/Mul_8_output_0 -> (8, 32, 300, 12)[FLOAT]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/ReduceSum for ONNX node: /model/decoder/decoder/layers.0/cross_attn/ReduceSum
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/ReduceSum_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/ReduceSum_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/ReduceSum [ReduceSum] outputs: [/model/decoder/decoder/layers.0/cross_attn/ReduceSum_output_0 -> (8, 32, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_10 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Reshape_10 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/ReduceSum_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_11_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_10 [Reshape] inputs: [/model/decoder/decoder/layers.0/cross_attn/ReduceSum_output_0 -> (8, 32, 300)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_11_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_567 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_10 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Reshape_10
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_10_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Reshape_10_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Reshape_10 [Reshape] outputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_10_output_0 -> (1, 256, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Reshape_10_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Transpose_3 [Transpose] inputs: [/model/decoder/decoder/layers.0/cross_attn/Reshape_10_output_0 -> (1, 256, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_3 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/Transpose_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/Transpose_3 [Transpose] outputs: [/model/decoder/decoder/layers.0/cross_attn/Transpose_3_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.0/cross_attn/Transpose_3_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_568 for ONNX node: tmp_weight_568
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_569 for ONNX node: tmp_weight_569
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.cross_attn.output_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.0.cross_attn.output_proj.weight -> (256, 256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.cross_attn.output_proj.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_570 for ONNX node: tmp_weight_570
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_571 for ONNX node: tmp_weight_571
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose for ONNX node: /model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_572 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_573 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul for ONNX node: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.cross_attn.output_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/Add [Add] inputs: [model.decoder.decoder.layers.0.cross_attn.output_proj.bias -> (256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.cross_attn.output_proj.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_574 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_575 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add for ONNX node: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/cross_attn/output_proj/Add [Add] outputs: [/model/decoder/decoder/layers.0/cross_attn/output_proj/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/Add_3 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/Add_3 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/norm1/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/Add_3 [Add] inputs: [/model/decoder/decoder/layers.0/norm1/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/output_proj/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/Add_3 for ONNX node: /model/decoder/decoder/layers.0/Add_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/Add_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/Add_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/Add_3 [Add] outputs: [/model/decoder/decoder/layers.0/Add_3_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/norm2/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/norm2/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/Add_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.norm2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.norm2.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/norm2/LayerNormalization [LayerNormalization] inputs: [/model/decoder/decoder/layers.0/Add_3_output_0 -> (1, 300, 256)[FLOAT]], [model.decoder.decoder.layers.0.norm2.weight -> (256)[FLOAT]], [model.decoder.decoder.layers.0.norm2.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.norm2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.norm2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_578 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_579 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_580 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_581 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/norm2/LayerNormalization for ONNX node: /model/decoder/decoder/layers.0/norm2/LayerNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/norm2/LayerNormalization_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/norm2/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/norm2/LayerNormalization [LayerNormalization] outputs: [/model/decoder/decoder/layers.0/norm2/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/norm2/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.0/norm2/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.0/linear1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.0/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_582 for ONNX node: tmp_weight_582
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/layers.0/linear1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_583 for ONNX node: tmp_weight_583
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.linear1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.0.linear1.weight -> (1024, 256)[FLOAT]], [/model/decoder/decoder/layers.0/linear1/weight_quantizer/Constant_1_output_0 -> (1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0 -> (1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.linear1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.0/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_584 for ONNX node: tmp_weight_584
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.0/linear1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear1/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.0/linear1/weight_quantizer/QuantizeLinear_output_0 -> (1024, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.0/linear1/weight_quantizer/QuantizeLinear_output_0 -> (1024, 256)[INT8]], [/model/decoder/decoder/layers.0/linear1/weight_quantizer/Constant_1_output_0 -> (1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0 -> (1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_585 for ONNX node: tmp_weight_585
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear1/Transpose for ONNX node: /model/decoder/decoder/layers.0/linear1/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear1/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.0/linear1/Transpose_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.0/linear1/Transpose_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_586 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_587 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear1/MatMul for ONNX node: /model/decoder/decoder/layers.0/linear1/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear1/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.0/linear1/MatMul_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.linear1.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/Add [Add] inputs: [model.decoder.decoder.layers.0.linear1.bias -> (1024)[FLOAT]], [/model/decoder/decoder/layers.0/linear1/MatMul_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.linear1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_588 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_589 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear1/Add for ONNX node: /model/decoder/decoder/layers.0/linear1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear1/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear1/Add [Add] outputs: [/model/decoder/decoder/layers.0/linear1/Add_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/activation/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/activation/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/activation/Relu [Relu] inputs: [/model/decoder/decoder/layers.0/linear1/Add_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/activation/Relu for ONNX node: /model/decoder/decoder/layers.0/activation/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/activation/Relu_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/activation/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/activation/Relu [Relu] outputs: [/model/decoder/decoder/layers.0/activation/Relu_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/activation/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.0/activation/Relu_output_0 -> (1, 300, 1024)[FLOAT]], [/model/decoder/decoder/layers.0/linear2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.0/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_590 for ONNX node: tmp_weight_590
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 1024)[INT8]], [/model/decoder/decoder/layers.0/linear2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_591 for ONNX node: tmp_weight_591
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.linear2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.0.linear2.weight -> (256, 1024)[FLOAT]], [/model/decoder/decoder/layers.0/linear2/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.linear2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.0/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_592 for ONNX node: tmp_weight_592
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.0/linear2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear2/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.0/linear2/weight_quantizer/QuantizeLinear_output_0 -> (256, 1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.0/linear2/weight_quantizer/QuantizeLinear_output_0 -> (256, 1024)[INT8]], [/model/decoder/decoder/layers.0/linear2/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_593 for ONNX node: tmp_weight_593
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear2/Transpose for ONNX node: /model/decoder/decoder/layers.0/linear2/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear2/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.0/linear2/Transpose_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 1024)[FLOAT]], [/model/decoder/decoder/layers.0/linear2/Transpose_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_594 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_595 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear2/MatMul for ONNX node: /model/decoder/decoder/layers.0/linear2/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear2/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.0/linear2/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/linear2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/linear2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.linear2.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/Add [Add] inputs: [model.decoder.decoder.layers.0.linear2.bias -> (256)[FLOAT]], [/model/decoder/decoder/layers.0/linear2/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.linear2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_596 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_597 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/linear2/Add for ONNX node: /model/decoder/decoder/layers.0/linear2/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/linear2/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/linear2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/linear2/Add [Add] outputs: [/model/decoder/decoder/layers.0/linear2/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/Add_4 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/Add_4 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/norm2/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/linear2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/Add_4 [Add] inputs: [/model/decoder/decoder/layers.0/norm2/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.0/linear2/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/Add_4 for ONNX node: /model/decoder/decoder/layers.0/Add_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/Add_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/Add_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/Add_4 [Add] outputs: [/model/decoder/decoder/layers.0/Add_4_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.0/norm3/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.0/norm3/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/Add_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.norm3.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.0.norm3.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/norm3/LayerNormalization [LayerNormalization] inputs: [/model/decoder/decoder/layers.0/Add_4_output_0 -> (1, 300, 256)[FLOAT]], [model.decoder.decoder.layers.0.norm3.weight -> (256)[FLOAT]], [model.decoder.decoder.layers.0.norm3.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.norm3.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.0.norm3.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_600 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_601 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_602 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_603 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization for ONNX node: /model/decoder/decoder/layers.0/norm3/LayerNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.0/norm3/LayerNormalization_output_0 for ONNX tensor: /model/decoder/decoder/layers.0/norm3/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/norm3/LayerNormalization [LayerNormalization] outputs: [/model/decoder/decoder/layers.0/norm3/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/norm3/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.0/norm3/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_604 for ONNX node: tmp_weight_604
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_605 for ONNX node: tmp_weight_605
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.0.layers.0.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.dec_bbox_head.0.layers.0.weight -> (256, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.0.layers.0.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_606 for ONNX node: tmp_weight_606
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_607 for ONNX node: tmp_weight_607
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose [Transpose] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose [Transpose] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul [MatMul] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_608 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_609 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul [MatMul] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.0.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/Add [Add] inputs: [model.decoder.dec_bbox_head.0.layers.0.bias -> (256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.0.layers.0.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_610 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_611 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.0/Add [Add] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.0/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/act/Relu [Relu] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.0/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/act/Relu for ONNX node: /model/decoder/decoder/dec_bbox_head.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/act/Relu_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/act/Relu [Relu] outputs: [/model/decoder/decoder/dec_bbox_head.0/act/Relu_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.0/act/Relu_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_612 for ONNX node: tmp_weight_612
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_613 for ONNX node: tmp_weight_613
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.0.layers.1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.dec_bbox_head.0.layers.1.weight -> (256, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.0.layers.1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_614 for ONNX node: tmp_weight_614
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_615 for ONNX node: tmp_weight_615
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose [Transpose] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose [Transpose] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul [MatMul] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_616 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_617 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul [MatMul] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.0.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/Add [Add] inputs: [model.decoder.dec_bbox_head.0.layers.1.bias -> (256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.0.layers.1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_618 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_619 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.1/Add [Add] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/act_1/Relu [Relu] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu for ONNX node: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/act_1/Relu [Relu] outputs: [/model/decoder/decoder/dec_bbox_head.0/act_1/Relu_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.0/act_1/Relu_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_620 for ONNX node: tmp_weight_620
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_621 for ONNX node: tmp_weight_621
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.0.layers.2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.dec_bbox_head.0.layers.2.weight -> (4, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/Constant_1_output_0 -> (4)[FLOAT]], [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0 -> (4)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.0.layers.2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_622 for ONNX node: tmp_weight_622
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/QuantizeLinear_output_0 -> (4, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/QuantizeLinear_output_0 -> (4, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/Constant_1_output_0 -> (4)[FLOAT]], [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0 -> (4)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_623 for ONNX node: tmp_weight_623
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear_output_0 -> (4, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose [Transpose] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear_output_0 -> (4, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose [Transpose] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose_output_0 -> (256, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul [MatMul] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose_output_0 -> (256, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_624 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_625 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul [MatMul] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.0.layers.2.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/Add [Add] inputs: [model.decoder.dec_bbox_head.0.layers.2.bias -> (4)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.0.layers.2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_626 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_627 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add for ONNX node: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.0/layers.2/Add [Add] outputs: [/model/decoder/decoder/dec_bbox_head.0/layers.2/Add_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Clip [Clip]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Clip [Clip]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip [Clip] inputs: [/model/decoder/decoder/Sigmoid_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Constant_1_output_0 -> ()[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_1_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Clip for ONNX node: /model/decoder/decoder/Clip
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Clip_output_0 for ONNX tensor: /model/decoder/decoder/Clip_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip [Clip] outputs: [/model/decoder/decoder/Clip_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Clip_1 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Clip_1 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Clip_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_1 [Clip] inputs: [/model/decoder/decoder/Clip_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Constant_3_output_0 -> ()[FLOAT]], [optional input, not set], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Constant_3_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_629 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_630 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_631 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_632 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Clip_1_output_0 for ONNX tensor: /model/decoder/decoder/Clip_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_1 [Clip] outputs: [/model/decoder/decoder/Clip_1_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Sub [Sub]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Sub [Sub]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Clip_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sub [Sub] inputs: [/model/encoder/encoder.0/layers.0/activation/Constant_1_output_0 -> ()[FLOAT]], [/model/decoder/decoder/Clip_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_633 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_634 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Sub for ONNX node: /model/decoder/decoder/Sub
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Sub_output_0 for ONNX tensor: /model/decoder/decoder/Sub_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sub [Sub] outputs: [/model/decoder/decoder/Sub_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Clip_2 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Clip_2 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sub_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_2 [Clip] inputs: [/model/decoder/decoder/Sub_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Constant_3_output_0 -> ()[FLOAT]], [optional input, not set], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_636 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_637 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_638 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_639 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Clip_2_output_0 for ONNX tensor: /model/decoder/decoder/Clip_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_2 [Clip] outputs: [/model/decoder/decoder/Clip_2_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Div [Div]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Div [Div]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Clip_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Clip_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Div [Div] inputs: [/model/decoder/decoder/Clip_1_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Clip_2_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Div for ONNX node: /model/decoder/decoder/Div
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Div_output_0 for ONNX tensor: /model/decoder/decoder/Div_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Div [Div] outputs: [/model/decoder/decoder/Div_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Log [Log]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Log [Log]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Div_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Log [Log] inputs: [/model/decoder/decoder/Div_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Log for ONNX node: /model/decoder/decoder/Log
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Log_output_0 for ONNX tensor: /model/decoder/decoder/Log_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Log [Log] outputs: [/model/decoder/decoder/Log_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Log_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Add [Add] inputs: [/model/decoder/decoder/dec_bbox_head.0/layers.2/Add_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Log_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Add for ONNX node: /model/decoder/decoder/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Add_output_0 for ONNX tensor: /model/decoder/decoder/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Add [Add] outputs: [/model/decoder/decoder/Add_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Sigmoid_1 [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Sigmoid_1 [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sigmoid_1 [Sigmoid] inputs: [/model/decoder/decoder/Add_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Sigmoid_1 for ONNX node: /model/decoder/decoder/Sigmoid_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Sigmoid_1_output_0 for ONNX tensor: /model/decoder/decoder/Sigmoid_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sigmoid_1 [Sigmoid] outputs: [/model/decoder/decoder/Sigmoid_1_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sigmoid_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/Sigmoid_1_output_0 -> (1, 300, 4)[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_640 for ONNX node: tmp_weight_640
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear_output_0 -> (1, 300, 4)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear_output_0 -> (1, 300, 4)[INT8]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_641 for ONNX node: tmp_weight_641
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0_1/MatMul [MatMul] inputs: [/model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.0/Transpose_output_0 -> (4, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_642 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_643 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul for ONNX node: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0_1/MatMul [MatMul] outputs: [/model/decoder/decoder/query_pos_head/layers.0_1/MatMul_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0_1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0_1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.query_pos_head.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0_1/Add [Add] inputs: [model.decoder.query_pos_head.layers.0.bias -> (512)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.0_1/MatMul_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_644 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_645 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0_1/Add for ONNX node: /model/decoder/decoder/query_pos_head/layers.0_1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0_1/Add_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0_1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0_1/Add [Add] outputs: [/model/decoder/decoder/query_pos_head/layers.0_1/Add_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/act_1/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/act_1/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0_1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/act_1/Relu [Relu] inputs: [/model/decoder/decoder/query_pos_head/layers.0_1/Add_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/act_1/Relu for ONNX node: /model/decoder/decoder/query_pos_head/act_1/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/act_1/Relu_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/act_1/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/act_1/Relu [Relu] outputs: [/model/decoder/decoder/query_pos_head/act_1/Relu_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/act_1/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/query_pos_head/act_1/Relu_output_0 -> (1, 300, 512)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_646 for ONNX node: tmp_weight_646
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear_output_0 -> (1, 300, 512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear_output_0 -> (1, 300, 512)[INT8]], [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_647 for ONNX node: tmp_weight_647
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1_1/MatMul [MatMul] inputs: [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear_output_0 -> (1, 300, 512)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1/Transpose_output_0 -> (512, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_648 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_649 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul for ONNX node: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1_1/MatMul [MatMul] outputs: [/model/decoder/decoder/query_pos_head/layers.1_1/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1_1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1_1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.query_pos_head.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1_1/Add [Add] inputs: [model.decoder.query_pos_head.layers.1.bias -> (256)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1_1/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_650 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_651 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1_1/Add for ONNX node: /model/decoder/decoder/query_pos_head/layers.1_1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1_1/Add_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1_1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1_1/Add [Add] outputs: [/model/decoder/decoder/query_pos_head/layers.1_1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/norm3/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1_1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/Add [Add] inputs: [/model/decoder/decoder/layers.0/norm3/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1_1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/Add for ONNX node: /model/decoder/decoder/layers.1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/Add [Add] outputs: [/model/decoder/decoder/layers.1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Transpose for ONNX node: /model/decoder/decoder/layers.1/self_attn/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.1/self_attn/Transpose_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/norm3/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose_1 [Transpose] inputs: [/model/decoder/decoder/layers.0/norm3/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Transpose_1 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose_1 [Transpose] outputs: [/model/decoder/decoder/layers.1/self_attn/Transpose_1_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::MatMul_3808
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.1/self_attn/Transpose_output_0 -> (300, 1, 256)[FLOAT]], [onnx::MatMul_3808 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::MatMul_3808 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_652 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_653 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/MatMul for ONNX node: /model/decoder/decoder/layers.1/self_attn/MatMul
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.1/self_attn/MatMul_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Add_3803
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Add [Add] inputs: [onnx::Add_3803 -> (256)[FLOAT]], [/model/decoder/decoder/layers.1/self_attn/MatMul_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Add_3803 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_654 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_655 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Add for ONNX node: /model/decoder/decoder/layers.1/self_attn/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Add [Add] outputs: [/model/decoder/decoder/layers.1/self_attn/Add_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/MatMul_1 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/MatMul_1 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::MatMul_3809
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul_1 [MatMul] inputs: [/model/decoder/decoder/layers.1/self_attn/Transpose_output_0 -> (300, 1, 256)[FLOAT]], [onnx::MatMul_3809 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::MatMul_3809 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_656 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_657 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/MatMul_1 for ONNX node: /model/decoder/decoder/layers.1/self_attn/MatMul_1
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul_1: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/MatMul_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/MatMul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul_1 [MatMul] outputs: [/model/decoder/decoder/layers.1/self_attn/MatMul_1_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Add_3805
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/MatMul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Add_1 [Add] inputs: [onnx::Add_3805 -> (256)[FLOAT]], [/model/decoder/decoder/layers.1/self_attn/MatMul_1_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Add_3805 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_658 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_659 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Add_1 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Add_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Add_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Add_1 [Add] outputs: [/model/decoder/decoder/layers.1/self_attn/Add_1_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/MatMul_2 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/MatMul_2 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::MatMul_3810
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul_2 [MatMul] inputs: [/model/decoder/decoder/layers.1/self_attn/Transpose_1_output_0 -> (300, 1, 256)[FLOAT]], [onnx::MatMul_3810 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::MatMul_3810 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_660 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_661 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/MatMul_2 for ONNX node: /model/decoder/decoder/layers.1/self_attn/MatMul_2
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul_2: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/MatMul_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/MatMul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul_2 [MatMul] outputs: [/model/decoder/decoder/layers.1/self_attn/MatMul_2_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Add_3807
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/MatMul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Add_2 [Add] inputs: [onnx::Add_3807 -> (256)[FLOAT]], [/model/decoder/decoder/layers.1/self_attn/MatMul_2_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Add_3807 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_662 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_663 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Add_2 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Add_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Add_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Add_2 [Add] outputs: [/model/decoder/decoder/layers.1/self_attn/Add_2_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1669
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Reshape [Reshape] inputs: [/model/decoder/decoder/layers.1/self_attn/Add_output_0 -> (300, 1, 256)[FLOAT]], [_v_1669 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_664 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Reshape for ONNX node: /model/decoder/decoder/layers.1/self_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Reshape_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Reshape [Reshape] outputs: [/model/decoder/decoder/layers.1/self_attn/Reshape_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose_2 [Transpose] inputs: [/model/decoder/decoder/layers.1/self_attn/Reshape_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Transpose_2 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose_2 [Transpose] outputs: [/model/decoder/decoder/layers.1/self_attn/Transpose_2_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1669
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Reshape_1 [Reshape] inputs: [/model/decoder/decoder/layers.1/self_attn/Add_1_output_0 -> (300, 1, 256)[FLOAT]], [_v_1669 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_665 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Reshape_1 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Reshape_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Reshape_1 [Reshape] outputs: [/model/decoder/decoder/layers.1/self_attn/Reshape_1_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1669
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Reshape_2 [Reshape] inputs: [/model/decoder/decoder/layers.1/self_attn/Add_2_output_0 -> (300, 1, 256)[FLOAT]], [_v_1669 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_666 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Reshape_2 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Reshape_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Reshape_2 [Reshape] outputs: [/model/decoder/decoder/layers.1/self_attn/Reshape_2_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose_3 [Transpose] inputs: [/model/decoder/decoder/layers.1/self_attn/Reshape_2_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Transpose_3 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose_3 [Transpose] outputs: [/model/decoder/decoder/layers.1/self_attn/Transpose_3_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Mul_1 [Mul] inputs: [/model/decoder/decoder/layers.1/self_attn/Transpose_2_output_0 -> (8, 300, 32)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/Constant_7_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_667 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_668 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Mul_1 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Mul_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Mul_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Mul_1 [Mul] outputs: [/model/decoder/decoder/layers.1/self_attn/Mul_1_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose_4 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose_4 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose_4 [Transpose] inputs: [/model/decoder/decoder/layers.1/self_attn/Reshape_1_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Transpose_4 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Transpose_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose_4 [Transpose] outputs: [/model/decoder/decoder/layers.1/self_attn/Transpose_4_output_0 -> (8, 32, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/MatMul_3 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/MatMul_3 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Transpose_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul_3 [MatMul] inputs: [/model/decoder/decoder/layers.1/self_attn/Mul_1_output_0 -> (8, 300, 32)[FLOAT]], [/model/decoder/decoder/layers.1/self_attn/Transpose_4_output_0 -> (8, 32, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/MatMul_3 for ONNX node: /model/decoder/decoder/layers.1/self_attn/MatMul_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/MatMul_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/MatMul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul_3 [MatMul] outputs: [/model/decoder/decoder/layers.1/self_attn/MatMul_3_output_0 -> (8, 300, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/MatMul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Softmax [Softmax] inputs: [/model/decoder/decoder/layers.1/self_attn/MatMul_3_output_0 -> (8, 300, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Softmax for ONNX node: /model/decoder/decoder/layers.1/self_attn/Softmax
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_669 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Softmax_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Softmax [Softmax] outputs: [/model/decoder/decoder/layers.1/self_attn/Softmax_output_0 -> (8, 300, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/MatMul_4 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/MatMul_4 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul_4 [MatMul] inputs: [/model/decoder/decoder/layers.1/self_attn/Softmax_output_0 -> (8, 300, 300)[FLOAT]], [/model/decoder/decoder/layers.1/self_attn/Transpose_3_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/MatMul_4 for ONNX node: /model/decoder/decoder/layers.1/self_attn/MatMul_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/MatMul_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/MatMul_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul_4 [MatMul] outputs: [/model/decoder/decoder/layers.1/self_attn/MatMul_4_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose_5 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose_5 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/MatMul_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose_5 [Transpose] inputs: [/model/decoder/decoder/layers.1/self_attn/MatMul_4_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Transpose_5 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Transpose_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_5_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose_5 [Transpose] outputs: [/model/decoder/decoder/layers.1/self_attn/Transpose_5_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Reshape_3 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Reshape_3 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Transpose_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1846
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Reshape_3 [Reshape] inputs: [/model/decoder/decoder/layers.1/self_attn/Transpose_5_output_0 -> (300, 8, 32)[FLOAT]], [_v_1846 -> (2)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_670 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Reshape_3 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Reshape_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Reshape_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Reshape_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Reshape_3 [Reshape] outputs: [/model/decoder/decoder/layers.1/self_attn/Reshape_3_output_0 -> (300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Gemm [Gemm]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Gemm [Gemm]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Reshape_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.self_attn.out_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.self_attn.out_proj.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Gemm [Gemm] inputs: [/model/decoder/decoder/layers.1/self_attn/Reshape_3_output_0 -> (300, 256)[FLOAT]], [model.decoder.decoder.layers.1.self_attn.out_proj.weight -> (256, 256)[FLOAT]], [model.decoder.decoder.layers.1.self_attn.out_proj.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.self_attn.out_proj.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Using opA: 0 opB: 1
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Gemm for ONNX node: /model/decoder/decoder/layers.1/self_attn/Gemm
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.self_attn.out_proj.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_671 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_672 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Gemm_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Gemm_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Gemm [Gemm] outputs: [/model/decoder/decoder/layers.1/self_attn/Gemm_output_0 -> (300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Gemm_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1675
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Reshape_4 [Reshape] inputs: [/model/decoder/decoder/layers.1/self_attn/Gemm_output_0 -> (300, 256)[FLOAT]], [_v_1675 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_673 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Reshape_4 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Reshape_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Reshape_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Reshape_4 [Reshape] outputs: [/model/decoder/decoder/layers.1/self_attn/Reshape_4_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose_6 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/self_attn/Transpose_6 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose_6 [Transpose] inputs: [/model/decoder/decoder/layers.1/self_attn/Reshape_4_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/self_attn/Transpose_6 for ONNX node: /model/decoder/decoder/layers.1/self_attn/Transpose_6
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_6_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/self_attn/Transpose_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/Transpose_6 [Transpose] outputs: [/model/decoder/decoder/layers.1/self_attn/Transpose_6_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/norm3/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/self_attn/Transpose_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/Add_1 [Add] inputs: [/model/decoder/decoder/layers.0/norm3/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.1/self_attn/Transpose_6_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/Add_1 for ONNX node: /model/decoder/decoder/layers.1/Add_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/Add_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/Add_1 [Add] outputs: [/model/decoder/decoder/layers.1/Add_1_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/norm1/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/norm1/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.norm1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.norm1.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/norm1/LayerNormalization [LayerNormalization] inputs: [/model/decoder/decoder/layers.1/Add_1_output_0 -> (1, 300, 256)[FLOAT]], [model.decoder.decoder.layers.1.norm1.weight -> (256)[FLOAT]], [model.decoder.decoder.layers.1.norm1.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.norm1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.norm1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_676 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_677 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_678 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_679 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/norm1/LayerNormalization for ONNX node: /model/decoder/decoder/layers.1/norm1/LayerNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/norm1/LayerNormalization_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/norm1/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/norm1/LayerNormalization [LayerNormalization] outputs: [/model/decoder/decoder/layers.1/norm1/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/norm1/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1_1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/Add_2 [Add] inputs: [/model/decoder/decoder/layers.1/norm1/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1_1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/Add_2 for ONNX node: /model/decoder/decoder/layers.1/Add_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/Add_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/Add_2 [Add] outputs: [/model/decoder/decoder/layers.1/Add_2_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.cross_attn.value_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.1.cross_attn.value_proj.weight -> (256, 256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.cross_attn.value_proj.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_680 for ONNX node: tmp_weight_680
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_681 for ONNX node: tmp_weight_681
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose for ONNX node: /model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_682 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_683 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul for ONNX node: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.cross_attn.value_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/value_proj/Add [Add] inputs: [model.decoder.decoder.layers.1.cross_attn.value_proj.bias -> (256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.cross_attn.value_proj.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_684 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_685 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add for ONNX node: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/value_proj/Add [Add] outputs: [/model/decoder/decoder/layers.1/cross_attn/value_proj/Add_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1848
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape [Reshape] inputs: [/model/decoder/decoder/layers.1/cross_attn/value_proj/Add_output_0 -> (1, 8400, 256)[FLOAT]], [_v_1848 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_686 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Reshape for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape [Reshape] outputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_output_0 -> (1, 8400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.1/Add_2_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_687 for ONNX node: tmp_weight_687
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_688 for ONNX node: tmp_weight_688
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.cross_attn.sampling_offsets.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.1.cross_attn.sampling_offsets.weight -> (192, 256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0 -> (192)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0 -> (192)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.cross_attn.sampling_offsets.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_689 for ONNX node: tmp_weight_689
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0 -> (192, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0 -> (192, 256)[INT8]], [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0 -> (192)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0 -> (192)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_690 for ONNX node: tmp_weight_690
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0 -> (192, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0 -> (192, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose for ONNX node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose_output_0 -> (256, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose_output_0 -> (256, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_691 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_692 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul for ONNX node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul_output_0 -> (1, 300, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.cross_attn.sampling_offsets.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add [Add] inputs: [model.decoder.decoder.layers.1.cross_attn.sampling_offsets.bias -> (192)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul_output_0 -> (1, 300, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.cross_attn.sampling_offsets.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_693 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_694 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add for ONNX node: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add [Add] outputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add_output_0 -> (1, 300, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1663
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_1 [Reshape] inputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add_output_0 -> (1, 300, 192)[FLOAT]], [_v_1663 -> (5)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_695 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_1 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_1 [Reshape] outputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_1_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.cross_attn.attention_weights.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.1.cross_attn.attention_weights.weight -> (96, 256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0 -> (96)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0 -> (96)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.cross_attn.attention_weights.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_696 for ONNX node: tmp_weight_696
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0 -> (96, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0 -> (96, 256)[INT8]], [/model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0 -> (96)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0 -> (96)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_697 for ONNX node: tmp_weight_697
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0 -> (96, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0 -> (96, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose for ONNX node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose_output_0 -> (256, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose_output_0 -> (256, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_698 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_699 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul for ONNX node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul_output_0 -> (1, 300, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.cross_attn.attention_weights.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add [Add] inputs: [model.decoder.decoder.layers.1.cross_attn.attention_weights.bias -> (96)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul_output_0 -> (1, 300, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.cross_attn.attention_weights.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_700 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_701 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add for ONNX node: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add [Add] outputs: [/model/decoder/decoder/layers.1/cross_attn/attention_weights/Add_output_0 -> (1, 300, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1665
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_2 [Reshape] inputs: [/model/decoder/decoder/layers.1/cross_attn/attention_weights/Add_output_0 -> (1, 300, 96)[FLOAT]], [_v_1665 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_702 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_2 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_2 [Reshape] outputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_2_output_0 -> (1, 300, 8, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Softmax [Softmax] inputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_2_output_0 -> (1, 300, 8, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Softmax for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Softmax
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_703 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Softmax_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Softmax [Softmax] outputs: [/model/decoder/decoder/layers.1/cross_attn/Softmax_output_0 -> (1, 300, 8, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Mul_3755
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Mul [Mul] inputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_1_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [onnx::Mul_3755 -> (12, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_704 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_705 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Mul for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Mul_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Mul [Mul] outputs: [/model/decoder/decoder/layers.1/cross_attn/Mul_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sigmoid_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1997
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8 [Unsqueeze] inputs: [/model/decoder/decoder/Sigmoid_1_output_0 -> (1, 300, 4)[FLOAT]], [_v_1997 -> (2)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8 [Unsqueeze] outputs: [/model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8_output_0 -> (1, 300, 1, 1, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Slice [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Slice [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Constant_15_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Constant_21_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Slice [Slice] inputs: [/model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8_output_0 -> (1, 300, 1, 1, 4)[FLOAT]], [/model/decoder/decoder/Constant_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Constant_15_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0 -> (1)[INT64]], [/model/decoder/Constant_21_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_706 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_707 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_709 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_710 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_712 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_713 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_715 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_716 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_717 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_719 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_720 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_721 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_723 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_724 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_726 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_727 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_728 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_729 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_731 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_732 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_733 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_734 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_736 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_737 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_738 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Slice for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Slice
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Slice_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Slice_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Slice [Slice] outputs: [/model/decoder/decoder/layers.1/cross_attn/Slice_output_0 -> (1, 300, 1, 1, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Slice_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Mul_1 [Mul] inputs: [/model/decoder/decoder/layers.1/cross_attn/Mul_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/Slice_output_0 -> (1, 300, 1, 1, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Mul_1 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Mul_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Mul_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Mul_1 [Mul] outputs: [/model/decoder/decoder/layers.1/cross_attn/Mul_1_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Mul_2 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Mul_2 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Mul_2 [Mul] inputs: [/model/decoder/decoder/layers.1/cross_attn/Mul_1_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_2_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_739 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_740 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Mul_2 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Mul_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Mul_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Mul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Mul_2 [Mul] outputs: [/model/decoder/decoder/layers.1/cross_attn/Mul_2_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Slice_1 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Slice_1 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Unsqueeze_1255
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Constant_21_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Slice_1 [Slice] inputs: [/model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8_output_0 -> (1, 300, 1, 1, 4)[FLOAT]], [onnx::Unsqueeze_1255 -> (1)[INT64]], [/model/decoder/decoder/Constant_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0 -> (1)[INT64]], [/model/decoder/Constant_21_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_741 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_742 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_744 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_745 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_747 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_748 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_750 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_751 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_752 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_754 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_755 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_756 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_758 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_759 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_761 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_762 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_763 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_764 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_766 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_767 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_768 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_769 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_771 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_772 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_773 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Slice_1 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Slice_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Slice_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Slice_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Slice_1 [Slice] outputs: [/model/decoder/decoder/layers.1/cross_attn/Slice_1_output_0 -> (1, 300, 1, 1, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Slice_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Mul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Add [Add] inputs: [/model/decoder/decoder/layers.1/cross_attn/Slice_1_output_0 -> (1, 300, 1, 1, 2)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/Mul_2_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Add for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Add [Add] outputs: [/model/decoder/decoder/layers.1/cross_attn/Add_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_output_0 -> (1, 8400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Transpose for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.1/cross_attn/Transpose_output_0 -> (1, 8, 32, 8400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1749
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_4 [Reshape] inputs: [/model/decoder/decoder/layers.1/cross_attn/Transpose_output_0 -> (1, 8, 32, 8400)[FLOAT]], [_v_1749 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_774 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_4 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Reshape_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_4 [Reshape] outputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_4_output_0 -> (8, 32, 8400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Slice_4 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Slice_4 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Unsqueeze_1255
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Slice_4 [Slice] inputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_4_output_0 -> (8, 32, 8400)[FLOAT]], [onnx::Unsqueeze_1255 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0 -> (1)[INT64]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_775 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_776 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_778 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_779 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_781 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_782 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_784 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_785 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_786 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_788 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_789 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_790 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_792 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_793 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_795 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_796 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_797 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_798 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_800 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_801 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_802 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_803 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_805 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_806 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_807 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Slice_4 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Slice_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Slice_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Slice_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Slice_4 [Slice] outputs: [/model/decoder/decoder/layers.1/cross_attn/Slice_4_output_0 -> (8, 32, 6400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Slice_5 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Slice_5 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Slice_5 [Slice] inputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_4_output_0 -> (8, 32, 8400)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Add_2_output_0 -> (1)[INT64]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_808 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_809 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_811 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_812 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_814 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_815 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_817 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_818 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_819 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_821 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_822 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_823 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_825 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_826 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_828 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_829 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_830 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_831 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_833 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_834 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_835 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_836 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_838 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_839 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_840 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Slice_5 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Slice_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Slice_5_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Slice_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Slice_5 [Slice] outputs: [/model/decoder/decoder/layers.1/cross_attn/Slice_5_output_0 -> (8, 32, 1600)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Slice_6 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Slice_6 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Add_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Slice_6 [Slice] inputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_4_output_0 -> (8, 32, 8400)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Add_2_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Add_3_output_0 -> (1)[INT64]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_841 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_842 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_844 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_845 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_847 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_848 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_850 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_851 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_852 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_854 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_855 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_856 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_858 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_859 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_861 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_862 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_863 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_864 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_866 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_867 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_868 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_869 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_871 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_872 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_873 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Slice_6 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Slice_6
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Slice_6_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Slice_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Slice_6 [Slice] outputs: [/model/decoder/decoder/layers.1/cross_attn/Slice_6_output_0 -> (8, 32, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Mul_3 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Mul_3 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Constant_39_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Mul_3 [Mul] inputs: [/model/decoder/decoder/layers.1/cross_attn/Add_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Constant_39_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_874 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_875 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Mul_3 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Mul_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Mul_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Mul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Mul_3 [Mul] outputs: [/model/decoder/decoder/layers.1/cross_attn/Mul_3_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Sub [Sub]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Sub [Sub]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Mul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Sub [Sub] inputs: [/model/decoder/decoder/layers.1/cross_attn/Mul_3_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_1_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_876 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_877 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Sub for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Sub
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Sub_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Sub_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Sub [Sub] outputs: [/model/decoder/decoder/layers.1/cross_attn/Sub_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Sub_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Transpose_1 [Transpose] inputs: [/model/decoder/decoder/layers.1/cross_attn/Sub_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_1 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Transpose_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Transpose_1 [Transpose] outputs: [/model/decoder/decoder/layers.1/cross_attn/Transpose_1_output_0 -> (1, 8, 300, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_5 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_5 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1850
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_5 [Reshape] inputs: [/model/decoder/decoder/layers.1/cross_attn/Transpose_1_output_0 -> (1, 8, 300, 12, 2)[FLOAT]], [_v_1850 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_878 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_5 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Reshape_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_5_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_5 [Reshape] outputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_5_output_0 -> (8, 300, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Split [Split]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Split [Split]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Reshape_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Split_2305
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Split [Split] inputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_5_output_0 -> (8, 300, 12, 2)[FLOAT]], [onnx::Split_2305 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_879 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Split for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Split
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_880 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Split_881 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Split
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_882 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Split_883 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Split
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Split_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Split_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Split_output_1 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Split_output_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Split_output_2 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Split_output_2
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Split [Split] outputs: [/model/decoder/decoder/layers.1/cross_attn/Split_output_0 -> (8, 300, 4, 2)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/Split_output_1 -> (8, 300, 4, 2)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/Split_output_2 -> (8, 300, 4, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_6 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_6 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Slice_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_6 [Reshape] inputs: [/model/decoder/decoder/layers.1/cross_attn/Slice_4_output_0 -> (8, 32, 6400)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_6_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_884 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_6 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Reshape_6
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_6_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_6 [Reshape] outputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_6_output_0 -> (8, 32, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/GridSample [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/GridSample [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Reshape_6_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Split_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/GridSample [GridSample] inputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_6_output_0 -> (8, 32, 80, 80)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/Split_output_0 -> (8, 300, 4, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/GridSample for ONNX node: /model/decoder/decoder/layers.1/cross_attn/GridSample
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/GridSample_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/GridSample_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/GridSample [GridSample] outputs: [/model/decoder/decoder/layers.1/cross_attn/GridSample_output_0 -> (8, 32, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_7 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_7 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Slice_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_7 [Reshape] inputs: [/model/decoder/decoder/layers.1/cross_attn/Slice_5_output_0 -> (8, 32, 1600)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_7_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_885 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_7 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Reshape_7
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_7_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_7 [Reshape] outputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_7_output_0 -> (8, 32, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/GridSample_1 [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/GridSample_1 [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Reshape_7_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Split_output_1
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/GridSample_1 [GridSample] inputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_7_output_0 -> (8, 32, 40, 40)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/Split_output_1 -> (8, 300, 4, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/GridSample_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/GridSample_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/GridSample_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/GridSample_1 [GridSample] outputs: [/model/decoder/decoder/layers.1/cross_attn/GridSample_1_output_0 -> (8, 32, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_8 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_8 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Slice_6_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_8 [Reshape] inputs: [/model/decoder/decoder/layers.1/cross_attn/Slice_6_output_0 -> (8, 32, 400)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_8_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_886 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_8 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Reshape_8
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_8_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_8 [Reshape] outputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_8_output_0 -> (8, 32, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/GridSample_2 [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/GridSample_2 [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Reshape_8_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Split_output_2
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/GridSample_2 [GridSample] inputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_8_output_0 -> (8, 32, 20, 20)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/Split_output_2 -> (8, 300, 4, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_2 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/GridSample_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/GridSample_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/GridSample_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/GridSample_2 [GridSample] outputs: [/model/decoder/decoder/layers.1/cross_attn/GridSample_2_output_0 -> (8, 32, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Transpose_2 [Transpose] inputs: [/model/decoder/decoder/layers.1/cross_attn/Softmax_output_0 -> (1, 300, 8, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_2 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Transpose_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Transpose_2 [Transpose] outputs: [/model/decoder/decoder/layers.1/cross_attn/Transpose_2_output_0 -> (1, 8, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_9 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_9 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_9_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_9 [Reshape] inputs: [/model/decoder/decoder/layers.1/cross_attn/Transpose_2_output_0 -> (1, 8, 300, 12)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_9_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_887 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_9 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Reshape_9
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_9_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_9_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_9 [Reshape] outputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_9_output_0 -> (8, 1, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Concat_10 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Concat_10 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/GridSample_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/GridSample_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/GridSample_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Concat_10 [Concat] inputs: [/model/decoder/decoder/layers.1/cross_attn/GridSample_output_0 -> (8, 32, 300, 4)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/GridSample_1_output_0 -> (8, 32, 300, 4)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/GridSample_2_output_0 -> (8, 32, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Concat_10 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Concat_10
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Concat_10_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Concat_10_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Concat_10 [Concat] outputs: [/model/decoder/decoder/layers.1/cross_attn/Concat_10_output_0 -> (8, 32, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Mul_5 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Mul_5 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Concat_10_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Reshape_9_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Mul_5 [Mul] inputs: [/model/decoder/decoder/layers.1/cross_attn/Concat_10_output_0 -> (8, 32, 300, 12)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/Reshape_9_output_0 -> (8, 1, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Mul_5 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Mul_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Mul_5_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Mul_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Mul_5 [Mul] outputs: [/model/decoder/decoder/layers.1/cross_attn/Mul_5_output_0 -> (8, 32, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/ReduceSum [ReduceSum]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/ReduceSum [ReduceSum]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Mul_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/ReduceSum [ReduceSum] inputs: [/model/decoder/decoder/layers.1/cross_attn/Mul_5_output_0 -> (8, 32, 300, 12)[FLOAT]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/ReduceSum for ONNX node: /model/decoder/decoder/layers.1/cross_attn/ReduceSum
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/ReduceSum_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/ReduceSum_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/ReduceSum [ReduceSum] outputs: [/model/decoder/decoder/layers.1/cross_attn/ReduceSum_output_0 -> (8, 32, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_10 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Reshape_10 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/ReduceSum_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_11_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_10 [Reshape] inputs: [/model/decoder/decoder/layers.1/cross_attn/ReduceSum_output_0 -> (8, 32, 300)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_11_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_888 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_10 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Reshape_10
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_10_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Reshape_10_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Reshape_10 [Reshape] outputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_10_output_0 -> (1, 256, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Reshape_10_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Transpose_3 [Transpose] inputs: [/model/decoder/decoder/layers.1/cross_attn/Reshape_10_output_0 -> (1, 256, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_3 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/Transpose_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/Transpose_3 [Transpose] outputs: [/model/decoder/decoder/layers.1/cross_attn/Transpose_3_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.1/cross_attn/Transpose_3_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_889 for ONNX node: tmp_weight_889
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_890 for ONNX node: tmp_weight_890
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.cross_attn.output_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.1.cross_attn.output_proj.weight -> (256, 256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.cross_attn.output_proj.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_891 for ONNX node: tmp_weight_891
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_892 for ONNX node: tmp_weight_892
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose for ONNX node: /model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_893 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_894 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul for ONNX node: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.cross_attn.output_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/Add [Add] inputs: [model.decoder.decoder.layers.1.cross_attn.output_proj.bias -> (256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.cross_attn.output_proj.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_895 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_896 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add for ONNX node: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/cross_attn/output_proj/Add [Add] outputs: [/model/decoder/decoder/layers.1/cross_attn/output_proj/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/Add_3 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/Add_3 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/norm1/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/Add_3 [Add] inputs: [/model/decoder/decoder/layers.1/norm1/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.1/cross_attn/output_proj/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/Add_3 for ONNX node: /model/decoder/decoder/layers.1/Add_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/Add_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/Add_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/Add_3 [Add] outputs: [/model/decoder/decoder/layers.1/Add_3_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/norm2/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/norm2/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/Add_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.norm2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.norm2.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/norm2/LayerNormalization [LayerNormalization] inputs: [/model/decoder/decoder/layers.1/Add_3_output_0 -> (1, 300, 256)[FLOAT]], [model.decoder.decoder.layers.1.norm2.weight -> (256)[FLOAT]], [model.decoder.decoder.layers.1.norm2.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.norm2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.norm2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_899 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_900 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_901 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_902 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/norm2/LayerNormalization for ONNX node: /model/decoder/decoder/layers.1/norm2/LayerNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/norm2/LayerNormalization_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/norm2/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/norm2/LayerNormalization [LayerNormalization] outputs: [/model/decoder/decoder/layers.1/norm2/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/norm2/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.1/norm2/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.1/linear1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.1/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_903 for ONNX node: tmp_weight_903
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/layers.1/linear1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_904 for ONNX node: tmp_weight_904
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.linear1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.1.linear1.weight -> (1024, 256)[FLOAT]], [/model/decoder/decoder/layers.1/linear1/weight_quantizer/Constant_1_output_0 -> (1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0 -> (1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.linear1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.1/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_905 for ONNX node: tmp_weight_905
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.1/linear1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear1/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.1/linear1/weight_quantizer/QuantizeLinear_output_0 -> (1024, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.1/linear1/weight_quantizer/QuantizeLinear_output_0 -> (1024, 256)[INT8]], [/model/decoder/decoder/layers.1/linear1/weight_quantizer/Constant_1_output_0 -> (1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0 -> (1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_906 for ONNX node: tmp_weight_906
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear1/Transpose for ONNX node: /model/decoder/decoder/layers.1/linear1/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear1/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.1/linear1/Transpose_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.1/linear1/Transpose_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_907 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_908 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear1/MatMul for ONNX node: /model/decoder/decoder/layers.1/linear1/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear1/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.1/linear1/MatMul_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.linear1.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/Add [Add] inputs: [model.decoder.decoder.layers.1.linear1.bias -> (1024)[FLOAT]], [/model/decoder/decoder/layers.1/linear1/MatMul_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.linear1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_909 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_910 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear1/Add for ONNX node: /model/decoder/decoder/layers.1/linear1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear1/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear1/Add [Add] outputs: [/model/decoder/decoder/layers.1/linear1/Add_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/activation/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/activation/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/activation/Relu [Relu] inputs: [/model/decoder/decoder/layers.1/linear1/Add_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/activation/Relu for ONNX node: /model/decoder/decoder/layers.1/activation/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/activation/Relu_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/activation/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/activation/Relu [Relu] outputs: [/model/decoder/decoder/layers.1/activation/Relu_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/activation/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.1/activation/Relu_output_0 -> (1, 300, 1024)[FLOAT]], [/model/decoder/decoder/layers.1/linear2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.1/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_911 for ONNX node: tmp_weight_911
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 1024)[INT8]], [/model/decoder/decoder/layers.1/linear2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_912 for ONNX node: tmp_weight_912
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.linear2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.1.linear2.weight -> (256, 1024)[FLOAT]], [/model/decoder/decoder/layers.1/linear2/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.linear2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.1/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_913 for ONNX node: tmp_weight_913
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.1/linear2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear2/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.1/linear2/weight_quantizer/QuantizeLinear_output_0 -> (256, 1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.1/linear2/weight_quantizer/QuantizeLinear_output_0 -> (256, 1024)[INT8]], [/model/decoder/decoder/layers.1/linear2/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_914 for ONNX node: tmp_weight_914
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear2/Transpose for ONNX node: /model/decoder/decoder/layers.1/linear2/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear2/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.1/linear2/Transpose_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 1024)[FLOAT]], [/model/decoder/decoder/layers.1/linear2/Transpose_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_915 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_916 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear2/MatMul for ONNX node: /model/decoder/decoder/layers.1/linear2/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear2/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.1/linear2/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/linear2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/linear2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.linear2.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/Add [Add] inputs: [model.decoder.decoder.layers.1.linear2.bias -> (256)[FLOAT]], [/model/decoder/decoder/layers.1/linear2/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.linear2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_917 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_918 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/linear2/Add for ONNX node: /model/decoder/decoder/layers.1/linear2/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/linear2/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/linear2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/linear2/Add [Add] outputs: [/model/decoder/decoder/layers.1/linear2/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/Add_4 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/Add_4 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/norm2/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/linear2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/Add_4 [Add] inputs: [/model/decoder/decoder/layers.1/norm2/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.1/linear2/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/Add_4 for ONNX node: /model/decoder/decoder/layers.1/Add_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/Add_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/Add_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/Add_4 [Add] outputs: [/model/decoder/decoder/layers.1/Add_4_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.1/norm3/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.1/norm3/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/Add_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.norm3.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.1.norm3.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/norm3/LayerNormalization [LayerNormalization] inputs: [/model/decoder/decoder/layers.1/Add_4_output_0 -> (1, 300, 256)[FLOAT]], [model.decoder.decoder.layers.1.norm3.weight -> (256)[FLOAT]], [model.decoder.decoder.layers.1.norm3.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.norm3.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.1.norm3.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_921 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_922 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_923 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_924 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization for ONNX node: /model/decoder/decoder/layers.1/norm3/LayerNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.1/norm3/LayerNormalization_output_0 for ONNX tensor: /model/decoder/decoder/layers.1/norm3/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/norm3/LayerNormalization [LayerNormalization] outputs: [/model/decoder/decoder/layers.1/norm3/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/norm3/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.1/norm3/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_925 for ONNX node: tmp_weight_925
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_926 for ONNX node: tmp_weight_926
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.1.layers.0.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.dec_bbox_head.1.layers.0.weight -> (256, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.1.layers.0.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_927 for ONNX node: tmp_weight_927
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_928 for ONNX node: tmp_weight_928
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose [Transpose] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose [Transpose] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul [MatMul] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_929 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_930 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul [MatMul] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.1.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/Add [Add] inputs: [model.decoder.dec_bbox_head.1.layers.0.bias -> (256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.1.layers.0.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_931 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_932 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.0/Add [Add] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.0/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/act/Relu [Relu] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.0/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/act/Relu for ONNX node: /model/decoder/decoder/dec_bbox_head.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/act/Relu_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/act/Relu [Relu] outputs: [/model/decoder/decoder/dec_bbox_head.1/act/Relu_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.1/act/Relu_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_933 for ONNX node: tmp_weight_933
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_934 for ONNX node: tmp_weight_934
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.1.layers.1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.dec_bbox_head.1.layers.1.weight -> (256, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.1.layers.1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_935 for ONNX node: tmp_weight_935
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_936 for ONNX node: tmp_weight_936
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose [Transpose] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose [Transpose] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul [MatMul] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_937 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_938 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul [MatMul] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.1.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/Add [Add] inputs: [model.decoder.dec_bbox_head.1.layers.1.bias -> (256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.1.layers.1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_939 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_940 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.1/Add [Add] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/act_1/Relu [Relu] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu for ONNX node: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/act_1/Relu [Relu] outputs: [/model/decoder/decoder/dec_bbox_head.1/act_1/Relu_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.1/act_1/Relu_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_941 for ONNX node: tmp_weight_941
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_942 for ONNX node: tmp_weight_942
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.1.layers.2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.dec_bbox_head.1.layers.2.weight -> (4, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/Constant_1_output_0 -> (4)[FLOAT]], [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0 -> (4)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.1.layers.2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_943 for ONNX node: tmp_weight_943
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/QuantizeLinear_output_0 -> (4, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/QuantizeLinear_output_0 -> (4, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/Constant_1_output_0 -> (4)[FLOAT]], [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0 -> (4)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_944 for ONNX node: tmp_weight_944
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear_output_0 -> (4, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose [Transpose] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear_output_0 -> (4, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose [Transpose] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose_output_0 -> (256, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul [MatMul] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose_output_0 -> (256, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_945 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_946 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul [MatMul] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.1.layers.2.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/Add [Add] inputs: [model.decoder.dec_bbox_head.1.layers.2.bias -> (4)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.1.layers.2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_947 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_948 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add for ONNX node: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.1/layers.2/Add [Add] outputs: [/model/decoder/decoder/dec_bbox_head.1/layers.2/Add_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Clip_3 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Clip_3 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sigmoid_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_3 [Clip] inputs: [/model/decoder/decoder/Sigmoid_1_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Constant_1_output_0 -> ()[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_1_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Clip_3 for ONNX node: /model/decoder/decoder/Clip_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Clip_3_output_0 for ONNX tensor: /model/decoder/decoder/Clip_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_3 [Clip] outputs: [/model/decoder/decoder/Clip_3_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Clip_4 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Clip_4 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Clip_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_4 [Clip] inputs: [/model/decoder/decoder/Clip_3_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Constant_3_output_0 -> ()[FLOAT]], [optional input, not set], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_950 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_951 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_952 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_953 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Clip_4_output_0 for ONNX tensor: /model/decoder/decoder/Clip_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_4 [Clip] outputs: [/model/decoder/decoder/Clip_4_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Sub_1 [Sub]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Sub_1 [Sub]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Clip_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sub_1 [Sub] inputs: [/model/encoder/encoder.0/layers.0/activation/Constant_1_output_0 -> ()[FLOAT]], [/model/decoder/decoder/Clip_3_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_954 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_955 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Sub_1 for ONNX node: /model/decoder/decoder/Sub_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Sub_1_output_0 for ONNX tensor: /model/decoder/decoder/Sub_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sub_1 [Sub] outputs: [/model/decoder/decoder/Sub_1_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Clip_5 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Clip_5 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sub_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_5 [Clip] inputs: [/model/decoder/decoder/Sub_1_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Constant_3_output_0 -> ()[FLOAT]], [optional input, not set], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_957 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_958 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_959 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_960 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Clip_5_output_0 for ONNX tensor: /model/decoder/decoder/Clip_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_5 [Clip] outputs: [/model/decoder/decoder/Clip_5_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Div_1 [Div]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Div_1 [Div]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Clip_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Clip_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Div_1 [Div] inputs: [/model/decoder/decoder/Clip_4_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Clip_5_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Div_1 for ONNX node: /model/decoder/decoder/Div_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Div_1_output_0 for ONNX tensor: /model/decoder/decoder/Div_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Div_1 [Div] outputs: [/model/decoder/decoder/Div_1_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Log_1 [Log]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Log_1 [Log]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Div_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Log_1 [Log] inputs: [/model/decoder/decoder/Div_1_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Log_1 for ONNX node: /model/decoder/decoder/Log_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Log_1_output_0 for ONNX tensor: /model/decoder/decoder/Log_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Log_1 [Log] outputs: [/model/decoder/decoder/Log_1_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Log_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Add_1 [Add] inputs: [/model/decoder/decoder/dec_bbox_head.1/layers.2/Add_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Log_1_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Add_1 for ONNX node: /model/decoder/decoder/Add_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Add_1_output_0 for ONNX tensor: /model/decoder/decoder/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Add_1 [Add] outputs: [/model/decoder/decoder/Add_1_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Sigmoid_2 [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Sigmoid_2 [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sigmoid_2 [Sigmoid] inputs: [/model/decoder/decoder/Add_1_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Sigmoid_2 for ONNX node: /model/decoder/decoder/Sigmoid_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Sigmoid_2_output_0 for ONNX tensor: /model/decoder/decoder/Sigmoid_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sigmoid_2 [Sigmoid] outputs: [/model/decoder/decoder/Sigmoid_2_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sigmoid_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/Sigmoid_2_output_0 -> (1, 300, 4)[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_961 for ONNX node: tmp_weight_961
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear_output_0 -> (1, 300, 4)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear_output_0 -> (1, 300, 4)[INT8]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_962 for ONNX node: tmp_weight_962
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0_2/MatMul [MatMul] inputs: [/model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.0/Transpose_output_0 -> (4, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_963 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_964 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul for ONNX node: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0_2/MatMul [MatMul] outputs: [/model/decoder/decoder/query_pos_head/layers.0_2/MatMul_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.0_2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.0_2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.query_pos_head.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0_2/Add [Add] inputs: [model.decoder.query_pos_head.layers.0.bias -> (512)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.0_2/MatMul_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_965 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_966 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.0_2/Add for ONNX node: /model/decoder/decoder/query_pos_head/layers.0_2/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.0_2/Add_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.0_2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.0_2/Add [Add] outputs: [/model/decoder/decoder/query_pos_head/layers.0_2/Add_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/act_2/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/act_2/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.0_2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/act_2/Relu [Relu] inputs: [/model/decoder/decoder/query_pos_head/layers.0_2/Add_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/act_2/Relu for ONNX node: /model/decoder/decoder/query_pos_head/act_2/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/act_2/Relu_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/act_2/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/act_2/Relu [Relu] outputs: [/model/decoder/decoder/query_pos_head/act_2/Relu_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/act_2/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/query_pos_head/act_2/Relu_output_0 -> (1, 300, 512)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_967 for ONNX node: tmp_weight_967
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear_output_0 -> (1, 300, 512)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear_output_0 -> (1, 300, 512)[INT8]], [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_968 for ONNX node: tmp_weight_968
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear for ONNX node: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear_output_0 -> (1, 300, 512)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1_2/MatMul [MatMul] inputs: [/model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear_output_0 -> (1, 300, 512)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1/Transpose_output_0 -> (512, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_969 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_970 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul for ONNX node: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1_2/MatMul [MatMul] outputs: [/model/decoder/decoder/query_pos_head/layers.1_2/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/query_pos_head/layers.1_2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/query_pos_head/layers.1_2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.query_pos_head.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1_2/Add [Add] inputs: [model.decoder.query_pos_head.layers.1.bias -> (256)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1_2/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_971 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_972 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/query_pos_head/layers.1_2/Add for ONNX node: /model/decoder/decoder/query_pos_head/layers.1_2/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/query_pos_head/layers.1_2/Add_output_0 for ONNX tensor: /model/decoder/decoder/query_pos_head/layers.1_2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/query_pos_head/layers.1_2/Add [Add] outputs: [/model/decoder/decoder/query_pos_head/layers.1_2/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/norm3/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1_2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/Add [Add] inputs: [/model/decoder/decoder/layers.1/norm3/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1_2/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/Add for ONNX node: /model/decoder/decoder/layers.2/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/Add [Add] outputs: [/model/decoder/decoder/layers.2/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.2/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Transpose for ONNX node: /model/decoder/decoder/layers.2/self_attn/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.2/self_attn/Transpose_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/norm3/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose_1 [Transpose] inputs: [/model/decoder/decoder/layers.1/norm3/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Transpose_1 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose_1 [Transpose] outputs: [/model/decoder/decoder/layers.2/self_attn/Transpose_1_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::MatMul_3880
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.2/self_attn/Transpose_output_0 -> (300, 1, 256)[FLOAT]], [onnx::MatMul_3880 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::MatMul_3880 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_973 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_974 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/MatMul for ONNX node: /model/decoder/decoder/layers.2/self_attn/MatMul
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.2/self_attn/MatMul_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Add_3875
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Add [Add] inputs: [onnx::Add_3875 -> (256)[FLOAT]], [/model/decoder/decoder/layers.2/self_attn/MatMul_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Add_3875 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_975 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_976 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Add for ONNX node: /model/decoder/decoder/layers.2/self_attn/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Add [Add] outputs: [/model/decoder/decoder/layers.2/self_attn/Add_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/MatMul_1 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/MatMul_1 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::MatMul_3881
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul_1 [MatMul] inputs: [/model/decoder/decoder/layers.2/self_attn/Transpose_output_0 -> (300, 1, 256)[FLOAT]], [onnx::MatMul_3881 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::MatMul_3881 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_977 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_978 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/MatMul_1 for ONNX node: /model/decoder/decoder/layers.2/self_attn/MatMul_1
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul_1: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/MatMul_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/MatMul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul_1 [MatMul] outputs: [/model/decoder/decoder/layers.2/self_attn/MatMul_1_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Add_3877
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/MatMul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Add_1 [Add] inputs: [onnx::Add_3877 -> (256)[FLOAT]], [/model/decoder/decoder/layers.2/self_attn/MatMul_1_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Add_3877 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_979 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_980 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Add_1 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Add_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Add_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Add_1 [Add] outputs: [/model/decoder/decoder/layers.2/self_attn/Add_1_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/MatMul_2 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/MatMul_2 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::MatMul_3882
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul_2 [MatMul] inputs: [/model/decoder/decoder/layers.2/self_attn/Transpose_1_output_0 -> (300, 1, 256)[FLOAT]], [onnx::MatMul_3882 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::MatMul_3882 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_981 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_982 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/MatMul_2 for ONNX node: /model/decoder/decoder/layers.2/self_attn/MatMul_2
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul_2: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/MatMul_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/MatMul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul_2 [MatMul] outputs: [/model/decoder/decoder/layers.2/self_attn/MatMul_2_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Add_3879
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/MatMul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Add_2 [Add] inputs: [onnx::Add_3879 -> (256)[FLOAT]], [/model/decoder/decoder/layers.2/self_attn/MatMul_2_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: onnx::Add_3879 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_983 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_984 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Add_2 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Add_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Add_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Add_2 [Add] outputs: [/model/decoder/decoder/layers.2/self_attn/Add_2_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1669
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Reshape [Reshape] inputs: [/model/decoder/decoder/layers.2/self_attn/Add_output_0 -> (300, 1, 256)[FLOAT]], [_v_1669 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_985 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Reshape for ONNX node: /model/decoder/decoder/layers.2/self_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Reshape_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Reshape [Reshape] outputs: [/model/decoder/decoder/layers.2/self_attn/Reshape_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose_2 [Transpose] inputs: [/model/decoder/decoder/layers.2/self_attn/Reshape_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Transpose_2 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose_2 [Transpose] outputs: [/model/decoder/decoder/layers.2/self_attn/Transpose_2_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1669
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Reshape_1 [Reshape] inputs: [/model/decoder/decoder/layers.2/self_attn/Add_1_output_0 -> (300, 1, 256)[FLOAT]], [_v_1669 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_986 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Reshape_1 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Reshape_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Reshape_1 [Reshape] outputs: [/model/decoder/decoder/layers.2/self_attn/Reshape_1_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1669
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Reshape_2 [Reshape] inputs: [/model/decoder/decoder/layers.2/self_attn/Add_2_output_0 -> (300, 1, 256)[FLOAT]], [_v_1669 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_987 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Reshape_2 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Reshape_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Reshape_2 [Reshape] outputs: [/model/decoder/decoder/layers.2/self_attn/Reshape_2_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose_3 [Transpose] inputs: [/model/decoder/decoder/layers.2/self_attn/Reshape_2_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Transpose_3 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose_3 [Transpose] outputs: [/model/decoder/decoder/layers.2/self_attn/Transpose_3_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/self_attn/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Mul_1 [Mul] inputs: [/model/decoder/decoder/layers.2/self_attn/Transpose_2_output_0 -> (8, 300, 32)[FLOAT]], [/model/encoder/encoder.0/layers.0/self_attn/Constant_7_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_988 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_989 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Mul_1 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Mul_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Mul_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Mul_1 [Mul] outputs: [/model/decoder/decoder/layers.2/self_attn/Mul_1_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose_4 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose_4 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose_4 [Transpose] inputs: [/model/decoder/decoder/layers.2/self_attn/Reshape_1_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Transpose_4 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Transpose_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose_4 [Transpose] outputs: [/model/decoder/decoder/layers.2/self_attn/Transpose_4_output_0 -> (8, 32, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/MatMul_3 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/MatMul_3 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Transpose_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul_3 [MatMul] inputs: [/model/decoder/decoder/layers.2/self_attn/Mul_1_output_0 -> (8, 300, 32)[FLOAT]], [/model/decoder/decoder/layers.2/self_attn/Transpose_4_output_0 -> (8, 32, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/MatMul_3 for ONNX node: /model/decoder/decoder/layers.2/self_attn/MatMul_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/MatMul_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/MatMul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul_3 [MatMul] outputs: [/model/decoder/decoder/layers.2/self_attn/MatMul_3_output_0 -> (8, 300, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/MatMul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Softmax [Softmax] inputs: [/model/decoder/decoder/layers.2/self_attn/MatMul_3_output_0 -> (8, 300, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Softmax for ONNX node: /model/decoder/decoder/layers.2/self_attn/Softmax
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_990 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Softmax_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Softmax [Softmax] outputs: [/model/decoder/decoder/layers.2/self_attn/Softmax_output_0 -> (8, 300, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/MatMul_4 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/MatMul_4 [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul_4 [MatMul] inputs: [/model/decoder/decoder/layers.2/self_attn/Softmax_output_0 -> (8, 300, 300)[FLOAT]], [/model/decoder/decoder/layers.2/self_attn/Transpose_3_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/MatMul_4 for ONNX node: /model/decoder/decoder/layers.2/self_attn/MatMul_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/MatMul_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/MatMul_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul_4 [MatMul] outputs: [/model/decoder/decoder/layers.2/self_attn/MatMul_4_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose_5 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose_5 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/MatMul_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose_5 [Transpose] inputs: [/model/decoder/decoder/layers.2/self_attn/MatMul_4_output_0 -> (8, 300, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Transpose_5 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Transpose_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_5_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose_5 [Transpose] outputs: [/model/decoder/decoder/layers.2/self_attn/Transpose_5_output_0 -> (300, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Reshape_3 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Reshape_3 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Transpose_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1846
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Reshape_3 [Reshape] inputs: [/model/decoder/decoder/layers.2/self_attn/Transpose_5_output_0 -> (300, 8, 32)[FLOAT]], [_v_1846 -> (2)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_991 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Reshape_3 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Reshape_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Reshape_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Reshape_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Reshape_3 [Reshape] outputs: [/model/decoder/decoder/layers.2/self_attn/Reshape_3_output_0 -> (300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Gemm [Gemm]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Gemm [Gemm]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Reshape_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.self_attn.out_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.self_attn.out_proj.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Gemm [Gemm] inputs: [/model/decoder/decoder/layers.2/self_attn/Reshape_3_output_0 -> (300, 256)[FLOAT]], [model.decoder.decoder.layers.2.self_attn.out_proj.weight -> (256, 256)[FLOAT]], [model.decoder.decoder.layers.2.self_attn.out_proj.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.self_attn.out_proj.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Using opA: 0 opB: 1
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Gemm for ONNX node: /model/decoder/decoder/layers.2/self_attn/Gemm
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.self_attn.out_proj.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_992 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_993 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Gemm_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Gemm_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Gemm [Gemm] outputs: [/model/decoder/decoder/layers.2/self_attn/Gemm_output_0 -> (300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Gemm_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1675
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Reshape_4 [Reshape] inputs: [/model/decoder/decoder/layers.2/self_attn/Gemm_output_0 -> (300, 256)[FLOAT]], [_v_1675 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_994 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Reshape_4 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Reshape_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Reshape_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Reshape_4 [Reshape] outputs: [/model/decoder/decoder/layers.2/self_attn/Reshape_4_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose_6 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/self_attn/Transpose_6 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose_6 [Transpose] inputs: [/model/decoder/decoder/layers.2/self_attn/Reshape_4_output_0 -> (300, 1, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/self_attn/Transpose_6 for ONNX node: /model/decoder/decoder/layers.2/self_attn/Transpose_6
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_6_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/self_attn/Transpose_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/Transpose_6 [Transpose] outputs: [/model/decoder/decoder/layers.2/self_attn/Transpose_6_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.1/norm3/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/self_attn/Transpose_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/Add_1 [Add] inputs: [/model/decoder/decoder/layers.1/norm3/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.2/self_attn/Transpose_6_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/Add_1 for ONNX node: /model/decoder/decoder/layers.2/Add_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/Add_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/Add_1 [Add] outputs: [/model/decoder/decoder/layers.2/Add_1_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/norm1/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/norm1/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.norm1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.norm1.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/norm1/LayerNormalization [LayerNormalization] inputs: [/model/decoder/decoder/layers.2/Add_1_output_0 -> (1, 300, 256)[FLOAT]], [model.decoder.decoder.layers.2.norm1.weight -> (256)[FLOAT]], [model.decoder.decoder.layers.2.norm1.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.norm1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.norm1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_997 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_998 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_999 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1000 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/norm1/LayerNormalization for ONNX node: /model/decoder/decoder/layers.2/norm1/LayerNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/norm1/LayerNormalization_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/norm1/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/norm1/LayerNormalization [LayerNormalization] outputs: [/model/decoder/decoder/layers.2/norm1/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/norm1/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/query_pos_head/layers.1_2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/Add_2 [Add] inputs: [/model/decoder/decoder/layers.2/norm1/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/query_pos_head/layers.1_2/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/Add_2 for ONNX node: /model/decoder/decoder/layers.2/Add_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/Add_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/Add_2 [Add] outputs: [/model/decoder/decoder/layers.2/Add_2_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.cross_attn.value_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.2.cross_attn.value_proj.weight -> (256, 256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.cross_attn.value_proj.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1001 for ONNX node: tmp_weight_1001
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1002 for ONNX node: tmp_weight_1002
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose for ONNX node: /model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear_output_0 -> (1, 8400, 256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1003 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1004 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul for ONNX node: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.cross_attn.value_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/value_proj/Add [Add] inputs: [model.decoder.decoder.layers.2.cross_attn.value_proj.bias -> (256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.cross_attn.value_proj.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1005 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1006 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add for ONNX node: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/value_proj/Add [Add] outputs: [/model/decoder/decoder/layers.2/cross_attn/value_proj/Add_output_0 -> (1, 8400, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1848
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape [Reshape] inputs: [/model/decoder/decoder/layers.2/cross_attn/value_proj/Add_output_0 -> (1, 8400, 256)[FLOAT]], [_v_1848 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1007 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Reshape for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape [Reshape] outputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_output_0 -> (1, 8400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.2/Add_2_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1008 for ONNX node: tmp_weight_1008
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1009 for ONNX node: tmp_weight_1009
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.cross_attn.sampling_offsets.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.2.cross_attn.sampling_offsets.weight -> (192, 256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0 -> (192)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0 -> (192)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.cross_attn.sampling_offsets.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1010 for ONNX node: tmp_weight_1010
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0 -> (192, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear_output_0 -> (192, 256)[INT8]], [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0 -> (192)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_output_0 -> (192)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1011 for ONNX node: tmp_weight_1011
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0 -> (192, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear_output_0 -> (192, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose for ONNX node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose_output_0 -> (256, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose_output_0 -> (256, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1012 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1013 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul for ONNX node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul_output_0 -> (1, 300, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.cross_attn.sampling_offsets.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add [Add] inputs: [model.decoder.decoder.layers.2.cross_attn.sampling_offsets.bias -> (192)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul_output_0 -> (1, 300, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.cross_attn.sampling_offsets.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1014 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1015 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add for ONNX node: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add [Add] outputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add_output_0 -> (1, 300, 192)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_1 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1663
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_1 [Reshape] inputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add_output_0 -> (1, 300, 192)[FLOAT]], [_v_1663 -> (5)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1016 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_1 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_1 [Reshape] outputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_1_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.cross_attn.attention_weights.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.2.cross_attn.attention_weights.weight -> (96, 256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0 -> (96)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0 -> (96)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.cross_attn.attention_weights.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1017 for ONNX node: tmp_weight_1017
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0 -> (96, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/QuantizeLinear_output_0 -> (96, 256)[INT8]], [/model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0 -> (96)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_output_0 -> (96)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1018 for ONNX node: tmp_weight_1018
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0 -> (96, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear_output_0 -> (96, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose for ONNX node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose_output_0 -> (256, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose_output_0 -> (256, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1019 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1020 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul for ONNX node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul_output_0 -> (1, 300, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.cross_attn.attention_weights.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add [Add] inputs: [model.decoder.decoder.layers.2.cross_attn.attention_weights.bias -> (96)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul_output_0 -> (1, 300, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.cross_attn.attention_weights.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1021 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1022 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add for ONNX node: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add [Add] outputs: [/model/decoder/decoder/layers.2/cross_attn/attention_weights/Add_output_0 -> (1, 300, 96)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_2 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1665
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_2 [Reshape] inputs: [/model/decoder/decoder/layers.2/cross_attn/attention_weights/Add_output_0 -> (1, 300, 96)[FLOAT]], [_v_1665 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1023 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_2 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_2 [Reshape] outputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_2_output_0 -> (1, 300, 8, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Softmax [Softmax]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Reshape_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Softmax [Softmax] inputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_2_output_0 -> (1, 300, 8, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Softmax for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Softmax
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1024 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Softmax_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Softmax [Softmax] outputs: [/model/decoder/decoder/layers.2/cross_attn/Softmax_output_0 -> (1, 300, 8, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Reshape_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Mul_3755
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Mul [Mul] inputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_1_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [onnx::Mul_3755 -> (12, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1025 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1026 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Mul for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Mul_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Mul [Mul] outputs: [/model/decoder/decoder/layers.2/cross_attn/Mul_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sigmoid_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1997
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8 [Unsqueeze] inputs: [/model/decoder/decoder/Sigmoid_2_output_0 -> (1, 300, 4)[FLOAT]], [_v_1997 -> (2)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8 [Unsqueeze] outputs: [/model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8_output_0 -> (1, 300, 1, 1, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Slice [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Slice [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Constant_15_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Constant_21_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Slice [Slice] inputs: [/model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8_output_0 -> (1, 300, 1, 1, 4)[FLOAT]], [/model/decoder/decoder/Constant_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Constant_15_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0 -> (1)[INT64]], [/model/decoder/Constant_21_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1027 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1028 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1030 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1031 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1033 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1034 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1036 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1037 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1038 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1040 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1041 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1042 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1044 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1045 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1047 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1048 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1049 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1050 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1052 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1053 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1054 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1055 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1057 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1058 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1059 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Slice for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Slice
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Slice_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Slice_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Slice [Slice] outputs: [/model/decoder/decoder/layers.2/cross_attn/Slice_output_0 -> (1, 300, 1, 1, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Slice_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Mul_1 [Mul] inputs: [/model/decoder/decoder/layers.2/cross_attn/Mul_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/Slice_output_0 -> (1, 300, 1, 1, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Mul_1 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Mul_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Mul_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Mul_1 [Mul] outputs: [/model/decoder/decoder/layers.2/cross_attn/Mul_1_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Mul_2 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Mul_2 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Mul_2 [Mul] inputs: [/model/decoder/decoder/layers.2/cross_attn/Mul_1_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_2_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1060 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1061 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Mul_2 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Mul_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Mul_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Mul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Mul_2 [Mul] outputs: [/model/decoder/decoder/layers.2/cross_attn/Mul_2_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Slice_1 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Slice_1 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Unsqueeze_1255
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Constant_21_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Slice_1 [Slice] inputs: [/model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8_output_0 -> (1, 300, 1, 1, 4)[FLOAT]], [onnx::Unsqueeze_1255 -> (1)[INT64]], [/model/decoder/decoder/Constant_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Constant_13_output_0 -> (1)[INT64]], [/model/decoder/Constant_21_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1062 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1063 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1065 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1066 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1068 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1069 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1071 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1072 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1073 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1075 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1076 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1077 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1079 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1080 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1082 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1083 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1084 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1085 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1087 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1088 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1089 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1090 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1092 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1093 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1094 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Slice_1 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Slice_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Slice_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Slice_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Slice_1 [Slice] outputs: [/model/decoder/decoder/layers.2/cross_attn/Slice_1_output_0 -> (1, 300, 1, 1, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Slice_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Mul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Add [Add] inputs: [/model/decoder/decoder/layers.2/cross_attn/Slice_1_output_0 -> (1, 300, 1, 1, 2)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/Mul_2_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Add for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Add [Add] outputs: [/model/decoder/decoder/layers.2/cross_attn/Add_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Reshape_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_output_0 -> (1, 8400, 8, 32)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Transpose for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.2/cross_attn/Transpose_output_0 -> (1, 8, 32, 8400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_4 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1749
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_4 [Reshape] inputs: [/model/decoder/decoder/layers.2/cross_attn/Transpose_output_0 -> (1, 8, 32, 8400)[FLOAT]], [_v_1749 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1095 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_4 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Reshape_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_4 [Reshape] outputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_4_output_0 -> (8, 32, 8400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Slice_4 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Slice_4 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Unsqueeze_1255
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Slice_4 [Slice] inputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_4_output_0 -> (8, 32, 8400)[FLOAT]], [onnx::Unsqueeze_1255 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0 -> (1)[INT64]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1096 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1097 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1099 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1100 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1102 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1103 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1105 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1106 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1107 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1109 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1110 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1111 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1113 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1114 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1116 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1117 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1118 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1119 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1121 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1122 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1123 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1124 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1126 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1127 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1128 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Slice_4 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Slice_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Slice_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Slice_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Slice_4 [Slice] outputs: [/model/decoder/decoder/layers.2/cross_attn/Slice_4_output_0 -> (8, 32, 6400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Slice_5 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Slice_5 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Slice_5 [Slice] inputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_4_output_0 -> (8, 32, 8400)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Unsqueeze_9_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Add_2_output_0 -> (1)[INT64]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1129 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1130 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1132 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1133 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1135 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1136 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1138 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1139 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1140 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1142 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1143 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1144 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1146 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1147 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1149 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1150 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1151 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1152 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1154 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1155 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1156 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1157 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1159 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1160 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1161 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Slice_5 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Slice_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Slice_5_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Slice_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Slice_5 [Slice] outputs: [/model/decoder/decoder/layers.2/cross_attn/Slice_5_output_0 -> (8, 32, 1600)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Slice_6 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Slice_6 [Slice]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Reshape_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Add_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Slice_6 [Slice] inputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_4_output_0 -> (8, 32, 8400)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Add_2_output_0 -> (1)[INT64]], [/model/decoder/decoder/layers.0/cross_attn/Add_3_output_0 -> (1)[INT64]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1162 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1163 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1165 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1166 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1168 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1169 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1171 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1172 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1173 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1175 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1176 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1177 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1179 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1180 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1182 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1183 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1184 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1185 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1187 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1188 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1189 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1190 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeTensorFromDims_1192 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeElementWise_1193 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1194 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Slice_6 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Slice_6
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Slice_6_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Slice_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Slice_6 [Slice] outputs: [/model/decoder/decoder/layers.2/cross_attn/Slice_6_output_0 -> (8, 32, 400)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Mul_3 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Mul_3 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Constant_39_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Mul_3 [Mul] inputs: [/model/decoder/decoder/layers.2/cross_attn/Add_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Constant_39_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1195 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1196 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Mul_3 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Mul_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Mul_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Mul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Mul_3 [Mul] outputs: [/model/decoder/decoder/layers.2/cross_attn/Mul_3_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Sub [Sub]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Sub [Sub]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Mul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Sub [Sub] inputs: [/model/decoder/decoder/layers.2/cross_attn/Mul_3_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_1_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1197 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1198 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Sub for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Sub
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Sub_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Sub_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Sub [Sub] outputs: [/model/decoder/decoder/layers.2/cross_attn/Sub_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Transpose_1 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Sub_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Transpose_1 [Transpose] inputs: [/model/decoder/decoder/layers.2/cross_attn/Sub_output_0 -> (1, 300, 8, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_1 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Transpose_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Transpose_1 [Transpose] outputs: [/model/decoder/decoder/layers.2/cross_attn/Transpose_1_output_0 -> (1, 8, 300, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_5 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_5 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Transpose_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: _v_1850
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_5 [Reshape] inputs: [/model/decoder/decoder/layers.2/cross_attn/Transpose_1_output_0 -> (1, 8, 300, 12, 2)[FLOAT]], [_v_1850 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1199 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_5 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Reshape_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_5_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_5 [Reshape] outputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_5_output_0 -> (8, 300, 12, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Split [Split]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Split [Split]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Reshape_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Split_2305
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Split [Split] inputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_5_output_0 -> (8, 300, 12, 2)[FLOAT]], [onnx::Split_2305 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1200 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Split for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Split
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1201 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Split_1202 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Split
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1203 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Split_1204 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Split
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Split_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Split_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Split_output_1 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Split_output_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Split_output_2 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Split_output_2
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Split [Split] outputs: [/model/decoder/decoder/layers.2/cross_attn/Split_output_0 -> (8, 300, 4, 2)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/Split_output_1 -> (8, 300, 4, 2)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/Split_output_2 -> (8, 300, 4, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_6 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_6 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Slice_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_6 [Reshape] inputs: [/model/decoder/decoder/layers.2/cross_attn/Slice_4_output_0 -> (8, 32, 6400)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_6_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1205 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_6 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Reshape_6
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_6_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_6 [Reshape] outputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_6_output_0 -> (8, 32, 80, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/GridSample [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/GridSample [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Reshape_6_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Split_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/GridSample [GridSample] inputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_6_output_0 -> (8, 32, 80, 80)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/Split_output_0 -> (8, 300, 4, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/GridSample for ONNX node: /model/decoder/decoder/layers.2/cross_attn/GridSample
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/GridSample_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/GridSample_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/GridSample [GridSample] outputs: [/model/decoder/decoder/layers.2/cross_attn/GridSample_output_0 -> (8, 32, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_7 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_7 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Slice_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_7 [Reshape] inputs: [/model/decoder/decoder/layers.2/cross_attn/Slice_5_output_0 -> (8, 32, 1600)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_7_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1206 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_7 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Reshape_7
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_7_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_7 [Reshape] outputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_7_output_0 -> (8, 32, 40, 40)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/GridSample_1 [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/GridSample_1 [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Reshape_7_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Split_output_1
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/GridSample_1 [GridSample] inputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_7_output_0 -> (8, 32, 40, 40)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/Split_output_1 -> (8, 300, 4, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/GridSample_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/GridSample_1_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/GridSample_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/GridSample_1 [GridSample] outputs: [/model/decoder/decoder/layers.2/cross_attn/GridSample_1_output_0 -> (8, 32, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_8 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_8 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Slice_6_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_8 [Reshape] inputs: [/model/decoder/decoder/layers.2/cross_attn/Slice_6_output_0 -> (8, 32, 400)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_8_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1207 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_8 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Reshape_8
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_8_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_8 [Reshape] outputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_8_output_0 -> (8, 32, 20, 20)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/GridSample_2 [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/GridSample_2 [GridSample]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Reshape_8_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Split_output_2
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/GridSample_2 [GridSample] inputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_8_output_0 -> (8, 32, 20, 20)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/Split_output_2 -> (8, 300, 4, 2)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_2 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/GridSample_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/GridSample_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/GridSample_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/GridSample_2 [GridSample] outputs: [/model/decoder/decoder/layers.2/cross_attn/GridSample_2_output_0 -> (8, 32, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Transpose_2 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Softmax_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Transpose_2 [Transpose] inputs: [/model/decoder/decoder/layers.2/cross_attn/Softmax_output_0 -> (1, 300, 8, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_2 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Transpose_2_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Transpose_2 [Transpose] outputs: [/model/decoder/decoder/layers.2/cross_attn/Transpose_2_output_0 -> (1, 8, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_9 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_9 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Transpose_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_9_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_9 [Reshape] inputs: [/model/decoder/decoder/layers.2/cross_attn/Transpose_2_output_0 -> (1, 8, 300, 12)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_9_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1208 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_9 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Reshape_9
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_9_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_9_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_9 [Reshape] outputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_9_output_0 -> (8, 1, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Concat_10 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Concat_10 [Concat]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/GridSample_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/GridSample_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/GridSample_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Concat_10 [Concat] inputs: [/model/decoder/decoder/layers.2/cross_attn/GridSample_output_0 -> (8, 32, 300, 4)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/GridSample_1_output_0 -> (8, 32, 300, 4)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/GridSample_2_output_0 -> (8, 32, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Concat_10 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Concat_10
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Concat_10_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Concat_10_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Concat_10 [Concat] outputs: [/model/decoder/decoder/layers.2/cross_attn/Concat_10_output_0 -> (8, 32, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Mul_5 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Mul_5 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Concat_10_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Reshape_9_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Mul_5 [Mul] inputs: [/model/decoder/decoder/layers.2/cross_attn/Concat_10_output_0 -> (8, 32, 300, 12)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/Reshape_9_output_0 -> (8, 1, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Mul_5 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Mul_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Mul_5_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Mul_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Mul_5 [Mul] outputs: [/model/decoder/decoder/layers.2/cross_attn/Mul_5_output_0 -> (8, 32, 300, 12)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/ReduceSum [ReduceSum]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/ReduceSum [ReduceSum]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Mul_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/ReduceSum [ReduceSum] inputs: [/model/decoder/decoder/layers.2/cross_attn/Mul_5_output_0 -> (8, 32, 300, 12)[FLOAT]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/ReduceSum for ONNX node: /model/decoder/decoder/layers.2/cross_attn/ReduceSum
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/ReduceSum_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/ReduceSum_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/ReduceSum [ReduceSum] outputs: [/model/decoder/decoder/layers.2/cross_attn/ReduceSum_output_0 -> (8, 32, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_10 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Reshape_10 [Reshape]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/ReduceSum_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.0/cross_attn/Concat_11_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_10 [Reshape] inputs: [/model/decoder/decoder/layers.2/cross_attn/ReduceSum_output_0 -> (8, 32, 300)[FLOAT]], [/model/decoder/decoder/layers.0/cross_attn/Concat_11_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1209 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_10 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Reshape_10
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_10_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Reshape_10_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Reshape_10 [Reshape] outputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_10_output_0 -> (1, 256, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/Transpose_3 [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Reshape_10_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Transpose_3 [Transpose] inputs: [/model/decoder/decoder/layers.2/cross_attn/Reshape_10_output_0 -> (1, 256, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_3 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/Transpose_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/Transpose_3 [Transpose] outputs: [/model/decoder/decoder/layers.2/cross_attn/Transpose_3_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/Transpose_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.2/cross_attn/Transpose_3_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1210 for ONNX node: tmp_weight_1210
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1211 for ONNX node: tmp_weight_1211
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.cross_attn.output_proj.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.2.cross_attn.output_proj.weight -> (256, 256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.cross_attn.output_proj.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1212 for ONNX node: tmp_weight_1212
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1213 for ONNX node: tmp_weight_1213
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose for ONNX node: /model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1214 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1215 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul for ONNX node: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.cross_attn.output_proj.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/Add [Add] inputs: [model.decoder.decoder.layers.2.cross_attn.output_proj.bias -> (256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.cross_attn.output_proj.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1216 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1217 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add for ONNX node: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/cross_attn/output_proj/Add [Add] outputs: [/model/decoder/decoder/layers.2/cross_attn/output_proj/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/Add_3 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/Add_3 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/norm1/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/Add_3 [Add] inputs: [/model/decoder/decoder/layers.2/norm1/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.2/cross_attn/output_proj/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/Add_3 for ONNX node: /model/decoder/decoder/layers.2/Add_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/Add_3_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/Add_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/Add_3 [Add] outputs: [/model/decoder/decoder/layers.2/Add_3_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/norm2/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/norm2/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/Add_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.norm2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.norm2.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/norm2/LayerNormalization [LayerNormalization] inputs: [/model/decoder/decoder/layers.2/Add_3_output_0 -> (1, 300, 256)[FLOAT]], [model.decoder.decoder.layers.2.norm2.weight -> (256)[FLOAT]], [model.decoder.decoder.layers.2.norm2.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.norm2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.norm2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1220 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1221 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1222 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1223 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/norm2/LayerNormalization for ONNX node: /model/decoder/decoder/layers.2/norm2/LayerNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/norm2/LayerNormalization_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/norm2/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/norm2/LayerNormalization [LayerNormalization] outputs: [/model/decoder/decoder/layers.2/norm2/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/norm2/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.2/norm2/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.2/linear1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.2/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1224 for ONNX node: tmp_weight_1224
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/layers.2/linear1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1225 for ONNX node: tmp_weight_1225
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.linear1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.2.linear1.weight -> (1024, 256)[FLOAT]], [/model/decoder/decoder/layers.2/linear1/weight_quantizer/Constant_1_output_0 -> (1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0 -> (1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.linear1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.2/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1226 for ONNX node: tmp_weight_1226
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.2/linear1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear1/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.2/linear1/weight_quantizer/QuantizeLinear_output_0 -> (1024, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.2/linear1/weight_quantizer/QuantizeLinear_output_0 -> (1024, 256)[INT8]], [/model/decoder/decoder/layers.2/linear1/weight_quantizer/Constant_1_output_0 -> (1024)[FLOAT]], [/model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_output_0 -> (1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1227 for ONNX node: tmp_weight_1227
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear1/Transpose for ONNX node: /model/decoder/decoder/layers.2/linear1/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear1/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.2/linear1/Transpose_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.2/linear1/Transpose_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1228 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1229 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear1/MatMul for ONNX node: /model/decoder/decoder/layers.2/linear1/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear1/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.2/linear1/MatMul_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.linear1.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/Add [Add] inputs: [model.decoder.decoder.layers.2.linear1.bias -> (1024)[FLOAT]], [/model/decoder/decoder/layers.2/linear1/MatMul_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.linear1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1230 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1231 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear1/Add for ONNX node: /model/decoder/decoder/layers.2/linear1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear1/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear1/Add [Add] outputs: [/model/decoder/decoder/layers.2/linear1/Add_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/activation/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/activation/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/activation/Relu [Relu] inputs: [/model/decoder/decoder/layers.2/linear1/Add_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/activation/Relu for ONNX node: /model/decoder/decoder/layers.2/activation/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/activation/Relu_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/activation/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/activation/Relu [Relu] outputs: [/model/decoder/decoder/layers.2/activation/Relu_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/activation/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.2/activation/Relu_output_0 -> (1, 300, 1024)[FLOAT]], [/model/decoder/decoder/layers.2/linear2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.2/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1232 for ONNX node: tmp_weight_1232
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 1024)[INT8]], [/model/decoder/decoder/layers.2/linear2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1233 for ONNX node: tmp_weight_1233
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.linear2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.decoder.layers.2.linear2.weight -> (256, 1024)[FLOAT]], [/model/decoder/decoder/layers.2/linear2/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.linear2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/layers.2/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1234 for ONNX node: tmp_weight_1234
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/layers.2/linear2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear2/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/layers.2/linear2/weight_quantizer/QuantizeLinear_output_0 -> (256, 1024)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/layers.2/linear2/weight_quantizer/QuantizeLinear_output_0 -> (256, 1024)[INT8]], [/model/decoder/decoder/layers.2/linear2/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1235 for ONNX node: tmp_weight_1235
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/Transpose [Transpose] inputs: [/model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear_output_0 -> (256, 1024)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear2/Transpose for ONNX node: /model/decoder/decoder/layers.2/linear2/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear2/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/Transpose [Transpose] outputs: [/model/decoder/decoder/layers.2/linear2/Transpose_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/MatMul [MatMul] inputs: [/model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 1024)[FLOAT]], [/model/decoder/decoder/layers.2/linear2/Transpose_output_0 -> (1024, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1236 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1237 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear2/MatMul for ONNX node: /model/decoder/decoder/layers.2/linear2/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear2/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/MatMul [MatMul] outputs: [/model/decoder/decoder/layers.2/linear2/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/linear2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/linear2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.linear2.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/Add [Add] inputs: [model.decoder.decoder.layers.2.linear2.bias -> (256)[FLOAT]], [/model/decoder/decoder/layers.2/linear2/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.linear2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1238 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1239 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/linear2/Add for ONNX node: /model/decoder/decoder/layers.2/linear2/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/linear2/Add_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/linear2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/linear2/Add [Add] outputs: [/model/decoder/decoder/layers.2/linear2/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/Add_4 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/Add_4 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/norm2/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/linear2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/Add_4 [Add] inputs: [/model/decoder/decoder/layers.2/norm2/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/layers.2/linear2/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/Add_4 for ONNX node: /model/decoder/decoder/layers.2/Add_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/Add_4_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/Add_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/Add_4 [Add] outputs: [/model/decoder/decoder/layers.2/Add_4_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/layers.2/norm3/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/layers.2/norm3/LayerNormalization [LayerNormalization]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/Add_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.norm3.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.decoder.layers.2.norm3.bias
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/norm3/LayerNormalization [LayerNormalization] inputs: [/model/decoder/decoder/layers.2/Add_4_output_0 -> (1, 300, 256)[FLOAT]], [model.decoder.decoder.layers.2.norm3.weight -> (256)[FLOAT]], [model.decoder.decoder.layers.2.norm3.bias -> (256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.norm3.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.decoder.layers.2.norm3.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1242 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1243 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1244 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1245 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/layers.2/norm3/LayerNormalization for ONNX node: /model/decoder/decoder/layers.2/norm3/LayerNormalization
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/layers.2/norm3/LayerNormalization_output_0 for ONNX tensor: /model/decoder/decoder/layers.2/norm3/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/norm3/LayerNormalization [LayerNormalization] outputs: [/model/decoder/decoder/layers.2/norm3/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/layers.2/norm3/LayerNormalization_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/layers.2/norm3/LayerNormalization_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1246 for ONNX node: tmp_weight_1246
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1247 for ONNX node: tmp_weight_1247
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.2.layers.0.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.dec_bbox_head.2.layers.0.weight -> (256, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.2.layers.0.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1248 for ONNX node: tmp_weight_1248
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1249 for ONNX node: tmp_weight_1249
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose [Transpose] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose [Transpose] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul [MatMul] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1250 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1251 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul [MatMul] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.2.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/Add [Add] inputs: [model.decoder.dec_bbox_head.2.layers.0.bias -> (256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.2.layers.0.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1252 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1253 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.0/Add [Add] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/act/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/act/Relu [Relu] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/act/Relu for ONNX node: /model/decoder/decoder/dec_bbox_head.2/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/act/Relu_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/act/Relu [Relu] outputs: [/model/decoder/decoder/dec_bbox_head.2/act/Relu_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/act/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.2/act/Relu_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1254 for ONNX node: tmp_weight_1254
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1255 for ONNX node: tmp_weight_1255
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.2.layers.1.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.dec_bbox_head.2.layers.1.weight -> (256, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.2.layers.1.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1256 for ONNX node: tmp_weight_1256
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/QuantizeLinear_output_0 -> (256, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/Constant_1_output_0 -> (256)[FLOAT]], [/model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_output_0 -> (256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1257 for ONNX node: tmp_weight_1257
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose [Transpose] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose [Transpose] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul [MatMul] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose_output_0 -> (256, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1258 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1259 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul [MatMul] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.2.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/Add [Add] inputs: [model.decoder.dec_bbox_head.2.layers.1.bias -> (256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.2.layers.1.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1260 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1261 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.1/Add [Add] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu [Relu]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/act_1/Relu [Relu] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.1/Add_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu for ONNX node: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/act_1/Relu [Relu] outputs: [/model/decoder/decoder/dec_bbox_head.2/act_1/Relu_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.2/act_1/Relu_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1262 for ONNX node: tmp_weight_1262
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear_output_0 -> (1, 300, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/Constant_1_output_0 -> ()[FLOAT]], [/model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_output_0 -> ()[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1263 for ONNX node: tmp_weight_1263
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.2.layers.2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.dec_bbox_head.2.layers.2.weight -> (4, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/Constant_1_output_0 -> (4)[FLOAT]], [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0 -> (4)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.2.layers.2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1264 for ONNX node: tmp_weight_1264
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/QuantizeLinear_output_0 -> (4, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/QuantizeLinear_output_0 -> (4, 256)[INT8]], [/model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/Constant_1_output_0 -> (4)[FLOAT]], [/model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_output_0 -> (4)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1265 for ONNX node: tmp_weight_1265
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear_output_0 -> (4, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose [Transpose] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear_output_0 -> (4, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose [Transpose] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose_output_0 -> (256, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul [MatMul] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose_output_0 -> (256, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1266 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1267 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul [MatMul] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_bbox_head.2.layers.2.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/Add [Add] inputs: [model.decoder.dec_bbox_head.2.layers.2.bias -> (4)[FLOAT]], [/model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_bbox_head.2.layers.2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1268 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1269 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add for ONNX node: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add_output_0 for ONNX tensor: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_bbox_head.2/layers.2/Add [Add] outputs: [/model/decoder/decoder/dec_bbox_head.2/layers.2/Add_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Clip_6 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Clip_6 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sigmoid_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_6 [Clip] inputs: [/model/decoder/decoder/Sigmoid_2_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Constant_1_output_0 -> ()[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_1_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Clip_6 for ONNX node: /model/decoder/decoder/Clip_6
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Clip_6_output_0 for ONNX tensor: /model/decoder/decoder/Clip_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_6 [Clip] outputs: [/model/decoder/decoder/Clip_6_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Clip_7 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Clip_7 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Clip_6_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_7 [Clip] inputs: [/model/decoder/decoder/Clip_6_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Constant_3_output_0 -> ()[FLOAT]], [optional input, not set], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1271 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1272 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1273 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1274 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Clip_7_output_0 for ONNX tensor: /model/decoder/decoder/Clip_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_7 [Clip] outputs: [/model/decoder/decoder/Clip_7_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Sub_2 [Sub]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Sub_2 [Sub]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Clip_6_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sub_2 [Sub] inputs: [/model/encoder/encoder.0/layers.0/activation/Constant_1_output_0 -> ()[FLOAT]], [/model/decoder/decoder/Clip_6_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1275 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1276 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Sub_2 for ONNX node: /model/decoder/decoder/Sub_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Sub_2_output_0 for ONNX tensor: /model/decoder/decoder/Sub_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sub_2 [Sub] outputs: [/model/decoder/decoder/Sub_2_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Clip_8 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Clip_8 [Clip]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sub_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Constant_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_8 [Clip] inputs: [/model/decoder/decoder/Sub_2_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Constant_3_output_0 -> ()[FLOAT]], [optional input, not set], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1278 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1279 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1280 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1281 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Clip_8_output_0 for ONNX tensor: /model/decoder/decoder/Clip_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Clip_8 [Clip] outputs: [/model/decoder/decoder/Clip_8_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Div_2 [Div]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Div_2 [Div]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Clip_7_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Clip_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Div_2 [Div] inputs: [/model/decoder/decoder/Clip_7_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Clip_8_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Div_2 for ONNX node: /model/decoder/decoder/Div_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Div_2_output_0 for ONNX tensor: /model/decoder/decoder/Div_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Div_2 [Div] outputs: [/model/decoder/decoder/Div_2_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Log_2 [Log]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Log_2 [Log]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Div_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Log_2 [Log] inputs: [/model/decoder/decoder/Div_2_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Log_2 for ONNX node: /model/decoder/decoder/Log_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Log_2_output_0 for ONNX tensor: /model/decoder/decoder/Log_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Log_2 [Log] outputs: [/model/decoder/decoder/Log_2_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Add_2 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Log_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Add_2 [Add] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.2/Add_output_0 -> (1, 300, 4)[FLOAT]], [/model/decoder/decoder/Log_2_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Add_2 for ONNX node: /model/decoder/decoder/Add_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Add_2_output_0 for ONNX tensor: /model/decoder/decoder/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Add_2 [Add] outputs: [/model/decoder/decoder/Add_2_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Sigmoid_3 [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Sigmoid_3 [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Add_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sigmoid_3 [Sigmoid] inputs: [/model/decoder/decoder/Add_2_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Sigmoid_3 for ONNX node: /model/decoder/decoder/Sigmoid_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Sigmoid_3_output_0 for ONNX tensor: /model/decoder/decoder/Sigmoid_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Sigmoid_3 [Sigmoid] outputs: [/model/decoder/decoder/Sigmoid_3_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_score_head.2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_score_head.2/weight_quantizer/QuantizeLinear [QuantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_score_head.2.weight
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_score_head.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_score_head.2/weight_quantizer/QuantizeLinear [QuantizeLinear] inputs: [model.decoder.dec_score_head.2.weight -> (80, 256)[FLOAT]], [/model/decoder/decoder/dec_score_head.2/weight_quantizer/Constant_1_output_0 -> (80)[FLOAT]], [/model/decoder/enc_score_head/weight_quantizer/Constant_output_0 -> (80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_score_head.2.weight required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/Constant_1_output_0 for ONNX node: /model/decoder/decoder/dec_score_head.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1282 for ONNX node: tmp_weight_1282
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/QuantizeLinear for ONNX node: /model/decoder/decoder/dec_score_head.2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_score_head.2/weight_quantizer/QuantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_score_head.2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_score_head.2/weight_quantizer/QuantizeLinear [QuantizeLinear] outputs: [/model/decoder/decoder/dec_score_head.2/weight_quantizer/QuantizeLinear_output_0 -> (80, 256)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear [DequantizeLinear]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_score_head.2/weight_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_score_head.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/enc_score_head/weight_quantizer/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear [DequantizeLinear] inputs: [/model/decoder/decoder/dec_score_head.2/weight_quantizer/QuantizeLinear_output_0 -> (80, 256)[INT8]], [/model/decoder/decoder/dec_score_head.2/weight_quantizer/Constant_1_output_0 -> (80)[FLOAT]], [/model/decoder/enc_score_head/weight_quantizer/Constant_output_0 -> (80)[INT8]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: tmp_weight_1283 for ONNX node: tmp_weight_1283
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear for ONNX node: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear_output_0 for ONNX tensor: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear [DequantizeLinear] outputs: [/model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear_output_0 -> (80, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_score_head.2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_score_head.2/Transpose [Transpose]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_score_head.2/Transpose [Transpose] inputs: [/model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear_output_0 -> (80, 256)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_score_head.2/Transpose for ONNX node: /model/decoder/decoder/dec_score_head.2/Transpose
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_score_head.2/Transpose_output_0 for ONNX tensor: /model/decoder/decoder/dec_score_head.2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_score_head.2/Transpose [Transpose] outputs: [/model/decoder/decoder/dec_score_head.2/Transpose_output_0 -> (256, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_score_head.2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_score_head.2/MatMul [MatMul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_score_head.2/Transpose_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_score_head.2/MatMul [MatMul] inputs: [/model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear_output_0 -> (1, 300, 256)[FLOAT]], [/model/decoder/decoder/dec_score_head.2/Transpose_output_0 -> (256, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1284 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1285 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_score_head.2/MatMul for ONNX node: /model/decoder/decoder/dec_score_head.2/MatMul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_score_head.2/MatMul_output_0 for ONNX tensor: /model/decoder/decoder/dec_score_head.2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_score_head.2/MatMul [MatMul] outputs: [/model/decoder/decoder/dec_score_head.2/MatMul_output_0 -> (1, 300, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/dec_score_head.2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/dec_score_head.2/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: model.decoder.dec_score_head.2.bias
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_score_head.2/MatMul_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_score_head.2/Add [Add] inputs: [model.decoder.dec_score_head.2.bias -> (80)[FLOAT]], [/model/decoder/decoder/dec_score_head.2/MatMul_output_0 -> (1, 300, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: model.decoder.dec_score_head.2.bias required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1286 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1287 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/dec_score_head.2/Add for ONNX node: /model/decoder/decoder/dec_score_head.2/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/dec_score_head.2/Add_output_0 for ONNX tensor: /model/decoder/decoder/dec_score_head.2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/dec_score_head.2/Add [Add] outputs: [/model/decoder/decoder/dec_score_head.2/Add_output_0 -> (1, 300, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Unsqueeze_3 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Unsqueeze_3 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Sigmoid_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Unsqueeze_1255
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Unsqueeze_3 [Unsqueeze] inputs: [/model/decoder/decoder/Sigmoid_3_output_0 -> (1, 300, 4)[FLOAT]], [onnx::Unsqueeze_1255 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Unsqueeze_3 for ONNX node: /model/decoder/decoder/Unsqueeze_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Unsqueeze_3_output_0 for ONNX tensor: /model/decoder/decoder/Unsqueeze_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Unsqueeze_3 [Unsqueeze] outputs: [/model/decoder/decoder/Unsqueeze_3_output_0 -> (1, 1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/decoder/Unsqueeze_4 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/decoder/Unsqueeze_4 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/dec_score_head.2/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Unsqueeze_1255
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Unsqueeze_4 [Unsqueeze] inputs: [/model/decoder/decoder/dec_score_head.2/Add_output_0 -> (1, 300, 80)[FLOAT]], [onnx::Unsqueeze_1255 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/decoder/Unsqueeze_4 for ONNX node: /model/decoder/decoder/Unsqueeze_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/decoder/Unsqueeze_4_output_0 for ONNX tensor: /model/decoder/decoder/Unsqueeze_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/Unsqueeze_4 [Unsqueeze] outputs: [/model/decoder/decoder/Unsqueeze_4_output_0 -> (1, 1, 300, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Gather_8 [Gather]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Gather_8 [Gather]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Unsqueeze_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Gather_8 [Gather] inputs: [/model/decoder/decoder/Unsqueeze_4_output_0 -> (1, 1, 300, 80)[FLOAT]], [/model/encoder/Constant_2_output_0 -> ()[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/encoder/Constant_2_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Using Gather axis: 0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1288 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Gather_8 for ONNX node: /model/decoder/Gather_8
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Gather_8_output_0 for ONNX tensor: /model/decoder/Gather_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Gather_8 [Gather] outputs: [/model/decoder/Gather_8_output_0 -> (1, 300, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /model/decoder/Gather_9 [Gather]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /model/decoder/Gather_9 [Gather]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/decoder/Unsqueeze_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Gather_9 [Gather] inputs: [/model/decoder/decoder/Unsqueeze_3_output_0 -> (1, 1, 300, 4)[FLOAT]], [/model/encoder/Constant_2_output_0 -> ()[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Using Gather axis: 0
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1289 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Gather_9 for ONNX node: /model/decoder/Gather_9
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /model/decoder/Gather_9_output_0 for ONNX tensor: /model/decoder/Gather_9_output_0
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/Gather_9 [Gather] outputs: [/model/decoder/Gather_9_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Split [Split]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Split [Split]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Gather_9_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Split [Split] inputs: [/model/decoder/Gather_9_output_0 -> (1, 300, 4)[FLOAT]], [/postprocessor/Constant_output_0 -> (4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1290 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Split for ONNX node: /postprocessor/Split
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1291 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Split_1292 for ONNX node: /postprocessor/Split
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1293 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Split_1294 for ONNX node: /postprocessor/Split
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1295 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Split_1296 for ONNX node: /postprocessor/Split
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Split_output_0 for ONNX tensor: /postprocessor/Split_output_0
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Split_output_1 for ONNX tensor: /postprocessor/Split_output_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Split_output_2 for ONNX tensor: /postprocessor/Split_output_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Split_output_3 for ONNX tensor: /postprocessor/Split_output_3
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Split [Split] outputs: [/postprocessor/Split_output_0 -> (1, 300, 1)[FLOAT]], [/postprocessor/Split_output_1 -> (1, 300, 1)[FLOAT]], [/postprocessor/Split_output_2 -> (1, 300, 1)[FLOAT]], [/postprocessor/Split_output_3 -> (1, 300, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Squeeze [Squeeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Squeeze [Squeeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Split_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Squeeze [Squeeze] inputs: [/postprocessor/Split_output_0 -> (1, 300, 1)[FLOAT]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Squeeze for ONNX node: /postprocessor/Squeeze
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Squeeze_output_0 for ONNX tensor: /postprocessor/Squeeze_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Squeeze [Squeeze] outputs: [/postprocessor/Squeeze_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Squeeze_1 [Squeeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Squeeze_1 [Squeeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Split_output_1
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Squeeze_1 [Squeeze] inputs: [/postprocessor/Split_output_1 -> (1, 300, 1)[FLOAT]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Squeeze_1 for ONNX node: /postprocessor/Squeeze_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Squeeze_1_output_0 for ONNX tensor: /postprocessor/Squeeze_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Squeeze_1 [Squeeze] outputs: [/postprocessor/Squeeze_1_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Squeeze_2 [Squeeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Squeeze_2 [Squeeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Split_output_2
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Squeeze_2 [Squeeze] inputs: [/postprocessor/Split_output_2 -> (1, 300, 1)[FLOAT]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Squeeze_2 for ONNX node: /postprocessor/Squeeze_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Squeeze_2_output_0 for ONNX tensor: /postprocessor/Squeeze_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Squeeze_2 [Squeeze] outputs: [/postprocessor/Squeeze_2_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Squeeze_3 [Squeeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Squeeze_3 [Squeeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Split_output_3
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Squeeze_3 [Squeeze] inputs: [/postprocessor/Split_output_3 -> (1, 300, 1)[FLOAT]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Squeeze_3 for ONNX node: /postprocessor/Squeeze_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Squeeze_3_output_0 for ONNX tensor: /postprocessor/Squeeze_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Squeeze_3 [Squeeze] outputs: [/postprocessor/Squeeze_3_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Mul [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Squeeze_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Mul [Mul] inputs: [/postprocessor/Squeeze_2_output_0 -> (1, 300)[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_2_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1297 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1298 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Mul for ONNX node: /postprocessor/Mul
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Mul_output_0 for ONNX tensor: /postprocessor/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Mul [Mul] outputs: [/postprocessor/Mul_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Sub [Sub]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Sub [Sub]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Squeeze_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Sub [Sub] inputs: [/postprocessor/Squeeze_output_0 -> (1, 300)[FLOAT]], [/postprocessor/Mul_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Sub for ONNX node: /postprocessor/Sub
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Sub_output_0 for ONNX tensor: /postprocessor/Sub_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Sub [Sub] outputs: [/postprocessor/Sub_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Mul_1 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Squeeze_3_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/encoder.0/layers.0/activation/Constant_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Mul_1 [Mul] inputs: [/postprocessor/Squeeze_3_output_0 -> (1, 300)[FLOAT]], [/model/encoder/encoder.0/layers.0/activation/Constant_2_output_0 -> ()[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1299 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1300 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Mul_1 for ONNX node: /postprocessor/Mul_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Mul_1_output_0 for ONNX tensor: /postprocessor/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Mul_1 [Mul] outputs: [/postprocessor/Mul_1_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Sub_1 [Sub]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Sub_1 [Sub]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Squeeze_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Sub_1 [Sub] inputs: [/postprocessor/Squeeze_1_output_0 -> (1, 300)[FLOAT]], [/postprocessor/Mul_1_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Sub_1 for ONNX node: /postprocessor/Sub_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Sub_1_output_0 for ONNX tensor: /postprocessor/Sub_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Sub_1 [Sub] outputs: [/postprocessor/Sub_1_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Add [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Squeeze_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Mul_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Add [Add] inputs: [/postprocessor/Squeeze_output_0 -> (1, 300)[FLOAT]], [/postprocessor/Mul_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Add for ONNX node: /postprocessor/Add
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Add_output_0 for ONNX tensor: /postprocessor/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Add [Add] outputs: [/postprocessor/Add_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Add_1 [Add]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Squeeze_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Mul_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Add_1 [Add] inputs: [/postprocessor/Squeeze_1_output_0 -> (1, 300)[FLOAT]], [/postprocessor/Mul_1_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Add_1 for ONNX node: /postprocessor/Add_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Add_1_output_0 for ONNX tensor: /postprocessor/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Add_1 [Add] outputs: [/postprocessor/Add_1_output_0 -> (1, 300)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Unsqueeze [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Unsqueeze [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Sub_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Unsqueeze [Unsqueeze] inputs: [/postprocessor/Sub_output_0 -> (1, 300)[FLOAT]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Unsqueeze for ONNX node: /postprocessor/Unsqueeze
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Unsqueeze_output_0 for ONNX tensor: /postprocessor/Unsqueeze_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Unsqueeze [Unsqueeze] outputs: [/postprocessor/Unsqueeze_output_0 -> (1, 300, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Unsqueeze_1 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Unsqueeze_1 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Sub_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Unsqueeze_1 [Unsqueeze] inputs: [/postprocessor/Sub_1_output_0 -> (1, 300)[FLOAT]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Unsqueeze_1 for ONNX node: /postprocessor/Unsqueeze_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Unsqueeze_1_output_0 for ONNX tensor: /postprocessor/Unsqueeze_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Unsqueeze_1 [Unsqueeze] outputs: [/postprocessor/Unsqueeze_1_output_0 -> (1, 300, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Unsqueeze_2 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Unsqueeze_2 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Add_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Unsqueeze_2 [Unsqueeze] inputs: [/postprocessor/Add_output_0 -> (1, 300)[FLOAT]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Unsqueeze_2 for ONNX node: /postprocessor/Unsqueeze_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Unsqueeze_2_output_0 for ONNX tensor: /postprocessor/Unsqueeze_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Unsqueeze_2 [Unsqueeze] outputs: [/postprocessor/Unsqueeze_2_output_0 -> (1, 300, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Unsqueeze_3 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Unsqueeze_3 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Add_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Unsqueeze_3 [Unsqueeze] inputs: [/postprocessor/Add_1_output_0 -> (1, 300)[FLOAT]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Unsqueeze_3 for ONNX node: /postprocessor/Unsqueeze_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Unsqueeze_3_output_0 for ONNX tensor: /postprocessor/Unsqueeze_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Unsqueeze_3 [Unsqueeze] outputs: [/postprocessor/Unsqueeze_3_output_0 -> (1, 300, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Concat [Concat]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Concat [Concat]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Unsqueeze_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Unsqueeze_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Unsqueeze_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Unsqueeze_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Concat [Concat] inputs: [/postprocessor/Unsqueeze_output_0 -> (1, 300, 1)[FLOAT]], [/postprocessor/Unsqueeze_1_output_0 -> (1, 300, 1)[FLOAT]], [/postprocessor/Unsqueeze_2_output_0 -> (1, 300, 1)[FLOAT]], [/postprocessor/Unsqueeze_3_output_0 -> (1, 300, 1)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Concat for ONNX node: /postprocessor/Concat
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Concat_output_0 for ONNX tensor: /postprocessor/Concat_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Concat [Concat] outputs: [/postprocessor/Concat_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Tile [Tile]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Tile [Tile]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: orig_target_sizes
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Tile_3498
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Tile [Tile] inputs: [orig_target_sizes -> (1, 2)[INT64]], [onnx::Tile_3498 -> (2)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1301 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Tile for ONNX node: /postprocessor/Tile
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Tile_output_0 for ONNX tensor: /postprocessor/Tile_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Tile [Tile] outputs: [/postprocessor/Tile_output_0 -> (1, 4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Unsqueeze_4 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Unsqueeze_4 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Tile_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Constant_21_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Unsqueeze_4 [Unsqueeze] inputs: [/postprocessor/Tile_output_0 -> (1, 4)[INT64]], [/model/decoder/Constant_21_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /model/decoder/Constant_21_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Unsqueeze_4 for ONNX node: /postprocessor/Unsqueeze_4
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Unsqueeze_4_output_0 for ONNX tensor: /postprocessor/Unsqueeze_4_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Unsqueeze_4 [Unsqueeze] outputs: [/postprocessor/Unsqueeze_4_output_0 -> (1, 1, 4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: Cast_3039 [Cast]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: Cast_3039 [Cast]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Unsqueeze_4_output_0
[05/21/2025-09:28:09] [V] [TRT] Cast_3039 [Cast] inputs: [/postprocessor/Unsqueeze_4_output_0 -> (1, 1, 4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Casting to type: float32
[05/21/2025-09:28:09] [V] [TRT] Registering layer: Cast_3039 for ONNX node: Cast_3039
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: onnx::Mul_3505 for ONNX tensor: onnx::Mul_3505
[05/21/2025-09:28:09] [V] [TRT] Cast_3039 [Cast] outputs: [onnx::Mul_3505 -> (1, 1, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Mul_2 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Mul_2 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Concat_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: onnx::Mul_3505
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Mul_2 [Mul] inputs: [/postprocessor/Concat_output_0 -> (1, 300, 4)[FLOAT]], [onnx::Mul_3505 -> (1, 1, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Mul_2 for ONNX node: /postprocessor/Mul_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Mul_2_output_0 for ONNX tensor: /postprocessor/Mul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Mul_2 [Mul] outputs: [/postprocessor/Mul_2_output_0 -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Sigmoid [Sigmoid]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Gather_8_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Sigmoid [Sigmoid] inputs: [/model/decoder/Gather_8_output_0 -> (1, 300, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Sigmoid for ONNX node: /postprocessor/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Sigmoid_output_0 for ONNX tensor: /postprocessor/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Sigmoid [Sigmoid] outputs: [/postprocessor/Sigmoid_output_0 -> (1, 300, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Flatten [Flatten]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Flatten [Flatten]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Sigmoid_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Flatten [Flatten] inputs: [/postprocessor/Sigmoid_output_0 -> (1, 300, 80)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1302 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Flatten for ONNX node: /postprocessor/Flatten
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Flatten_output_0 for ONNX tensor: /postprocessor/Flatten_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Flatten [Flatten] outputs: [/postprocessor/Flatten_output_0 -> (1, 24000)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/TopK [TopK]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/TopK [TopK]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Flatten_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Constant_18_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/TopK [TopK] inputs: [/postprocessor/Flatten_output_0 -> (1, 24000)[FLOAT]], [/model/decoder/Constant_18_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_convertToScalar_1303 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/TopK for ONNX node: /postprocessor/TopK
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1304 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: scores_1305 for ONNX tensor: scores
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/TopK_output_1 for ONNX tensor: /postprocessor/TopK_output_1
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/TopK [TopK] outputs: [scores -> (1, 300)[FLOAT]], [/postprocessor/TopK_output_1 -> (1, 300)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Div [Div]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Div [Div]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/TopK_output_1
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Constant_14_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Div [Div] inputs: [/postprocessor/TopK_output_1 -> (1, 300)[INT64]], [/postprocessor/Constant_14_output_0 -> ()[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Constant_14_output_0 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1306 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1307 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Div for ONNX node: /postprocessor/Div
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Div_output_0 for ONNX tensor: /postprocessor/Div_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Div [Div] outputs: [/postprocessor/Div_output_0 -> (1, 300)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Mul_3 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Mul_3 [Mul]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Div_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Constant_14_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Mul_3 [Mul] inputs: [/postprocessor/Div_output_0 -> (1, 300)[INT64]], [/postprocessor/Constant_14_output_0 -> ()[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeShuffle_1308 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_Broadcast_1309 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Mul_3 for ONNX node: /postprocessor/Mul_3
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Mul_3_output_0 for ONNX tensor: /postprocessor/Mul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Mul_3 [Mul] outputs: [/postprocessor/Mul_3_output_0 -> (1, 300)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Sub_2 [Sub]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Sub_2 [Sub]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/TopK_output_1
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Mul_3_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Sub_2 [Sub] inputs: [/postprocessor/TopK_output_1 -> (1, 300)[INT64]], [/postprocessor/Mul_3_output_0 -> (1, 300)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Sub_2 for ONNX node: /postprocessor/Sub_2
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: labels_1310 for ONNX tensor: labels
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Sub_2 [Sub] outputs: [labels -> (1, 300)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Unsqueeze_5 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Unsqueeze_5 [Unsqueeze]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Div_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/encoder/Constant_7_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Unsqueeze_5 [Unsqueeze] inputs: [/postprocessor/Div_output_0 -> (1, 300)[INT64]], [/model/encoder/Constant_7_output_0 -> (1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Unsqueeze_5 for ONNX node: /postprocessor/Unsqueeze_5
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Unsqueeze_5_output_0 for ONNX tensor: /postprocessor/Unsqueeze_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Unsqueeze_5 [Unsqueeze] outputs: [/postprocessor/Unsqueeze_5_output_0 -> (1, 300, 1)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/Tile_1 [Tile]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/Tile_1 [Tile]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Unsqueeze_5_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /model/decoder/Concat_5_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Tile_1 [Tile] inputs: [/postprocessor/Unsqueeze_5_output_0 -> (1, 300, 1)[INT64]], [/model/decoder/Concat_5_output_0 -> (3)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_ShapeSlice_1311 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/Tile_1 for ONNX node: /postprocessor/Tile_1
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: /postprocessor/Tile_1_output_0 for ONNX tensor: /postprocessor/Tile_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/Tile_1 [Tile] outputs: [/postprocessor/Tile_1_output_0 -> (1, 300, 4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Static check for parsing node: /postprocessor/GatherElements [GatherElements]
[05/21/2025-09:28:09] [V] [TRT] Parsing node: /postprocessor/GatherElements [GatherElements]
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Mul_2_output_0
[05/21/2025-09:28:09] [V] [TRT] Searching for input: /postprocessor/Tile_1_output_0
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/GatherElements [GatherElements] inputs: [/postprocessor/Mul_2_output_0 -> (1, 300, 4)[FLOAT]], [/postprocessor/Tile_1_output_0 -> (1, 300, 4)[INT64]], 
[05/21/2025-09:28:09] [V] [TRT] Using Gather axis: 1
[05/21/2025-09:28:09] [V] [TRT] Registering layer: ONNXTRT_castHelper_1312 required by ONNX-TRT
[05/21/2025-09:28:09] [V] [TRT] Registering layer: /postprocessor/GatherElements for ONNX node: /postprocessor/GatherElements
[05/21/2025-09:28:09] [V] [TRT] Registering tensor: boxes_1313 for ONNX tensor: boxes
[05/21/2025-09:28:09] [V] [TRT] /postprocessor/GatherElements [GatherElements] outputs: [boxes -> (1, 300, 4)[FLOAT]], 
[05/21/2025-09:28:09] [V] [TRT] Marking labels_1310 as output: labels
[05/21/2025-09:28:09] [W] [TRT] ModelImporter.cpp:804: Make sure output labels has Int64 binding.
[05/21/2025-09:28:09] [V] [TRT] Marking boxes_1313 as output: boxes
[05/21/2025-09:28:09] [V] [TRT] Marking scores_1305 as output: scores
[05/21/2025-09:28:09] [I] Finished parsing network model. Parse time: 0.145987
[05/21/2025-09:28:09] [V] [TRT] Trying to set exclusive file lock ./timing.cache.lock

[05/21/2025-09:28:09] [I] [TRT] Loaded 12228577 bytes of timing cache from ./timing.cache
[05/21/2025-09:28:09] [V] [TRT] Loaded 938 timing cache entries.
[05/21/2025-09:28:09] [V] [TRT] Loaded 13084 bytes of code generator cache.
[05/21/2025-09:28:09] [V] [TRT] Loaded 12117773 bytes of compilation cache.
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul_2: broadcasting input1 to make tensors conform, dims(input0)=[400,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul: broadcasting input1 to make tensors conform, dims(input0)=[400,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] /model/encoder/encoder.0/layers.0/self_attn/MatMul_1: broadcasting input1 to make tensors conform, dims(input0)=[400,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul_2: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.0/self_attn/MatMul_1: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul_2: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.1/self_attn/MatMul_1: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul_2: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [V] [TRT] /model/decoder/decoder/layers.2/self_attn/MatMul_1: broadcasting input1 to make tensors conform, dims(input0)=[300,1,256][NONE] dims(input1)=[1,256,256][NONE].
[05/21/2025-09:28:09] [W] [TRT] Calibrator won't be used in explicit quantization mode. Please insert Quantize/Dequantize layers to indicate which tensors to quantize/dequantize.
[05/21/2025-09:28:09] [V] [TRT] Original: 1920 layers
[05/21/2025-09:28:09] [V] [TRT] After dead-layer removal: 1920 layers
[05/21/2025-09:28:09] [V] [TRT] Graph construction completed in 0.0212407 seconds.
[05/21/2025-09:28:09] [V] [TRT] After adding DebugOutput nodes: 1920 layers
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_3619
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_3619 with ONNXTRT_Broadcast
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::Add_3614
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::Add_3614 with ONNXTRT_Broadcast_99
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_3620
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_3620 with ONNXTRT_Broadcast_101
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::Add_3616
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::Add_3616 with ONNXTRT_Broadcast_103
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_3621
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_3621 with ONNXTRT_Broadcast_105
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::Add_3618
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::Add_3618 with ONNXTRT_Broadcast_107
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.encoder.encoder.0.layers.0.self_attn.out_proj.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.encoder.encoder.0.layers.0.self_attn.out_proj.bias with ONNXTRT_Broadcast_116
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.encoder.encoder.0.layers.0.norm1.weight
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.encoder.encoder.0.layers.0.norm1.weight with ONNXTRT_Broadcast_121
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.encoder.encoder.0.layers.0.norm1.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.encoder.encoder.0.layers.0.norm1.bias with ONNXTRT_Broadcast_123
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.encoder.encoder.0.layers.0.linear1.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.encoder.encoder.0.layers.0.linear1.bias with ONNXTRT_Broadcast_131
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on /model/encoder/encoder.0/layers.0/activation/Constant_output_0
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing /model/encoder/encoder.0/layers.0/activation/Constant_output_0 with ONNXTRT_Broadcast_133
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.encoder.encoder.0.layers.0.linear2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.encoder.encoder.0.layers.0.linear2.bias with ONNXTRT_Broadcast_145
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.encoder.encoder.0.layers.0.norm2.weight
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.encoder.encoder.0.layers.0.norm2.weight with ONNXTRT_Broadcast_149
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.encoder.encoder.0.layers.0.norm2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.encoder.encoder.0.layers.0.norm2.bias with ONNXTRT_Broadcast_151
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.enc_output.proj.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.enc_output.proj.bias with ONNXTRT_Broadcast_275
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.enc_output.norm.weight
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.enc_output.norm.weight with ONNXTRT_Broadcast_279
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.enc_output.norm.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.enc_output.norm.bias with ONNXTRT_Broadcast_281
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.enc_score_head.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.enc_score_head.bias with ONNXTRT_Broadcast_289
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.enc_bbox_head.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.enc_bbox_head.layers.0.bias with ONNXTRT_Broadcast_295
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.enc_bbox_head.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.enc_bbox_head.layers.1.bias with ONNXTRT_Broadcast_303
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.enc_bbox_head.layers.2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.enc_bbox_head.layers.2.bias with ONNXTRT_Broadcast_311
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_3736
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_3736 with ONNXTRT_Broadcast_332
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::Add_3731
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::Add_3731 with ONNXTRT_Broadcast_334
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_3737
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_3737 with ONNXTRT_Broadcast_336
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::Add_3733
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::Add_3733 with ONNXTRT_Broadcast_338
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_3738
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_3738 with ONNXTRT_Broadcast_340
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::Add_3735
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::Add_3735 with ONNXTRT_Broadcast_342
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.self_attn.out_proj.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.self_attn.out_proj.bias with ONNXTRT_Broadcast_351
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.norm1.weight
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.norm1.weight with ONNXTRT_Broadcast_356
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.norm1.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.norm1.bias with ONNXTRT_Broadcast_358
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.cross_attn.value_proj.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.cross_attn.value_proj.bias with ONNXTRT_Broadcast_366
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.cross_attn.sampling_offsets.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.cross_attn.sampling_offsets.bias with ONNXTRT_Broadcast_375
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.cross_attn.attention_weights.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.cross_attn.attention_weights.bias with ONNXTRT_Broadcast_382
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.cross_attn.output_proj.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.cross_attn.output_proj.bias with ONNXTRT_Broadcast_575
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.norm2.weight
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.norm2.weight with ONNXTRT_Broadcast_579
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.norm2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.norm2.bias with ONNXTRT_Broadcast_581
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.linear1.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.linear1.bias with ONNXTRT_Broadcast_589
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.linear2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.linear2.bias with ONNXTRT_Broadcast_597
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.norm3.weight
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.norm3.weight with ONNXTRT_Broadcast_601
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.0.norm3.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.0.norm3.bias with ONNXTRT_Broadcast_603
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.dec_bbox_head.0.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.dec_bbox_head.0.layers.0.bias with ONNXTRT_Broadcast_611
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.dec_bbox_head.0.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.dec_bbox_head.0.layers.1.bias with ONNXTRT_Broadcast_619
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.dec_bbox_head.0.layers.2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.dec_bbox_head.0.layers.2.bias with ONNXTRT_Broadcast_627
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on (Unnamed Layer* 1426) [Constant]
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing (Unnamed Layer* 1426) [Constant] with ONNXTRT_Broadcast_632
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on (Unnamed Layer* 1433) [Constant]
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing (Unnamed Layer* 1433) [Constant] with ONNXTRT_Broadcast_639
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_3808
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_3808 with ONNXTRT_Broadcast_653
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::Add_3803
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::Add_3803 with ONNXTRT_Broadcast_655
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_3809
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_3809 with ONNXTRT_Broadcast_657
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::Add_3805
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::Add_3805 with ONNXTRT_Broadcast_659
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_3810
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_3810 with ONNXTRT_Broadcast_661
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::Add_3807
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::Add_3807 with ONNXTRT_Broadcast_663
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.self_attn.out_proj.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.self_attn.out_proj.bias with ONNXTRT_Broadcast_672
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.norm1.weight
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.norm1.weight with ONNXTRT_Broadcast_677
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.norm1.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.norm1.bias with ONNXTRT_Broadcast_679
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.cross_attn.value_proj.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.cross_attn.value_proj.bias with ONNXTRT_Broadcast_685
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.cross_attn.sampling_offsets.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.cross_attn.sampling_offsets.bias with ONNXTRT_Broadcast_694
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.cross_attn.attention_weights.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.cross_attn.attention_weights.bias with ONNXTRT_Broadcast_701
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.cross_attn.output_proj.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.cross_attn.output_proj.bias with ONNXTRT_Broadcast_896
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.norm2.weight
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.norm2.weight with ONNXTRT_Broadcast_900
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.norm2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.norm2.bias with ONNXTRT_Broadcast_902
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.linear1.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.linear1.bias with ONNXTRT_Broadcast_910
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.linear2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.linear2.bias with ONNXTRT_Broadcast_918
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.norm3.weight
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.norm3.weight with ONNXTRT_Broadcast_922
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.1.norm3.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.1.norm3.bias with ONNXTRT_Broadcast_924
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.dec_bbox_head.1.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.dec_bbox_head.1.layers.0.bias with ONNXTRT_Broadcast_932
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.dec_bbox_head.1.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.dec_bbox_head.1.layers.1.bias with ONNXTRT_Broadcast_940
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.dec_bbox_head.1.layers.2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.dec_bbox_head.1.layers.2.bias with ONNXTRT_Broadcast_948
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on (Unnamed Layer* 1834) [Constant]
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing (Unnamed Layer* 1834) [Constant] with ONNXTRT_Broadcast_953
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on (Unnamed Layer* 1841) [Constant]
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing (Unnamed Layer* 1841) [Constant] with ONNXTRT_Broadcast_960
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_3880
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_3880 with ONNXTRT_Broadcast_974
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::Add_3875
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::Add_3875 with ONNXTRT_Broadcast_976
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_3881
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_3881 with ONNXTRT_Broadcast_978
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::Add_3877
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::Add_3877 with ONNXTRT_Broadcast_980
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::MatMul_3882
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::MatMul_3882 with ONNXTRT_Broadcast_982
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on onnx::Add_3879
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing onnx::Add_3879 with ONNXTRT_Broadcast_984
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.self_attn.out_proj.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.self_attn.out_proj.bias with ONNXTRT_Broadcast_993
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.norm1.weight
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.norm1.weight with ONNXTRT_Broadcast_998
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.norm1.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.norm1.bias with ONNXTRT_Broadcast_1000
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.cross_attn.value_proj.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.cross_attn.value_proj.bias with ONNXTRT_Broadcast_1006
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.cross_attn.sampling_offsets.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.cross_attn.sampling_offsets.bias with ONNXTRT_Broadcast_1015
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.cross_attn.attention_weights.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.cross_attn.attention_weights.bias with ONNXTRT_Broadcast_1022
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.cross_attn.output_proj.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.cross_attn.output_proj.bias with ONNXTRT_Broadcast_1217
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.norm2.weight
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.norm2.weight with ONNXTRT_Broadcast_1221
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.norm2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.norm2.bias with ONNXTRT_Broadcast_1223
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.linear1.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.linear1.bias with ONNXTRT_Broadcast_1231
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.linear2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.linear2.bias with ONNXTRT_Broadcast_1239
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.norm3.weight
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.norm3.weight with ONNXTRT_Broadcast_1243
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.decoder.layers.2.norm3.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.decoder.layers.2.norm3.bias with ONNXTRT_Broadcast_1245
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.dec_bbox_head.2.layers.0.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.dec_bbox_head.2.layers.0.bias with ONNXTRT_Broadcast_1253
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.dec_bbox_head.2.layers.1.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.dec_bbox_head.2.layers.1.bias with ONNXTRT_Broadcast_1261
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.dec_bbox_head.2.layers.2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.dec_bbox_head.2.layers.2.bias with ONNXTRT_Broadcast_1269
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on (Unnamed Layer* 2242) [Constant]
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing (Unnamed Layer* 2242) [Constant] with ONNXTRT_Broadcast_1274
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on (Unnamed Layer* 2249) [Constant]
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing (Unnamed Layer* 2249) [Constant] with ONNXTRT_Broadcast_1281
[05/21/2025-09:28:09] [V] [TRT] Running: ConstShuffleFusion on model.decoder.dec_score_head.2.bias
[05/21/2025-09:28:09] [V] [TRT] ConstShuffleFusion: Fusing model.decoder.dec_score_head.2.bias with ONNXTRT_Broadcast_1287
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/encoder/encoder.0/layers.0/linear1/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/encoder/encoder.0/layers.0/linear1/Transpose with ONNXTRT_Broadcast_129
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/encoder/encoder.0/layers.0/linear2/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/encoder/encoder.0/layers.0/linear2/Transpose with ONNXTRT_Broadcast_143
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/enc_output/proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/enc_output/proj/Transpose with ONNXTRT_Broadcast_273
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/enc_score_head/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/enc_score_head/Transpose with ONNXTRT_Broadcast_287
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/enc_bbox_head/layers.0/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/enc_bbox_head/layers.0/Transpose with ONNXTRT_Broadcast_293
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/enc_bbox_head/layers.1/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/enc_bbox_head/layers.1/Transpose with ONNXTRT_Broadcast_301
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/enc_bbox_head/layers.2/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/enc_bbox_head/layers.2/Transpose with ONNXTRT_Broadcast_309
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/cross_attn/value_proj/Transpose with ONNXTRT_Broadcast_364
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Transpose with ONNXTRT_Broadcast_373
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/cross_attn/attention_weights/Transpose with ONNXTRT_Broadcast_380
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/cross_attn/output_proj/Transpose with ONNXTRT_Broadcast_573
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/linear1/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/linear1/Transpose with ONNXTRT_Broadcast_587
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/linear2/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/linear2/Transpose with ONNXTRT_Broadcast_595
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/dec_bbox_head.0/layers.0/Transpose with ONNXTRT_Broadcast_609
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/dec_bbox_head.0/layers.1/Transpose with ONNXTRT_Broadcast_617
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/dec_bbox_head.0/layers.2/Transpose with ONNXTRT_Broadcast_625
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/cross_attn/value_proj/Transpose with ONNXTRT_Broadcast_683
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Transpose with ONNXTRT_Broadcast_692
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/cross_attn/attention_weights/Transpose with ONNXTRT_Broadcast_699
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/cross_attn/output_proj/Transpose with ONNXTRT_Broadcast_894
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/linear1/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/linear1/Transpose with ONNXTRT_Broadcast_908
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/linear2/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/linear2/Transpose with ONNXTRT_Broadcast_916
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/dec_bbox_head.1/layers.0/Transpose with ONNXTRT_Broadcast_930
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/dec_bbox_head.1/layers.1/Transpose with ONNXTRT_Broadcast_938
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/dec_bbox_head.1/layers.2/Transpose with ONNXTRT_Broadcast_946
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/cross_attn/value_proj/Transpose with ONNXTRT_Broadcast_1004
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Transpose with ONNXTRT_Broadcast_1013
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/cross_attn/attention_weights/Transpose with ONNXTRT_Broadcast_1020
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/cross_attn/output_proj/Transpose with ONNXTRT_Broadcast_1215
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/linear1/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/linear1/Transpose with ONNXTRT_Broadcast_1229
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/linear2/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/linear2/Transpose with ONNXTRT_Broadcast_1237
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/dec_bbox_head.2/layers.0/Transpose with ONNXTRT_Broadcast_1251
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/dec_bbox_head.2/layers.1/Transpose with ONNXTRT_Broadcast_1259
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/dec_bbox_head.2/layers.2/Transpose with ONNXTRT_Broadcast_1267
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/dec_score_head.2/Transpose
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/dec_score_head.2/Transpose with ONNXTRT_Broadcast_1285
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/encoder/encoder.0/layers.0/self_attn/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/encoder/encoder.0/layers.0/self_attn/Reshape_2 with /model/encoder/encoder.0/layers.0/self_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/encoder/encoder.0/layers.0/self_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/encoder/encoder.0/layers.0/self_attn/Reshape with /model/encoder/encoder.0/layers.0/self_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/encoder/encoder.0/layers.0/self_attn/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/encoder/encoder.0/layers.0/self_attn/Reshape_1 with /model/encoder/encoder.0/layers.0/self_attn/Transpose_4
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleErasure on ONNXTRT_ShapeShuffle_113
[05/21/2025-09:28:09] [V] [TRT] Removing ONNXTRT_ShapeShuffle_113
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/encoder/encoder.0/layers.0/self_attn/Transpose_5
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/encoder/encoder.0/layers.0/self_attn/Transpose_5 with /model/encoder/encoder.0/layers.0/self_attn/Reshape_3
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/encoder/encoder.0/layers.0/self_attn/Reshape_4
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/encoder/encoder.0/layers.0/self_attn/Reshape_4 with /model/encoder/encoder.0/layers.0/self_attn/Transpose_6
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/encoder/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/encoder/Transpose_1 with /model/encoder/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/Reshape
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/Reshape with /model/decoder/Transpose
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/Reshape_1 with /model/decoder/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/Reshape_2 with /model/decoder/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/cross_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/cross_attn/Reshape with /model/decoder/decoder/layers.0/cross_attn/Transpose
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/cross_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/cross_attn/Reshape with /model/decoder/decoder/layers.1/cross_attn/Transpose
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/cross_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/cross_attn/Reshape with /model/decoder/decoder/layers.2/cross_attn/Transpose
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/self_attn/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/self_attn/Reshape_2 with /model/decoder/decoder/layers.0/self_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/self_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/self_attn/Reshape with /model/decoder/decoder/layers.0/self_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/self_attn/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/self_attn/Reshape_1 with /model/decoder/decoder/layers.0/self_attn/Transpose_4
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleErasure on ONNXTRT_ShapeShuffle_348
[05/21/2025-09:28:09] [V] [TRT] Removing ONNXTRT_ShapeShuffle_348
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/self_attn/Transpose_5
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/self_attn/Transpose_5 with /model/decoder/decoder/layers.0/self_attn/Reshape_3
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/self_attn/Reshape_4
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/self_attn/Reshape_4 with /model/decoder/decoder/layers.0/self_attn/Transpose_6
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on ONNXTRT_ShapeShuffle_384
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing ONNXTRT_ShapeShuffle_384 with /model/decoder/decoder/layers.0/cross_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on ONNXTRT_ShapeShuffle_384 + /model/decoder/decoder/layers.0/cross_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing ONNXTRT_ShapeShuffle_384 + /model/decoder/decoder/layers.0/cross_attn/Transpose_2 with /model/decoder/decoder/layers.0/cross_attn/Reshape_9
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/cross_attn/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/cross_attn/Transpose_1 with /model/decoder/decoder/layers.0/cross_attn/Reshape_5
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.0/cross_attn/Reshape_10
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.0/cross_attn/Reshape_10 with /model/decoder/decoder/layers.0/cross_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/self_attn/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/self_attn/Reshape_2 with /model/decoder/decoder/layers.1/self_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/self_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/self_attn/Reshape with /model/decoder/decoder/layers.1/self_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/self_attn/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/self_attn/Reshape_1 with /model/decoder/decoder/layers.1/self_attn/Transpose_4
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleErasure on ONNXTRT_ShapeShuffle_669
[05/21/2025-09:28:09] [V] [TRT] Removing ONNXTRT_ShapeShuffle_669
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/self_attn/Transpose_5
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/self_attn/Transpose_5 with /model/decoder/decoder/layers.1/self_attn/Reshape_3
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/self_attn/Reshape_4
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/self_attn/Reshape_4 with /model/decoder/decoder/layers.1/self_attn/Transpose_6
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on ONNXTRT_ShapeShuffle_703
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing ONNXTRT_ShapeShuffle_703 with /model/decoder/decoder/layers.1/cross_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on ONNXTRT_ShapeShuffle_703 + /model/decoder/decoder/layers.1/cross_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing ONNXTRT_ShapeShuffle_703 + /model/decoder/decoder/layers.1/cross_attn/Transpose_2 with /model/decoder/decoder/layers.1/cross_attn/Reshape_9
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/cross_attn/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/cross_attn/Transpose_1 with /model/decoder/decoder/layers.1/cross_attn/Reshape_5
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.1/cross_attn/Reshape_10
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.1/cross_attn/Reshape_10 with /model/decoder/decoder/layers.1/cross_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/self_attn/Reshape_2
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/self_attn/Reshape_2 with /model/decoder/decoder/layers.2/self_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/self_attn/Reshape
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/self_attn/Reshape with /model/decoder/decoder/layers.2/self_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/self_attn/Reshape_1
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/self_attn/Reshape_1 with /model/decoder/decoder/layers.2/self_attn/Transpose_4
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleErasure on ONNXTRT_ShapeShuffle_990
[05/21/2025-09:28:09] [V] [TRT] Removing ONNXTRT_ShapeShuffle_990
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/self_attn/Transpose_5
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/self_attn/Transpose_5 with /model/decoder/decoder/layers.2/self_attn/Reshape_3
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/self_attn/Reshape_4
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/self_attn/Reshape_4 with /model/decoder/decoder/layers.2/self_attn/Transpose_6
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on ONNXTRT_ShapeShuffle_1024
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing ONNXTRT_ShapeShuffle_1024 with /model/decoder/decoder/layers.2/cross_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on ONNXTRT_ShapeShuffle_1024 + /model/decoder/decoder/layers.2/cross_attn/Transpose_2
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing ONNXTRT_ShapeShuffle_1024 + /model/decoder/decoder/layers.2/cross_attn/Transpose_2 with /model/decoder/decoder/layers.2/cross_attn/Reshape_9
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/cross_attn/Transpose_1
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/cross_attn/Transpose_1 with /model/decoder/decoder/layers.2/cross_attn/Reshape_5
[05/21/2025-09:28:09] [V] [TRT] Running: ShuffleShuffleFusion on /model/decoder/decoder/layers.2/cross_attn/Reshape_10
[05/21/2025-09:28:09] [V] [TRT] ShuffleShuffleFusion: Fusing /model/decoder/decoder/layers.2/cross_attn/Reshape_10 with /model/decoder/decoder/layers.2/cross_attn/Transpose_3
[05/21/2025-09:28:09] [V] [TRT] QDQ graph optimizer - constant folding of Q/DQ initializers
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_5
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_9
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_13
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_17
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_19
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_23
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_27
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_31
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_35
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_39
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_43
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_47
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_51
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_55
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_59
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_63
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_67
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_71
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_75
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_79
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_83
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_87
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_89
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_91
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_95
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_126
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_140
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_155
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_159
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_163
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_167
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_171
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_173
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_177
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_181
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_185
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_189
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_193
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_197
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_199
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_203
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_207
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_211
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_215
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_219
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_223
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_225
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_229
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_233
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_237
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_241
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_245
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_249
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_251
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_255
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_257
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_259
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_263
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_output/proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_270
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_score_head/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_284
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_bbox_head/layers.0/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_290
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_bbox_head/layers.1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_298
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_bbox_head/layers.2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_306
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_317
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_325
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_361
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_370
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_377
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_570
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/linear1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_584
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/linear2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_592
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_606
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_614
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_622
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_680
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_689
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_696
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_891
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/linear1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_905
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/linear2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_913
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_927
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_935
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_943
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1001
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1010
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1017
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1212
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/linear1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1226
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/linear2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1234
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1248
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1256
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1264
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_score_head.2/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1282
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_2
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_10
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_18
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_24
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_32
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_40
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_48
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_56
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_64
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_72
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_80
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_88
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_92
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_127
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_156
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/lateral_convs.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_164
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_172
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_178
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_186
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_194
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_200
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_208
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_216
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_224
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_230
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_238
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_246
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_252
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_258
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_264
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_285
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/enc_score_head/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_299
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/enc_bbox_head/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_318
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_362
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_378
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_585
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.0/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_607
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_623
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_690
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_892
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_914
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.1/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_936
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1002
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1018
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1227
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.2/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1249
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1265
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_3
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_4
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_7
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_8
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_11
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_12
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_15
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_16
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_21
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_22
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_25
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_26
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_29
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_30
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_37
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_38
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_34
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_41
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_42
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_45
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_46
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_49
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_50
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_57
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_58
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_54
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_61
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_62
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_65
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_66
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_69
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_70
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_77
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_78
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_74
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_81
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_82
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_85
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_86
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_93
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_94
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/input_proj.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_124
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_125
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/encoder.0/layers.0/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_138
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_139
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/encoder.0/layers.0/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_153
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_154
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/lateral_convs.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_157
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_158
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_161
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_162
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_165
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_166
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_169
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_170
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_175
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_176
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_179
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_180
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/lateral_convs.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_183
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_184
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_187
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_188
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_191
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_192
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_195
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_196
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_201
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_202
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_205
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_206
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_209
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_210
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_213
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_214
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_217
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_218
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_221
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_222
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_227
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_228
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_231
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_232
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_235
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_236
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_239
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_240
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_243
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_244
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_247
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_248
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_253
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_254
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_261
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_262
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/input_proj.2/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_359
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_268
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_360
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_269
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/enc_output/proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_score_head/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_282
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_score_head/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_283
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/enc_score_head/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_296
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_297
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/enc_bbox_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_304
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_305
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/enc_bbox_head/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_315
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_316
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_323
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_324
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_368
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_369
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_568
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_569
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_582
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_583
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.0/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_590
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_591
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.0/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_604
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_605
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_612
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_613
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_620
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_621
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_640
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_641
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_646
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_647
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_687
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_688
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_889
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_890
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_903
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_904
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.1/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_911
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_912
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.1/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_925
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_926
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_933
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_934
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_941
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_942
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_961
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_962
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_1/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_967
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_968
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1008
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1009
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1210
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1211
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1224
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1225
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.2/linear1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1232
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1233
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.2/linear2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1246
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1247
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1254
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1255
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1262
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1263
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_6
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_14
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_20
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_28
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_36
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_44
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_52
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_60
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_68
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_76
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_84
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_90
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/input_proj.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_96
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/input_proj.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_141
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_160
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_168
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_174
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_182
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/lateral_convs.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_190
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_198
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_204
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_212
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_220
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_226
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_234
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_242
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_250
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_256
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_260
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/input_proj.1/conv/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_271
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/enc_output/proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_291
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/enc_bbox_head/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_307
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/enc_bbox_head/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_326
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_371
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_571
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_593
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.0/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_615
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_681
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_697
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_906
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.1/linear1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_928
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_944
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1011
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1213
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1235
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/layers.2/linear2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1257
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_1283
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/decoder/dec_score_head.2/weight_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_33
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_53
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Running: ConstQDQInitializersFusion on /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing tmp_weight_73
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/Constant_1_output_0
[05/21/2025-09:28:09] [V] [TRT] Found /model/decoder/decoder/layers.2/self_attn/MatMul_4 to be part of self-attention pattern.
[05/21/2025-09:28:09] [V] [TRT] Found /model/decoder/decoder/layers.1/self_attn/MatMul_4 to be part of self-attention pattern.
[05/21/2025-09:28:09] [V] [TRT] Found /model/decoder/decoder/layers.2/self_attn/MatMul_3 to be part of self-attention pattern.
[05/21/2025-09:28:09] [V] [TRT] Found /model/decoder/decoder/layers.1/self_attn/MatMul_3 to be part of self-attention pattern.
[05/21/2025-09:28:09] [V] [TRT] Found /model/decoder/decoder/layers.0/self_attn/MatMul_4 to be part of self-attention pattern.
[05/21/2025-09:28:09] [V] [TRT] Found /model/decoder/decoder/layers.0/self_attn/Softmax to be part of self-attention pattern.
[05/21/2025-09:28:09] [V] [TRT] Found /model/decoder/decoder/layers.0/self_attn/MatMul_3 to be part of self-attention pattern.
[05/21/2025-09:28:09] [V] [TRT] Found /model/encoder/encoder.0/layers.0/self_attn/MatMul_4 to be part of self-attention pattern.
[05/21/2025-09:28:09] [V] [TRT] Found /model/encoder/encoder.0/layers.0/self_attn/Softmax to be part of self-attention pattern.
[05/21/2025-09:28:09] [V] [TRT] Found /model/decoder/decoder/layers.2/self_attn/Softmax to be part of self-attention pattern.
[05/21/2025-09:28:09] [V] [TRT] Found /model/decoder/decoder/layers.1/self_attn/Softmax to be part of self-attention pattern.
[05/21/2025-09:28:09] [V] [TRT] Found /model/encoder/encoder.0/layers.0/self_attn/MatMul_3 to be part of self-attention pattern.
[05/21/2025-09:28:09] [V] [TRT] Found and reassigned Myelin backends for Self-Attention nodes
[05/21/2025-09:28:09] [V] [TRT] After Myelin optimization: 464 layers
[05/21/2025-09:28:09] [V] [TRT] QDQ graph optimizer - constant folding of Q/DQ initializers
[05/21/2025-09:28:09] [V] [TRT] QDQ graph optimizer forward pass - DQ motions and fusions
[05/21/2025-09:28:09] [V] [TRT] QDQ graph optimizer backward pass
[05/21/2025-09:28:09] [V] [TRT] QDQ graph optimizer quantization pass - Generate quantized ops
[05/21/2025-09:28:09] [V] [TRT] Running: SplitDQAcrossFanOut on /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: SplitDQAcrossFanOut on /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: SplitDQAcrossFanOut on /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: SplitDQAcrossFanOut on /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: SplitDQAcrossFanOut on /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: SplitDQAcrossFanOut on /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: SplitDQAcrossFanOut on /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: SplitDQAcrossFanOut on /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: SplitDQAcrossFanOut on /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: SplitDQAcrossFanOut on /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: EltReluFusion on /model/backbone/res_layers.0/blocks.0/Add
[05/21/2025-09:28:09] [V] [TRT] EltReluFusion: Fusing /model/backbone/res_layers.0/blocks.0/Add with /model/backbone/res_layers.0/blocks.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: EltReluFusion on /model/backbone/res_layers.0/blocks.1/Add
[05/21/2025-09:28:09] [V] [TRT] EltReluFusion: Fusing /model/backbone/res_layers.0/blocks.1/Add with /model/backbone/res_layers.0/blocks.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: EltReluFusion on /model/backbone/res_layers.1/blocks.0/Add
[05/21/2025-09:28:09] [V] [TRT] EltReluFusion: Fusing /model/backbone/res_layers.1/blocks.0/Add with /model/backbone/res_layers.1/blocks.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: EltReluFusion on /model/backbone/res_layers.1/blocks.1/Add
[05/21/2025-09:28:09] [V] [TRT] EltReluFusion: Fusing /model/backbone/res_layers.1/blocks.1/Add with /model/backbone/res_layers.1/blocks.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: EltReluFusion on /model/backbone/res_layers.2/blocks.0/Add
[05/21/2025-09:28:09] [V] [TRT] EltReluFusion: Fusing /model/backbone/res_layers.2/blocks.0/Add with /model/backbone/res_layers.2/blocks.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: EltReluFusion on /model/backbone/res_layers.2/blocks.1/Add
[05/21/2025-09:28:09] [V] [TRT] EltReluFusion: Fusing /model/backbone/res_layers.2/blocks.1/Add with /model/backbone/res_layers.2/blocks.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: EltReluFusion on /model/backbone/res_layers.3/blocks.0/Add
[05/21/2025-09:28:09] [V] [TRT] EltReluFusion: Fusing /model/backbone/res_layers.3/blocks.0/Add with /model/backbone/res_layers.3/blocks.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: EltReluFusion on /model/backbone/res_layers.3/blocks.1/Add
[05/21/2025-09:28:09] [V] [TRT] EltReluFusion: Fusing /model/backbone/res_layers.3/blocks.1/Add with /model/backbone/res_layers.3/blocks.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ScaleActivationFusion on /model/backbone/conv1/conv1_1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] ScaleActivationFusion: Fusing /model/backbone/conv1/conv1_1/norm/BatchNormalization with /model/backbone/conv1/conv1_1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ScaleActivationFusion on /model/backbone/conv1/conv1_2/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] ScaleActivationFusion: Fusing /model/backbone/conv1/conv1_2/norm/BatchNormalization with /model/backbone/conv1/conv1_2/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ScaleActivationFusion on /model/backbone/conv1/conv1_3/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] ScaleActivationFusion: Fusing /model/backbone/conv1/conv1_3/norm/BatchNormalization with /model/backbone/conv1/conv1_3/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ScaleActivationFusion on /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] ScaleActivationFusion: Fusing /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization with /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ScaleActivationFusion on /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] ScaleActivationFusion: Fusing /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization with /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ScaleActivationFusion on /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] ScaleActivationFusion: Fusing /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization with /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ScaleActivationFusion on /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] ScaleActivationFusion: Fusing /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization with /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ScaleActivationFusion on /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] ScaleActivationFusion: Fusing /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization with /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ScaleActivationFusion on /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] ScaleActivationFusion: Fusing /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization with /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ScaleActivationFusion on /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] ScaleActivationFusion: Fusing /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization with /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ScaleActivationFusion on /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] ScaleActivationFusion: Fusing /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization with /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.conv1.conv1_1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.conv1.conv1_1.conv.weight with /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.conv1.conv1_2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.conv1.conv1_2.conv.weight with /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.conv1.conv1_3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.conv1.conv1_3.conv.weight with /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.0.blocks.0.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.0.blocks.0.branch2a.conv.weight with /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.0.blocks.0.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.0.blocks.0.branch2b.conv.weight with /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.0.blocks.0.short.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.0.blocks.0.short.conv.weight with /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.0.blocks.1.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.0.blocks.1.branch2a.conv.weight with /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.0.blocks.1.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.0.blocks.1.branch2b.conv.weight with /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.1.blocks.0.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.1.blocks.0.branch2a.conv.weight with /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.1.blocks.0.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.1.blocks.0.branch2b.conv.weight with /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.1.blocks.0.short.conv.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.1.blocks.0.short.conv.conv.weight with /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.1.blocks.1.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.1.blocks.1.branch2a.conv.weight with /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.1.blocks.1.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.1.blocks.1.branch2b.conv.weight with /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.2.blocks.0.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.2.blocks.0.branch2a.conv.weight with /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.2.blocks.0.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.2.blocks.0.branch2b.conv.weight with /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.2.blocks.0.short.conv.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.2.blocks.0.short.conv.conv.weight with /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.2.blocks.1.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.2.blocks.1.branch2a.conv.weight with /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.2.blocks.1.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.2.blocks.1.branch2b.conv.weight with /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.3.blocks.0.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.3.blocks.0.branch2a.conv.weight with /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.3.blocks.0.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.3.blocks.0.branch2b.conv.weight with /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.3.blocks.0.short.conv.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.3.blocks.0.short.conv.conv.weight with /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.3.blocks.1.branch2a.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.3.blocks.1.branch2a.conv.weight with /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.backbone.res_layers.3.blocks.1.branch2b.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.backbone.res_layers.3.blocks.1.branch2b.conv.weight with /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.input_proj.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.input_proj.2.conv.weight with /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.input_proj.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.input_proj.0.conv.weight with /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.input_proj.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.input_proj.1.conv.weight with /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.lateral_convs.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.lateral_convs.0.conv.weight with /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.fpn_blocks.0.conv1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.fpn_blocks.0.conv1.conv.weight with /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight with /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight with /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight with /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.fpn_blocks.0.conv2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.fpn_blocks.0.conv2.conv.weight with /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.fpn_blocks.0.conv3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.fpn_blocks.0.conv3.conv.weight with /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.lateral_convs.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.lateral_convs.1.conv.weight with /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.fpn_blocks.1.conv1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.fpn_blocks.1.conv1.conv.weight with /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight with /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight with /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight with /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.fpn_blocks.1.conv2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.fpn_blocks.1.conv2.conv.weight with /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.fpn_blocks.1.conv3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.fpn_blocks.1.conv3.conv.weight with /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.downsample_convs.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.downsample_convs.0.conv.weight with /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.pan_blocks.0.conv1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.pan_blocks.0.conv1.conv.weight with /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.pan_blocks.0.bottlenecks.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.pan_blocks.0.bottlenecks.0.conv.weight with /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.pan_blocks.0.bottlenecks.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.pan_blocks.0.bottlenecks.1.conv.weight with /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.pan_blocks.0.bottlenecks.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.pan_blocks.0.bottlenecks.2.conv.weight with /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.pan_blocks.0.conv2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.pan_blocks.0.conv2.conv.weight with /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.pan_blocks.0.conv3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.pan_blocks.0.conv3.conv.weight with /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.downsample_convs.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.downsample_convs.1.conv.weight with /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.pan_blocks.1.conv1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.pan_blocks.1.conv1.conv.weight with /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.pan_blocks.1.bottlenecks.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.pan_blocks.1.bottlenecks.0.conv.weight with /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.pan_blocks.1.bottlenecks.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.pan_blocks.1.bottlenecks.1.conv.weight with /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.pan_blocks.1.bottlenecks.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.pan_blocks.1.bottlenecks.2.conv.weight with /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.pan_blocks.1.conv2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.pan_blocks.1.conv2.conv.weight with /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.encoder.pan_blocks.1.conv3.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.encoder.pan_blocks.1.conv3.conv.weight with /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.decoder.input_proj.0.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.decoder.input_proj.0.conv.weight with /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.decoder.input_proj.1.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.decoder.input_proj.1.conv.weight with /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsQuantizeFusion on model.decoder.input_proj.2.conv.weight
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsQuantizeFusion: Fusing model.decoder.input_proj.2.conv.weight with /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on /model/backbone/MaxPool
[05/21/2025-09:28:09] [V] [TRT] Swapping /model/backbone/MaxPool with /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on /model/encoder/Concat_2
[05/21/2025-09:28:09] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on /model/encoder/Concat_3
[05/21/2025-09:28:09] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on /model/encoder/Concat_4
[05/21/2025-09:28:09] [V] [TRT] Running: SplitQAcrossPrecedingFanIn on /model/encoder/Concat_5
[05/21/2025-09:28:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on /model/encoder/Resize
[05/21/2025-09:28:09] [V] [TRT] Swapping /model/encoder/Resize with /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Running: VanillaSwapWithFollowingQ on /model/encoder/Resize_1
[05/21/2025-09:28:09] [V] [TRT] Swapping /model/encoder/Resize_1 with /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Running: HorizontalMergeQNodes on /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Eliminating /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_1 which duplicates (Q) /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/lateral_convs.0/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/lateral_convs.0/act/Sigmoid with /model/encoder/lateral_convs.0/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/fpn_blocks.0/conv1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/fpn_blocks.0/conv1/act/Sigmoid with /model/encoder/fpn_blocks.0/conv1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid with /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid with /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/fpn_blocks.0/conv2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/fpn_blocks.0/conv2/act/Sigmoid with /model/encoder/fpn_blocks.0/conv2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul) with /model/encoder/fpn_blocks.0/Add
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid with /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul) with PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add)
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/fpn_blocks.0/conv3/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/fpn_blocks.0/conv3/act/Sigmoid with /model/encoder/fpn_blocks.0/conv3/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/lateral_convs.1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/lateral_convs.1/act/Sigmoid with /model/encoder/lateral_convs.1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/fpn_blocks.1/conv1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/fpn_blocks.1/conv1/act/Sigmoid with /model/encoder/fpn_blocks.1/conv1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid with /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid with /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/fpn_blocks.1/conv2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/fpn_blocks.1/conv2/act/Sigmoid with /model/encoder/fpn_blocks.1/conv2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul) with /model/encoder/fpn_blocks.1/Add
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid with /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul) with PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add)
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/fpn_blocks.1/conv3/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/fpn_blocks.1/conv3/act/Sigmoid with /model/encoder/fpn_blocks.1/conv3/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/downsample_convs.0/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/downsample_convs.0/act/Sigmoid with /model/encoder/downsample_convs.0/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/pan_blocks.0/conv1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/pan_blocks.0/conv1/act/Sigmoid with /model/encoder/pan_blocks.0/conv1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid with /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid with /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/pan_blocks.0/conv2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/pan_blocks.0/conv2/act/Sigmoid with /model/encoder/pan_blocks.0/conv2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul) with /model/encoder/pan_blocks.0/Add
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid with /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul) with PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add)
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/pan_blocks.0/conv3/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/pan_blocks.0/conv3/act/Sigmoid with /model/encoder/pan_blocks.0/conv3/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/downsample_convs.1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/downsample_convs.1/act/Sigmoid with /model/encoder/downsample_convs.1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/pan_blocks.1/conv1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/pan_blocks.1/conv1/act/Sigmoid with /model/encoder/pan_blocks.1/conv1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid with /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid with /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/pan_blocks.1/conv2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/pan_blocks.1/conv2/act/Sigmoid with /model/encoder/pan_blocks.1/conv2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul) with /model/encoder/pan_blocks.1/Add
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid with /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul) with PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add)
[05/21/2025-09:28:09] [V] [TRT] Running: PointWiseFusion on /model/encoder/pan_blocks.1/conv3/act/Sigmoid
[05/21/2025-09:28:09] [V] [TRT] PointWiseFusion: Fusing /model/encoder/pan_blocks.1/conv3/act/Sigmoid with /model/encoder/pan_blocks.1/conv3/act/Mul
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/conv1/conv1_1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_1/norm/BatchNormalization + /model/backbone/conv1/conv1_1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/conv1/conv1_2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_2/norm/BatchNormalization + /model/backbone/conv1/conv1_2/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/conv1/conv1_3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_3/norm/BatchNormalization + /model/backbone/conv1/conv1_3/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.0/blocks.0/short/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization + /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization + /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization + /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization + /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization + /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization + /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization + /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization + /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/input_proj.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/input_proj.0/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/input_proj.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/input_proj.1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/lateral_convs.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/lateral_convs.0/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/fpn_blocks.0/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/fpn_blocks.0/conv1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/fpn_blocks.0/conv3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/lateral_convs.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/lateral_convs.1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/fpn_blocks.1/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/fpn_blocks.1/conv1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/fpn_blocks.1/conv3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/downsample_convs.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.0/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/pan_blocks.0/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/pan_blocks.0/conv1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/pan_blocks.0/conv3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/downsample_convs.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/pan_blocks.1/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/pan_blocks.1/conv1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: QConvOrDeconvScaleFusion on /model/encoder/pan_blocks.1/conv3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/fpn_blocks.0/conv1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/fpn_blocks.0/conv1/conv/Conv with PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv with PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv with PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/fpn_blocks.0/conv3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/fpn_blocks.0/conv3/conv/Conv with PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/lateral_convs.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/lateral_convs.1/conv/Conv with PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/fpn_blocks.1/conv1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/fpn_blocks.1/conv1/conv/Conv with PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv with PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv with PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/fpn_blocks.1/conv3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/fpn_blocks.1/conv3/conv/Conv with PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/downsample_convs.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/downsample_convs.0/conv/Conv with PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/pan_blocks.0/conv1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/pan_blocks.0/conv1/conv/Conv with PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv with PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv with PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/pan_blocks.0/conv3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/pan_blocks.0/conv3/conv/Conv with PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/downsample_convs.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/downsample_convs.1/conv/Conv with PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/pan_blocks.1/conv1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/pan_blocks.1/conv1/conv/Conv with PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv with PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv with PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: GenericConvActFusion on /model/encoder/pan_blocks.1/conv3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] GenericConvActFusion: Fusing /model/encoder/pan_blocks.1/conv3/conv/Conv with PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/conv1/conv1_1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear into /model/backbone/conv1/conv1_1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear and /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear) into /model/backbone/conv1/conv1_1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/conv1/conv1_2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear into /model/backbone/conv1/conv1_2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear and /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear) into /model/backbone/conv1/conv1_2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/conv1/conv1_3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear into /model/backbone/conv1/conv1_3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear and /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear) into /model/backbone/conv1/conv1_3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.0/blocks.0/short/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_1 and /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.0/blocks.0/short/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear into /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear into /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear into /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear into /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear and /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/input_proj.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear and /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear) into /model/encoder/input_proj.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/input_proj.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 into /model/encoder/input_proj.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_2 and /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear) into /model/encoder/input_proj.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_2
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/lateral_convs.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear and /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear) into /model/encoder/lateral_convs.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/fpn_blocks.0/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_clone_1 and /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear) into /model/encoder/fpn_blocks.0/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear into /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear and /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear) into /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear into /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear and /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear) into /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear and /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear) into /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear into /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear and /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear) into /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_0 into /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear and /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear) into /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/fpn_blocks.1/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_clone_1 and /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear) into /model/encoder/fpn_blocks.1/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear into /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear and /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear) into /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear into /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear and /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear) into /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear and /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear) into /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear into /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear and /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear) into /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/decoder/input_proj.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear_clone_1 and /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear) into /model/decoder/input_proj.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/pan_blocks.0/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_clone_1 and /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear) into /model/encoder/pan_blocks.0/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear into /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear and /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear) into /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear into /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear and /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear) into /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear and /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear) into /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear into /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear and /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear) into /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/decoder/input_proj.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear_clone_1 and /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear) into /model/decoder/input_proj.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/pan_blocks.1/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_clone_1 and /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear) into /model/encoder/pan_blocks.1/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear into /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear and /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear) into /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear into /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear and /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear) into /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear and /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear) into /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear into /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear and /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear) into /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/decoder/input_proj.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear and /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear) into /model/decoder/input_proj.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear into /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_0 and /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear into /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_0 and /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear into /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_0 and /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear into /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_0 and /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear) into /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/input_proj.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_1 into /model/encoder/input_proj.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_2 and /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear) into /model/encoder/input_proj.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_2
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear into /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_clone_0 and /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear) into /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear into /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_clone_0 and /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear) into /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 into /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear_clone_0 and /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear) into /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear into /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_clone_0 and /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear) into /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_0 into /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear_clone_0 and /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear) into /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeDoubleInputNodes on /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear into /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] QuantizeDoubleInputNodes: fusing (/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_clone_0 and /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear) into /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear_clone_0
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeSingleInputNodes on /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeSingleInputNodes on /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeSingleInputNodes on /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Removing /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear_clone_1
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeGenericNodes on PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))
[05/21/2025-09:28:09] [V] [TRT] QuantizeGenericNodes: fusing /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear into PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeGenericNodes on PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))
[05/21/2025-09:28:09] [V] [TRT] QuantizeGenericNodes: fusing /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear into PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeGenericNodes on PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))
[05/21/2025-09:28:09] [V] [TRT] QuantizeGenericNodes: fusing /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear into PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: QuantizeGenericNodes on PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))
[05/21/2025-09:28:09] [V] [TRT] QuantizeGenericNodes: fusing /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear into PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))
[05/21/2025-09:28:09] [V] [TRT] Removing /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear with /model/backbone/conv1/conv1_1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear with /model/backbone/conv1/conv1_2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear with /model/backbone/conv1/conv1_3/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.0/blocks.0/short/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear with /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear with /model/encoder/input_proj.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear with /model/encoder/input_proj.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear with /model/encoder/input_proj.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear with /model/encoder/lateral_convs.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear with /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear with /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear with /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear with /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear with /model/encoder/fpn_blocks.0/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear with /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear with /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear with /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear with /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear with /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear with /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear with /model/encoder/fpn_blocks.1/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear with /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear with /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear with /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear with /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear with /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear with /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear with /model/encoder/pan_blocks.0/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear with /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear with /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear with /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear with /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear with /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear with /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear with /model/encoder/pan_blocks.1/conv2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear with /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear with /model/decoder/input_proj.0/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear with /model/decoder/input_proj.1/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConstWeightsFusion on model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear
[05/21/2025-09:28:09] [V] [TRT] ConstWeightsFusion: Fusing model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear with /model/decoder/input_proj.2/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] Running: ConvEltwiseSumFusion on model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] ConvEltwiseSumFusion: Fusing model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv with /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ConvEltwiseSumFusion on model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] ConvEltwiseSumFusion: Fusing model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv with /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ConvEltwiseSumFusion on model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] ConvEltwiseSumFusion: Fusing model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv with /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ConvEltwiseSumFusion on model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] ConvEltwiseSumFusion: Fusing model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv with /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ConvEltwiseSumFusion on model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] ConvEltwiseSumFusion: Fusing model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv with /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ConvEltwiseSumFusion on model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] ConvEltwiseSumFusion: Fusing model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv with /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ConvEltwiseSumFusion on model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] ConvEltwiseSumFusion: Fusing model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv with /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu
[05/21/2025-09:28:09] [V] [TRT] Running: ConvEltwiseSumFusion on model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv
[05/21/2025-09:28:09] [V] [TRT] ConvEltwiseSumFusion: Fusing model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv with /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu
[05/21/2025-09:28:09] [V] [TRT] After dupe layer removal: 86 layers
[05/21/2025-09:28:09] [V] [TRT] After final dead-layer removal: 86 layers
[05/21/2025-09:28:10] [V] [TRT] After tensor merging: 86 layers
[05/21/2025-09:28:10] [V] [TRT] QDQ graph optimizer quantization epilogue pass
[05/21/2025-09:28:10] [V] [TRT] QDQ optimization pass
[05/21/2025-09:28:10] [V] [TRT] QDQ graph optimizer constant fold dangling QDQ pass
[05/21/2025-09:28:10] [V] [TRT] Running: QDQToCopy on /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:10] [V] [TRT] Swap the layer type of /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear from QUANTIZE to kQDQ
[05/21/2025-09:28:10] [V] [TRT] Running: QDQToCopy on /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:10] [V] [TRT] Swap the layer type of /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear from QUANTIZE to kQDQ
[05/21/2025-09:28:10] [V] [TRT] Running: QDQToCopy on /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:10] [V] [TRT] Swap the layer type of /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear from QUANTIZE to kQDQ
[05/21/2025-09:28:10] [V] [TRT] Running: QDQToCopy on /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:10] [V] [TRT] Swap the layer type of /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear from QUANTIZE to kQDQ
[05/21/2025-09:28:10] [V] [TRT] Running: QDQToCopy on /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:10] [V] [TRT] Swap the layer type of /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear from QUANTIZE to kQDQ
[05/21/2025-09:28:10] [V] [TRT] Running: QDQToCopy on /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:10] [V] [TRT] Swap the layer type of /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear from QUANTIZE to kQDQ
[05/21/2025-09:28:10] [V] [TRT] Running: QDQToCopy on /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:10] [V] [TRT] Swap the layer type of /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear from QUANTIZE to kQDQ
[05/21/2025-09:28:10] [V] [TRT] Running: QDQToCopy on /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:10] [V] [TRT] Swap the layer type of /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear from QUANTIZE to kQDQ
[05/21/2025-09:28:10] [V] [TRT] Running: QDQToCopy on /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:10] [V] [TRT] Swap the layer type of /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear from QUANTIZE to kQDQ
[05/21/2025-09:28:10] [V] [TRT] Running: QDQToCopy on /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:10] [V] [TRT] Swap the layer type of /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear from QUANTIZE to kQDQ
[05/21/2025-09:28:10] [V] [TRT] Running: QDQToCopy on /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0
[05/21/2025-09:28:10] [V] [TRT] Swap the layer type of /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 from QUANTIZE to kQDQ
[05/21/2025-09:28:10] [V] [TRT] Running: QDQToCopy on /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1
[05/21/2025-09:28:10] [V] [TRT] Swap the layer type of /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 from QUANTIZE to kQDQ
[05/21/2025-09:28:10] [V] [TRT] After dupe layer removal: 86 layers
[05/21/2025-09:28:10] [V] [TRT] After final dead-layer removal: 86 layers
[05/21/2025-09:28:10] [V] [TRT] After tensor merging: 86 layers
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Running: ConvSwishGeToSsTransformation on model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Modifying configuration of model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] After vertical fusions: 86 layers
[05/21/2025-09:28:10] [V] [TRT] After dupe layer removal: 86 layers
[05/21/2025-09:28:10] [V] [TRT] After final dead-layer removal: 86 layers
[05/21/2025-09:28:10] [V] [TRT] After tensor merging: 86 layers
[05/21/2025-09:28:10] [V] [TRT] After slice removal: 86 layers
[05/21/2025-09:28:10] [V] [TRT] Eliminating concatenation /model/encoder/Concat_5
[05/21/2025-09:28:10] [V] [TRT] Retargeting /model/encoder/Concat_5_/model/encoder/downsample_convs.1/act/Mul_output_0_clone_0 to /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:10] [V] [TRT] Retargeting /model/encoder/Concat_5_/model/encoder/lateral_convs.0/act/Mul_output_0_clone_1 to /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:10] [V] [TRT] Eliminating concatenation /model/encoder/Concat_4
[05/21/2025-09:28:10] [V] [TRT] Retargeting /model/encoder/Concat_4_/model/encoder/downsample_convs.0/act/Mul_output_0_clone_0 to /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:10] [V] [TRT] Generating copy for /model/encoder/Resize_1_output_0 to /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 because input does not support striding.
[05/21/2025-09:28:10] [V] [TRT] Eliminating concatenation /model/encoder/Concat_3
[05/21/2025-09:28:10] [V] [TRT] Generating copy for /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 to /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 because input does not support striding.
[05/21/2025-09:28:10] [V] [TRT] Retargeting /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1 to /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:10] [V] [TRT] Eliminating concatenation /model/encoder/Concat_2
[05/21/2025-09:28:10] [V] [TRT] Generating copy for /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 to /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 because input does not support striding.
[05/21/2025-09:28:10] [V] [TRT] Retargeting /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1 to /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0
[05/21/2025-09:28:10] [V] [TRT] After concat removal: 85 layers
[05/21/2025-09:28:10] [V] [TRT] Trying to split Reshape and strided tensor
[05/21/2025-09:28:10] [V] [TRT] Graph optimization time: 0.0472407 seconds.
[05/21/2025-09:28:10] [V] [TRT] Building graph using backend strategy 2
[05/21/2025-09:28:10] [I] [TRT] Global timing cache in use. Profiling results in this builder pass will be stored.
[05/21/2025-09:28:10] [V] [TRT] Constructing optimization profile number 0 [1/1].
[05/21/2025-09:28:10] [V] [TRT] Applying generic optimizations to the graph for inference.
[05/21/2025-09:28:10] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(1228800,409600,640,1) -> Int8(3276800,102400,320,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv [Int8(1228800,409600,640,1) -> Int8(102400,102400:32,320,1)] got cached result: CaskConvolution, tactic 0x11764d94950382f8, 0.00543221 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv [Int8(409600,409600:4,640,1) -> Int8(102400,102400:32,320,1)] got cached result: CaskConvolution, tactic 0x5cc792a989a1d1a6, 0.00457586 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv [Int8(409600,1:16,640,1) -> Int8(204800,1:16,640,2)] got cached result: CaskConvolution, tactic 0xddba7fee89e9dcbf, 0.0103004 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv [Int8(409600,409600:32,640,1) -> Int8(102400,102400:32,320,1)] got cached result: CaskConvolution, tactic 0x13463e9bf9ae0d73, 0.0115436 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(3276800,102400,320,1) -> Int8(3276800,102400,320,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv [Int8(819200,102400:4,320,1) -> Int8(102400,102400:32,320,1)] got cached result: CaskConvolution, tactic 0x0f47434ace2a7d18, 0.0198514 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv [Int8(204800,1:16,640,2) -> Int8(204800,1:16,640,2)] got cached result: CaskConvolution, tactic 0xa60c3259c62a72b2, 0.0111142 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv [Int8(102400,102400:32,320,1) -> Int8(102400,102400:32,320,1)] got cached result: CaskConvolution, tactic 0x13463e9bf9ae0d73, 0.00973379 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(3276800,102400,320,1) -> Int8(6553600,102400,320,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv [Int8(819200,102400:4,320,1) -> Int8(204800,102400:32,320,1)] got cached result: CaskConvolution, tactic 0x0f47434ace2a7d18, 0.0316187 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv [Int8(204800,1:16,640,2) -> Int8(409600,1:16,1280,4)] got cached result: CaskConvolution, tactic 0xbe784bf72795274c, 0.0186674 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv [Int8(102400,102400:32,320,1) -> Int8(204800,102400:32,320,1)] got cached result: CaskConvolution, tactic 0x9dafb2758560cc1d, 0.0109208 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for /model/backbone/MaxPool
[05/21/2025-09:28:10] [V] [TRT] /model/backbone/MaxPool [Int8(1638400,102400:4,320,1) -> Int8(409600,25600:4,160,1)] got cached result: CaskPooling, tactic 0x1f6c40e3e09ec730, 0.00583205 ms
[05/21/2025-09:28:10] [V] [TRT] /model/backbone/MaxPool [Int8(204800,102400:32,320,1) -> Int8(51200,25600:32,160,1)] got cached result: CaskPooling, tactic 0x94215b398b8eb3ba, 0.0061579 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(1638400,25600,160,1) -> Int8(1638400,25600,160,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv [Int8(409600,25600:4,160,1) -> Int8(51200,25600:32,160,1)] got cached result: CaskConvolution, tactic 0x0f47434ace2a7d18, 0.0201006 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv [Int8(102400,1:16,640,4) -> Int8(102400,1:16,640,4)] got cached result: CaskConvolution, tactic 0x5f5aa01645d48746, 0.00816254 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv [Int8(51200,25600:32,160,1) -> Int8(51200,25600:32,160,1)] got cached result: CaskConvolution, tactic 0x9dafb2758560cc1d, 0.00649662 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv [Int8(409600,25600:4,160,1) -> Float(1638400,25600,160,1)] got cached result: CaskConvolution, tactic 0x69c4e2ca38eadce2, 0.0206008 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv [Int8(51200,25600:32,160,1) -> Float(1638400,25600,160,1)] got cached result: CaskConvolution, tactic 0x23b890da05937b9e, 0.0101218 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv [Int8(51200,25600:32,160,1) -> Float(51200,25600:32,160,1)] got cached result: CaskConvolution, tactic 0xb936321f82fd390c, 0.0119615 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv [Int8(51200,25600:32,160,1) -> Half(51200,25600:32,160,1)] got cached result: CaskConvolution, tactic 0xe2bc5a4963d23ad0, 0.00820521 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu [Int8(409600,25600:4,160,1), Float(1638400,25600,160,1) -> Float(1638400,25600,160,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.00787777 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu [Int8(51200,25600:32,160,1), Float(1638400,25600,160,1) -> Float(1638400,25600,160,1)] got cached result: CaskConvolution, tactic 0x733ba2a91a48d431, 0.0100038 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu [Int8(51200,25600:32,160,1), Float(51200,25600:32,160,1) -> Float(51200,25600:32,160,1)] got cached result: CaskConvolution, tactic 0x6d377e4222886190, 0.00750148 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu [Int8(51200,25600:32,160,1), Half(51200,25600:32,160,1) -> Half(51200,25600:32,160,1)] got cached result: CaskConvolution, tactic 0x1cfa820c55616892, 0.00557292 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(1638400,25600,160,1) -> Int8(1638400,25600,160,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv [Int8(409600,25600:4,160,1) -> Int8(51200,25600:32,160,1)] got cached result: CaskConvolution, tactic 0x0f47434ace2a7d18, 0.0201006 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv [Int8(102400,1:16,640,4) -> Int8(102400,1:16,640,4)] got cached result: CaskConvolution, tactic 0x5f5aa01645d48746, 0.00816254 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv [Int8(51200,25600:32,160,1) -> Int8(51200,25600:32,160,1)] got cached result: CaskConvolution, tactic 0x9dafb2758560cc1d, 0.00649662 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu [Int8(409600,25600:4,160,1), Float(1638400,25600,160,1) -> Float(1638400,25600,160,1)] got cached result: CaskConvolution, tactic 0x69c4e2ca38eadce2, 0.0213394 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu [Int8(51200,25600:32,160,1), Float(1638400,25600,160,1) -> Float(1638400,25600,160,1)] got cached result: CaskConvolution, tactic 0x23b890da05937b9e, 0.0121303 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu [Int8(51200,25600:32,160,1), Float(51200,25600:32,160,1) -> Float(51200,25600:32,160,1)] got cached result: CaskConvolution, tactic 0x0e07dc8353bf7e9f, 0.0108754 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu [Int8(51200,25600:32,160,1), Half(51200,25600:32,160,1) -> Half(51200,25600:32,160,1)] got cached result: CaskConvolution, tactic 0xe2bc5a4963d23ad0, 0.00873681 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool
[05/21/2025-09:28:10] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool [Int8(409600,25600:4,160,1) -> Int8(102400,6400:4,80,1)] got cached result: CaskPooling, tactic 0xb4d3d3158ab4fbc4, 0.00286885 ms
[05/21/2025-09:28:10] [V] [TRT] /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool [Int8(51200,25600:32,160,1) -> Int8(12800,6400:32,80,1)] got cached result: CaskPooling, tactic 0xd9375d43b61ffbcb, 0.00265702 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(1638400,25600,160,1) -> Int8(819200,6400,80,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv [Int8(409600,25600:4,160,1) -> Int8(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x0f47434ace2a7d18, 0.0150222 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv [Int8(102400,1:16,640,4) -> Int8(51200,1:16,640,8)] got cached result: CaskConvolution, tactic 0xfc2fdbdaf1a06f8b, 0.0056633 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv [Int8(51200,25600:32,160,1) -> Int8(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x705baf38e41eee0b, 0.00565837 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv [Int8(204800,6400:4,80,1) -> Float(819200,6400,80,1)] got cached result: CaskConvolution, tactic 0x69c4e2ca38eadce2, 0.0214746 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv [Int8(25600,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: CaskConvolution, tactic 0x23b890da05937b9e, 0.0087204 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv [Int8(25600,6400:32,80,1) -> Float(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x2d8ab2aa0639fda9, 0.00924343 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv [Int8(25600,6400:32,80,1) -> Half(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x4133eb8759ee0d6d, 0.00711837 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu [Int8(102400,6400:4,80,1), Float(819200,6400,80,1) -> Float(819200,6400,80,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.00669091 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu [Int8(12800,6400:32,80,1), Float(819200,6400,80,1) -> Float(819200,6400,80,1)] got cached result: CaskConvolution, tactic 0x733ba2a91a48d431, 0.00630917 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu [Int8(12800,6400:32,80,1), Float(25600,6400:32,80,1) -> Float(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x6d377e4222886190, 0.00488808 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu [Int8(12800,6400:32,80,1), Half(25600,6400:32,80,1) -> Half(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x8e1dd2962c589dd4, 0.00372583 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(819200,6400,80,1) -> Int8(819200,6400,80,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv [Int8(204800,6400:4,80,1) -> Int8(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x0f47434ace2a7d18, 0.0263223 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv [Int8(51200,1:16,640,8) -> Int8(51200,1:16,640,8)] got cached result: CaskConvolution, tactic 0xfc2fdbdaf1a06f8b, 0.00784313 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv [Int8(25600,6400:32,80,1) -> Int8(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x214f03e23f252333, 0.00599962 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu [Int8(204800,6400:4,80,1), Float(819200,6400,80,1) -> Float(819200,6400,80,1)] got cached result: CaskConvolution, tactic 0x69c4e2ca38eadce2, 0.022193 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu [Int8(25600,6400:32,80,1), Float(819200,6400,80,1) -> Float(819200,6400,80,1)] got cached result: CaskConvolution, tactic 0xa8b56a226b057463, 0.00932257 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu [Int8(25600,6400:32,80,1), Float(25600,6400:32,80,1) -> Float(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0xad886d4d69834922, 0.00840444 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu [Int8(25600,6400:32,80,1), Half(25600,6400:32,80,1) -> Half(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x4133eb8759ee0d6d, 0.00760373 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool
[05/21/2025-09:28:10] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool [Int8(204800,6400:4,80,1) -> Int8(51200,1600:4,40,1)] got cached result: CaskPooling, tactic 0xb4d3d3158ab4fbc4, 0.0024811 ms
[05/21/2025-09:28:10] [V] [TRT] /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool [Int8(25600,6400:32,80,1) -> Int8(6400,1600:32,40,1)] got cached result: CaskPooling, tactic 0xd9375d43b61ffbcb, 0.00240282 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(819200,6400,80,1) -> Int8(409600,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv [Int8(204800,6400:4,80,1) -> Int8(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x0f47434ace2a7d18, 0.0255977 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv [Int8(51200,1:16,640,8) -> Int8(25600,1:16,640,16)] got cached result: CaskConvolution, tactic 0x43b9fdc4b56fb1b6, 0.00611505 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv [Int8(25600,6400:32,80,1) -> Int8(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0xbb88763c3b0e94d4, 0.00553108 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv [Int8(102400,1600:4,40,1) -> Float(409600,1600,40,1)] got cached result: CaskConvolution, tactic 0x69c4e2ca38eadce2, 0.037632 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv [Int8(12800,1600:32,40,1) -> Float(409600,1600,40,1)] got cached result: CaskConvolution, tactic 0x85c1a5f7f239cf84, 0.008956 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv [Int8(12800,1600:32,40,1) -> Float(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x2d8ab2aa0639fda9, 0.00822476 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv [Int8(12800,1600:32,40,1) -> Half(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0xad6872a374321f7e, 0.00705938 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu [Int8(51200,1600:4,40,1), Float(409600,1600,40,1) -> Float(409600,1600,40,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.00744343 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu [Int8(6400,1600:32,40,1), Float(409600,1600,40,1) -> Float(409600,1600,40,1)] got cached result: CaskConvolution, tactic 0x733ba2a91a48d431, 0.00517943 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu [Int8(6400,1600:32,40,1), Float(12800,1600:32,40,1) -> Float(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x6d377e4222886190, 0.00387126 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu [Int8(6400,1600:32,40,1), Half(12800,1600:32,40,1) -> Half(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x8e1dd2962c589dd4, 0.00332052 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(409600,1600,40,1) -> Int8(409600,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv [Int8(102400,1600:4,40,1) -> Int8(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x0f47434ace2a7d18, 0.0484312 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv [Int8(25600,1:16,640,16) -> Int8(25600,1:16,640,16)] got cached result: CaskConvolution, tactic 0x43b9fdc4b56fb1b6, 0.00900543 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv [Int8(12800,1600:32,40,1) -> Int8(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0xbb88763c3b0e94d4, 0.00704065 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu [Int8(102400,1600:4,40,1), Float(409600,1600,40,1) -> Float(409600,1600,40,1)] got cached result: CaskConvolution, tactic 0x69c4e2ca38eadce2, 0.0384457 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu [Int8(12800,1600:32,40,1), Float(409600,1600,40,1) -> Float(409600,1600,40,1)] got cached result: CaskConvolution, tactic 0x85c1a5f7f239cf84, 0.00976853 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu [Int8(12800,1600:32,40,1), Float(12800,1600:32,40,1) -> Float(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x2d8ab2aa0639fda9, 0.00794591 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu [Int8(12800,1600:32,40,1), Half(12800,1600:32,40,1) -> Half(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0xad6872a374321f7e, 0.00730057 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool
[05/21/2025-09:28:10] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool [Int8(102400,1600:4,40,1) -> Int8(25600,400:4,20,1)] got cached result: CaskPooling, tactic 0xb4d3d3158ab4fbc4, 0.00226229 ms
[05/21/2025-09:28:10] [V] [TRT] /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool [Int8(12800,1600:32,40,1) -> Int8(3200,400:32,20,1)] got cached result: CaskPooling, tactic 0xd9375d43b61ffbcb, 0.00249545 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(409600,1600,40,1) -> Int8(204800,400,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv [Int8(102400,1600:4,40,1) -> Int8(6400,400:32,20,1)] got cached result: CaskConvolution, tactic 0x0f47434ace2a7d18, 0.0475429 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv [Int8(25600,1:16,640,16) -> Int8(12800,1:16,640,32)] got cached result: CaskConvolution, tactic 0x19e870769dcaba51, 0.00750103 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv [Int8(12800,1600:32,40,1) -> Int8(6400,400:32,20,1)] got cached result: CaskConvolution, tactic 0x322f337abc345152, 0.00678483 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv [Int8(51200,400:4,20,1) -> Float(204800,400,20,1)] got cached result: CaskConvolution, tactic 0x69c4e2ca38eadce2, 0.070336 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv [Int8(6400,400:32,20,1) -> Float(204800,400,20,1)] got cached result: CaskConvolution, tactic 0x85c1a5f7f239cf84, 0.0124091 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv [Int8(6400,400:32,20,1) -> Float(6400,400:32,20,1)] got cached result: CaskConvolution, tactic 0x45f7566cdb2b10fb, 0.00999192 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv [Int8(6400,400:32,20,1) -> Half(6400,400:32,20,1)] got cached result: CaskConvolution, tactic 0xc5159665a920f22c, 0.00989562 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu [Int8(25600,400:4,20,1), Float(204800,400,20,1) -> Float(204800,400,20,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.00906171 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu [Int8(3200,400:32,20,1), Float(204800,400,20,1) -> Float(204800,400,20,1)] got cached result: CaskConvolution, tactic 0x5e4f6d7c83746fd6, 0.0050363 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu [Int8(3200,400:32,20,1), Float(6400,400:32,20,1) -> Float(6400,400:32,20,1)] got cached result: CaskConvolution, tactic 0x65fbe45b4cb1d8a5, 0.00351353 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu [Int8(3200,400:32,20,1), Half(6400,400:32,20,1) -> Half(6400,400:32,20,1)] got cached result: CaskConvolution, tactic 0x4f8662a723b489e1, 0.00346133 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,400,20,1) -> Int8(204800,400,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv [Int8(51200,400:4,20,1) -> Int8(6400,400:32,20,1)] got cached result: CaskConvolution, tactic 0x0f47434ace2a7d18, 0.0915749 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv [Int8(12800,1:16,640,32) -> Int8(12800,1:16,640,32)] got cached result: CaskConvolution, tactic 0x22ebff09f6ab32eb, 0.0119867 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv [Int8(6400,400:32,20,1) -> Int8(6400,400:32,20,1)] got cached result: CaskConvolution, tactic 0x1d53511430a5d47e, 0.00944772 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu [Int8(51200,400:4,20,1), Float(204800,400,20,1) -> Float(204800,400,20,1)] got cached result: CaskConvolution, tactic 0x69c4e2ca38eadce2, 0.070944 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu [Int8(6400,400:32,20,1), Float(204800,400,20,1) -> Float(204800,400,20,1)] got cached result: CaskConvolution, tactic 0x85c1a5f7f239cf84, 0.0132085 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu [Int8(6400,400:32,20,1), Float(6400,400:32,20,1) -> Float(6400,400:32,20,1)] got cached result: CaskConvolution, tactic 0x45f7566cdb2b10fb, 0.00999162 ms
[05/21/2025-09:28:10] [V] [TRT] model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu [Int8(6400,400:32,20,1), Half(6400,400:32,20,1) -> Half(6400,400:32,20,1)] got cached result: CaskConvolution, tactic 0xc5159665a920f22c, 0.00994865 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv [Int8(51200,400:4,20,1) -> Float(102400,400,20,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.011725 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv [Int8(6400,400:32,20,1) -> Float(102400,400,20,1)] got cached result: CaskConvolution, tactic 0x5e4f6d7c83746fd6, 0.00408346 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv [Int8(6400,400:32,20,1) -> Float(3200,400:32,20,1)] got cached result: CaskConvolution, tactic 0x6d377e4222886190, 0.00332874 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv [Int8(6400,400:32,20,1) -> Half(3200,400:32,20,1)] got cached result: CaskConvolution, tactic 0x7524377e24bc511f, 0.00333204 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Float(102400,400,20,1) -> Float(102400,400,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] --------------- Timing Runner: {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]} (Myelin[0x80000023])
[05/21/2025-09:28:10] [I] [TRT] Compiler backend is used during engine build.
[05/21/2025-09:28:10] [V] [TRT]  (foreignNode) Set user's cuda kernel library
[05/21/2025-09:28:10] [V] [TRT] Subgraph compilation completed in 0.069 seconds.
[05/21/2025-09:28:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0469211
[05/21/2025-09:28:10] [V] [TRT] {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]} (Myelin[0x80000023]) profiling completed in 0.0999693 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0469211
[05/21/2025-09:28:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Half(102400,400,20,1) -> Half(102400,400,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] --------------- Timing Runner: {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]} (Myelin[0x80000023])
[05/21/2025-09:28:10] [V] [TRT]  (foreignNode) Set user's cuda kernel library
[05/21/2025-09:28:10] [V] [TRT] Subgraph compilation completed in 0.069 seconds.
[05/21/2025-09:28:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0323877
[05/21/2025-09:28:10] [V] [TRT] {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]} (Myelin[0x80000023]) profiling completed in 0.227731 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0323877
[05/21/2025-09:28:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Half(12800,1:8,640,32) -> Half(12800,1:8,640,32) ***************
[05/21/2025-09:28:10] [V] [TRT] --------------- Timing Runner: {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]} (Myelin[0x80000023])
[05/21/2025-09:28:10] [V] [TRT]  (foreignNode) Set user's cuda kernel library
[05/21/2025-09:28:10] [V] [TRT] Subgraph compilation completed in 0.046 seconds.
[05/21/2025-09:28:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.03072
[05/21/2025-09:28:10] [V] [TRT] {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]} (Myelin[0x80000023]) profiling completed in 0.065727 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.03072
[05/21/2025-09:28:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: BFloat16(102400,400,20,1) -> BFloat16(102400,400,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] --------------- Timing Runner: {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]} (Myelin[0x80000023])
[05/21/2025-09:28:10] [V] [TRT]  (foreignNode) Set user's cuda kernel library
[05/21/2025-09:28:10] [V] [TRT] Subgraph compilation completed in 0.062 seconds.
[05/21/2025-09:28:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0340553
[05/21/2025-09:28:10] [V] [TRT] {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]} (Myelin[0x80000023]) profiling completed in 0.14513 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0340553
[05/21/2025-09:28:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(819200,6400,80,1) -> Int8(3276800,6400,80,1) long-strided ***************
[05/21/2025-09:28:10] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(819200,6400,80,1) -> Int8(1638400,6400,80,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv [Int8(204800,6400:4,80,1) -> Int8(102400,6400:32,80,1) long-strided] got cached result: CaskConvolution, tactic 0x7a2c2a831965ff85, 0.00797816 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv [Int8(204800,6400:4,80,1) -> Int8(51200,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x7a2c2a831965ff85, 0.00796368 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv [Int8(51200,1:16,640,8) -> Int8(204800,1:16,2560,32) long-strided] got cached result: CaskConvolution, tactic 0x5693be686f87be25, 0.00520637 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv [Int8(51200,1:16,640,8) -> Int8(102400,1:16,1280,16)] got cached result: CaskConvolution, tactic 0x5693be686f87be25, 0.00517045 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv [Int8(25600,6400:32,80,1) -> Int8(102400,6400:32,80,1) long-strided] got cached result: CaskConvolution, tactic 0x483ad1560c6e5e27, 0.00468896 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv [Int8(25600,6400:32,80,1) -> Int8(51200,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x5e4918ccf433630e, 0.00458114 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(409600,1600,40,1) -> Int8(819200,1600,40,1) long-strided ***************
[05/21/2025-09:28:10] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(409600,1600,40,1) -> Int8(409600,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv [Int8(102400,1600:4,40,1) -> Int8(25600,1600:32,40,1) long-strided] got cached result: CaskConvolution, tactic 0x7a2c2a831965ff85, 0.00683233 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv [Int8(102400,1600:4,40,1) -> Int8(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x7a2c2a831965ff85, 0.00687303 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv [Int8(25600,1:16,640,16) -> Int8(51200,1:16,1280,32) long-strided] got cached result: CaskConvolution, tactic 0x22ebff09f6ab32eb, 0.00368867 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv [Int8(25600,1:16,640,16) -> Int8(25600,1:16,640,16)] got cached result: CaskConvolution, tactic 0x788dd0382d5ebd44, 0.00357451 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv [Int8(12800,1600:32,40,1) -> Int8(25600,1600:32,40,1) long-strided] got cached result: CaskConvolution, tactic 0x483ad1560c6e5e27, 0.00342977 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv [Int8(12800,1600:32,40,1) -> Int8(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x483ad1560c6e5e27, 0.00342705 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv [Int8(25600,400:4,20,1) -> Float(102400,400,20,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.0083327 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv [Int8(3200,400:32,20,1) -> Float(102400,400,20,1)] got cached result: CaskConvolution, tactic 0x5e4f6d7c83746fd6, 0.00400127 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv [Int8(3200,400:32,20,1) -> Float(3200,400:32,20,1)] got cached result: CaskConvolution, tactic 0x6d377e4222886190, 0.00294652 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv [Int8(3200,400:32,20,1) -> Half(3200,400:32,20,1)] got cached result: CaskConvolution, tactic 0x7524377e24bc511f, 0.00295109 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Float(102400,400,20,1) -> Float(102400,400,20,1)] got cached result: PointWiseV2, tactic 0x0000000000000005, 0.001896 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Float(102400,400,20,1) -> Half(102400,400,20,1)] got cached result: PointWiseV2, tactic 0x0000000000000005, 0.00189738 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Float(102400,1,5120,256) -> Float(102400,1,5120,256)] got cached result: PointWiseV2, tactic 0x0000000000000005, 0.00189107 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Float(1,400,20,1) -> Float(1,400,20,1)] got cached result: PointWiseV2, tactic 0x0000000000000005, 0.00190436 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Float(25600,1:4,1280,64) -> Float(25600,1:4,1280,64)] got cached result: PointWiseV2, tactic 0x0000000000000000, 0.001904 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Float(3200,400:32,20,1) -> Float(3200,400:32,20,1)] got cached result: PointWiseV2, tactic 0x000000000000001f, 0.00209285 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Float(3200,400:32,20,1) -> Half(3200,400:32,20,1)] got cached result: PointWiseV2, tactic 0x000000000000001f, 0.0020753 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Float(1:4,400,20,1) -> Float(1:4,400,20,1)] got cached result: PointWiseV2, tactic 0x000000000000001d, 0.00343815 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Half(102400,400,20,1) -> Float(102400,400,20,1)] got cached result: PointWiseV2, tactic 0x0000000000000005, 0.00206302 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Half(102400,400,20,1) -> Half(102400,400,20,1)] got cached result: PointWiseV2, tactic 0x0000000000000005, 0.00206126 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Half(51200,1:2,2560,128) -> Half(51200,1:2,2560,128)] got cached result: PointWiseV2, tactic 0x000000000000000f, 0.00207059 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Half(12800,1:8,640,32) -> Half(12800,1:8,640,32)] got cached result: PointWiseV2, tactic 0x000000000000001c, 0.002045 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Half(6400,1:16,320,16) -> Half(6400,1:16,320,16)] got cached result: PointWiseV2, tactic 0x000000000000001d, 0.002051 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Half(3200,400:32,20,1) -> Float(3200,400:32,20,1)] got cached result: PointWiseV2, tactic 0x0000000000000018, 0.00205153 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Half(3200,400:32,20,1) -> Half(3200,400:32,20,1)] got cached result: PointWiseV2, tactic 0x0000000000000018, 0.00205995 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Half(1:8,400,20,1) -> Half(1:8,400,20,1)] got cached result: PointWiseV2, tactic 0x000000000000001d, 0.00351476 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) [Half(102400:32,400,20,1) -> Half(102400:32,400,20,1)] got cached result: PointWiseV2, tactic 0x0000000000000014, 0.00808686 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for /model/encoder/Resize
[05/21/2025-09:28:10] [V] [TRT] /model/encoder/Resize [Int8(102400,400,20,1) -> Int8(409600,1600,40,1)] got cached result: Resize, tactic 0x0000000000000000, 0.00950486 ms
[05/21/2025-09:28:10] [V] [TRT] /model/encoder/Resize [Int8(3200,400:32,20,1) -> Int8(12800,1600:32,40,1)] got cached result: Resize, tactic 0x0000000000000003, 0.00233563 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv [Int8(204800,1600:4,40,1) -> Float(204800,1600,40,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.012856 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv [Int8(25600,1600:32,40,1) -> Float(204800,1600,40,1)] got cached result: CaskConvolution, tactic 0x733ba2a91a48d431, 0.00522449 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv [Int8(25600,1600:32,40,1) -> Float(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x9ec201b34455146e, 0.00441461 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv [Int8(25600,1600:32,40,1) -> Half(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x8e1dd2962c589dd4, 0.00413048 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(819200,1600,40,1) -> Int8(204800,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,1600:4,40,1) -> Int8(6400,1600:32,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,1:16,1280,32) -> Int8(12800,1:16,320,8) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul) [Int8(25600,1600:32,40,1) -> Int8(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x2eba0b6a8ec55fa3, 0.00383976 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,1600,40,1) -> Int8(204800,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,1600:4,40,1) -> Int8(6400,1600:32,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(12800,1:16,320,8) -> Int8(12800,1:16,320,8) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul) [Int8(6400,1600:32,40,1) -> Int8(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x6176c23707257237, 0.00490895 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,1600,40,1) -> Int8(204800,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,1600:4,40,1) -> Int8(6400,1600:32,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(12800,1:16,320,8) -> Int8(12800,1:16,320,8) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul) [Int8(6400,1600:32,40,1) -> Int8(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x6176c23707257237, 0.00490895 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Int8(51200,1600:4,40,1) -> Float(204800,1600,40,1)] got cached result: CaskConvolution, tactic 0x69c4e2ca38eadce2, 0.02125 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Int8(6400,1600:32,40,1) -> Float(204800,1600,40,1)] got cached result: CaskConvolution, tactic 0x85c1a5f7f239cf84, 0.0059621 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Int8(6400,1600:32,40,1) -> Float(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0xb936321f82fd390c, 0.00505379 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Int8(6400,1600:32,40,1) -> Half(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0xad6872a374321f7e, 0.00478781 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add)) [Float(204800,1600,40,1), Float(204800,1600,40,1) -> Int8(204800,1600,40,1)] got cached result: PointWiseV2, tactic 0x0000000000000002, 0.00238598 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add)) [Float(6400,1600:32,40,1), Float(6400,1600:32,40,1) -> Int8(6400,1600:32,40,1)] got cached result: PointWiseV2, tactic 0x0000000000000015, 0.00291017 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add)) [Half(204800,1600,40,1), Half(204800,1600,40,1) -> Int8(204800,1600,40,1)] got cached result: PointWiseV2, tactic 0x0000000000000005, 0.00245687 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add)) [Half(6400,1600:32,40,1), Half(6400,1600:32,40,1) -> Int8(6400,1600:32,40,1)] got cached result: PointWiseV2, tactic 0x0000000000000018, 0.0025738 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,1600,40,1) -> Int8(409600,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,1600:4,40,1) -> Int8(12800,1600:32,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(12800,1:16,320,8) -> Int8(25600,1:16,640,16) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul) [Int8(6400,1600:32,40,1) -> Int8(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x2eba0b6a8ec55fa3, 0.00347592 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(409600,1600,40,1) -> Int8(409600,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(102400,1600:4,40,1) -> Int8(12800,1600:32,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(25600,1:16,640,16) -> Int8(25600,1:16,640,16) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul) [Int8(12800,1600:32,40,1) -> Int8(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x2eba0b6a8ec55fa3, 0.0040066 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for /model/encoder/Resize_1
[05/21/2025-09:28:10] [V] [TRT] /model/encoder/Resize_1 [Int8(409600,1600,40,1) -> Int8(1638400,6400,80,1)] got cached result: Resize, tactic 0x0000000000000000, 0.0314103 ms
[05/21/2025-09:28:10] [V] [TRT] /model/encoder/Resize_1 [Int8(12800,1600:32,40,1) -> Int8(51200,6400:32,80,1)] got cached result: Resize, tactic 0x0000000000000005, 0.00324124 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv [Int8(819200,6400:4,80,1) -> Float(819200,6400,80,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.0130298 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv [Int8(102400,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: CaskConvolution, tactic 0x733ba2a91a48d431, 0.00845903 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv [Int8(102400,6400:32,80,1) -> Float(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x5f1a472d416ff35e, 0.00789317 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv [Int8(102400,6400:32,80,1) -> Half(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x758f8b2079a95b2e, 0.00552967 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(3276800,6400,80,1) -> Int8(819200,6400,80,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(819200,6400:4,80,1) -> Int8(25600,6400:32,80,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,1:16,2560,32) -> Int8(51200,1:16,640,8) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul) [Int8(102400,6400:32,80,1) -> Int8(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x458f02d2b10db57c, 0.00554127 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(819200,6400,80,1) -> Int8(819200,6400,80,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,6400:4,80,1) -> Int8(25600,6400:32,80,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,1:16,640,8) -> Int8(51200,1:16,640,8) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul) [Int8(25600,6400:32,80,1) -> Int8(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0xfdf7509af98902e0, 0.0069218 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(819200,6400,80,1) -> Int8(819200,6400,80,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,6400:4,80,1) -> Int8(25600,6400:32,80,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,1:16,640,8) -> Int8(51200,1:16,640,8) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul) [Int8(25600,6400:32,80,1) -> Int8(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0xfdf7509af98902e0, 0.0069218 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Int8(204800,6400:4,80,1) -> Float(819200,6400,80,1)] got cached result: CaskConvolution, tactic 0x69c4e2ca38eadce2, 0.0214746 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Int8(25600,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: CaskConvolution, tactic 0x23b890da05937b9e, 0.0087204 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Int8(25600,6400:32,80,1) -> Float(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x2d8ab2aa0639fda9, 0.00924343 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Int8(25600,6400:32,80,1) -> Half(25600,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x4133eb8759ee0d6d, 0.00711837 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add)) [Float(819200,6400,80,1), Float(819200,6400,80,1) -> Int8(819200,6400,80,1)] got cached result: PointWiseV2, tactic 0x0000000000000005, 0.00337031 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add)) [Float(25600,6400:32,80,1), Float(25600,6400:32,80,1) -> Int8(25600,6400:32,80,1)] got cached result: PointWiseV2, tactic 0x0000000000000019, 0.00548131 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add)) [Half(819200,6400,80,1), Half(819200,6400,80,1) -> Int8(819200,6400,80,1)] got cached result: PointWiseV2, tactic 0x0000000000000005, 0.00303028 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add)) [Half(25600,6400:32,80,1), Half(25600,6400:32,80,1) -> Int8(25600,6400:32,80,1)] got cached result: PointWiseV2, tactic 0x000000000000001f, 0.00386224 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(819200,6400,80,1) -> Int8(1638400,6400,80,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,6400:4,80,1) -> Int8(51200,6400:32,80,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,1:16,640,8) -> Int8(102400,1:16,1280,16) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul) [Int8(25600,6400:32,80,1) -> Int8(51200,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x65a38dbc9e991257, 0.00473983 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv [Int8(409600,6400:4,80,1) -> Float(1638400,6400,80,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.011718 ms
[05/21/2025-09:28:10] [V] [TRT] model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv [Int8(51200,6400:32,80,1) -> Float(1638400,6400,80,1)] got cached result: CaskConvolution, tactic 0x733ba2a91a48d431, 0.00969478 ms
[05/21/2025-09:28:10] [V] [TRT] model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv [Int8(51200,6400:32,80,1) -> Float(51200,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x9ec201b34455146e, 0.00913886 ms
[05/21/2025-09:28:10] [V] [TRT] model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv [Int8(51200,6400:32,80,1) -> Half(51200,6400:32,80,1)] got cached result: CaskConvolution, tactic 0x8486adb55ae0ca6c, 0.00603848 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(1638400,6400,80,1) -> Int8(819200,1600,40,1) long-strided ***************
[05/21/2025-09:28:10] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(1638400,6400,80,1) -> Int8(409600,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(409600,6400:4,80,1) -> Int8(25600,1600:32,40,1) long-strided ***************
[05/21/2025-09:28:10] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(409600,6400:4,80,1) -> Int8(12800,1600:32,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(102400,1:16,1280,16) -> Int8(51200,1:16,1280,32) long-strided ***************
[05/21/2025-09:28:10] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(102400,1:16,1280,16) -> Int8(25600,1:16,640,16) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul) [Int8(51200,6400:32,80,1) -> Int8(25600,1600:32,40,1) long-strided] got cached result: CaskConvolution, tactic 0xc722efd60bc6ea84, 0.00794235 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul) [Int8(51200,6400:32,80,1) -> Int8(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0xc722efd60bc6ea84, 0.00795098 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv [Int8(204800,1600:4,40,1) -> Float(204800,1600,40,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.012856 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv [Int8(25600,1600:32,40,1) -> Float(204800,1600,40,1)] got cached result: CaskConvolution, tactic 0x733ba2a91a48d431, 0.00522449 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv [Int8(25600,1600:32,40,1) -> Float(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x9ec201b34455146e, 0.00441461 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv [Int8(25600,1600:32,40,1) -> Half(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x8e1dd2962c589dd4, 0.00413048 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(819200,1600,40,1) -> Int8(204800,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,1600:4,40,1) -> Int8(6400,1600:32,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,1:16,1280,32) -> Int8(12800,1:16,320,8) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul) [Int8(25600,1600:32,40,1) -> Int8(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x2eba0b6a8ec55fa3, 0.00383976 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,1600,40,1) -> Int8(204800,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,1600:4,40,1) -> Int8(6400,1600:32,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(12800,1:16,320,8) -> Int8(12800,1:16,320,8) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul) [Int8(6400,1600:32,40,1) -> Int8(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x6176c23707257237, 0.00490895 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,1600,40,1) -> Int8(204800,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,1600:4,40,1) -> Int8(6400,1600:32,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(12800,1:16,320,8) -> Int8(12800,1:16,320,8) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul) [Int8(6400,1600:32,40,1) -> Int8(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x6176c23707257237, 0.00490895 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Int8(51200,1600:4,40,1) -> Float(204800,1600,40,1)] got cached result: CaskConvolution, tactic 0x69c4e2ca38eadce2, 0.02125 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Int8(6400,1600:32,40,1) -> Float(204800,1600,40,1)] got cached result: CaskConvolution, tactic 0x85c1a5f7f239cf84, 0.0059621 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Int8(6400,1600:32,40,1) -> Float(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0xb936321f82fd390c, 0.00505379 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv [Int8(6400,1600:32,40,1) -> Half(6400,1600:32,40,1)] got cached result: CaskConvolution, tactic 0xad6872a374321f7e, 0.00478781 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add)) [Float(204800,1600,40,1), Float(204800,1600,40,1) -> Int8(204800,1600,40,1)] got cached result: PointWiseV2, tactic 0x0000000000000002, 0.00238598 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add)) [Float(6400,1600:32,40,1), Float(6400,1600:32,40,1) -> Int8(6400,1600:32,40,1)] got cached result: PointWiseV2, tactic 0x0000000000000015, 0.00291017 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add)) [Half(204800,1600,40,1), Half(204800,1600,40,1) -> Int8(204800,1600,40,1)] got cached result: PointWiseV2, tactic 0x0000000000000005, 0.00245687 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add)) [Half(6400,1600:32,40,1), Half(6400,1600:32,40,1) -> Int8(6400,1600:32,40,1)] got cached result: PointWiseV2, tactic 0x0000000000000018, 0.0025738 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,1600,40,1) -> Int8(409600,1600,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,1600:4,40,1) -> Int8(12800,1600:32,40,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(12800,1:16,320,8) -> Int8(25600,1:16,640,16) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul) [Int8(6400,1600:32,40,1) -> Int8(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x2eba0b6a8ec55fa3, 0.00347592 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv [Int8(102400,1600:4,40,1) -> Float(409600,1600,40,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.00835225 ms
[05/21/2025-09:28:10] [V] [TRT] model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv [Int8(12800,1600:32,40,1) -> Float(409600,1600,40,1)] got cached result: CaskConvolution, tactic 0x733ba2a91a48d431, 0.00446074 ms
[05/21/2025-09:28:10] [V] [TRT] model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv [Int8(12800,1600:32,40,1) -> Float(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x6d377e4222886190, 0.00445687 ms
[05/21/2025-09:28:10] [V] [TRT] model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv [Int8(12800,1600:32,40,1) -> Half(12800,1600:32,40,1)] got cached result: CaskConvolution, tactic 0x8e1dd2962c589dd4, 0.00359977 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(409600,1600,40,1) -> Int8(204800,400,20,1) long-strided ***************
[05/21/2025-09:28:10] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(409600,1600,40,1) -> Int8(102400,400,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(102400,1600:4,40,1) -> Int8(6400,400:32,20,1) long-strided ***************
[05/21/2025-09:28:10] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(102400,1600:4,40,1) -> Int8(3200,400:32,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(25600,1:16,640,16) -> Int8(12800,1:16,640,32) long-strided ***************
[05/21/2025-09:28:10] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(25600,1:16,640,16) -> Int8(6400,1:16,320,16) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul) [Int8(12800,1600:32,40,1) -> Int8(6400,400:32,20,1) long-strided] got cached result: CaskConvolution, tactic 0xc985777c89c6b3a4, 0.00535263 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul) [Int8(12800,1600:32,40,1) -> Int8(3200,400:32,20,1)] got cached result: CaskConvolution, tactic 0xc985777c89c6b3a4, 0.00533672 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv [Int8(51200,400:4,20,1) -> Float(51200,400,20,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.0115524 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv [Int8(6400,400:32,20,1) -> Float(51200,400,20,1)] got cached result: CaskConvolution, tactic 0x5e4f6d7c83746fd6, 0.00439231 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv [Int8(6400,400:32,20,1) -> Float(1600,400:32,20,1)] got cached result: CaskConvolution, tactic 0x6d377e4222886190, 0.00312109 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv [Int8(6400,400:32,20,1) -> Half(1600,400:32,20,1)] got cached result: CaskConvolution, tactic 0x7524377e24bc511f, 0.00312248 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(204800,400,20,1) -> Int8(51200,400,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,400:4,20,1) -> Int8(1600,400:32,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(12800,1:16,640,32) -> Int8(3200,1:16,160,8) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul) [Int8(6400,400:32,20,1) -> Int8(1600,400:32,20,1)] got cached result: CaskConvolution, tactic 0xc6cdb1e47323bb01, 0.00316929 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,400,20,1) -> Int8(51200,400,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(12800,400:4,20,1) -> Int8(1600,400:32,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(3200,1:16,160,8) -> Int8(3200,1:16,160,8) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul) [Int8(1600,400:32,20,1) -> Int8(1600,400:32,20,1)] got cached result: CaskConvolution, tactic 0xc985777c89c6b3a4, 0.00403086 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,400,20,1) -> Int8(51200,400,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(12800,400:4,20,1) -> Int8(1600,400:32,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(3200,1:16,160,8) -> Int8(3200,1:16,160,8) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul) [Int8(1600,400:32,20,1) -> Int8(1600,400:32,20,1)] got cached result: CaskConvolution, tactic 0xc985777c89c6b3a4, 0.00403086 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Int8(12800,400:4,20,1) -> Float(51200,400,20,1)] got cached result: CaskConvolution, tactic 0x69c4e2ca38eadce2, 0.0212728 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Int8(1600,400:32,20,1) -> Float(51200,400,20,1)] got cached result: CaskConvolution, tactic 0x85c1a5f7f239cf84, 0.00589842 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Int8(1600,400:32,20,1) -> Float(1600,400:32,20,1)] got cached result: CaskConvolution, tactic 0xd14bd6d95fefd45e, 0.00399873 ms
[05/21/2025-09:28:10] [V] [TRT] model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv [Int8(1600,400:32,20,1) -> Half(1600,400:32,20,1)] got cached result: CaskConvolution, tactic 0x51a916d02de43689, 0.00401676 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add)) [Float(51200,400,20,1), Float(51200,400,20,1) -> Int8(51200,400,20,1)] got cached result: PointWiseV2, tactic 0x000000000000001c, 0.00202102 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add)) [Float(1600,400:32,20,1), Float(1600,400:32,20,1) -> Int8(1600,400:32,20,1)] got cached result: PointWiseV2, tactic 0x0000000000000018, 0.00211785 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add)) [Half(51200,400,20,1), Half(51200,400,20,1) -> Int8(51200,400,20,1)] got cached result: PointWiseV2, tactic 0x000000000000001c, 0.00202347 ms
[05/21/2025-09:28:10] [V] [TRT] PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add)) [Half(1600,400:32,20,1), Half(1600,400:32,20,1) -> Int8(1600,400:32,20,1)] got cached result: PointWiseV2, tactic 0x0000000000000018, 0.00209007 ms
[05/21/2025-09:28:10] [V] [TRT] =============== Computing costs for model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(51200,400,20,1) -> Int8(102400,400,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(12800,400:4,20,1) -> Int8(3200,400:32,20,1) ***************
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:10] [V] [TRT] *************** Autotuning format combination: Int8(3200,1:16,160,8) -> Int8(6400,1:16,320,16) ***************
[05/21/2025-09:28:11] [V] [TRT] Skipping CaskConvolution: No valid tactics for model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:11] [V] [TRT] Skipping CaskFlattenConvolution: No valid tactics for model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)
[05/21/2025-09:28:11] [V] [TRT] model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul) [Int8(1600,400:32,20,1) -> Int8(3200,400:32,20,1)] got cached result: CaskConvolution, tactic 0xc6cdb1e47323bb01, 0.00273863 ms
[05/21/2025-09:28:11] [V] [TRT] =============== Computing costs for model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv
[05/21/2025-09:28:11] [V] [TRT] model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv [Int8(25600,400:4,20,1) -> Float(102400,400,20,1)] got cached result: CaskConvolution, tactic 0xff6944b17d5b2e32, 0.00832711 ms
[05/21/2025-09:28:11] [V] [TRT] model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv [Int8(3200,400:32,20,1) -> Float(102400,400,20,1)] got cached result: CaskConvolution, tactic 0x5e4f6d7c83746fd6, 0.0036916 ms
[05/21/2025-09:28:11] [V] [TRT] model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv [Int8(3200,400:32,20,1) -> Float(3200,400:32,20,1)] got cached result: CaskConvolution, tactic 0x6d377e4222886190, 0.00295818 ms
[05/21/2025-09:28:11] [V] [TRT] model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv [Int8(3200,400:32,20,1) -> Half(3200,400:32,20,1)] got cached result: CaskConvolution, tactic 0x7524377e24bc511f, 0.00296126 ms
[05/21/2025-09:28:11] [V] [TRT] =============== Computing costs for {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]}
[05/21/2025-09:28:11] [V] [TRT] *************** Autotuning format combination: Int64(2,1), Float(1638400,6400,80,1), Float(409600,1600,40,1), Float(102400,400,20,1) -> Int64(300,1), Float(1200,4,1), Float(300,1) ***************
[05/21/2025-09:28:11] [V] [TRT] --------------- Timing Runner: {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]} (Myelin[0x80000023])
[05/21/2025-09:28:13] [V] [TRT]  (foreignNode) Set user's cuda kernel library
[05/21/2025-09:28:13] [V] [TRT] Subgraph compilation completed in 2.223 seconds.
[05/21/2025-09:28:13] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.411209
[05/21/2025-09:28:13] [V] [TRT] {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]} (Myelin[0x80000023]) profiling completed in 2.34817 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.411209
[05/21/2025-09:28:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[05/21/2025-09:28:13] [V] [TRT] *************** Autotuning format combination: Int64(2,1), Half(1638400,6400,80,1), Half(409600,1600,40,1), Half(102400,400,20,1) -> Int64(300,1), Half(1200,4,1), Half(300,1) ***************
[05/21/2025-09:28:13] [V] [TRT] --------------- Timing Runner: {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]} (Myelin[0x80000023])
[05/21/2025-09:28:15] [V] [TRT]  (foreignNode) Set user's cuda kernel library
[05/21/2025-09:28:15] [V] [TRT]  (foreignNode) infusible
[05/21/2025-09:28:15] [V] [TRT] Subgraph compilation completed in 2.222 seconds.
[05/21/2025-09:28:15] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.467529
[05/21/2025-09:28:15] [V] [TRT] {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]} (Myelin[0x80000023]) profiling completed in 2.38281 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.467529
[05/21/2025-09:28:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[05/21/2025-09:28:15] [V] [TRT] *************** Autotuning format combination: Int64(2,1), Half(204800,1:8,2560,32), Half(51200,1:8,1280,32), Half(12800,1:8,640,32) -> Int64(300,1), Float(1200,4,1), Float(300,1) ***************
[05/21/2025-09:28:15] [V] [TRT] --------------- Timing Runner: {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]} (Myelin[0x80000023])
[05/21/2025-09:28:18] [V] [TRT]  (foreignNode) Set user's cuda kernel library
[05/21/2025-09:28:18] [V] [TRT]  (foreignNode) infusible
[05/21/2025-09:28:18] [V] [TRT] Subgraph compilation completed in 2.228 seconds.
[05/21/2025-09:28:18] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.488448
[05/21/2025-09:28:18] [V] [TRT] {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]} (Myelin[0x80000023]) profiling completed in 2.38734 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.488448
[05/21/2025-09:28:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[05/21/2025-09:28:18] [V] [TRT] *************** Autotuning format combination: Int64(2,1), BFloat16(1638400,6400,80,1), BFloat16(409600,1600,40,1), BFloat16(102400,400,20,1) -> Int64(300,1), BFloat16(1200,4,1), BFloat16(300,1) ***************
[05/21/2025-09:28:18] [V] [TRT] --------------- Timing Runner: {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]} (Myelin[0x80000023])
[05/21/2025-09:28:20] [V] [TRT]  (foreignNode) Set user's cuda kernel library
[05/21/2025-09:28:20] [V] [TRT] Subgraph compilation completed in 2.462 seconds.
[05/21/2025-09:28:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.471186
[05/21/2025-09:28:20] [V] [TRT] {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]} (Myelin[0x80000023]) profiling completed in 2.78646 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.471186
[05/21/2025-09:28:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear [Float(1228800,409600,640,1) -> Int8(1228800,409600,640,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.004517 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear [Float(1228800,409600,640,1) -> Int8(409600,409600:4,640,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00360617 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear [Float(1228800,409600,640,1) -> Int8(409600,1:16,640,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0235533 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear [Float(1228800,409600,640,1) -> Int8(409600,409600:32,640,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0183783 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1228800,409600,640,1) -> Int8(409600,409600:4,640,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00578834 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1228800,409600,640,1) -> Int8(409600,1:16,640,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0246941 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1228800,409600,640,1) -> Int8(409600,409600:32,640,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0220473 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,409600:4,640,1) -> Int8(1228800,409600,640,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00809676 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,409600:4,640,1) -> Int8(409600,1:16,640,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0116121 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,409600:4,640,1) -> Int8(409600,409600:32,640,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0155744 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1:16,640,1) -> Int8(1228800,409600,640,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00842703 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1:16,640,1) -> Int8(409600,409600:4,640,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0103758 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1:16,640,1) -> Int8(409600,409600:32,640,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0235696 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,409600:32,640,1) -> Int8(1228800,409600,640,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0113009 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,409600:32,640,1) -> Int8(409600,409600:4,640,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00480579 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,409600:32,640,1) -> Int8(409600,1:16,640,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0123432 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1:16,640,2) -> Int8(819200,102400:4,320,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0130126 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1:16,640,2) -> Int8(102400,102400:32,320,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0131059 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,102400:32,320,1) -> Int8(819200,102400:4,320,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00439799 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,102400:32,320,1) -> Int8(204800,1:16,640,2)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0110864 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1:16,640,2) -> Int8(819200,102400:4,320,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0130126 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1:16,640,2) -> Int8(102400,102400:32,320,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0131059 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,102400:32,320,1) -> Int8(819200,102400:4,320,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00439799 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,102400:32,320,1) -> Int8(204800,1:16,640,2)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0110864 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/MaxPool_output_0 -> <out>) [Int8(409600,1:16,1280,4) -> Int8(1638400,102400:4,320,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0114054 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/MaxPool_output_0 -> <out>) [Int8(409600,1:16,1280,4) -> Int8(204800,102400:32,320,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.011852 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/MaxPool_output_0 -> <out>) [Int8(204800,102400:32,320,1) -> Int8(1638400,102400:4,320,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00615657 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0) [Int8(409600,25600:4,160,1) -> Int8(1638400,25600,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0100934 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0) [Int8(409600,25600:4,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0106903 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0) [Int8(409600,25600:4,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00366371 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0) [Int8(51200,25600:32,160,1) -> Int8(1638400,25600,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00938857 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0) [Int8(51200,25600:32,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00329527 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0) [Int8(51200,25600:32,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00788042 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00441461 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00756138 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00778538 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,25600:4,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00790496 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,25600:4,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00366711 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00744891 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00759579 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,25600:32,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00325735 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,25600:32,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00712991 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00744891 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00759579 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,25600:32,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00325735 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00441461 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00778538 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,25600:4,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00366711 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00744891 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00759579 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,25600:32,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00325735 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(1638400,25600,160,1) -> Float(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00717577 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(1638400,25600,160,1) -> Half(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00640358 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(51200,25600:32,160,1) -> Float(1638400,25600,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00671626 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(51200,25600:32,160,1) -> Half(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00726217 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Half(51200,25600:32,160,1) -> Float(1638400,25600,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00781353 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Half(51200,25600:32,160,1) -> Float(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00829308 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.0/blocks.0/act/Relu_output_0) [Float(1638400,25600,160,1) -> Float(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0110073 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.0/blocks.0/act/Relu_output_0) [Float(1638400,25600,160,1) -> Half(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0144256 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.0/blocks.0/act/Relu_output_0) [Float(51200,25600:32,160,1) -> Float(1638400,25600,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0196863 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.0/blocks.0/act/Relu_output_0) [Float(51200,25600:32,160,1) -> Half(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0248488 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.0/blocks.0/act/Relu_output_0) [Half(51200,25600:32,160,1) -> Float(1638400,25600,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.012253 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.0/blocks.0/act/Relu_output_0) [Half(51200,25600:32,160,1) -> Float(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0219402 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(1638400,25600,160,1) -> Int8(1638400,25600,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00485349 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(1638400,25600,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00336904 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(1638400,25600,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00883254 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(1638400,25600,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00953996 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(51200,25600:32,160,1) -> Int8(1638400,25600,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00962591 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(51200,25600:32,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00982583 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(51200,25600:32,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00891375 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(51200,25600:32,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00932286 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(51200,25600:32,160,1) -> Int8(1638400,25600,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00894 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(51200,25600:32,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00769925 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(51200,25600:32,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00805333 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(51200,25600:32,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00777456 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00441461 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00756138 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00778538 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,25600:4,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00790496 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,25600:4,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00366711 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00744891 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00759579 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,25600:32,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00325735 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,25600:32,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00712991 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00744891 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00759579 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,25600:32,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00325735 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/act/Relu_output_0 -> <out>) [Float(1638400,25600,160,1) -> Float(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00717577 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/act/Relu_output_0 -> <out>) [Float(1638400,25600,160,1) -> Half(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00640358 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/act/Relu_output_0 -> <out>) [Float(51200,25600:32,160,1) -> Float(1638400,25600,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00671626 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/act/Relu_output_0 -> <out>) [Float(51200,25600:32,160,1) -> Half(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00726217 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/act/Relu_output_0 -> <out>) [Half(51200,25600:32,160,1) -> Float(1638400,25600,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00781353 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.0/blocks.0/act/Relu_output_0 -> <out>) [Half(51200,25600:32,160,1) -> Float(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00829308 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(1638400,25600,160,1) -> Int8(1638400,25600,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00485349 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(1638400,25600,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00336904 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(1638400,25600,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00883254 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(1638400,25600,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00953996 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(51200,25600:32,160,1) -> Int8(1638400,25600,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00962591 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(51200,25600:32,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00982583 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(51200,25600:32,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00891375 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(51200,25600:32,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00932286 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Half(51200,25600:32,160,1) -> Int8(1638400,25600,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00894 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Half(51200,25600:32,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00769925 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Half(51200,25600:32,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00805333 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Half(51200,25600:32,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00777456 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00441461 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00778538 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,25600:4,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00366711 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00744891 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00759579 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,25600:32,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00325735 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00441461 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00756138 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,25600,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00778538 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,25600:4,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00790496 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,25600:4,160,1) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00366711 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00744891 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,640,4) -> Int8(51200,25600:32,160,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00759579 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,25600:32,160,1) -> Int8(409600,25600:4,160,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00325735 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,25600:32,160,1) -> Int8(102400,1:16,640,4)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00712991 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,640,8) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00715954 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,640,8) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0073344 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,6400:32,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00251605 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,6400:4,80,1) -> Int8(12800,6400:32,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00220898 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,6400:32,80,1) -> Int8(102400,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00224007 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(819200,6400,80,1) -> Float(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00525845 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(819200,6400,80,1) -> Half(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00531708 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(25600,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00572343 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(25600,6400:32,80,1) -> Half(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00586533 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Half(25600,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00594304 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Half(25600,6400:32,80,1) -> Float(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00617276 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.1/blocks.0/act/Relu_output_0) [Float(819200,6400,80,1) -> Float(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00655003 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.1/blocks.0/act/Relu_output_0) [Float(819200,6400,80,1) -> Half(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00685301 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.1/blocks.0/act/Relu_output_0) [Float(25600,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00690852 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.1/blocks.0/act/Relu_output_0) [Float(25600,6400:32,80,1) -> Half(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00679564 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.1/blocks.0/act/Relu_output_0) [Half(25600,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00682122 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.1/blocks.0/act/Relu_output_0) [Half(25600,6400:32,80,1) -> Float(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00721006 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(819200,6400,80,1) -> Int8(819200,6400,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00335564 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(819200,6400,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00261203 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(819200,6400,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00584101 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(819200,6400,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00602895 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(25600,6400:32,80,1) -> Int8(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00610857 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(25600,6400:32,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00638311 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(25600,6400:32,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x0000000000000000, 0.00546303 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(25600,6400:32,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00630599 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(25600,6400:32,80,1) -> Int8(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00656603 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(25600,6400:32,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00501643 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(25600,6400:32,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00555182 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(25600,6400:32,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00600495 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00289783 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00580992 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00626564 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,6400:4,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00605333 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,6400:4,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00277749 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,640,8) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00715954 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,640,8) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0073344 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,6400:32,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00251605 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,6400:32,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003ea, 0.005616 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,640,8) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00715954 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,640,8) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0073344 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,6400:32,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00251605 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/act/Relu_output_0 -> <out>) [Float(819200,6400,80,1) -> Float(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00525845 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/act/Relu_output_0 -> <out>) [Float(819200,6400,80,1) -> Half(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00531708 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/act/Relu_output_0 -> <out>) [Float(25600,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00572343 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/act/Relu_output_0 -> <out>) [Float(25600,6400:32,80,1) -> Half(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00586533 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/act/Relu_output_0 -> <out>) [Half(25600,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00594304 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.1/blocks.0/act/Relu_output_0 -> <out>) [Half(25600,6400:32,80,1) -> Float(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00617276 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(819200,6400,80,1) -> Int8(819200,6400,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00335564 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(819200,6400,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00261203 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(819200,6400,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00584101 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(819200,6400,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00602895 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(25600,6400:32,80,1) -> Int8(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00610857 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(25600,6400:32,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00638311 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(25600,6400:32,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x0000000000000000, 0.00546303 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(25600,6400:32,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00630599 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Half(25600,6400:32,80,1) -> Int8(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00656603 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Half(25600,6400:32,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00501643 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Half(25600,6400:32,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00555182 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Half(25600,6400:32,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00600495 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00289783 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00626564 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,6400:4,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00277749 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,640,8) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00715954 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,640,8) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0073344 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,6400:32,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00251605 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00289783 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00580992 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00626564 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,6400:4,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00605333 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,6400:4,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00277749 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,640,8) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00715954 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,640,8) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0073344 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,6400:32,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00251605 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,6400:32,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003ea, 0.005616 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00547437 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00556185 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1600:32,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226071 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1600:4,40,1) -> Int8(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00219699 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(6400,1600:32,40,1) -> Int8(51200,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0022505 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(409600,1600,40,1) -> Float(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00530438 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(409600,1600,40,1) -> Half(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00527575 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(12800,1600:32,40,1) -> Float(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00528588 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(12800,1600:32,40,1) -> Half(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00530624 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Half(12800,1600:32,40,1) -> Float(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00469486 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Half(12800,1600:32,40,1) -> Float(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00524065 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.2/blocks.0/act/Relu_output_0) [Float(409600,1600,40,1) -> Float(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00543492 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.2/blocks.0/act/Relu_output_0) [Float(409600,1600,40,1) -> Half(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00538667 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.2/blocks.0/act/Relu_output_0) [Float(12800,1600:32,40,1) -> Float(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00566611 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.2/blocks.0/act/Relu_output_0) [Float(12800,1600:32,40,1) -> Half(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00564185 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.2/blocks.0/act/Relu_output_0) [Half(12800,1600:32,40,1) -> Float(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00470017 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.2/blocks.0/act/Relu_output_0) [Half(12800,1600:32,40,1) -> Float(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00564396 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(409600,1600,40,1) -> Int8(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00263439 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(409600,1600,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00216051 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(409600,1600,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00533536 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(409600,1600,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00531725 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(12800,1600:32,40,1) -> Int8(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00528392 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(12800,1600:32,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00531555 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(12800,1600:32,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00378526 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(12800,1600:32,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00541613 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(12800,1600:32,40,1) -> Int8(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00480731 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(12800,1600:32,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00370919 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(12800,1600:32,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x0000000000000000, 0.00387768 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(12800,1600:32,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00534722 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0025446 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00542087 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00557609 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1600:4,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00428787 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1600:4,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00265228 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00547437 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00556185 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1600:32,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226071 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1600:32,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0041135 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00547437 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00556185 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1600:32,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226071 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/act/Relu_output_0 -> <out>) [Float(409600,1600,40,1) -> Float(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00530438 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/act/Relu_output_0 -> <out>) [Float(409600,1600,40,1) -> Half(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00527575 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/act/Relu_output_0 -> <out>) [Float(12800,1600:32,40,1) -> Float(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00528588 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/act/Relu_output_0 -> <out>) [Float(12800,1600:32,40,1) -> Half(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00530624 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/act/Relu_output_0 -> <out>) [Half(12800,1600:32,40,1) -> Float(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00469486 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/act/Relu_output_0 -> <out>) [Half(12800,1600:32,40,1) -> Float(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00524065 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(409600,1600,40,1) -> Int8(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00263439 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(409600,1600,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00216051 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(409600,1600,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00533536 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(409600,1600,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00531725 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(12800,1600:32,40,1) -> Int8(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00528392 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(12800,1600:32,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00531555 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(12800,1600:32,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00378526 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Float(12800,1600:32,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00541613 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Half(12800,1600:32,40,1) -> Int8(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00480731 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Half(12800,1600:32,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00370919 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Half(12800,1600:32,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x0000000000000000, 0.00387768 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear [Half(12800,1600:32,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00534722 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0025446 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00557609 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1600:4,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00265228 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00547437 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00556185 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1600:32,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226071 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0025446 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00542087 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00557609 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1600:4,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00428787 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1600:4,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00265228 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00547437 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00556185 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1600:32,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226071 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1600:32,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0041135 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1:16,640,32) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00532893 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1:16,640,32) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00549486 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(6400,400:32,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00209259 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,400:4,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226129 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(3200,400:32,20,1) -> Int8(25600,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00194959 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(204800,400,20,1) -> Float(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00544576 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(204800,400,20,1) -> Half(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00535416 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(6400,400:32,20,1) -> Float(204800,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00462717 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Float(6400,400:32,20,1) -> Half(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00535907 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Half(6400,400:32,20,1) -> Float(204800,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00348711 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0 -> <out>) [Half(6400,400:32,20,1) -> Float(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00537075 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.3/blocks.0/act/Relu_output_0) [Float(204800,400,20,1) -> Float(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00545845 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.3/blocks.0/act/Relu_output_0) [Float(204800,400,20,1) -> Half(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00535026 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.3/blocks.0/act/Relu_output_0) [Float(6400,400:32,20,1) -> Float(204800,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00463794 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.3/blocks.0/act/Relu_output_0) [Float(6400,400:32,20,1) -> Half(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00536212 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.3/blocks.0/act/Relu_output_0) [Half(6400,400:32,20,1) -> Float(204800,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00346732 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/backbone/res_layers.3/blocks.0/act/Relu_output_0) [Half(6400,400:32,20,1) -> Float(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00531335 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(204800,400,20,1) -> Int8(204800,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226057 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(204800,400,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00199683 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(204800,400,20,1) -> Int8(12800,1:16,640,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00476495 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(204800,400,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00545863 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(6400,400:32,20,1) -> Int8(204800,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00464737 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(6400,400:32,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00476048 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(6400,400:32,20,1) -> Int8(12800,1:16,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00293784 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Float(6400,400:32,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00541088 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(6400,400:32,20,1) -> Int8(204800,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00362869 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(6400,400:32,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00293467 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(6400,400:32,20,1) -> Int8(12800,1:16,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.0029879 ms
[05/21/2025-09:28:20] [V] [TRT] /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear [Half(6400,400:32,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00414367 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,400,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00229145 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,400,20,1) -> Int8(12800,1:16,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00530353 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,400,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00550752 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,400:4,20,1) -> Int8(12800,1:16,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00337892 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,400:4,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00263963 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1:16,640,32) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00532893 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1:16,640,32) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00549486 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(6400,400:32,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00209259 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(6400,400:32,20,1) -> Int8(12800,1:16,640,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00317287 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1:16,640,32) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00532893 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1:16,640,32) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00549486 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(6400,400:32,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00209259 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/act/Relu_output_0 -> <out>) [Float(204800,400,20,1) -> Float(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00544576 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/act/Relu_output_0 -> <out>) [Float(204800,400,20,1) -> Half(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00535416 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/act/Relu_output_0 -> <out>) [Float(6400,400:32,20,1) -> Float(204800,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00462717 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/act/Relu_output_0 -> <out>) [Float(6400,400:32,20,1) -> Half(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00535907 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/act/Relu_output_0 -> <out>) [Half(6400,400:32,20,1) -> Float(204800,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00348711 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/act/Relu_output_0 -> <out>) [Half(6400,400:32,20,1) -> Float(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00537075 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear [Float(204800,400,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00199683 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear [Float(204800,400,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00545863 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear [Float(6400,400:32,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00476048 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear [Float(6400,400:32,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00541088 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear [Half(6400,400:32,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00293467 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear [Half(6400,400:32,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00414367 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,400:4,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00263963 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(6400,400:32,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00209259 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(102400,400,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00179788 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(102400,400,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226801 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(102400,400,20,1) -> BFloat16(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00179788 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(3200,400:32,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00334448 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(3200,400:32,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00334299 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(3200,400:32,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00238089 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(3200,400:32,20,1) -> BFloat16(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00334299 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/Conv_output_0 -> <out>) [Half(3200,400:32,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00277292 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/Conv_output_0 -> <out>) [Half(3200,400:32,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00271759 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/Conv_output_0 -> <out>) [Half(3200,400:32,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.0023426 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/input_proj.2/conv/Conv_output_0 -> <out>) [Half(3200,400:32,20,1) -> BFloat16(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00271759 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00289783 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00580992 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00626564 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,6400:4,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00605333 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,6400:4,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00277749 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,640,8) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00715954 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,640,8) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0073344 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,6400:32,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00251605 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,6400:32,80,1) -> Int8(51200,1:16,640,8)] got cached result: Reformat, tactic 0x00000000000003ea, 0.005616 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(204800,1:16,2560,32) long-strided -> Int8(3276800,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00598495 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(204800,1:16,2560,32) long-strided -> Int8(819200,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00554532 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(204800,1:16,2560,32) long-strided -> Int8(102400,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0054637 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(102400,6400:32,80,1) long-strided -> Int8(3276800,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00552264 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(102400,6400:32,80,1) long-strided -> Int8(819200,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00302848 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(102400,6400:32,80,1) long-strided -> Int8(204800,1:16,2560,32)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00554198 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(102400,1:16,1280,16) -> Int8(3276800,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00603333 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(102400,1:16,1280,16) -> Int8(819200,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00620305 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(102400,1:16,1280,16) -> Int8(204800,1:16,2560,32)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00656894 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(102400,1:16,1280,16) -> Int8(102400,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00685083 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(51200,6400:32,80,1) -> Int8(3276800,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.0073808 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(51200,6400:32,80,1) -> Int8(819200,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00301619 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(51200,6400:32,80,1) -> Int8(204800,1:16,2560,32)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00668052 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_3_/model/encoder/input_proj.0/norm/BatchNormalization_output_0_clone_1) [Int8(51200,6400:32,80,1) -> Int8(102400,6400:32,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00340876 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0025446 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00542087 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00557609 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1600:4,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00428787 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1600:4,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00265228 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00547437 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00556185 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1600:32,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226071 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1600:32,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0041135 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(51200,1:16,1280,32) long-strided -> Int8(819200,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00650909 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(51200,1:16,1280,32) long-strided -> Int8(204800,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00660945 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(51200,1:16,1280,32) long-strided -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00684365 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(25600,1600:32,40,1) long-strided -> Int8(819200,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00533536 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(25600,1600:32,40,1) long-strided -> Int8(204800,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00227113 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(25600,1600:32,40,1) long-strided -> Int8(51200,1:16,1280,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.0040862 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(25600,1:16,640,16) -> Int8(819200,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00535788 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(25600,1:16,640,16) -> Int8(204800,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.005408 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(25600,1:16,640,16) -> Int8(51200,1:16,1280,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0040913 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(25600,1:16,640,16) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00553864 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(12800,1600:32,40,1) -> Int8(819200,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00535128 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(12800,1600:32,40,1) -> Int8(204800,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226968 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(12800,1600:32,40,1) -> Int8(51200,1:16,1280,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00410736 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_2_/model/encoder/input_proj.1/norm/BatchNormalization_output_0_clone_1) [Int8(12800,1600:32,40,1) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00237302 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear [Float(102400,400,20,1) -> Int8(25600,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00189907 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear [Float(102400,400,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00406997 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear [Half(102400,400,20,1) -> Int8(25600,400:4,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00247236 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear [Half(102400,400,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0040593 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear [Half(12800,1:8,640,32) -> Int8(25600,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00353684 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear [Half(12800,1:8,640,32) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00490286 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear [BFloat16(102400,400,20,1) -> Int8(25600,400:4,20,1)] got cached result: MyelinReformat, tactic 0x0000000000000000, 0.00189341 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear [BFloat16(102400,400,20,1) -> Int8(3200,400:32,20,1)] got cached result: MyelinReformat, tactic 0x0000000000000000, 0.00232428 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,400:4,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226129 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(3200,400:32,20,1) -> Int8(25600,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00194959 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(102400,400,20,1) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x0000000000000000, 0.00204944 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(102400,400,20,1) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00227962 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(102400,400,20,1) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x0000000000000000, 0.00205597 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(102400,400,20,1) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00449014 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(102400,400,20,1) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00405448 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(102400,400,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00179788 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(102400,400,20,1) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x0000000000000000, 0.00318781 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(102400,400,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226801 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(102400,400,20,1) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x0000000000000000, 0.0031935 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(102400,400,20,1) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00398857 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(102400,400,20,1) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00276897 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(102400,400,20,1) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00703325 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(3200,400:32,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00334448 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(3200,400:32,20,1) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00233674 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(3200,400:32,20,1) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00335628 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(3200,400:32,20,1) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x0000000000000000, 0.00239048 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(3200,400:32,20,1) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00548741 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(3200,400:32,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00334299 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(3200,400:32,20,1) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00239932 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(3200,400:32,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00238089 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(3200,400:32,20,1) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00238446 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(3200,400:32,20,1) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00495338 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(3200,400:32,20,1) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00709181 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Float(3200,400:32,20,1) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00919429 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Half(3200,400:32,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00277292 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Half(3200,400:32,20,1) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x0000000000000000, 0.00314872 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Half(3200,400:32,20,1) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00273553 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Half(3200,400:32,20,1) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x0000000000000000, 0.0023997 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Half(3200,400:32,20,1) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00486324 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Half(3200,400:32,20,1) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00735931 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Half(3200,400:32,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00271759 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Half(3200,400:32,20,1) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x0000000000000000, 0.00232479 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Half(3200,400:32,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.0023426 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Half(3200,400:32,20,1) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x0000000000000000, 0.00231889 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Half(3200,400:32,20,1) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00524082 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0 -> <out>) [Half(3200,400:32,20,1) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00610857 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,400,20,1) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x0000000000000000, 0.00205244 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,400,20,1) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00228571 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,400,20,1) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x0000000000000000, 0.00207033 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,400,20,1) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.004473 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,400,20,1) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00405714 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,400,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00180594 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,400,20,1) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0032001 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,400,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226457 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,400,20,1) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00319624 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,400,20,1) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0039934 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,400,20,1) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00275789 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,400,20,1) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00703369 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,1,5120,256) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00199492 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,1,5120,256) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00334809 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,1,5120,256) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00233401 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,1,5120,256) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00530878 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,1,5120,256) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00549062 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,1,5120,256) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00326306 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,1,5120,256) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x0000000000000000, 0.00232568 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,1,5120,256) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00234094 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,1,5120,256) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x0000000000000000, 0.00233932 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,1,5120,256) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00492721 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,1,5120,256) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00520784 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(102400,1,5120,256) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00618362 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1,400,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00195751 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1,400,20,1) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x0000000000000000, 0.00320518 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1,400,20,1) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00322458 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1,400,20,1) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.004535 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1,400,20,1) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.004064 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1,400,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00189299 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1,400,20,1) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00319898 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1,400,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00320559 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1,400,20,1) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x0000000000000000, 0.00320975 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1,400,20,1) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00404851 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1,400,20,1) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00490393 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1,400,20,1) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00596152 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(25600,1:4,1280,64) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00199555 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(25600,1:4,1280,64) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0023183 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(25600,1:4,1280,64) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00336957 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(25600,1:4,1280,64) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00535162 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(25600,1:4,1280,64) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00548724 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(25600,1:4,1280,64) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00332145 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(25600,1:4,1280,64) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x0000000000000000, 0.00238796 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(25600,1:4,1280,64) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00238872 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(25600,1:4,1280,64) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x0000000000000000, 0.00237654 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(25600,1:4,1280,64) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00498065 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(25600,1:4,1280,64) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00524082 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(25600,1:4,1280,64) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00619676 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(3200,400:32,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00335628 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(3200,400:32,20,1) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00234072 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(3200,400:32,20,1) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00335745 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(3200,400:32,20,1) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x0000000000000000, 0.00239551 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(3200,400:32,20,1) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00551437 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(3200,400:32,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00335043 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(3200,400:32,20,1) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00239322 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(3200,400:32,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00240229 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(3200,400:32,20,1) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00239299 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(3200,400:32,20,1) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00496047 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(3200,400:32,20,1) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00525665 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(3200,400:32,20,1) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00617447 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1:4,400,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0024234 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1:4,400,20,1) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00320681 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1:4,400,20,1) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00241425 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1:4,400,20,1) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x0000000000000000, 0.0032773 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1:4,400,20,1) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00448743 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1:4,400,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00241691 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1:4,400,20,1) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00323637 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1:4,400,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00320569 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1:4,400,20,1) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00322865 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1:4,400,20,1) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00400203 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1:4,400,20,1) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.004928 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Float(1:4,400,20,1) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00603238 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400,400,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0018954 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400,400,20,1) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x0000000000000000, 0.00324622 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400,400,20,1) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00227476 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400,400,20,1) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x0000000000000000, 0.00331127 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400,400,20,1) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.004476 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400,400,20,1) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00407403 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400,400,20,1) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x0000000000000000, 0.00320681 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400,400,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00234529 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400,400,20,1) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x0000000000000000, 0.00318496 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400,400,20,1) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00392068 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400,400,20,1) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00276141 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400,400,20,1) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00550558 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(51200,1:2,2560,128) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00348071 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(51200,1:2,2560,128) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x0000000000000000, 0.00232125 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(51200,1:2,2560,128) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.003472 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(51200,1:2,2560,128) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0024067 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(51200,1:2,2560,128) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00522939 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(51200,1:2,2560,128) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00732114 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(51200,1:2,2560,128) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00346057 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(51200,1:2,2560,128) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00230175 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(51200,1:2,2560,128) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x0000000000000000, 0.00230103 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(51200,1:2,2560,128) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00495417 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(51200,1:2,2560,128) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00535213 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(51200,1:2,2560,128) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00607295 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(12800,1:8,640,32) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0020245 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(12800,1:8,640,32) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00233283 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(12800,1:8,640,32) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00347178 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(12800,1:8,640,32) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x0000000000000000, 0.00239863 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(12800,1:8,640,32) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00524131 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(12800,1:8,640,32) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.007344 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(12800,1:8,640,32) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00203139 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(12800,1:8,640,32) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x0000000000000000, 0.00228463 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(12800,1:8,640,32) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00228876 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(12800,1:8,640,32) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00494897 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(12800,1:8,640,32) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00526367 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(12800,1:8,640,32) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00609238 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(6400,1:16,320,16) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00347222 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(6400,1:16,320,16) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00232988 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(6400,1:16,320,16) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00348049 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(6400,1:16,320,16) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x0000000000000000, 0.0023949 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(6400,1:16,320,16) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.005224 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(6400,1:16,320,16) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00735589 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(6400,1:16,320,16) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00347124 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(6400,1:16,320,16) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0022831 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(6400,1:16,320,16) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00232037 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(6400,1:16,320,16) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00495054 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(6400,1:16,320,16) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00523314 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(6400,1:16,320,16) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00607219 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(3200,400:32,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00273001 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(3200,400:32,20,1) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00234784 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(3200,400:32,20,1) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00271784 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(3200,400:32,20,1) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x0000000000000000, 0.00239558 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(3200,400:32,20,1) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00488899 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(3200,400:32,20,1) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00736091 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(3200,400:32,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0027351 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(3200,400:32,20,1) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0022982 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(3200,400:32,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00232538 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(3200,400:32,20,1) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00232737 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(3200,400:32,20,1) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00521992 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(3200,400:32,20,1) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00610019 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(1:8,400,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00242441 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(1:8,400,20,1) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x0000000000000000, 0.00322529 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(1:8,400,20,1) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00240686 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(1:8,400,20,1) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00330525 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(1:8,400,20,1) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00448543 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(1:8,400,20,1) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00387361 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(1:8,400,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00240282 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(1:8,400,20,1) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0031938 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(1:8,400,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00320975 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(1:8,400,20,1) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00320488 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(1:8,400,20,1) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00395255 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(1:8,400,20,1) -> Half(102400:32,400,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.006064 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400:32,400,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00268876 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400:32,400,20,1) -> Float(102400,1,5120,256)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00333151 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400:32,400,20,1) -> Float(1,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00270266 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400:32,400,20,1) -> Float(25600,1:4,1280,64)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00333193 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400:32,400,20,1) -> Float(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00482667 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400:32,400,20,1) -> Float(1:4,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00446986 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400:32,400,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0027012 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400:32,400,20,1) -> Half(51200,1:2,2560,128)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00325101 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400:32,400,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00325621 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400:32,400,20,1) -> Half(6400,1:16,320,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00325818 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400:32,400,20,1) -> Half(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00433108 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/lateral_convs.0/act/Mul_output_0) [Half(102400:32,400,20,1) -> Half(1:8,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00494708 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Float(102400,400,20,1) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00203087 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Float(102400,400,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00406997 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Float(102400,1,5120,256) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00339721 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Float(102400,1,5120,256) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00500792 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Float(1,400,20,1) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00204833 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Float(1,400,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00408176 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Float(25600,1:4,1280,64) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00339774 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Float(25600,1:4,1280,64) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0050229 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Float(3200,400:32,20,1) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00336255 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Float(3200,400:32,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00494077 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Float(1:4,400,20,1) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00245339 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Float(1:4,400,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0039654 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(102400,400,20,1) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00202315 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(102400,400,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0040593 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(51200,1:2,2560,128) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00349826 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(51200,1:2,2560,128) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00491535 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(12800,1:8,640,32) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00349792 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(12800,1:8,640,32) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00490286 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(6400,1:16,320,16) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00351019 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(6400,1:16,320,16) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00490408 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(3200,400:32,20,1) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00285831 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(3200,400:32,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00310439 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(1:8,400,20,1) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00261045 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(1:8,400,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00410057 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(102400:32,400,20,1) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00289079 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0 [Half(102400:32,400,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00442708 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/Resize_output_0 -> <out>) [Int8(102400,400,20,1) -> Int8(3200,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00429539 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/Resize_output_0 -> <out>) [Int8(3200,400:32,20,1) -> Int8(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00310001 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy [Int8(409600,1600,40,1) -> Int8(819200,1600,40,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00237295 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy [Int8(409600,1600,40,1) -> Int8(204800,1600:4,40,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00254637 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy [Int8(409600,1600,40,1) -> Int8(51200,1:16,1280,32) long-strided] got cached result: Reformat, tactic 0x00000000000003ea, 0.00540885 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy [Int8(409600,1600,40,1) -> Int8(25600,1600:32,40,1) long-strided] got cached result: Reformat, tactic 0x00000000000003ea, 0.00548199 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy [Int8(12800,1600:32,40,1) -> Int8(819200,1600,40,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00533841 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy [Int8(12800,1600:32,40,1) -> Int8(204800,1600:4,40,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.0022515 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy [Int8(12800,1600:32,40,1) -> Int8(51200,1:16,1280,32) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00409117 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy [Int8(12800,1600:32,40,1) -> Int8(25600,1600:32,40,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00236867 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,1600,40,1) -> Int8(204800,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00301667 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,1600,40,1) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00545829 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1600:4,40,1) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00356984 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,1280,32) -> Int8(204800,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00545507 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,1280,32) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00548317 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1600:32,40,1) -> Int8(204800,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00250707 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,1600,40,1) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00545829 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1600:4,40,1) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00356984 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,1280,32) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00548317 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(6400,1600:32,40,1) -> Int8(51200,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0022505 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(204800,1600,40,1) -> Float(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00530675 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(204800,1600,40,1) -> Half(204800,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00201433 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(204800,1600,40,1) -> Half(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00528082 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(6400,1600:32,40,1) -> Float(204800,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0046195 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(6400,1600:32,40,1) -> Half(204800,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00457529 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(6400,1600:32,40,1) -> Half(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00520882 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Half(6400,1600:32,40,1) -> Float(204800,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00345295 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Half(6400,1600:32,40,1) -> Float(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00526155 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Half(6400,1600:32,40,1) -> Half(204800,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0033667 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(204800,1600,40,1) -> Float(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00530675 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(204800,1600,40,1) -> Half(204800,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00201433 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(204800,1600,40,1) -> Half(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00528082 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(6400,1600:32,40,1) -> Float(204800,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0046195 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(6400,1600:32,40,1) -> Half(204800,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00457529 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(6400,1600:32,40,1) -> Half(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00520882 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Half(6400,1600:32,40,1) -> Float(204800,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00345295 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Half(6400,1600:32,40,1) -> Float(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00526155 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Half(6400,1600:32,40,1) -> Half(204800,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0033667 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1600,40,1) -> Int8(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00550523 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Resize_1_output_0) [Int8(12800,1600:32,40,1) -> Int8(409600,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00531877 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Resize_1_output_0) [Int8(12800,1600:32,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00410188 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/Resize_1_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00557609 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/Resize_1_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00534298 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/Resize_1_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00556185 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/Resize_1_output_0 -> <out>) [Int8(12800,1600:32,40,1) -> Int8(409600,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00533858 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy [Int8(1638400,6400,80,1) -> Int8(3276800,6400,80,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00321341 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy [Int8(1638400,6400,80,1) -> Int8(819200,6400:4,80,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00398362 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy [Int8(1638400,6400,80,1) -> Int8(204800,1:16,2560,32) long-strided] got cached result: Reformat, tactic 0x00000000000003ea, 0.00598095 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy [Int8(1638400,6400,80,1) -> Int8(102400,6400:32,80,1) long-strided] got cached result: Reformat, tactic 0x00000000000003ea, 0.00544559 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy [Int8(51200,6400:32,80,1) -> Int8(3276800,6400,80,1) long-strided] got cached result: Reformat, tactic 0x00000000000003ea, 0.00564343 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy [Int8(51200,6400:32,80,1) -> Int8(819200,6400:4,80,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00301419 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy [Int8(51200,6400:32,80,1) -> Int8(204800,1:16,2560,32) long-strided] got cached result: Reformat, tactic 0x00000000000003ea, 0.00542019 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy [Int8(51200,6400:32,80,1) -> Int8(102400,6400:32,80,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.0034068 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(3276800,6400,80,1) -> Int8(819200,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00588416 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(3276800,6400,80,1) -> Int8(102400,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00618933 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400:4,80,1) -> Int8(102400,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00807441 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1:16,2560,32) -> Int8(819200,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00756475 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1:16,2560,32) -> Int8(102400,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00835606 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,6400:32,80,1) -> Int8(819200,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00395935 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(3276800,6400,80,1) -> Int8(102400,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00618933 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400:4,80,1) -> Int8(102400,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00807441 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1:16,2560,32) -> Int8(102400,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00835606 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,6400:32,80,1) -> Int8(204800,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00251605 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(819200,6400,80,1) -> Float(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00525845 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(819200,6400,80,1) -> Half(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00312 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(819200,6400,80,1) -> Half(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00531708 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(25600,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00572343 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(25600,6400:32,80,1) -> Half(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00688022 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(25600,6400:32,80,1) -> Half(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00586533 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Half(25600,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00594304 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Half(25600,6400:32,80,1) -> Float(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00617276 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Half(25600,6400:32,80,1) -> Half(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00708506 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(819200,6400,80,1) -> Float(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00525845 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(819200,6400,80,1) -> Half(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00312 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(819200,6400,80,1) -> Half(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00531708 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(25600,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00572343 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(25600,6400:32,80,1) -> Half(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00688022 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(25600,6400:32,80,1) -> Half(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00586533 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Half(25600,6400:32,80,1) -> Float(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00594304 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Half(25600,6400:32,80,1) -> Float(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00617276 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Half(25600,6400:32,80,1) -> Half(819200,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00708506 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,6400,80,1) -> Int8(25600,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00626564 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0) [Int8(51200,6400:32,80,1) -> Int8(1638400,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00723726 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0) [Int8(51200,6400:32,80,1) -> Int8(409600,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00300124 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0) [Int8(51200,6400:32,80,1) -> Int8(102400,1:16,1280,16)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00603352 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,6400,80,1) -> Int8(409600,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00402032 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,6400,80,1) -> Int8(51200,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00615924 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,6400:4,80,1) -> Int8(51200,6400:32,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00407086 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,1280,16) -> Int8(409600,6400:4,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00686084 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,1280,16) -> Int8(51200,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00740914 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,6400:32,80,1) -> Int8(409600,6400:4,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00301343 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1638400,6400,80,1) -> Int8(51200,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00615924 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,6400:4,80,1) -> Int8(51200,6400:32,80,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00407086 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1:16,1280,16) -> Int8(51200,6400:32,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00740914 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_4_/model/encoder/downsample_convs.0/act/Mul_output_0_clone_0) [Int8(25600,1600:32,40,1) long-strided -> Int8(819200,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00533536 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_4_/model/encoder/downsample_convs.0/act/Mul_output_0_clone_0) [Int8(25600,1600:32,40,1) long-strided -> Int8(204800,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00227113 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_4_/model/encoder/downsample_convs.0/act/Mul_output_0_clone_0) [Int8(25600,1600:32,40,1) long-strided -> Int8(51200,1:16,1280,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.0040862 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_4_/model/encoder/downsample_convs.0/act/Mul_output_0_clone_0) [Int8(12800,1600:32,40,1) -> Int8(819200,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00535128 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_4_/model/encoder/downsample_convs.0/act/Mul_output_0_clone_0) [Int8(12800,1600:32,40,1) -> Int8(204800,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226968 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_4_/model/encoder/downsample_convs.0/act/Mul_output_0_clone_0) [Int8(12800,1600:32,40,1) -> Int8(51200,1:16,1280,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00410736 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_4_/model/encoder/downsample_convs.0/act/Mul_output_0_clone_0) [Int8(12800,1600:32,40,1) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00237302 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/encoder/Resize_1_output_0 copy
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Resize_1_output_0 copy [Int8(409600,1600,40,1) -> Int8(819200,1600,40,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00237714 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Resize_1_output_0 copy [Int8(409600,1600,40,1) -> Int8(204800,1600:4,40,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00252207 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Resize_1_output_0 copy [Int8(409600,1600,40,1) -> Int8(51200,1:16,1280,32) long-strided] got cached result: Reformat, tactic 0x00000000000003ea, 0.00533757 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Resize_1_output_0 copy [Int8(409600,1600,40,1) -> Int8(25600,1600:32,40,1) long-strided] got cached result: Reformat, tactic 0x00000000000003ea, 0.00545439 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Resize_1_output_0 copy [Int8(25600,1:16,640,16) -> Int8(819200,1600,40,1) long-strided] got cached result: Reformat, tactic 0x00000000000003ea, 0.0053953 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Resize_1_output_0 copy [Int8(25600,1:16,640,16) -> Int8(204800,1600:4,40,1) long-strided] got cached result: Reformat, tactic 0x00000000000003ea, 0.00539056 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Resize_1_output_0 copy [Int8(25600,1:16,640,16) -> Int8(51200,1:16,1280,32) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00410096 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Resize_1_output_0 copy [Int8(25600,1:16,640,16) -> Int8(25600,1600:32,40,1) long-strided] got cached result: Reformat, tactic 0x00000000000003ea, 0.00539208 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Resize_1_output_0 copy [Int8(12800,1600:32,40,1) -> Int8(819200,1600,40,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.0053462 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Resize_1_output_0 copy [Int8(12800,1600:32,40,1) -> Int8(204800,1600:4,40,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00225843 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Resize_1_output_0 copy [Int8(12800,1600:32,40,1) -> Int8(51200,1:16,1280,32) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00408411 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/Resize_1_output_0 copy [Int8(12800,1600:32,40,1) -> Int8(25600,1600:32,40,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.0023719 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,1600,40,1) -> Int8(204800,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00301667 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,1600,40,1) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00545829 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1600:4,40,1) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00356984 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,1280,32) -> Int8(204800,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00545507 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,1280,32) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00548317 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1600:32,40,1) -> Int8(204800,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00250707 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(819200,1600,40,1) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00545829 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1600:4,40,1) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00356984 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,1:16,1280,32) -> Int8(25600,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00548317 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(6400,1600:32,40,1) -> Int8(51200,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0022505 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(204800,1600,40,1) -> Float(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00530675 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(204800,1600,40,1) -> Half(204800,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00201433 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(204800,1600,40,1) -> Half(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00528082 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(6400,1600:32,40,1) -> Float(204800,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0046195 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(6400,1600:32,40,1) -> Half(204800,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00457529 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(6400,1600:32,40,1) -> Half(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00520882 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Half(6400,1600:32,40,1) -> Float(204800,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00345295 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Half(6400,1600:32,40,1) -> Float(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00526155 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Half(6400,1600:32,40,1) -> Half(204800,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0033667 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(204800,1600,40,1) -> Float(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00530675 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(204800,1600,40,1) -> Half(204800,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00201433 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(204800,1600,40,1) -> Half(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00528082 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(6400,1600:32,40,1) -> Float(204800,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0046195 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(6400,1600:32,40,1) -> Half(204800,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00457529 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(6400,1600:32,40,1) -> Half(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00520882 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Half(6400,1600:32,40,1) -> Float(204800,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00345295 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Half(6400,1600:32,40,1) -> Float(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00526155 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0 -> <out>) [Half(6400,1600:32,40,1) -> Half(204800,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.0033667 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,1600,40,1) -> Int8(6400,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00550523 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0) [Int8(12800,1600:32,40,1) -> Int8(409600,1600,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00531877 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0) [Int8(12800,1600:32,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226621 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0) [Int8(12800,1600:32,40,1) -> Int8(25600,1:16,640,16)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00410188 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0025446 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00557609 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1600:4,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00265228 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00547437 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00556185 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1600:32,40,1) -> Int8(102400,1600:4,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226071 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(409600,1600,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00557609 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(102400,1600:4,40,1) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00265228 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(25600,1:16,640,16) -> Int8(12800,1600:32,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00556185 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_5_/model/encoder/downsample_convs.1/act/Mul_output_0_clone_0) [Int8(6400,400:32,20,1) long-strided -> Int8(204800,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00310628 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_5_/model/encoder/downsample_convs.1/act/Mul_output_0_clone_0) [Int8(6400,400:32,20,1) long-strided -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00194063 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_5_/model/encoder/downsample_convs.1/act/Mul_output_0_clone_0) [Int8(6400,400:32,20,1) long-strided -> Int8(12800,1:16,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00281528 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_5_/model/encoder/downsample_convs.1/act/Mul_output_0_clone_0) [Int8(3200,400:32,20,1) -> Int8(204800,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00311891 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_5_/model/encoder/downsample_convs.1/act/Mul_output_0_clone_0) [Int8(3200,400:32,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00195305 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_5_/model/encoder/downsample_convs.1/act/Mul_output_0_clone_0) [Int8(3200,400:32,20,1) -> Int8(12800,1:16,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00281663 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> /model/encoder/Concat_5_/model/encoder/downsample_convs.1/act/Mul_output_0_clone_0) [Int8(3200,400:32,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00216433 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(102400,400,20,1) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.0020348 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(102400,400,20,1) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00187512 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(102400,400,20,1) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00341322 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(102400,400,20,1) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00395317 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(102400,1,5120,256) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00339476 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(102400,1,5120,256) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00347113 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(102400,1,5120,256) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.0025994 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(102400,1,5120,256) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00502242 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(1,400,20,1) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00205198 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(1,400,20,1) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00239619 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(1,400,20,1) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00340343 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(1,400,20,1) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00395305 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(25600,1:4,1280,64) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00340811 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(25600,1:4,1280,64) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00350394 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(25600,1:4,1280,64) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00260156 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(25600,1:4,1280,64) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00502195 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(3200,400:32,20,1) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00338488 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(3200,400:32,20,1) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00348005 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(3200,400:32,20,1) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00260995 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(3200,400:32,20,1) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00494786 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(1:4,400,20,1) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00245656 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(1:4,400,20,1) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00346166 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(1:4,400,20,1) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00347908 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Float(1:4,400,20,1) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00395367 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(102400,400,20,1) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00385997 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(102400,400,20,1) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.004024 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(102400,400,20,1) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00349659 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(102400,400,20,1) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00393872 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(51200,1:2,2560,128) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.0035016 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(51200,1:2,2560,128) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00355568 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(51200,1:2,2560,128) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00263389 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(51200,1:2,2560,128) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00509651 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(12800,1:8,640,32) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00351063 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(12800,1:8,640,32) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00354464 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(12800,1:8,640,32) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00264567 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(12800,1:8,640,32) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00508705 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(6400,1:16,320,16) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.0035268 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(6400,1:16,320,16) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00355367 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(6400,1:16,320,16) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00262716 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(6400,1:16,320,16) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00507334 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(3200,400:32,20,1) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00286245 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(3200,400:32,20,1) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00254244 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(3200,400:32,20,1) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00269956 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(3200,400:32,20,1) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x0000000000000000, 0.00312457 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(1:8,400,20,1) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00264779 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(1:8,400,20,1) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00266218 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(1:8,400,20,1) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00356583 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(1:8,400,20,1) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00409117 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(102400:32,400,20,1) -> Int8(204800,400,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00286939 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(102400:32,400,20,1) -> Int8(51200,400:4,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00292879 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(102400:32,400,20,1) -> Int8(12800,1:16,640,32) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00368281 ms
[05/21/2025-09:28:20] [V] [TRT] /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1 [Half(102400:32,400,20,1) -> Int8(6400,400:32,20,1) long-strided] got cached result: Reformat, tactic 0x00000000000003e8, 0.00433371 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,400,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00229145 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,400,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00550752 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,400:4,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00263963 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1:16,640,32) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00532893 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1:16,640,32) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00549486 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(6400,400:32,20,1) -> Int8(51200,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00209259 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(204800,400,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00550752 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,400:4,20,1) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00263963 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(12800,1:16,640,32) -> Int8(6400,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00549486 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(1600,400:32,20,1) -> Int8(12800,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00181503 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(51200,400,20,1) -> Float(1600,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00324894 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(51200,400,20,1) -> Half(51200,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00171293 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(51200,400,20,1) -> Half(1600,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00292777 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(1600,400:32,20,1) -> Float(51200,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0026924 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(1600,400:32,20,1) -> Half(51200,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00269376 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Float(1600,400:32,20,1) -> Half(1600,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00337425 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Half(1600,400:32,20,1) -> Float(51200,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00237849 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Half(1600,400:32,20,1) -> Float(1600,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00337403 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0 -> <out>) [Half(1600,400:32,20,1) -> Half(51200,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00233202 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(51200,400,20,1) -> Float(1600,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00324894 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(51200,400,20,1) -> Half(51200,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00171293 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(51200,400,20,1) -> Half(1600,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00292777 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(1600,400:32,20,1) -> Float(51200,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.0026924 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(1600,400:32,20,1) -> Half(51200,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00269376 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Float(1600,400:32,20,1) -> Half(1600,400:32,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00337425 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Half(1600,400:32,20,1) -> Float(51200,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00237849 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Half(1600,400:32,20,1) -> Float(1600,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00337403 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0 -> <out>) [Half(1600,400:32,20,1) -> Half(51200,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00233202 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(51200,400,20,1) -> Int8(1600,400:32,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00340221 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0 -> <out>) [Int8(3200,400:32,20,1) -> Int8(25600,400:4,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00194959 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.0/conv/Conv_output_0 -> <out>) [Float(1638400,6400,80,1) -> Half(1638400,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00457243 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.0/conv/Conv_output_0 -> <out>) [Float(1638400,6400,80,1) -> Half(204800,1:8,2560,32)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00529693 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.0/conv/Conv_output_0 -> <out>) [Float(1638400,6400,80,1) -> BFloat16(1638400,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00457243 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.0/conv/Conv_output_0 -> <out>) [Float(51200,6400:32,80,1) -> Float(1638400,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00647672 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.0/conv/Conv_output_0 -> <out>) [Float(51200,6400:32,80,1) -> Half(1638400,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00530743 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.0/conv/Conv_output_0 -> <out>) [Float(51200,6400:32,80,1) -> Half(204800,1:8,2560,32)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00519053 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.0/conv/Conv_output_0 -> <out>) [Float(51200,6400:32,80,1) -> BFloat16(1638400,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00530743 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.0/conv/Conv_output_0 -> <out>) [Half(51200,6400:32,80,1) -> Float(1638400,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00531708 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.0/conv/Conv_output_0 -> <out>) [Half(51200,6400:32,80,1) -> Half(1638400,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00573477 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.0/conv/Conv_output_0 -> <out>) [Half(51200,6400:32,80,1) -> Half(204800,1:8,2560,32)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00594853 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.0/conv/Conv_output_0 -> <out>) [Half(51200,6400:32,80,1) -> BFloat16(1638400,6400,80,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00573477 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.1/conv/Conv_output_0 -> <out>) [Float(409600,1600,40,1) -> Half(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00239299 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.1/conv/Conv_output_0 -> <out>) [Float(409600,1600,40,1) -> Half(51200,1:8,1280,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00253426 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.1/conv/Conv_output_0 -> <out>) [Float(409600,1600,40,1) -> BFloat16(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00239299 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.1/conv/Conv_output_0 -> <out>) [Float(12800,1600:32,40,1) -> Float(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00528588 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.1/conv/Conv_output_0 -> <out>) [Float(12800,1600:32,40,1) -> Half(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00525682 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.1/conv/Conv_output_0 -> <out>) [Float(12800,1600:32,40,1) -> Half(51200,1:8,1280,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00351643 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.1/conv/Conv_output_0 -> <out>) [Float(12800,1600:32,40,1) -> BFloat16(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003ea, 0.00525682 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.1/conv/Conv_output_0 -> <out>) [Half(12800,1600:32,40,1) -> Float(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00469486 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.1/conv/Conv_output_0 -> <out>) [Half(12800,1600:32,40,1) -> Half(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00459029 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.1/conv/Conv_output_0 -> <out>) [Half(12800,1600:32,40,1) -> Half(51200,1:8,1280,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00346656 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.1/conv/Conv_output_0 -> <out>) [Half(12800,1600:32,40,1) -> BFloat16(409600,1600,40,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00459029 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(102400,400,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00179788 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(102400,400,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.00226801 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(102400,400,20,1) -> BFloat16(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00179788 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(3200,400:32,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00334448 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(3200,400:32,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00334299 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(3200,400:32,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00238089 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.2/conv/Conv_output_0 -> <out>) [Float(3200,400:32,20,1) -> BFloat16(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00334299 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.2/conv/Conv_output_0 -> <out>) [Half(3200,400:32,20,1) -> Float(102400,400,20,1)] got cached result: Reformat, tactic 0x0000000000000000, 0.00277292 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.2/conv/Conv_output_0 -> <out>) [Half(3200,400:32,20,1) -> Half(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00271759 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.2/conv/Conv_output_0 -> <out>) [Half(3200,400:32,20,1) -> Half(12800,1:8,640,32)] got cached result: Reformat, tactic 0x0000000000000000, 0.0023426 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(/model/decoder/input_proj.2/conv/Conv_output_0 -> <out>) [Half(3200,400:32,20,1) -> BFloat16(102400,400,20,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00271759 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> boxes) [Half(1200,4,1) -> Float(1200,4,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00162873 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> boxes) [BFloat16(1200,4,1) -> Float(1200,4,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00162873 ms
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs for available format set
[05/21/2025-09:28:20] [V] [TRT] =============== Computing reformatting costs: 
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> scores) [Half(300,1) -> Float(300,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00162462 ms
[05/21/2025-09:28:20] [V] [TRT] Optimizer Reformat(<in> -> scores) [BFloat16(300,1) -> Float(300,1)] got cached result: Reformat, tactic 0x00000000000003e8, 0.00162462 ms
[05/21/2025-09:28:20] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]} (/model/encoder/input_proj.2/conv/Conv_output_0) from Half(3200,400:32,20,1) to Half(12800,1:8,640,32)
[05/21/2025-09:28:20] [V] [TRT] Formats and tactics selection completed in 10.9078 seconds.
[05/21/2025-09:28:20] [V] [TRT] After reformat layers: 86 layers
[05/21/2025-09:28:20] [V] [TRT] Total number of blocks in pre-optimized block assignment: 82
[05/21/2025-09:28:20] [I] [TRT] Detected 2 inputs and 3 output network tensors.
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv Host Persistent: 4880 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv Host Persistent: 4368 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: /model/backbone/MaxPool Host Persistent: 4144 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv Host Persistent: 4368 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv Host Persistent: 4368 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool Host Persistent: 4144 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv Host Persistent: 4368 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool Host Persistent: 4144 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool Host Persistent: 4144 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv Host Persistent: 4944 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv Host Persistent: 4368 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]} Host Persistent: 80 bytes Device Persistent: 0 bytes Scratch Memory: 1228800 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) Host Persistent: 308 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add)) Host Persistent: 436 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add)) Host Persistent: 436 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add)) Host Persistent: 436 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add)) Host Persistent: 436 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul) Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv Host Persistent: 5136 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
[05/21/2025-09:28:22] [V] [TRT] Layer: {ForeignNode[/postprocessor/Tile.../postprocessor/GatherElements]} Host Persistent: 80 bytes Device Persistent: 0 bytes Scratch Memory: 54067200 bytes
[05/21/2025-09:28:22] [V] [TRT] Skipped printing memory information for 18 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.
[05/21/2025-09:28:22] [I] [TRT] Total Host Persistent Memory: 307312 bytes
[05/21/2025-09:28:22] [I] [TRT] Total Device Persistent Memory: 0 bytes
[05/21/2025-09:28:22] [I] [TRT] Max Scratch Memory: 54067200 bytes
[05/21/2025-09:28:22] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 83 steps to complete.
[05/21/2025-09:28:22] [V] [TRT] STILL ALIVE: Started step 26 of 83
[05/21/2025-09:28:22] [V] [TRT] STILL ALIVE: Started step 76 of 83
[05/21/2025-09:28:22] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 1.09843ms to assign 5 blocks to 83 nodes requiring 62873600 bytes.
[05/21/2025-09:28:22] [V] [TRT] Total number of blocks in optimized block assignment: 5
[05/21/2025-09:28:22] [I] [TRT] Total Activation Memory: 62873600 bytes
[05/21/2025-09:28:22] [I] [TRT] Total Weights Memory: 23192452 bytes
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv Set kernel index: 0
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv Set kernel index: 1
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv Set kernel index: 2
[05/21/2025-09:28:22] [V] [TRT] Finalize: /model/backbone/MaxPool Set kernel index: 3
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv Set kernel index: 2
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv Set kernel index: 4
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu Set kernel index: 5
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv Set kernel index: 2
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu Set kernel index: 4
[05/21/2025-09:28:22] [V] [TRT] Finalize: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool Set kernel index: 6
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv Set kernel index: 7
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv Set kernel index: 8
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu Set kernel index: 9
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv Set kernel index: 10
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu Set kernel index: 8
[05/21/2025-09:28:22] [V] [TRT] Finalize: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool Set kernel index: 6
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv Set kernel index: 11
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv Set kernel index: 12
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu Set kernel index: 9
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv Set kernel index: 11
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu Set kernel index: 12
[05/21/2025-09:28:22] [V] [TRT] Finalize: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool Set kernel index: 6
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv Set kernel index: 13
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv Set kernel index: 14
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu Set kernel index: 15
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv Set kernel index: 16
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu Set kernel index: 14
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv Set kernel index: 17
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv Set kernel index: 18
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv Set kernel index: 18
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv Set kernel index: 17
[05/21/2025-09:28:22] [V] [TRT] Finalize: PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul) Set kernel index: 19
[05/21/2025-09:28:22] [V] [TRT] Finalize: /model/encoder/Resize Set kernel index: 20
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv Set kernel index: 9
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul) Set kernel index: 21
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul) Set kernel index: 22
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul) Set kernel index: 22
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv Set kernel index: 12
[05/21/2025-09:28:22] [V] [TRT] Finalize: PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add)) Set kernel index: 23
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul) Set kernel index: 21
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul) Set kernel index: 21
[05/21/2025-09:28:22] [V] [TRT] Finalize: /model/encoder/Resize_1 Set kernel index: 24
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv Set kernel index: 25
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul) Set kernel index: 26
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul) Set kernel index: 27
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul) Set kernel index: 27
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv Set kernel index: 8
[05/21/2025-09:28:22] [V] [TRT] Finalize: PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add)) Set kernel index: 28
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul) Set kernel index: 29
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv Set kernel index: 30
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul) Set kernel index: 31
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv Set kernel index: 9
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul) Set kernel index: 21
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul) Set kernel index: 22
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul) Set kernel index: 22
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv Set kernel index: 12
[05/21/2025-09:28:22] [V] [TRT] Finalize: PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add)) Set kernel index: 23
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul) Set kernel index: 21
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv Set kernel index: 30
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul) Set kernel index: 32
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv Set kernel index: 17
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul) Set kernel index: 33
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul) Set kernel index: 32
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul) Set kernel index: 32
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv Set kernel index: 34
[05/21/2025-09:28:22] [V] [TRT] Finalize: PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add)) Set kernel index: 23
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul) Set kernel index: 33
[05/21/2025-09:28:22] [V] [TRT] Finalize: model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv Set kernel index: 35
[05/21/2025-09:28:22] [V] [TRT] Total number of generated kernels selected for the engine: 36
[05/21/2025-09:28:22] [V] [TRT] Kernel: 0 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 1 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 2 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 3 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 4 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 5 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 6 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 7 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 8 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 9 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 10 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 11 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 12 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 13 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 14 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 15 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 16 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 17 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 18 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 19 TRT_SERIALIZABLE:generatedNativePointwise
[05/21/2025-09:28:22] [V] [TRT] Kernel: 20 TRT_SERIALIZABLE:ResizeVectorizedNearestKernel
[05/21/2025-09:28:22] [V] [TRT] Kernel: 21 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 22 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 23 TRT_SERIALIZABLE:generatedNativePointwise
[05/21/2025-09:28:22] [V] [TRT] Kernel: 24 TRT_SERIALIZABLE:ResizeVectorizedC4x4NearestKernel
[05/21/2025-09:28:22] [V] [TRT] Kernel: 25 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 26 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 27 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 28 TRT_SERIALIZABLE:generatedNativePointwise
[05/21/2025-09:28:22] [V] [TRT] Kernel: 29 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 30 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 31 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 32 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 33 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 34 CASK_STATIC
[05/21/2025-09:28:22] [V] [TRT] Kernel: 35 CASK_STATIC
[05/21/2025-09:28:22] [I] [TRT] Compiler backend is used during engine execution.
[05/21/2025-09:28:22] [V] [TRT] Disabling unused tactic source: JIT_CONVOLUTIONS
[05/21/2025-09:28:22] [I] [TRT] Engine generation completed in 12.0172 seconds.
[05/21/2025-09:28:22] [V] [TRT] Layers:
Name: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear, LayerType: Reformat, Inputs: [ { Name: images, Location: Device, Dimensions: [1,3,640,640], Format/Datatype: Float }], Outputs: [ { Name: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,3,640,640], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear]
Name: model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,3,640,640], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,32,320,320], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 32, Groups: 1, Weights: {"Type": "Int8", "Count": 864}, Bias: {"Type": "Float", "Count": 32}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_first_layer_i8i8_i8i32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_vect_c_32_tilesize8x16x32x32_stage1_warpsize4x1x1_tensor16x8x16_r3s3_u2v2_aligna4_alignc8, TacticValue: 0x5cc792a989a1d1a6, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/conv1/conv1_1/conv/Conv][ONNX Layer: /model/backbone/conv1/conv1_1/norm/BatchNormalization][ONNX Layer: /model/backbone/conv1/conv1_1/act/Relu][ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,32,320,320], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,32,320,320], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 32, Groups: 1, Weights: {"Type": "Int8", "Count": 9216}, Bias: {"Type": "Float", "Count": 32}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3, TacticValue: 0x13463e9bf9ae0d73, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/conv1/conv1_2/conv/Conv][ONNX Layer: /model/backbone/conv1/conv1_2/norm/BatchNormalization][ONNX Layer: /model/backbone/conv1/conv1_2/act/Relu][ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,32,320,320], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/MaxPool_output_0, Location: Device, Dimensions: [1,64,320,320], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Int8", "Count": 18432}, Bias: {"Type": "Float", "Count": 64}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu, TacticValue: 0x9dafb2758560cc1d, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/conv1/conv1_3/conv/Conv][ONNX Layer: /model/backbone/conv1/conv1_3/norm/BatchNormalization][ONNX Layer: /model/backbone/conv1/conv1_3/act/Relu][ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear]
Name: /model/backbone/MaxPool, LayerType: CaskPooling, Inputs: [ { Name: /model/backbone/MaxPool_output_0, Location: Device, Dimensions: [1,64,320,320], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Int8 }], ParameterType: Pooling, PoolingType: MAX, WindowSize: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], BlendFactor: 0, AverageCountExcludesPadding: 1, TacticName: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX, TacticValue: 0x94215b398b8eb3ba, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/MaxPool]
Name: model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Int8", "Count": 36864}, Bias: {"Type": "Float", "Count": 64}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu, TacticValue: 0x9dafb2758560cc1d, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv][ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu][ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Int8", "Count": 36864}, Bias: {"Type": "Float", "Count": 64}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xe2bc5a4963d23ad0, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv][ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Int8 }, { Name: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.0/blocks.0/act/Relu_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Int8", "Count": 4096}, Bias: {"Type": "Float", "Count": 64}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1, TacticValue: 0x1cfa820c55616892, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/Conv][ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.0/Add][ONNX Layer: /model/backbone/res_layers.0/blocks.0/act/Relu]
Name: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear, LayerType: Reformat, Inputs: [ { Name: /model/backbone/res_layers.0/blocks.0/act/Relu_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x00000000000003ea, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]
Name: model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Int8", "Count": 36864}, Bias: {"Type": "Float", "Count": 64}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu, TacticValue: 0x9dafb2758560cc1d, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv][ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu][ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Int8 }, { Name: /model/backbone/res_layers.0/blocks.0/act/Relu_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.0/blocks.1/act/Relu_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Int8", "Count": 36864}, Bias: {"Type": "Float", "Count": 64}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xe2bc5a4963d23ad0, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv][ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.0/blocks.1/Add][ONNX Layer: /model/backbone/res_layers.0/blocks.1/act/Relu]
Name: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear, LayerType: Reformat, Inputs: [ { Name: /model/backbone/res_layers.0/blocks.1/act/Relu_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x00000000000003ea, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]
Name: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool, LayerType: CaskPooling, Inputs: [ { Name: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,80,80], Format/Datatype: Int8 }], ParameterType: Pooling, PoolingType: AVERAGE, WindowSize: [2,2], PaddingMode: kEXPLICIT_ROUND_UP, PrePadding: [0,0], PostPadding: [0,0], Stride: [2,2], BlendFactor: 0, AverageCountExcludesPadding: 0, TacticName: sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE, TacticValue: 0xd9375d43b61ffbcb, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool][ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]
Name: model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,160,160], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 73728}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x705baf38e41eee0b, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv][ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu][ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x4133eb8759ee0d6d, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv][ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,64,80,80], Format/Datatype: Int8 }, { Name: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.1/blocks.0/act/Relu_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 8192}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1, TacticValue: 0x8e1dd2962c589dd4, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv][ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.0/Add][ONNX Layer: /model/backbone/res_layers.1/blocks.0/act/Relu]
Name: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear, LayerType: Reformat, Inputs: [ { Name: /model/backbone/res_layers.1/blocks.0/act/Relu_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x00000000000003ea, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]
Name: model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x128x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu, TacticValue: 0x214f03e23f252333, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv][ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu][ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }, { Name: /model/backbone/res_layers.1/blocks.0/act/Relu_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.1/blocks.1/act/Relu_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x4133eb8759ee0d6d, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv][ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.1/blocks.1/Add][ONNX Layer: /model/backbone/res_layers.1/blocks.1/act/Relu]
Name: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear, LayerType: Reformat, Inputs: [ { Name: /model/backbone/res_layers.1/blocks.1/act/Relu_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x00000000000003ea, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]
Name: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool, LayerType: CaskPooling, Inputs: [ { Name: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], ParameterType: Pooling, PoolingType: AVERAGE, WindowSize: [2,2], PaddingMode: kEXPLICIT_ROUND_UP, PrePadding: [0,0], PostPadding: [0,0], Stride: [2,2], BlendFactor: 0, AverageCountExcludesPadding: 0, TacticName: sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE, TacticValue: 0xd9375d43b61ffbcb, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool][ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]
Name: model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 294912}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xbb88763c3b0e94d4, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv][ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu][ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xad6872a374321f7e, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv][ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }, { Name: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.2/blocks.0/act/Relu_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 32768}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1, TacticValue: 0x8e1dd2962c589dd4, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv][ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.0/Add][ONNX Layer: /model/backbone/res_layers.2/blocks.0/act/Relu]
Name: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear, LayerType: Reformat, Inputs: [ { Name: /model/backbone/res_layers.2/blocks.0/act/Relu_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x00000000000003ea, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]
Name: model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xbb88763c3b0e94d4, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv][ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu][ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }, { Name: /model/backbone/res_layers.2/blocks.0/act/Relu_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.2/blocks.1/act/Relu_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xad6872a374321f7e, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv][ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.1/Add][ONNX Layer: /model/backbone/res_layers.2/blocks.1/act/Relu]
Name: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear, LayerType: Reformat, Inputs: [ { Name: /model/backbone/res_layers.2/blocks.1/act/Relu_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x00000000000003ea, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]
Name: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool, LayerType: CaskPooling, Inputs: [ { Name: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Int8 }], ParameterType: Pooling, PoolingType: AVERAGE, WindowSize: [2,2], PaddingMode: kEXPLICIT_ROUND_UP, PrePadding: [0,0], PostPadding: [0,0], Stride: [2,2], BlendFactor: 0, AverageCountExcludesPadding: 0, TacticName: sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE, TacticValue: 0xd9375d43b61ffbcb, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool][ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]
Name: model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Int8", "Count": 1179648}, Bias: {"Type": "Float", "Count": 512}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32, TacticValue: 0x322f337abc345152, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv][ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu][ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Int8", "Count": 2359296}, Bias: {"Type": "Float", "Count": 512}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xc5159665a920f22c, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv][ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Int8 }, { Name: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.3/blocks.0/act/Relu_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Int8", "Count": 131072}, Bias: {"Type": "Float", "Count": 512}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1, TacticValue: 0x4f8662a723b489e1, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv][ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.0/Add][ONNX Layer: /model/backbone/res_layers.3/blocks.0/act/Relu]
Name: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear, LayerType: Reformat, Inputs: [ { Name: /model/backbone/res_layers.3/blocks.0/act/Relu_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]
Name: model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Int8 }], Outputs: [ { Name: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Int8", "Count": 2359296}, Bias: {"Type": "Float", "Count": 512}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x64x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu, TacticValue: 0x1d53511430a5d47e, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv][ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu][ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]
Name: model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Int8 }, { Name: /model/backbone/res_layers.3/blocks.0/act/Relu_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Half }], Outputs: [ { Name: /model/backbone/res_layers.3/blocks.1/act/Relu_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Int8", "Count": 2359296}, Bias: {"Type": "Float", "Count": 512}, HasBias: 1, HasReLU: 1, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xc5159665a920f22c, StreamId: 0, Metadata: [ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv][ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization][ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.1/Add][ONNX Layer: /model/backbone/res_layers.3/blocks.1/act/Relu]
Name: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear, LayerType: Reformat, Inputs: [ { Name: /model/backbone/res_layers.3/blocks.1/act/Relu_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear]
Name: model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/input_proj.2/conv/Conv_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 131072}, Bias: {"Type": "Float", "Count": 0}, HasBias: 0, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1, TacticValue: 0x7524377e24bc511f, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/input_proj.2/conv/Conv][ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]
Name: Reformatting CopyNode for Input Tensor 0 to {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}, LayerType: Reformat, Inputs: [ { Name: /model/encoder/input_proj.2/conv/Conv_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Half }], Outputs: [ { Name: Reformatted Input Tensor 0 to {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Half }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: dummy_shape_call__mye8926_0_myl38_0, LayerType: shape_call, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __myl_MulAddResMovTraAddTra_myl38_1, LayerType: kgen, Inputs: [ { Name: /model/encoder/encoder_0/layers_0/Constant_output_0_constantHalf, Dimensions: [1,400,256], Format/Datatype: Half }, { Name: /model/encoder/input_proj_2/norm/BatchNormalization/model/encoder/input_proj_2/norm/BatchNormalization_shift_wHalf, Dimensions: [1,256,1,1], Format/Datatype: Half }, { Name: Reformatted Input Tensor 0 to {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}, Dimensions: [1,256,20,20], Format/Datatype: Half }, { Name: /model/encoder/input_proj_2/norm/BatchNormalization/model/encoder/input_proj_2/norm/BatchNormalization_scale_wHalf, Dimensions: [1,256,1,1], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/encoder_0/layers_0/self_attn/Transpose_1_first_transpose_output.1, Dimensions: [400,1,256], Format/Datatype: Half }, { Name: __myln_k_arg__bb1_4, Dimensions: [1,400,256], Format/Datatype: Half }, { Name: /model/encoder/encoder_0/layers_0/Add_output_0'.1, Dimensions: [1,400,256], Format/Datatype: Half }], TacticName: __myl_MulAddResMovTraAddTra_0xf4d05087139b538178007bf6bb80a08a, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/input_proj.2/norm/BatchNormalization][ONNX Layer: /model/encoder/Reshape][ONNX Layer: /model/encoder/encoder.0/layers.0/Add][ONNX Layer: /model/encoder/Transpose][ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1]
Name: __mye8857_myl38_2, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __mye8859_myl38_3, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl38_4, LayerType: gemm, Inputs: [ { Name: /model/encoder/encoder_0/layers_0/self_attn/Transpose_1_first_transpose_output.1, Dimensions: [400,256], Format/Datatype: Half }, { Name: __mye8790dconst, Dimensions: [256,256], Format/Datatype: Half }, { Name: __mye8279/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye8280/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_beta, Dimensions: [1], Format/Datatype: Float }, { Name: __mye8565_reshape, Dimensions: [1,256], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/encoder_0/layers_0/self_attn/Add_2_output_0'.1, Dimensions: [400,256], Format/Datatype: Half }], TacticName: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16, StreamId: 1, Metadata: [ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2][ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_2]
Name: __mye8861_myl38_5, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_6, LayerType: gemm, Inputs: [ { Name: /model/encoder/encoder_0/layers_0/Add_output_0'.1, Dimensions: [400,256], Format/Datatype: Half }, { Name: __mye8716_dconst, Dimensions: [2,256,256], Format/Datatype: Half }, { Name: __mye8321/model/encoder/encoder_0/layers_0/self_attn/MatMul_1_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye8322/model/encoder/encoder_0/layers_0/self_attn/MatMul_1_beta, Dimensions: [1], Format/Datatype: Float }, { Name: __mye8721_dconst, Dimensions: [2,1,256], Format/Datatype: Half }], Outputs: [ { Name: __mye8628, Dimensions: [2,400,256], Format/Datatype: Half }], TacticName: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1][ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_1][ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul][ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add]
Name: __mye8863_myl38_7, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: _gemm_mha_v2_myl38_8, LayerType: kgen, Inputs: [ { Name: __mye8628, Dimensions: [8,400,32], Format/Datatype: Half }, { Name: __mye8628, Dimensions: [8,32,400], Format/Datatype: Half }, { Name: /model/encoder/encoder_0/layers_0/self_attn/Add_2_output_0'.1, Dimensions: [8,400,32], Format/Datatype: Half }], Outputs: [ { Name: __myln_k_arg__bb1_7, Dimensions: [8,400,32], Format/Datatype: Half }], TacticName: _gemm_mha_v2_0xb49a52fc0767aa7be96106641036114d, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4][ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Softmax][ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3][ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Mul_1]
Name: __myl_Tra_myl38_9, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_7, Dimensions: [8,400,32], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/encoder_0/layers_0/self_attn/Transpose_5 _ /model/encoder/encoder_0/layers_0/self_attn/Reshape_3_first_transpose_output.1, Dimensions: [400,8,32], Format/Datatype: Half }], TacticName: __myl_Tra_0xb89fdb3500b2782dfe651a509d523a76, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5][ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3]
Name: /model/encoder/encoder_0/layers_0/self_attn/Gemm_myl38_10, LayerType: gemm, Inputs: [ { Name: /model/encoder/encoder_0/layers_0/self_attn/Transpose_5 _ /model/encoder/encoder_0/layers_0/self_attn/Reshape_3_first_transpose_output.1, Dimensions: [400,256], Format/Datatype: Half }, { Name: __mye8409_dconst, Dimensions: [256,256], Format/Datatype: Half }, { Name: __mye8359/model/encoder/encoder_0/layers_0/self_attn/Gemm_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye8360/model/encoder/encoder_0/layers_0/self_attn/Gemm_beta, Dimensions: [1], Format/Datatype: Float }, { Name: model_encoder_encoder_0_layers_0_self_attn_out_proj_bias _ ONNXTRT_Broadcast_116_constantHalf, Dimensions: [1,256], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/encoder_0/layers_0/self_attn/Gemm_output_0'.1, Dimensions: [400,256], Format/Datatype: Half }], TacticName: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Gemm]
Name: __myl_AddCasMeaSubMulMeaAddSqrDivMulCasMulAddCasMulMinMaxRouCas_myl38_11, LayerType: kgen, Inputs: [ { Name: model_encoder_encoder_0_layers_0_norm1_bias _ ONNXTRT_Broadcast_123_constantHalf, Dimensions: [1,1,256], Format/Datatype: Half }, { Name: model_encoder_encoder_0_layers_0_norm1_weight _ ONNXTRT_Broadcast_121_constantHalf, Dimensions: [1,1,256], Format/Datatype: Half }, { Name: __mye8922_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_4, Dimensions: [1,400,256], Format/Datatype: Half }, { Name: /model/encoder/encoder_0/layers_0/self_attn/Gemm_output_0'.1, Dimensions: [1,400,256], Format/Datatype: Half }], Outputs: [ { Name: __myln_k_arg__bb1_11, Dimensions: [1,400,256], Format/Datatype: Half }, { Name: __myln_k_arg__bb1_10, Dimensions: [1,400,256], Format/Datatype: Int8 }], TacticName: __myl_AddCasMeaSubMulMeaAddSqrDivMulCasMulAddCasMulMinMaxRouCas_0x67d6d88e10867297ea489fcf1246e2e4, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/encoder.0/layers.0/Add_1][ONNX Layer: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization][ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear]
Name: /model/encoder/encoder_0/layers_0/linear1/MatMul_myl38_12, LayerType: gemm, Inputs: [ { Name: __myln_k_arg__bb1_10, Dimensions: [1,400,256], Format/Datatype: Int8 }, { Name: __mye8795dconst, Dimensions: [1,256,1024], Format/Datatype: Int8 }, { Name: __mye8585_dconst, Dimensions: [1,1024], Format/Datatype: Float }, { Name: __mye8592zero_beta, Dimensions: [1,1024], Format/Datatype: Float }, { Name: __mye8596_dconst, Dimensions: [1,1,1024], Format/Datatype: Float }], Outputs: [ { Name: cast__mye8738_12, Dimensions: [1,400,1024], Format/Datatype: Int8 }], TacticName: sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_gelu_erf, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/MatMul][ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul_1][ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul][ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Add][ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Div][ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Erf][ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/Add]
Name: /model/encoder/encoder_0/layers_0/linear2/MatMul_myl38_13, LayerType: gemm, Inputs: [ { Name: cast__mye8738_12, Dimensions: [1,400,1024], Format/Datatype: Int8 }, { Name: __mye8800dconst, Dimensions: [1,1024,256], Format/Datatype: Int8 }, { Name: __mye8601_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye8608zero_beta, Dimensions: [1,256], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_13, Dimensions: [1,400,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul][ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]
Name: __myl_CasAddAddCasMeaSubMulMea_myl38_14, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_11, Dimensions: [1,400,256], Format/Datatype: Half }, { Name: model_encoder_encoder_0_layers_0_linear2_bias _ ONNXTRT_Broadcast_145_constantHalf, Dimensions: [1,1,256], Format/Datatype: Half }, { Name: __myln_k_arg__bb1_13, Dimensions: [1,400,256], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_15, Dimensions: [1,400,1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_14, Dimensions: [1,400,256], Format/Datatype: Float }], TacticName: __myl_CasAddAddCasMeaSubMulMea_0x49f50938e3a06c933ca11aab5f20134c, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul][ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add][ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization][ONNX Layer: /model/encoder/encoder.0/layers.0/Add_2]
Name: __myl_AddSqrDivMulCasMulAddTraRes_myl38_15, LayerType: kgen, Inputs: [ { Name: model_encoder_encoder_0_layers_0_norm2_weight _ ONNXTRT_Broadcast_149_constantHalf, Dimensions: [1,1,256], Format/Datatype: Half }, { Name: model_encoder_encoder_0_layers_0_norm2_bias _ ONNXTRT_Broadcast_151_constantHalf, Dimensions: [1,1,256], Format/Datatype: Half }, { Name: __myln_k_arg__bb1_14, Dimensions: [1,400,256], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_15, Dimensions: [1,400,1], Format/Datatype: Float }], Outputs: [ { Name: /model/encoder/Reshape_1_output_0, Dimensions: [1,256,20,20], Format/Datatype: Half }], TacticName: __myl_AddSqrDivMulCasMulAddTraRes_0xd61c74fd4ab12b19fae354ddcd6de65d, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization][ONNX Layer: /model/encoder/Transpose_1][ONNX Layer: /model/encoder/Reshape_1]
Name: model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,80,80], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 32768}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1, TacticValue: 0x483ad1560c6e5e27, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/input_proj.0/conv/Conv][ONNX Layer: /model/encoder/input_proj.0/norm/BatchNormalization][ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1, TacticValue: 0x483ad1560c6e5e27, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/input_proj.1/conv/Conv][ONNX Layer: /model/encoder/input_proj.1/norm/BatchNormalization][ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]
Name: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear, LayerType: Reformat, Inputs: [ { Name: /model/encoder/Reshape_1_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear]
Name: model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/lateral_convs.0/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1, TacticValue: 0x7524377e24bc511f, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/lateral_convs.0/conv/Conv][ONNX Layer: /model/encoder/lateral_convs.0/norm/BatchNormalization][ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear]
Name: PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul), LayerType: PointWiseV2, Inputs: [ { Name: /model/encoder/lateral_convs.0/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/lateral_convs.0/act/Mul_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Half }], ParameterType: PointWise, ParameterSubType: PointWiseExpression, NbInputArgs: 1, InputArgs: ["arg0"], NbOutputVars: 1, OutputVars: ["var4"], NbParams: 0, Params: [], NbLiterals: 5, Literals: ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"], NbOperations: 5, Operations: ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);"], TacticValue: 0x0000000000000018, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/lateral_convs.0/act/Sigmoid][ONNX Layer: /model/encoder/lateral_convs.0/act/Mul]
Name: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0, LayerType: Reformat, Inputs: [ { Name: /model/encoder/lateral_convs.0/act/Mul_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/Resize_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]
Name: /model/encoder/Resize, LayerType: Resize, Inputs: [ { Name: /model/encoder/Resize_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], ParameterType: Resize, InterpolationMode: NEAREST, ResizeScales: [1, 1, 2, 2, 0, 0, 0, 0], ExcludeOutside: 0, CubicCoeff: -0.75, CoordTransform: kASYMMETRIC, ResizeSelector: kFORMULA, NNRounding: kFLOOR, TacticValue: 0x0000000000000003, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/Resize]
Name: /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy, LayerType: Reformat, Inputs: [ { Name: /model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: CONCAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/Concat_2]
Name: model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1, TacticValue: 0x8e1dd2962c589dd4, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/Conv][ONNX Layer: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization][ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish, TacticValue: 0x2eba0b6a8ec55fa3, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/Conv][ONNX Layer: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization][ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid][ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Mul][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish, TacticValue: 0x6176c23707257237, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish, TacticValue: 0x6176c23707257237, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xad6872a374321f7e, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]
Name: PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add)), LayerType: PointWiseV2, Inputs: [ { Name: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Half }, { Name: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], ParameterType: PointWise, ParameterSubType: PointWiseExpression, NbInputArgs: 2, InputArgs: ["arg0", "arg1"], NbOutputVars: 1, OutputVars: ["var10"], NbParams: 0, Params: [], NbLiterals: 10, Literals: ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"], NbOperations: 11, Operations: ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"], TacticValue: 0x0000000000000018, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid][ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul][ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid][ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Mul][ONNX Layer: /model/encoder/fpn_blocks.0/Add][ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]
Name: model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 32768}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish, TacticValue: 0x2eba0b6a8ec55fa3, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/Conv][ONNX Layer: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization][ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid][ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Mul][ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/Resize_1_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish, TacticValue: 0x2eba0b6a8ec55fa3, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/lateral_convs.1/conv/Conv][ONNX Layer: /model/encoder/lateral_convs.1/norm/BatchNormalization][ONNX Layer: /model/encoder/lateral_convs.1/act/Sigmoid][ONNX Layer: /model/encoder/lateral_convs.1/act/Mul][ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear]
Name: /model/encoder/Resize_1, LayerType: Resize, Inputs: [ { Name: /model/encoder/Resize_1_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0, Location: Device, Dimensions: [1,256,80,80], Format/Datatype: Int8 }], ParameterType: Resize, InterpolationMode: NEAREST, ResizeScales: [1, 1, 2, 2, 0, 0, 0, 0], ExcludeOutside: 0, CubicCoeff: -0.75, CoordTransform: kASYMMETRIC, ResizeSelector: kFORMULA, NNRounding: kFLOOR, TacticValue: 0x0000000000000005, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/Resize_1]
Name: /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy, LayerType: Reformat, Inputs: [ { Name: /model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0, Location: Device, Dimensions: [1,256,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,80,80], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: CONCAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/Concat_3]
Name: model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1, TacticValue: 0x758f8b2079a95b2e, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/Conv][ONNX Layer: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization][ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish, TacticValue: 0x458f02d2b10db57c, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/Conv][ONNX Layer: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization][ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid][ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Mul][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish, TacticValue: 0xfdf7509af98902e0, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish, TacticValue: 0xfdf7509af98902e0, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x4133eb8759ee0d6d, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]
Name: PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add)), LayerType: PointWiseV2, Inputs: [ { Name: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Half }, { Name: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], ParameterType: PointWise, ParameterSubType: PointWiseExpression, NbInputArgs: 2, InputArgs: ["arg0", "arg1"], NbOutputVars: 1, OutputVars: ["var10"], NbParams: 0, Params: [], NbLiterals: 10, Literals: ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"], NbOperations: 11, Operations: ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"], TacticValue: 0x000000000000001f, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid][ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul][ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid][ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Mul][ONNX Layer: /model/encoder/fpn_blocks.1/Add][ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]
Name: model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,80,80], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 32768}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish, TacticValue: 0x65a38dbc9e991257, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/Conv][ONNX Layer: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization][ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid][ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Mul][ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]
Name: model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/decoder/input_proj.0/conv/Conv_output_0, Location: Device, Dimensions: [1,256,80,80], Format/Datatype: Float }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 0}, HasBias: 0, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4, TacticValue: 0x733ba2a91a48d431, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/input_proj.0/conv/Conv][ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,80,80], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish, TacticValue: 0xc722efd60bc6ea84, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/downsample_convs.0/conv/Conv][ONNX Layer: /model/encoder/downsample_convs.0/norm/BatchNormalization][ONNX Layer: /model/encoder/downsample_convs.0/act/Sigmoid][ONNX Layer: /model/encoder/downsample_convs.0/act/Mul][ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear]
Name: /model/encoder/Resize_1_output_0 copy, LayerType: Reformat, Inputs: [ { Name: /model/encoder/Resize_1_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: CONCAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/Concat_4]
Name: model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1, TacticValue: 0x8e1dd2962c589dd4, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/Conv][ONNX Layer: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization][ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish, TacticValue: 0x2eba0b6a8ec55fa3, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/Conv][ONNX Layer: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization][ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Sigmoid][ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Mul][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish, TacticValue: 0x6176c23707257237, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish, TacticValue: 0x6176c23707257237, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xad6872a374321f7e, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]
Name: PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add)), LayerType: PointWiseV2, Inputs: [ { Name: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Half }, { Name: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], ParameterType: PointWise, ParameterSubType: PointWiseExpression, NbInputArgs: 2, InputArgs: ["arg0", "arg1"], NbOutputVars: 1, OutputVars: ["var10"], NbParams: 0, Params: [], NbLiterals: 10, Literals: ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"], NbOperations: 11, Operations: ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"], TacticValue: 0x0000000000000018, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid][ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul][ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Sigmoid][ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Mul][ONNX Layer: /model/encoder/pan_blocks.0/Add][ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]
Name: model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 32768}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish, TacticValue: 0x2eba0b6a8ec55fa3, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/Conv][ONNX Layer: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization][ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Sigmoid][ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Mul][ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]
Name: model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/decoder/input_proj.1/conv/Conv_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Float }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 0}, HasBias: 0, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4, TacticValue: 0x733ba2a91a48d431, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/input_proj.1/conv/Conv][ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,40,40], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish, TacticValue: 0xc985777c89c6b3a4, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/downsample_convs.1/conv/Conv][ONNX Layer: /model/encoder/downsample_convs.1/norm/BatchNormalization][ONNX Layer: /model/encoder/downsample_convs.1/act/Sigmoid][ONNX Layer: /model/encoder/downsample_convs.1/act/Mul][ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear]
Name: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1, LayerType: Reformat, Inputs: [ { Name: /model/encoder/lateral_convs.0/act/Mul_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Int8 }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]
Name: model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,128,20,20], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1, TacticValue: 0x7524377e24bc511f, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/Conv][ONNX Layer: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization][ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,512,20,20], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,20,20], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish, TacticValue: 0xc6cdb1e47323bb01, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/Conv][ONNX Layer: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization][ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Sigmoid][ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Mul][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,20,20], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,20,20], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish, TacticValue: 0xc985777c89c6b3a4, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,20,20], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,20,20], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish, TacticValue: 0xc985777c89c6b3a4, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]
Name: model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,20,20], Format/Datatype: Int8 }], Outputs: [ { Name: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0, Location: Device, Dimensions: [1,128,20,20], Format/Datatype: Half }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x51a916d02de43689, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]
Name: PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add)), LayerType: PointWiseV2, Inputs: [ { Name: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0, Location: Device, Dimensions: [1,128,20,20], Format/Datatype: Half }, { Name: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0, Location: Device, Dimensions: [1,128,20,20], Format/Datatype: Half }], Outputs: [ { Name: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,20,20], Format/Datatype: Int8 }], ParameterType: PointWise, ParameterSubType: PointWiseExpression, NbInputArgs: 2, InputArgs: ["arg0", "arg1"], NbOutputVars: 1, OutputVars: ["var10"], NbParams: 0, Params: [], NbLiterals: 10, Literals: ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"], NbOperations: 11, Operations: ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"], TacticValue: 0x0000000000000018, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid][ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul][ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Sigmoid][ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Mul][ONNX Layer: /model/encoder/pan_blocks.1/Add][ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]
Name: model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul), LayerType: CaskConvolution, Inputs: [ { Name: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,128,20,20], Format/Datatype: Int8 }], Outputs: [ { Name: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Int8 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 32768}, Bias: {"Type": "Float", "Count": 256}, HasBias: 1, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: SWISH, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish, TacticValue: 0xc6cdb1e47323bb01, StreamId: 0, Metadata: [ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/Conv][ONNX Layer: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization][ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Sigmoid][ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Mul][ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]
Name: model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Int8 }], Outputs: [ { Name: /model/decoder/input_proj.2/conv/Conv_output_0, Location: Device, Dimensions: [1,256,20,20], Format/Datatype: Float }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 65536}, Bias: {"Type": "Float", "Count": 0}, HasBias: 0, HasReLU: 0, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4, TacticValue: 0x5e4f6d7c83746fd6, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/input_proj.2/conv/Conv][ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]
Name: dummy_shape_call__mye158089_0_myl85_0, LayerType: shape_call, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: entry^bb^signal^1_myl85_1, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: entry^bb^wait^1_myl85_2, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: __myl_MulAddResMulMinMaxRouCasTra_myl85_3, LayerType: kgen, Inputs: [ { Name: __mye155645_dconst, Dimensions: [1,1,6400], Format/Datatype: Float }, { Name: /model/decoder/input_proj_0/norm/BatchNormalization/model/decoder/input_proj_0/norm/BatchNormalization_shift_wFloat, Dimensions: [1,256,1,1], Format/Datatype: Float }, { Name: /model/decoder/input_proj.0/conv/Conv_output_0, Dimensions: [1,256,80,80], Format/Datatype: Float }, { Name: /model/decoder/input_proj_0/norm/BatchNormalization/model/decoder/input_proj_0/norm/BatchNormalization_scale_wFloat, Dimensions: [1,256,1,1], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_6, Dimensions: [1,6400,256], Format/Datatype: Int8 }, { Name: __myln_k_arg__bb1_5, Dimensions: [1,256,80,80], Format/Datatype: Float }], TacticName: __myl_MulAddResMulMinMaxRouCasTra_0xb7911a963641d99b9b7644b75b6b02a0, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/input_proj.0/norm/BatchNormalization][ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/Reshape][ONNX Layer: /model/decoder/Transpose]
Name: __myl_MulMinMaxRouCasResTra_myl85_4, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_5, Dimensions: [1,256,80,80], Format/Datatype: Float }, { Name: __mye157989_const-lit-in, Dimensions: [1], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_7, Dimensions: [1,6400,256], Format/Datatype: Int8 }], TacticName: __myl_MulMinMaxRouCasResTra_0x53ec280dcdcbc7be42089db5a99e26ce, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/Reshape][ONNX Layer: /model/decoder/Transpose]
Name: __myl_MulAddResMulMinMaxRouCasTra_myl85_5, LayerType: kgen, Inputs: [ { Name: __mye155668_dconst, Dimensions: [1,1,1600], Format/Datatype: Float }, { Name: /model/decoder/input_proj_1/norm/BatchNormalization/model/decoder/input_proj_1/norm/BatchNormalization_shift_wFloat, Dimensions: [1,256,1,1], Format/Datatype: Float }, { Name: /model/decoder/input_proj.1/conv/Conv_output_0, Dimensions: [1,256,40,40], Format/Datatype: Float }, { Name: /model/decoder/input_proj_1/norm/BatchNormalization/model/decoder/input_proj_1/norm/BatchNormalization_scale_wFloat, Dimensions: [1,256,1,1], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_9, Dimensions: [1,1600,256], Format/Datatype: Int8 }, { Name: __myln_k_arg__bb1_8, Dimensions: [1,256,40,40], Format/Datatype: Float }], TacticName: __myl_MulAddResMulMinMaxRouCasTra_0xc7826108fa2ff5e34bf8bfa07dbc52f7, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/input_proj.1/norm/BatchNormalization][ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/Reshape_1][ONNX Layer: /model/decoder/Transpose_1]
Name: __myl_MulMinMaxRouCasResTra_myl85_6, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_8, Dimensions: [1,256,40,40], Format/Datatype: Float }, { Name: __mye157989_const-lit-in, Dimensions: [1], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_10, Dimensions: [1,1600,256], Format/Datatype: Int8 }], TacticName: __myl_MulMinMaxRouCasResTra_0x8592f20b4eb6c9ee9a9e56f44ec5871e, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/Reshape_1][ONNX Layer: /model/decoder/Transpose_1]
Name: __mye157455_myl85_7, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: __mye157457_myl85_8, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_myl85_9, LayerType: kgen, Inputs: [ { Name: __mye157989_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_7, Dimensions: [1,6400,256], Format/Datatype: Int8 }, { Name: __myln_k_arg__bb1_10, Dimensions: [1,1600,256], Format/Datatype: Int8 }, { Name: __mye155691_dconst, Dimensions: [1,1,400], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_6, Dimensions: [1,6400,256], Format/Datatype: Int8 }, { Name: __myln_k_arg__bb1_9, Dimensions: [1,1600,256], Format/Datatype: Int8 }, { Name: /model/decoder/input_proj_2/norm/BatchNormalization/model/decoder/input_proj_2/norm/BatchNormalization_shift_wFloat, Dimensions: [1,256,1,1], Format/Datatype: Float }, { Name: /model/decoder/input_proj.2/conv/Conv_output_0, Dimensions: [1,256,20,20], Format/Datatype: Float }, { Name: /model/decoder/input_proj_2/norm/BatchNormalization/model/decoder/input_proj_2/norm/BatchNormalization_scale_wFloat, Dimensions: [1,256,1,1], Format/Datatype: Float }], Outputs: [ { Name: __mye154083_12, Dimensions: [1,8400,256], Format/Datatype: Int8 }, { Name: __myln_k_arg__bb1_11, Dimensions: [1,8400,256], Format/Datatype: Int8 }], TacticName: __myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_0x14d97ab92d57b85a1bd3815e99f6e152, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/input_proj.2/norm/BatchNormalization][ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/Concat_3][ONNX Layer: /model/decoder/Reshape_2][ONNX Layer: /model/decoder/Transpose_2][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]
Name: __mye157459_myl85_10, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __mye157461_myl85_11, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_12, LayerType: gemm, Inputs: [ { Name: __mye154083_12, Dimensions: [1,8400,256], Format/Datatype: Int8 }, { Name: __mye156340dconst, Dimensions: [3,256,256], Format/Datatype: Int8 }, { Name: __mye154107_dconst, Dimensions: [3,1,256], Format/Datatype: Float }, { Name: __mye154128_dconst, Dimensions: [3,1,256], Format/Datatype: Float }, { Name: __mye155126_dconst, Dimensions: [3,1,256], Format/Datatype: Float }], Outputs: [ { Name: __mye154083, Dimensions: [3,8400,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add]
Name: /model/decoder/enc_output/proj/MatMul_myl85_13, LayerType: gemm, Inputs: [ { Name: __myln_k_arg__bb1_11, Dimensions: [1,8400,256], Format/Datatype: Int8 }, { Name: __mye156345dconst, Dimensions: [1,256,256], Format/Datatype: Int8 }, { Name: __mye153194_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153201zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: model_decoder_enc_output_proj_bias _ ONNXTRT_Broadcast_275_constantFloat, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_14, Dimensions: [1,8400,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/enc_output/proj/MatMul][ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/enc_output/proj/Add]
Name: __myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_14, LayerType: kgen, Inputs: [ { Name: model_decoder_enc_output_norm_weight _ ONNXTRT_Broadcast_279_constantFloat, Dimensions: [1,1,256], Format/Datatype: Float }, { Name: model_decoder_enc_output_norm_bias _ ONNXTRT_Broadcast_281_constantFloat, Dimensions: [1,1,256], Format/Datatype: Float }, { Name: __mye157999_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_14, Dimensions: [1,8400,256], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_14, Dimensions: [1,8400,256], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_16, Dimensions: [1,8400,256], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_15, Dimensions: [1,8400,256], Format/Datatype: Int8 }], TacticName: __myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0xf1c80ff651c1b506b1815818d6281ad3, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/enc_output/norm/LayerNormalization][ONNX Layer: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear]
Name: __mye157463_myl85_15, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __mye157465_myl85_16, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/decoder/enc_score_head/MatMul_myl85_17, LayerType: gemm, Inputs: [ { Name: __myln_k_arg__bb1_15, Dimensions: [1,8400,256], Format/Datatype: Int8 }, { Name: __mye156355dconst, Dimensions: [1,256,80], Format/Datatype: Int8 }, { Name: __mye153232_dconst, Dimensions: [1,80], Format/Datatype: Float }, { Name: __mye153239zero_beta, Dimensions: [1,80], Format/Datatype: Float }, { Name: model_decoder_enc_score_head_bias _ ONNXTRT_Broadcast_289_constantFloat, Dimensions: [1,1,80], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_17, Dimensions: [1,8400,80], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/enc_score_head/MatMul][ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/enc_score_head/Add]
Name: __myl_Max_myl85_18, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_17, Dimensions: [1,8400,80], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/ReduceMax_output_0'_unsqueezed0.1, Dimensions: [1,8400,1], Format/Datatype: Float }], TacticName: __myl_Max_0x4330a02939b906fc5f8c1bd769456467, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/ReduceMax]
Name: __myl_Top_myl85_19, LayerType: kgen, Inputs: [ { Name: /model/decoder/ReduceMax_output_0'_unsqueezed0.1, Dimensions: [1,8400], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/TopK_output_0'.1, Dimensions: [1,300], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_20, Dimensions: [1,300], Format/Datatype: Int32 }], TacticName: __myl_Top_0x7e62297dffa2e596ee60049838a70f81, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/TopK]
Name: __mye157467_myl85_20, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/decoder/enc_bbox_head/layers_0/MatMul_myl85_21, LayerType: gemm, Inputs: [ { Name: __myln_k_arg__bb1_15, Dimensions: [1,8400,256], Format/Datatype: Int8 }, { Name: __mye157529_xformed___mye156350dconst, Dimensions: [1,256,256], Format/Datatype: Int8 }, { Name: __mye157537_xformed___mye153216_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153212zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye157533_xformed___mye153225_dconst, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/enc_bbox_head/layers_2/input_quantizer/QuantizeLinear_output_0'.1_21, Dimensions: [1,8400,256], Format/Datatype: Int8 }], TacticName: sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize32x32_stage4_warpsize2x4x1_r1s1_u1v1_hw1_c256_scalebias_relu, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/enc_bbox_head/layers.0/MatMul][ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/enc_bbox_head/act/Relu][ONNX Layer: /model/decoder/enc_bbox_head/layers.0/Add]
Name: /model/decoder/enc_bbox_head/layers_1/MatMul_myl85_22, LayerType: gemm, Inputs: [ { Name: /model/decoder/enc_bbox_head/layers_2/input_quantizer/QuantizeLinear_output_0'.1_21, Dimensions: [1,8400,256], Format/Datatype: Int8 }, { Name: __mye157541_xformed___mye156360dconst, Dimensions: [1,256,256], Format/Datatype: Int8 }, { Name: __mye157549_xformed___mye153254_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153250zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye157545_xformed___mye153263_dconst, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_22, Dimensions: [1,8400,256], Format/Datatype: Int8 }], TacticName: sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize32x32_stage4_warpsize2x4x1_r1s1_u1v1_hw1_c256_scalebias_relu, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/enc_bbox_head/layers.1/MatMul][ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/enc_bbox_head/act_1/Relu][ONNX Layer: /model/decoder/enc_bbox_head/layers.1/Add]
Name: __myl_FcAdd_myl85_23, LayerType: fusion, Inputs: [ { Name: model_decoder_anchors_constantFloat, Dimensions: [1,8400,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_22, Dimensions: [1,8400,256], Format/Datatype: Int8 }, { Name: __mye156365dconst, Dimensions: [1,256,4], Format/Datatype: Int8 }, { Name: __mye153270_dconst, Dimensions: [1,4], Format/Datatype: Float }, { Name: __mye153277zero_beta, Dimensions: [1,4], Format/Datatype: Float }, { Name: model_decoder_enc_bbox_head_layers_2_bias _ ONNXTRT_Broadcast_311_constantFloat, Dimensions: [1,1,4], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_23, Dimensions: [1,8400,4], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_by_fusion_tactic, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/enc_bbox_head/layers.2/MatMul][ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/enc_bbox_head/layers.2/Add][ONNX Layer: /model/decoder/Add]
Name: __mye157469_myl85_24, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_myl85_25, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_23, Dimensions: [1,8400,4], Format/Datatype: Float }, { Name: __mye158003_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_20, Dimensions: [1,300], Format/Datatype: Int32 }], Outputs: [ { Name: __myln_k_arg__bb1_26, Dimensions: [300,4], Format/Datatype: Float }, { Name: /model/decoder/decoder/query_pos_head/layers_0/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [300,4], Format/Datatype: Int8 }, { Name: __myln_k_arg__bb1_25, Dimensions: [1,300,1], Format/Datatype: Int32 }], TacticName: __myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_0xea994e8a02766a6b87cc77a0ab1bb663, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/Unsqueeze][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/decoder/Sigmoid][ONNX Layer: /model/decoder/GatherElements]
Name: __myl_MovCon_myl85_26, LayerType: kgen, Inputs: [ { Name: __mye156623, Dimensions: [1,300,12], Format/Datatype: Int8 }, { Name: /model/decoder/decoder/query_pos_head/layers_0/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [1,300,4], Format/Datatype: Int8 }], Outputs: [ { Name: /model/decoder/decoder/query_pos_head/layers_1/input_quantizer/QuantizeLinear_output_0'.1_27, Dimensions: [1,300,16], Format/Datatype: Int8 }], TacticName: __myl_MovCon_0x9482c2d60923b5d68d1030431d0b6d2e, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]
Name: /model/decoder/decoder/query_pos_head/layers_0/MatMul_myl85_27, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/query_pos_head/layers_1/input_quantizer/QuantizeLinear_output_0'.1_27, Dimensions: [1,300,16], Format/Datatype: Int8 }, { Name: __mye156637_dconst, Dimensions: [1,16,512], Format/Datatype: Int8 }, { Name: __mye153292_dconst, Dimensions: [1,512], Format/Datatype: Float }, { Name: __mye153288zero_beta, Dimensions: [1,512], Format/Datatype: Float }, { Name: __mye153301_dconst, Dimensions: [1,1,512], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1_28, Dimensions: [1,300,512], Format/Datatype: Int8 }], TacticName: sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]
Name: /model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_28, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1_28, Dimensions: [1,300,512], Format/Datatype: Int8 }, { Name: __mye156375dconst, Dimensions: [1,512,256], Format/Datatype: Int8 }, { Name: __mye153308_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153315zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye149975_dconst, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/MatMul][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/Add]
Name: __myl_RepGatResAdd_myl85_29, LayerType: kgen, Inputs: [ { Name: /model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_16, Dimensions: [1,8400,256], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_25, Dimensions: [1,300,1], Format/Datatype: Int32 }], Outputs: [ { Name: /model/decoder/decoder/layers_0/Add_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: /model/decoder/GatherElements_1_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: __myl_RepGatResAdd_0x3585782c9d9cf8f0d2b18744e46affde, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/GatherElements_1][ONNX Layer: /model/decoder/decoder/layers.0/Add]
Name: __mye157471_myl85_30, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __mye157473_myl85_31, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/decoder/decoder/layers_0/self_attn/MatMul_2_myl85_32, LayerType: gemm, Inputs: [ { Name: /model/decoder/GatherElements_1_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: __mye149953_dconst, Dimensions: [256,256], Format/Datatype: Float }, { Name: __mye149287/model/decoder/decoder/layers_0/self_attn/MatMul_2_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye149288/model/decoder/decoder/layers_0/self_attn/MatMul_2_beta, Dimensions: [1], Format/Datatype: Float }, { Name: __mye153089_reshape, Dimensions: [1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_0/self_attn/Add_2_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_2][ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_2]
Name: __mye157475_myl85_33, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_34, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_0/Add_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: __mye156380dconst, Dimensions: [2,256,256], Format/Datatype: Float }, { Name: __mye149341/model/decoder/decoder/layers_0/self_attn/MatMul_1_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye149342/model/decoder/decoder/layers_0/self_attn/MatMul_1_beta, Dimensions: [1], Format/Datatype: Float }, { Name: __mye155376_dconst, Dimensions: [2,1,256], Format/Datatype: Float }], Outputs: [ { Name: __mye154068, Dimensions: [2,300,256], Format/Datatype: Float }], TacticName: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_1][ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_1][ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul][ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add]
Name: /model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_35, LayerType: gemm, Inputs: [ { Name: __mye154068, Dimensions: [8,300,32], Format/Datatype: Float }, { Name: __mye154068, Dimensions: [8,32,300], Format/Datatype: Float }, { Name: __mye153149, Dimensions: [1,1,1], Format/Datatype: Float }, { Name: __mye149376/model/decoder/decoder/layers_0/self_attn/MatMul_3_beta, Dimensions: [1], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_34, Dimensions: [8,300,300], Format/Datatype: Float }], TacticName: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_3][ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Mul_1]
Name: __myl_MaxSubExpSumDivMul_myl85_36, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_34, Dimensions: [8,300,300], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_34, Dimensions: [8,300,300], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_0/self_attn/MatMul_4_output_0'.1_35, Dimensions: [8,300,300], Format/Datatype: Float }], TacticName: __myl_MaxSubExpSumDivMul_0x4bb1dc97991e61c47e3d11f2b659751f, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Softmax]
Name: __mye157477_myl85_37, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: /model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_38, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_0/self_attn/MatMul_4_output_0'.1_35, Dimensions: [8,300,300], Format/Datatype: Float }, { Name: /model/decoder/decoder/layers_0/self_attn/Add_2_output_0'.1, Dimensions: [8,300,32], Format/Datatype: Float }, { Name: __mye149386/model/decoder/decoder/layers_0/self_attn/MatMul_4_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye149387/model/decoder/decoder/layers_0/self_attn/MatMul_4_beta, Dimensions: [1], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_36, Dimensions: [8,300,32], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_4]
Name: __myl_Tra_myl85_39, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_36, Dimensions: [8,300,32], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_0/self_attn/Transpose_5 _ /model/decoder/decoder/layers_0/self_attn/Reshape_3_first_transpose_output.1, Dimensions: [300,8,32], Format/Datatype: Float }], TacticName: __myl_Tra_0xbff89681337b526d248c0838f5d94e94, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Transpose_5][ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Reshape_3]
Name: /model/decoder/decoder/layers_0/self_attn/Gemm_myl85_40, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_0/self_attn/Transpose_5 _ /model/decoder/decoder/layers_0/self_attn/Reshape_3_first_transpose_output.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: __mye149991_dconst, Dimensions: [256,256], Format/Datatype: Float }, { Name: __mye149400/model/decoder/decoder/layers_0/self_attn/Gemm_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye149401/model/decoder/decoder/layers_0/self_attn/Gemm_beta, Dimensions: [1], Format/Datatype: Float }, { Name: model_decoder_decoder_layers_0_self_attn_out_proj_bias _ ONNXTRT_Broadcast_351_constantFloat, Dimensions: [1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_0/self_attn/Gemm_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Gemm]
Name: __myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_41, LayerType: kgen, Inputs: [ { Name: __mye152985_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye152975_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye158007_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: /model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: /model/decoder/GatherElements_1_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Float }, { Name: /model/decoder/decoder/layers_0/self_attn/Gemm_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [300,256], Format/Datatype: Int8 }, { Name: __myln_k_arg__bb1_40, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: __myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_0x91b2c7046943674462a660380f1917c4, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/Add_1][ONNX Layer: /model/decoder/decoder/layers.0/norm1/LayerNormalization][ONNX Layer: /model/decoder/decoder/layers.0/Add_2][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]
Name: __myl_FcMulAdd_myl85_42, LayerType: fusion, Inputs: [ { Name: __mye154035_dconst, Dimensions: [1,288], Format/Datatype: Float }, { Name: __mye154017_dconst, Dimensions: [1,288], Format/Datatype: Float }, { Name: /model/decoder/decoder/layers_0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye156385dconst, Dimensions: [1,256,288], Format/Datatype: Int8 }, { Name: __mye153994_dconst, Dimensions: [1,1,288], Format/Datatype: Float }], Outputs: [ { Name: __mye154044mul_beta, Dimensions: [1,300,288], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add]
Name: __mye157479_myl85_43, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __mye157481_myl85_44, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: __myl_ResMaxSubExpSum_myl85_45, LayerType: kgen, Inputs: [ { Name: __mye154044mul_beta, Dimensions: [1,300,96], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_43, Dimensions: [1,300,8,12], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_42, Dimensions: [1,300,8,1], Format/Datatype: Float }], TacticName: __myl_ResMaxSubExpSum_0x7c7453772a39d1d1294358f10a1e770b, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_2][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]
Name: __mye157483_myl85_46, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_47, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_26, Dimensions: [300,4], Format/Datatype: Float }, { Name: __mye150470_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150470_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150470_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye154083, Dimensions: [1,8400,8,32], Format/Datatype: Float }, { Name: __mye150490_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150490_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150490_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150490_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150480_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150480_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150480_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150480_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150470_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18222, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150470_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18237, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150470_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18252, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150470_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18267, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150470_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18446, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150480_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18461, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150480_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18476, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150480_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18491, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150480_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18670, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150490_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18685, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150490_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18700, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150490_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18715, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150490_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150465_dconst, Dimensions: [2], Format/Datatype: Float }, { Name: __mye158011_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __mye150475_dconst, Dimensions: [2], Format/Datatype: Float }, { Name: __mye158011_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __mye150485_dconst, Dimensions: [2], Format/Datatype: Float }, { Name: __mye158011_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __mye150579, Dimensions: [1,1,1,1,1], Format/Datatype: Float }, { Name: __mye150575, Dimensions: [1,1,1,1,1], Format/Datatype: Float }, { Name: __mye149996_dconst, Dimensions: [1,1,1,12,1], Format/Datatype: Float }, { Name: __mye154044mul_beta, Dimensions: [1,300,192], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_46, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_45, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_44, Dimensions: [8,32,300,4], Format/Datatype: Float }], TacticName: __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_0x3718754d33237a7346a050fa256f2cc0, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_1][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_2][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_1][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Sub][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_1][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_5][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_6][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Add][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Split][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_2][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_4][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_4][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_5][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_6][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_6][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_7][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_8][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_1][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8]
Name: __mye157485_myl85_48, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_49, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_42, Dimensions: [1,300,8,1], Format/Datatype: Float }, { Name: __mye158021_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_45, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_44, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_46, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_43, Dimensions: [1,300,8,12], Format/Datatype: Float }], Outputs: [ { Name: __mye150954_q8, Dimensions: [8,32,300,1], Format/Datatype: Int8 }], TacticName: __myl_DivMulTraResConMulSumMulMinMaxRouCas_0xfdc36321684ce402a67e9cc028ee3fea, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_2][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_9][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Concat_10][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/ReduceSum][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_8][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear]
Name: __myl_Mov_myl85_50, LayerType: kgen, Inputs: [ { Name: __mye150954_q8, Dimensions: [1,300,256], Format/Datatype: Int8 }], Outputs: [ { Name: __myln_k_arg__bb1_48, Dimensions: [1,300,256], Format/Datatype: Int8 }], TacticName: __myl_Mov_0xccd11d8190e5ec819f0de6935e8e6ebe, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]
Name: __myl_FcAdd_myl85_51, LayerType: fusion, Inputs: [ { Name: __myln_k_arg__bb1_40, Dimensions: [1,300,256], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_48, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye155546_dconst, Dimensions: [1,256,256], Format/Datatype: Int8 }, { Name: __mye153341_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153348zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: model_decoder_decoder_layers_0_cross_attn_output_proj_bias _ ONNXTRT_Broadcast_575_constantFloat, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_49, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add][ONNX Layer: /model/decoder/decoder/layers.0/Add_3]
Name: __myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_52, LayerType: kgen, Inputs: [ { Name: __mye152940_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye152930_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye158025_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_49, Dimensions: [1,300,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_0/linear1/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [300,256], Format/Datatype: Int8 }, { Name: __myln_k_arg__bb1_51, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: __myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_0x7374e3706e69002aff2a29c077287875, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/norm2/LayerNormalization][ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear]
Name: /model/decoder/decoder/layers_0/linear1/MatMul_myl85_53, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_0/linear1/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye157553_xformed___mye156390dconst, Dimensions: [1,256,1024], Format/Datatype: Int8 }, { Name: __mye153363_dconst, Dimensions: [1,1024], Format/Datatype: Float }, { Name: __mye153359zero_beta, Dimensions: [1,1024], Format/Datatype: Float }, { Name: __mye153372_dconst, Dimensions: [1,1,1024], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_52, Dimensions: [1,300,1024], Format/Datatype: Int8 }], TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/linear1/MatMul][ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/activation/Relu][ONNX Layer: /model/decoder/decoder/layers.0/linear1/Add]
Name: __myl_FcAdd_myl85_54, LayerType: fusion, Inputs: [ { Name: __myln_k_arg__bb1_51, Dimensions: [1,300,256], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_52, Dimensions: [1,300,1024], Format/Datatype: Int8 }, { Name: __mye156395dconst, Dimensions: [1,1024,256], Format/Datatype: Int8 }, { Name: __mye153379_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153386zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: model_decoder_decoder_layers_0_linear2_bias _ ONNXTRT_Broadcast_597_constantFloat, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_53, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/linear2/MatMul][ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.0/linear2/Add][ONNX Layer: /model/decoder/decoder/layers.0/Add_4]
Name: __myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_55, LayerType: kgen, Inputs: [ { Name: __mye152904_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye152890_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye158029_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_53, Dimensions: [1,300,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: /model/decoder/decoder/dec_bbox_head_0/layers_0/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [300,256], Format/Datatype: Int8 }], TacticName: __myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0x4e14cc44ca088d44748af6a96514ac7a, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear]
Name: __mye157487_myl85_56, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __mye157489_myl85_57, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/decoder/decoder/layers_1/self_attn/MatMul_2_myl85_58, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: __mye150056_dconst, Dimensions: [256,256], Format/Datatype: Float }, { Name: __mye149485/model/decoder/decoder/layers_1/self_attn/MatMul_2_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye149486/model/decoder/decoder/layers_1/self_attn/MatMul_2_beta, Dimensions: [1], Format/Datatype: Float }, { Name: __mye152875_reshape, Dimensions: [1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_1/self_attn/Add_2_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_2][ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_2]
Name: __mye157491_myl85_59, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl85_60, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/dec_bbox_head_0/layers_0/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye157557_xformed___mye156400dconst, Dimensions: [1,256,256], Format/Datatype: Int8 }, { Name: __mye153401_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153397zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153410_dconst, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/dec_bbox_head_0/layers_2/input_quantizer/QuantizeLinear_output_0'.1_57, Dimensions: [1,300,256], Format/Datatype: Int8 }], TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act/Relu][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add]
Name: /model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl85_61, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/dec_bbox_head_0/layers_2/input_quantizer/QuantizeLinear_output_0'.1_57, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye157561_xformed___mye156405dconst, Dimensions: [1,256,256], Format/Datatype: Int8 }, { Name: __mye153428_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153424zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153437_dconst, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/dec_bbox_head_0/layers_2/Add_output_0'.1_58, Dimensions: [1,300,256], Format/Datatype: Int8 }], TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add]
Name: /model/decoder/decoder/dec_bbox_head_0/layers_2/MatMul_myl85_62, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/dec_bbox_head_0/layers_2/Add_output_0'.1_58, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye156410dconst, Dimensions: [1,256,4], Format/Datatype: Int8 }, { Name: __mye153444_dconst, Dimensions: [1,4], Format/Datatype: Float }, { Name: __mye153451zero_beta, Dimensions: [1,4], Format/Datatype: Float }, { Name: model_decoder_dec_bbox_head_0_layers_2_bias _ ONNXTRT_Broadcast_627_constantFloat, Dimensions: [1,1,4], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_59, Dimensions: [1,300,4], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add]
Name: __myl_MaxMinMaxSubMinMaxMinDivLogResAddNegExpAddDivMulMinMaxRouConCas_myl85_63, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_26, Dimensions: [300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_59, Dimensions: [1,300,4], Format/Datatype: Float }, { Name: __mye156644, Dimensions: [1,300,12], Format/Datatype: Float }, { Name: __mye158003_const-lit-in, Dimensions: [1], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_61, Dimensions: [1,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_60, Dimensions: [1,300,16], Format/Datatype: Int8 }], TacticName: __myl_MaxMinMaxSubMinMaxMinDivLogResAddNegExpAddDivMulMinMaxRouConCas_0xefac8e563c6580f9cd110df4750663ce, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear][ONNX Layer: /model/decoder/decoder/Log][ONNX Layer: /model/decoder/decoder/Sigmoid_1][ONNX Layer: /model/decoder/decoder/Add][ONNX Layer: /model/decoder/decoder/Div][ONNX Layer: /model/decoder/decoder/Sub][ONNX Layer: /model/decoder/decoder/Clip]
Name: /model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl85_64, LayerType: gemm, Inputs: [ { Name: __myln_k_arg__bb1_60, Dimensions: [1,300,16], Format/Datatype: Int8 }, { Name: __mye156660_dconst, Dimensions: [1,16,512], Format/Datatype: Int8 }, { Name: __mye153466_dconst, Dimensions: [1,512], Format/Datatype: Float }, { Name: __mye153462zero_beta, Dimensions: [1,512], Format/Datatype: Float }, { Name: __mye153475_dconst, Dimensions: [1,1,512], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1_62, Dimensions: [1,300,512], Format/Datatype: Int8 }], TacticName: sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/act_1/Relu][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/Add]
Name: /model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_65, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1_62, Dimensions: [1,300,512], Format/Datatype: Int8 }, { Name: __mye156420dconst, Dimensions: [1,512,256], Format/Datatype: Int8 }, { Name: __mye153482_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153489zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye150074_dconst, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/Add]
Name: __myl_Add_myl85_66, LayerType: kgen, Inputs: [ { Name: /model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: /model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_1/Add_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }], TacticName: __myl_Add_0xfcef7142c0478fafffb74a07ab8ea30f, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/Add]
Name: /model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_67, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_1/Add_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: __mye156425dconst, Dimensions: [2,256,256], Format/Datatype: Float }, { Name: __mye149550/model/decoder/decoder/layers_1/self_attn/MatMul_1_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye149551/model/decoder/decoder/layers_1/self_attn/MatMul_1_beta, Dimensions: [1], Format/Datatype: Float }, { Name: __mye155386_dconst, Dimensions: [2,1,256], Format/Datatype: Float }], Outputs: [ { Name: __mye153981, Dimensions: [2,300,256], Format/Datatype: Float }], TacticName: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_1][ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_1][ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul][ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add]
Name: /model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_68, LayerType: gemm, Inputs: [ { Name: __mye153981, Dimensions: [8,300,32], Format/Datatype: Float }, { Name: __mye153981, Dimensions: [8,32,300], Format/Datatype: Float }, { Name: __mye153153, Dimensions: [1,1,1], Format/Datatype: Float }, { Name: __mye149585/model/decoder/decoder/layers_1/self_attn/MatMul_3_beta, Dimensions: [1], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_66, Dimensions: [8,300,300], Format/Datatype: Float }], TacticName: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_3][ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Mul_1]
Name: __myl_MaxSubExpSumDivMul_myl85_69, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_66, Dimensions: [8,300,300], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_66, Dimensions: [8,300,300], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_1/self_attn/MatMul_4_output_0'.1_67, Dimensions: [8,300,300], Format/Datatype: Float }], TacticName: __myl_MaxSubExpSumDivMul_0x4bb1dc97991e61c47e3d11f2b659751f, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Softmax]
Name: __mye157493_myl85_70, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: /model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_71, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_1/self_attn/MatMul_4_output_0'.1_67, Dimensions: [8,300,300], Format/Datatype: Float }, { Name: /model/decoder/decoder/layers_1/self_attn/Add_2_output_0'.1, Dimensions: [8,300,32], Format/Datatype: Float }, { Name: __mye149595/model/decoder/decoder/layers_1/self_attn/MatMul_4_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye149596/model/decoder/decoder/layers_1/self_attn/MatMul_4_beta, Dimensions: [1], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_68, Dimensions: [8,300,32], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_4]
Name: __myl_Tra_myl85_72, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_68, Dimensions: [8,300,32], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_1/self_attn/Transpose_5 _ /model/decoder/decoder/layers_1/self_attn/Reshape_3_first_transpose_output.1, Dimensions: [300,8,32], Format/Datatype: Float }], TacticName: __myl_Tra_0xbff89681337b526d248c0838f5d94e94, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Transpose_5][ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Reshape_3]
Name: /model/decoder/decoder/layers_1/self_attn/Gemm_myl85_73, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_1/self_attn/Transpose_5 _ /model/decoder/decoder/layers_1/self_attn/Reshape_3_first_transpose_output.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: __mye150090_dconst, Dimensions: [256,256], Format/Datatype: Float }, { Name: __mye149609/model/decoder/decoder/layers_1/self_attn/Gemm_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye149610/model/decoder/decoder/layers_1/self_attn/Gemm_beta, Dimensions: [1], Format/Datatype: Float }, { Name: model_decoder_decoder_layers_1_self_attn_out_proj_bias _ ONNXTRT_Broadcast_672_constantFloat, Dimensions: [1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_1/self_attn/Gemm_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Gemm]
Name: __myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_74, LayerType: kgen, Inputs: [ { Name: __mye152825_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye152815_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye158036_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: /model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: /model/decoder/decoder/layers_1/self_attn/Gemm_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Float }, { Name: /model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1, Dimensions: [300,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [300,256], Format/Datatype: Int8 }, { Name: __myln_k_arg__bb1_72, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: __myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_0x2ee8fbc8ddb7baf5b46cceba6a86227b, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization][ONNX Layer: /model/decoder/decoder/layers.1/Add_1][ONNX Layer: /model/decoder/decoder/layers.1/norm1/LayerNormalization][ONNX Layer: /model/decoder/decoder/layers.1/Add_2][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]
Name: __myl_FcMulAdd_myl85_75, LayerType: fusion, Inputs: [ { Name: __mye153948_dconst, Dimensions: [1,288], Format/Datatype: Float }, { Name: __mye153930_dconst, Dimensions: [1,288], Format/Datatype: Float }, { Name: /model/decoder/decoder/layers_1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye156430dconst, Dimensions: [1,256,288], Format/Datatype: Int8 }, { Name: __mye153907_dconst, Dimensions: [1,1,288], Format/Datatype: Float }], Outputs: [ { Name: __mye153957mul_beta, Dimensions: [1,300,288], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add]
Name: __mye157495_myl85_76, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __mye157497_myl85_77, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: __myl_ResMaxSubExpSum_myl85_78, LayerType: kgen, Inputs: [ { Name: __mye153957mul_beta, Dimensions: [1,300,96], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_75, Dimensions: [1,300,8,12], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_74, Dimensions: [1,300,8,1], Format/Datatype: Float }], TacticName: __myl_ResMaxSubExpSum_0x7c7453772a39d1d1294358f10a1e770b, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_2][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]
Name: __mye157499_myl85_79, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_80, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_61, Dimensions: [1,300,4], Format/Datatype: Float }, { Name: __mye150500_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150500_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150500_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye154083, Dimensions: [1,8400,8,32], Format/Datatype: Float }, { Name: __mye150520_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150520_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150520_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150520_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150510_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150510_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150510_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150510_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150500_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18921, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150500_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18936, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150500_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18951, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150500_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye18966, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150500_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19145, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150510_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19160, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150510_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19175, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150510_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19190, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150510_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19369, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150520_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19384, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150520_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19399, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150520_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19414, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150520_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150495_dconst, Dimensions: [2], Format/Datatype: Float }, { Name: __mye158011_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __mye150505_dconst, Dimensions: [2], Format/Datatype: Float }, { Name: __mye158011_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __mye150515_dconst, Dimensions: [2], Format/Datatype: Float }, { Name: __mye158011_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __mye150607, Dimensions: [1,1,1,1,1], Format/Datatype: Float }, { Name: __mye150603, Dimensions: [1,1,1,1,1], Format/Datatype: Float }, { Name: __mye150095_dconst, Dimensions: [1,1,1,12,1], Format/Datatype: Float }, { Name: __mye153957mul_beta, Dimensions: [1,300,192], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_78, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_77, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_76, Dimensions: [8,32,300,4], Format/Datatype: Float }], TacticName: __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_0xc0b46290445cedee2db7e5baf77a0f2e, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_1][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_2][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_1][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Sub][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_1][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_5][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_3][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Add][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Split][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_2][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_4][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_4][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_5][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_6][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_6][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_7][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_8][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_1][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8]
Name: __mye157501_myl85_81, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_82, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_74, Dimensions: [1,300,8,1], Format/Datatype: Float }, { Name: __mye158049_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_77, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_76, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_78, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_75, Dimensions: [1,300,8,12], Format/Datatype: Float }], Outputs: [ { Name: __mye150960_q8, Dimensions: [8,32,300,1], Format/Datatype: Int8 }], TacticName: __myl_DivMulTraResConMulSumMulMinMaxRouCas_0xfdc36321684ce402a67e9cc028ee3fea, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_2][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_9][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Concat_10][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/ReduceSum][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_5][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear]
Name: __myl_Mov_myl85_83, LayerType: kgen, Inputs: [ { Name: __mye150960_q8, Dimensions: [1,300,256], Format/Datatype: Int8 }], Outputs: [ { Name: __myln_k_arg__bb1_80, Dimensions: [1,300,256], Format/Datatype: Int8 }], TacticName: __myl_Mov_0xccd11d8190e5ec819f0de6935e8e6ebe, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]
Name: __myl_FcAdd_myl85_84, LayerType: fusion, Inputs: [ { Name: __myln_k_arg__bb1_72, Dimensions: [1,300,256], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_80, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye155492_dconst, Dimensions: [1,256,256], Format/Datatype: Int8 }, { Name: __mye153515_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153522zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: model_decoder_decoder_layers_1_cross_attn_output_proj_bias _ ONNXTRT_Broadcast_896_constantFloat, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_81, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add][ONNX Layer: /model/decoder/decoder/layers.1/Add_3]
Name: __myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_85, LayerType: kgen, Inputs: [ { Name: __mye152780_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye152770_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye158053_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_81, Dimensions: [1,300,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_1/linear1/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [300,256], Format/Datatype: Int8 }, { Name: __myln_k_arg__bb1_83, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: __myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_0x7374e3706e69002aff2a29c077287875, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/norm2/LayerNormalization][ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear]
Name: /model/decoder/decoder/layers_1/linear1/MatMul_myl85_86, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_1/linear1/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye157565_xformed___mye156435dconst, Dimensions: [1,256,1024], Format/Datatype: Int8 }, { Name: __mye153537_dconst, Dimensions: [1,1024], Format/Datatype: Float }, { Name: __mye153533zero_beta, Dimensions: [1,1024], Format/Datatype: Float }, { Name: __mye153546_dconst, Dimensions: [1,1,1024], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_84, Dimensions: [1,300,1024], Format/Datatype: Int8 }], TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/linear1/MatMul][ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/activation/Relu][ONNX Layer: /model/decoder/decoder/layers.1/linear1/Add]
Name: __myl_FcAdd_myl85_87, LayerType: fusion, Inputs: [ { Name: __myln_k_arg__bb1_83, Dimensions: [1,300,256], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_84, Dimensions: [1,300,1024], Format/Datatype: Int8 }, { Name: __mye156440dconst, Dimensions: [1,1024,256], Format/Datatype: Int8 }, { Name: __mye153553_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153560zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: model_decoder_decoder_layers_1_linear2_bias _ ONNXTRT_Broadcast_918_constantFloat, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_85, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/linear2/MatMul][ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.1/linear2/Add][ONNX Layer: /model/decoder/decoder/layers.1/Add_4]
Name: __myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_88, LayerType: kgen, Inputs: [ { Name: __mye152744_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye152730_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye158057_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_85, Dimensions: [1,300,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: /model/decoder/decoder/dec_bbox_head_1/layers_0/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [300,256], Format/Datatype: Int8 }], TacticName: __myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0x4e14cc44ca088d44748af6a96514ac7a, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear]
Name: __mye157503_myl85_89, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __mye157505_myl85_90, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/decoder/decoder/layers_2/self_attn/MatMul_2_myl85_91, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: __mye150151_dconst, Dimensions: [256,256], Format/Datatype: Float }, { Name: __mye149694/model/decoder/decoder/layers_2/self_attn/MatMul_2_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye149695/model/decoder/decoder/layers_2/self_attn/MatMul_2_beta, Dimensions: [1], Format/Datatype: Float }, { Name: __mye152715_reshape, Dimensions: [1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_2/self_attn/Add_2_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_2][ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_2]
Name: __mye157507_myl85_92, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl85_93, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/dec_bbox_head_1/layers_0/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye157569_xformed___mye156445dconst, Dimensions: [1,256,256], Format/Datatype: Int8 }, { Name: __mye153575_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153571zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153584_dconst, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/dec_bbox_head_1/layers_2/input_quantizer/QuantizeLinear_output_0'.1_89, Dimensions: [1,300,256], Format/Datatype: Int8 }], TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act/Relu][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add]
Name: /model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl85_94, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/dec_bbox_head_1/layers_2/input_quantizer/QuantizeLinear_output_0'.1_89, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye157573_xformed___mye156450dconst, Dimensions: [1,256,256], Format/Datatype: Int8 }, { Name: __mye153602_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153598zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153611_dconst, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/dec_bbox_head_1/layers_2/Add_output_0'.1_90, Dimensions: [1,300,256], Format/Datatype: Int8 }], TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add]
Name: /model/decoder/decoder/dec_bbox_head_1/layers_2/MatMul_myl85_95, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/dec_bbox_head_1/layers_2/Add_output_0'.1_90, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye156455dconst, Dimensions: [1,256,4], Format/Datatype: Int8 }, { Name: __mye153618_dconst, Dimensions: [1,4], Format/Datatype: Float }, { Name: __mye153625zero_beta, Dimensions: [1,4], Format/Datatype: Float }, { Name: model_decoder_dec_bbox_head_1_layers_2_bias _ ONNXTRT_Broadcast_948_constantFloat, Dimensions: [1,1,4], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_91, Dimensions: [1,300,4], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add]
Name: __myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouConCas_myl85_96, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_61, Dimensions: [1,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_91, Dimensions: [1,300,4], Format/Datatype: Float }, { Name: __mye156667, Dimensions: [1,300,12], Format/Datatype: Float }, { Name: __mye158003_const-lit-in, Dimensions: [1], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_93, Dimensions: [1,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_92, Dimensions: [1,300,16], Format/Datatype: Int8 }], TacticName: __myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouConCas_0xa06819df43d11e9f71ec4d6314dfc9b2, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear][ONNX Layer: /model/decoder/decoder/Log_1][ONNX Layer: /model/decoder/decoder/Add_1][ONNX Layer: /model/decoder/decoder/Sigmoid_2][ONNX Layer: /model/decoder/decoder/Div_1][ONNX Layer: /model/decoder/decoder/Sub_1][ONNX Layer: /model/decoder/decoder/Clip_3]
Name: /model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl85_97, LayerType: gemm, Inputs: [ { Name: __myln_k_arg__bb1_92, Dimensions: [1,300,16], Format/Datatype: Int8 }, { Name: __mye156683_dconst, Dimensions: [1,16,512], Format/Datatype: Int8 }, { Name: __mye153640_dconst, Dimensions: [1,512], Format/Datatype: Float }, { Name: __mye153636zero_beta, Dimensions: [1,512], Format/Datatype: Float }, { Name: __mye153649_dconst, Dimensions: [1,1,512], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1_94, Dimensions: [1,300,512], Format/Datatype: Int8 }], TacticName: sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/act_2/Relu][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/Add]
Name: /model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_98, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1_94, Dimensions: [1,300,512], Format/Datatype: Int8 }, { Name: __mye156465dconst, Dimensions: [1,512,256], Format/Datatype: Int8 }, { Name: __mye153656_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153663zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye150169_dconst, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/Add]
Name: __myl_Add_myl85_99, LayerType: kgen, Inputs: [ { Name: /model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: /model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_2/Add_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }], TacticName: __myl_Add_0xfcef7142c0478fafffb74a07ab8ea30f, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/Add]
Name: /model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_100, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_2/Add_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: __mye156470dconst, Dimensions: [2,256,256], Format/Datatype: Float }, { Name: __mye149759/model/decoder/decoder/layers_2/self_attn/MatMul_1_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye149760/model/decoder/decoder/layers_2/self_attn/MatMul_1_beta, Dimensions: [1], Format/Datatype: Float }, { Name: __mye155396_dconst, Dimensions: [2,1,256], Format/Datatype: Float }], Outputs: [ { Name: __mye153894, Dimensions: [2,300,256], Format/Datatype: Float }], TacticName: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_1][ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_1][ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul][ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add]
Name: /model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_101, LayerType: gemm, Inputs: [ { Name: __mye153894, Dimensions: [8,300,32], Format/Datatype: Float }, { Name: __mye153894, Dimensions: [8,32,300], Format/Datatype: Float }, { Name: __mye153157, Dimensions: [1,1,1], Format/Datatype: Float }, { Name: __mye149794/model/decoder/decoder/layers_2/self_attn/MatMul_3_beta, Dimensions: [1], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_98, Dimensions: [8,300,300], Format/Datatype: Float }], TacticName: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_3][ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Mul_1]
Name: __myl_MaxSubExpSumDivMul_myl85_102, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_98, Dimensions: [8,300,300], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_98, Dimensions: [8,300,300], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_2/self_attn/MatMul_4_output_0'.1_99, Dimensions: [8,300,300], Format/Datatype: Float }], TacticName: __myl_MaxSubExpSumDivMul_0x4bb1dc97991e61c47e3d11f2b659751f, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Softmax]
Name: __mye157509_myl85_103, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: /model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_104, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_2/self_attn/MatMul_4_output_0'.1_99, Dimensions: [8,300,300], Format/Datatype: Float }, { Name: /model/decoder/decoder/layers_2/self_attn/Add_2_output_0'.1, Dimensions: [8,300,32], Format/Datatype: Float }, { Name: __mye149804/model/decoder/decoder/layers_2/self_attn/MatMul_4_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye149805/model/decoder/decoder/layers_2/self_attn/MatMul_4_beta, Dimensions: [1], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_100, Dimensions: [8,300,32], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_4]
Name: __myl_Tra_myl85_105, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_100, Dimensions: [8,300,32], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_2/self_attn/Transpose_5 _ /model/decoder/decoder/layers_2/self_attn/Reshape_3_first_transpose_output.1, Dimensions: [300,8,32], Format/Datatype: Float }], TacticName: __myl_Tra_0xbff89681337b526d248c0838f5d94e94, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Transpose_5][ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Reshape_3]
Name: /model/decoder/decoder/layers_2/self_attn/Gemm_myl85_106, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_2/self_attn/Transpose_5 _ /model/decoder/decoder/layers_2/self_attn/Reshape_3_first_transpose_output.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: __mye150185_dconst, Dimensions: [256,256], Format/Datatype: Float }, { Name: __mye149818/model/decoder/decoder/layers_2/self_attn/Gemm_alpha, Dimensions: [1], Format/Datatype: Float }, { Name: __mye149819/model/decoder/decoder/layers_2/self_attn/Gemm_beta, Dimensions: [1], Format/Datatype: Float }, { Name: model_decoder_decoder_layers_2_self_attn_out_proj_bias _ ONNXTRT_Broadcast_993_constantFloat, Dimensions: [1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_2/self_attn/Gemm_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Gemm]
Name: __myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_107, LayerType: kgen, Inputs: [ { Name: __mye152665_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye152655_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye158064_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: /model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1, Dimensions: [300,256], Format/Datatype: Float }, { Name: /model/decoder/decoder/layers_2/self_attn/Gemm_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Float }, { Name: /model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1, Dimensions: [300,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [300,256], Format/Datatype: Int8 }, { Name: __myln_k_arg__bb1_104, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: __myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_0x2ee8fbc8ddb7baf5b46cceba6a86227b, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization][ONNX Layer: /model/decoder/decoder/layers.2/Add_1][ONNX Layer: /model/decoder/decoder/layers.2/norm1/LayerNormalization][ONNX Layer: /model/decoder/decoder/layers.2/Add_2][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]
Name: __myl_FcMulAdd_myl85_108, LayerType: fusion, Inputs: [ { Name: __mye153861_dconst, Dimensions: [1,288], Format/Datatype: Float }, { Name: __mye153843_dconst, Dimensions: [1,288], Format/Datatype: Float }, { Name: /model/decoder/decoder/layers_2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye156475dconst, Dimensions: [1,256,288], Format/Datatype: Int8 }, { Name: __mye153820_dconst, Dimensions: [1,1,288], Format/Datatype: Float }], Outputs: [ { Name: __mye153870mul_beta, Dimensions: [1,300,288], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add]
Name: __mye157511_myl85_109, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __mye157513_myl85_110, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: __myl_ResMaxSubExpSum_myl85_111, LayerType: kgen, Inputs: [ { Name: __mye153870mul_beta, Dimensions: [1,300,96], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_107, Dimensions: [1,300,8,12], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_106, Dimensions: [1,300,8,1], Format/Datatype: Float }], TacticName: __myl_ResMaxSubExpSum_0x7c7453772a39d1d1294358f10a1e770b, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_2][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]
Name: __mye157515_myl85_112, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_113, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_93, Dimensions: [1,300,4], Format/Datatype: Float }, { Name: __mye150530_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150530_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150530_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye154083, Dimensions: [1,8400,8,32], Format/Datatype: Float }, { Name: __mye150550_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150550_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150550_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150550_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150540_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150540_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150540_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150540_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150530_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19620, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150530_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19635, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150530_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19650, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150530_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19665, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150530_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19844, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150540_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19859, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150540_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19874, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150540_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye19889, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150540_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye20068, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150550_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye20083, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150550_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye20098, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150550_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye20113, Dimensions: [1,1,1,2], Format/Datatype: Int32 }, { Name: __mye150550_dconst, Dimensions: [2], Format/Datatype: Int32 }, { Name: __mye150525_dconst, Dimensions: [2], Format/Datatype: Float }, { Name: __mye158011_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __mye150535_dconst, Dimensions: [2], Format/Datatype: Float }, { Name: __mye158011_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __mye150545_dconst, Dimensions: [2], Format/Datatype: Float }, { Name: __mye158011_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __mye150635, Dimensions: [1,1,1,1,1], Format/Datatype: Float }, { Name: __mye150631, Dimensions: [1,1,1,1,1], Format/Datatype: Float }, { Name: __mye150190_dconst, Dimensions: [1,1,1,12,1], Format/Datatype: Float }, { Name: __mye153870mul_beta, Dimensions: [1,300,192], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_110, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_109, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_108, Dimensions: [8,32,300,4], Format/Datatype: Float }], TacticName: __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_0xc0b46290445cedee2db7e5baf77a0f2e, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_1][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_2][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_1][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Sub][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_1][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_5][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_3][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Add][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Split][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_2][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_4][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_4][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_5][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_6][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_6][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_7][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_8][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_1][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8]
Name: __mye157517_myl85_114, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_115, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_106, Dimensions: [1,300,8,1], Format/Datatype: Float }, { Name: __mye158077_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_109, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_108, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_110, Dimensions: [8,32,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_107, Dimensions: [1,300,8,12], Format/Datatype: Float }], Outputs: [ { Name: __mye150966_q8, Dimensions: [8,32,300,1], Format/Datatype: Int8 }], TacticName: __myl_DivMulTraResConMulSumMulMinMaxRouCas_0xfdc36321684ce402a67e9cc028ee3fea, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_2][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_9][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Concat_10][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/ReduceSum][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_5][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear]
Name: __myl_Mov_myl85_116, LayerType: kgen, Inputs: [ { Name: __mye150966_q8, Dimensions: [1,300,256], Format/Datatype: Int8 }], Outputs: [ { Name: __myln_k_arg__bb1_112, Dimensions: [1,300,256], Format/Datatype: Int8 }], TacticName: __myl_Mov_0xccd11d8190e5ec819f0de6935e8e6ebe, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]
Name: __myl_FcAdd_myl85_117, LayerType: fusion, Inputs: [ { Name: __myln_k_arg__bb1_104, Dimensions: [1,300,256], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_112, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye155438_dconst, Dimensions: [1,256,256], Format/Datatype: Int8 }, { Name: __mye153689_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153696zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: model_decoder_decoder_layers_2_cross_attn_output_proj_bias _ ONNXTRT_Broadcast_1217_constantFloat, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_113, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add][ONNX Layer: /model/decoder/decoder/layers.2/Add_3]
Name: __myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_118, LayerType: kgen, Inputs: [ { Name: __mye152620_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye152610_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye158081_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_113, Dimensions: [1,300,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/layers_2/linear1/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [300,256], Format/Datatype: Int8 }, { Name: __myln_k_arg__bb1_115, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: __myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_0x7374e3706e69002aff2a29c077287875, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/norm2/LayerNormalization][ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear]
Name: /model/decoder/decoder/layers_2/linear1/MatMul_myl85_119, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/layers_2/linear1/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye157577_xformed___mye156480dconst, Dimensions: [1,256,1024], Format/Datatype: Int8 }, { Name: __mye153711_dconst, Dimensions: [1,1024], Format/Datatype: Float }, { Name: __mye153707zero_beta, Dimensions: [1,1024], Format/Datatype: Float }, { Name: __mye153720_dconst, Dimensions: [1,1,1024], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_116, Dimensions: [1,300,1024], Format/Datatype: Int8 }], TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/linear1/MatMul][ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/activation/Relu][ONNX Layer: /model/decoder/decoder/layers.2/linear1/Add]
Name: __myl_FcAdd_myl85_120, LayerType: fusion, Inputs: [ { Name: __myln_k_arg__bb1_115, Dimensions: [1,300,256], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_116, Dimensions: [1,300,1024], Format/Datatype: Int8 }, { Name: __mye156485dconst, Dimensions: [1,1024,256], Format/Datatype: Int8 }, { Name: __mye153727_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153734zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: model_decoder_decoder_layers_2_linear2_bias _ ONNXTRT_Broadcast_1239_constantFloat, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_117, Dimensions: [1,300,256], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/linear2/MatMul][ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/layers.2/linear2/Add][ONNX Layer: /model/decoder/decoder/layers.2/Add_4]
Name: __myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_121, LayerType: kgen, Inputs: [ { Name: __mye152584_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye158085_const-lit-in, Dimensions: [1], Format/Datatype: Float }, { Name: __mye152578_reshape, Dimensions: [1,256], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_117, Dimensions: [1,300,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/dec_bbox_head_2/layers_0/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [300,256], Format/Datatype: Int8 }], TacticName: __myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0x3f53c92c8e85fb99f9934c06da28da1c, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/layers.2/norm3/LayerNormalization][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear]
Name: __mye157519_myl85_122, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __mye157521_myl85_123, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/decoder/decoder/dec_score_head_2/MatMul_myl85_124, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/dec_bbox_head_2/layers_0/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye156490dconst, Dimensions: [1,256,80], Format/Datatype: Int8 }, { Name: __mye153738_dconst, Dimensions: [1,80], Format/Datatype: Float }, { Name: __mye153745zero_beta, Dimensions: [1,80], Format/Datatype: Float }, { Name: model_decoder_dec_score_head_2_bias _ ONNXTRT_Broadcast_1287_constantFloat, Dimensions: [1,1,80], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/dec_score_head_2/Add_output_0'.1, Dimensions: [1,300,80], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32, StreamId: 1, Metadata: [ONNX Layer: /model/decoder/decoder/dec_score_head.2/MatMul][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_score_head.2/Add]
Name: __myl_GatResNegExpAddDivRes_myl85_125, LayerType: kgen, Inputs: [ { Name: /model/decoder/decoder/dec_score_head_2/Add_output_0'.1, Dimensions: [1,1,300,80], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_120, Dimensions: [1,24000], Format/Datatype: Float }], TacticName: __myl_GatResNegExpAddDivRes_0x1d563258c32f843400fb4233ccab3fa6, StreamId: 1, Metadata: [ONNX Layer: /postprocessor/Sigmoid][ONNX Layer: /postprocessor/Flatten][ONNX Layer: /model/decoder/Gather_8]
Name: __myl_Top_myl85_126, LayerType: kgen, Inputs: [ { Name: __myln_k_arg__bb1_120, Dimensions: [1,24000], Format/Datatype: Float }], Outputs: [ { Name: scores, Dimensions: [1,300], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_122, Dimensions: [1,300], Format/Datatype: Int32 }], TacticName: __myl_Top_0x1c85ccd1fad109f046189f0d3e8dff44, StreamId: 1, Metadata: [ONNX Layer: /postprocessor/TopK]
Name: __mye157523_myl85_127, LayerType: signal, Inputs: [], Outputs: [], TacticName: , StreamId: 1, Metadata: 
Name: /model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl85_128, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/dec_bbox_head_2/layers_0/input_quantizer/QuantizeLinear_output_0'.1, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye157581_xformed___mye156495dconst, Dimensions: [1,256,256], Format/Datatype: Int8 }, { Name: __mye153760_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153756zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153769_dconst, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/dec_bbox_head_2/layers_2/input_quantizer/QuantizeLinear_output_0'.1_123, Dimensions: [1,300,256], Format/Datatype: Int8 }], TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act/Relu][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add]
Name: /model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl85_129, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/dec_bbox_head_2/layers_2/input_quantizer/QuantizeLinear_output_0'.1_123, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye157585_xformed___mye156500dconst, Dimensions: [1,256,256], Format/Datatype: Int8 }, { Name: __mye153787_dconst, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153783zero_beta, Dimensions: [1,256], Format/Datatype: Float }, { Name: __mye153796_dconst, Dimensions: [1,1,256], Format/Datatype: Float }], Outputs: [ { Name: /model/decoder/decoder/dec_bbox_head_2/layers_2/Add_output_0'.1_124, Dimensions: [1,300,256], Format/Datatype: Int8 }], TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add]
Name: /model/decoder/decoder/dec_bbox_head_2/layers_2/MatMul_myl85_130, LayerType: gemm, Inputs: [ { Name: /model/decoder/decoder/dec_bbox_head_2/layers_2/Add_output_0'.1_124, Dimensions: [1,300,256], Format/Datatype: Int8 }, { Name: __mye156505dconst, Dimensions: [1,256,4], Format/Datatype: Int8 }, { Name: __mye153803_dconst, Dimensions: [1,4], Format/Datatype: Float }, { Name: __mye153810zero_beta, Dimensions: [1,4], Format/Datatype: Float }, { Name: model_decoder_dec_bbox_head_2_layers_2_bias _ ONNXTRT_Broadcast_1269_constantFloat, Dimensions: [1,1,4], Format/Datatype: Float }], Outputs: [ { Name: __myln_k_arg__bb1_125, Dimensions: [1,300,4], Format/Datatype: Float }], TacticName: sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32, StreamId: 0, Metadata: [ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear][ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add]
Name: __mye157525_myl85_131, LayerType: wait, Inputs: [], Outputs: [], TacticName: , StreamId: 0, Metadata: 
Name: __myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_myl85_132, LayerType: kgen, Inputs: [ { Name: orig_target_sizes, Dimensions: [1,2], Format/Datatype: Int64 }, { Name: __myln_k_arg__bb1_122, Dimensions: [1,300], Format/Datatype: Int32 }, { Name: __mye150647, Dimensions: [1,1], Format/Datatype: Int64 }, { Name: __mye150651, Dimensions: [1,1], Format/Datatype: Float }, { Name: __mye150655, Dimensions: [1,1], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_125, Dimensions: [1,300,4], Format/Datatype: Float }, { Name: __myln_k_arg__bb1_93, Dimensions: [1,300,4], Format/Datatype: Float }], Outputs: [ { Name: labels, Dimensions: [1,300], Format/Datatype: Int64 }, { Name: boxes, Dimensions: [1,300,4], Format/Datatype: Float }], TacticName: __myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_0x046287ea34a14bdbbd780dcf069cdb4a, StreamId: 0, Metadata: [ONNX Layer: Cast_3039][ONNX Layer: /model/decoder/decoder/Clip_6][ONNX Layer: /model/decoder/decoder/Sub_2][ONNX Layer: /model/decoder/decoder/Div_2][ONNX Layer: /model/decoder/decoder/Sigmoid_3][ONNX Layer: /model/decoder/Gather_9][ONNX Layer: /model/decoder/decoder/Unsqueeze_3][ONNX Layer: /model/decoder/decoder/Add_2][ONNX Layer: /model/decoder/decoder/Log_2][ONNX Layer: /postprocessor/Split][ONNX Layer: /postprocessor/Squeeze_1][ONNX Layer: /postprocessor/Squeeze_2][ONNX Layer: /postprocessor/Mul][ONNX Layer: /postprocessor/Add][ONNX Layer: /postprocessor/Unsqueeze_2][ONNX Layer: /postprocessor/Sub][ONNX Layer: /postprocessor/Unsqueeze][ONNX Layer: /postprocessor/Concat][ONNX Layer: /postprocessor/Mul_2][ONNX Layer: /postprocessor/GatherElements][ONNX Layer: /postprocessor/Unsqueeze_5][ONNX Layer: /postprocessor/Unsqueeze_3][ONNX Layer: /postprocessor/Add_1][ONNX Layer: /postprocessor/Squeeze][ONNX Layer: /postprocessor/Unsqueeze_1][ONNX Layer: /postprocessor/Sub_1][ONNX Layer: /postprocessor/Mul_1][ONNX Layer: /postprocessor/Squeeze_3][ONNX Layer: /postprocessor/Mul_3][ONNX Layer: /postprocessor/Sub_2][ONNX Layer: /postprocessor/Div][ONNX Layer: /postprocessor/Unsqueeze_4][ONNX Layer: /postprocessor/Tile]

Bindings:
images
orig_target_sizes
labels
boxes
scores
[05/21/2025-09:28:22] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 3 MiB, GPU 66 MiB
[05/21/2025-09:28:22] [V] [TRT] Adding 1 engine(s) to plan file.
[05/21/2025-09:28:22] [V] [TRT] Adding 1 engine weights(s) to plan file.
[05/21/2025-09:28:22] [I] Engine built in 12.132 sec.
[05/21/2025-09:28:22] [I] Created engine with size: 28.0866 MiB
[05/21/2025-09:28:22] [V] [TRT] Trying to set exclusive file lock ./timing.cache.lock

[05/21/2025-09:28:22] [I] [TRT] Loaded 12228577 bytes of timing cache from ./timing.cache
[05/21/2025-09:28:22] [V] [TRT] Loaded 938 timing cache entries.
[05/21/2025-09:28:22] [V] [TRT] Loaded 13084 bytes of code generator cache.
[05/21/2025-09:28:22] [V] [TRT] Loaded 12117773 bytes of compilation cache.
[05/21/2025-09:28:22] [V] [TRT] Serializing timing cache. UUID = GPU-117c6cfa-7ace-5107-bd8e-0405fabb6962, commit ID = 86d89b8b44f12565
[05/21/2025-09:28:22] [I] [TRT] Serialized 13084 bytes of code generator cache.
[05/21/2025-09:28:22] [I] [TRT] Serialized 12117773 bytes of compilation cache.
[05/21/2025-09:28:22] [I] [TRT] Serialized 938 timing cache entries
[05/21/2025-09:28:22] [I] [TRT] Saved 12228577 bytes of timing cache to ./timing.cache
[05/21/2025-09:28:22] [I] [TRT] Loaded engine size: 28 MiB
[05/21/2025-09:28:22] [V] [TRT] Deserialization required 7890 microseconds.
[05/21/2025-09:28:22] [I] Engine deserialized in 0.0171687 sec.
[05/21/2025-09:28:22] [I] [TRT] [MS] Running engine with multi stream info
[05/21/2025-09:28:22] [I] [TRT] [MS] Number of aux streams is 1
[05/21/2025-09:28:22] [I] [TRT] [MS] Number of total worker streams is 2
[05/21/2025-09:28:22] [I] [TRT] [MS] The main stream provided by execute/enqueue calls is the first worker stream
[05/21/2025-09:28:22] [V] [TRT] Total per-runner device persistent memory is 0
[05/21/2025-09:28:22] [V] [TRT] Total per-runner host persistent memory is 307312
[05/21/2025-09:28:22] [V] [TRT] Allocated device scratch memory of size 62873600
[05/21/2025-09:28:22] [V] [TRT] - Runner scratch: 62873600 bytes
[05/21/2025-09:28:22] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +60, now: CPU 0, GPU 82 (MiB)
[05/21/2025-09:28:22] [V] [TRT] CUDA lazy loading is enabled.
[05/21/2025-09:28:22] [I] Setting persistentCacheLimit to 0 bytes.
[05/21/2025-09:28:22] [I] Created execution context with device memory size: 59.9609 MiB
[05/21/2025-09:28:22] [I] Using random values for input images
[05/21/2025-09:28:22] [I] Input binding for images with dimensions 1x3x640x640 is created.
[05/21/2025-09:28:22] [I] Using random values for input orig_target_sizes
[05/21/2025-09:28:22] [I] Input binding for orig_target_sizes with dimensions 1x2 is created.
[05/21/2025-09:28:22] [I] Output binding for labels with dimensions 1x300 is created.
[05/21/2025-09:28:22] [I] Output binding for boxes with dimensions 1x300x4 is created.
[05/21/2025-09:28:22] [I] Output binding for scores with dimensions 1x300 is created.
[05/21/2025-09:28:22] [I] Starting inference
[05/21/2025-09:28:26] [I] Warmup completed 177 queries over 200 ms
[05/21/2025-09:28:26] [I] Timing trace has 3127 queries over 3.00296 s
[05/21/2025-09:28:26] [I] 
[05/21/2025-09:28:26] [I] === Trace details ===
[05/21/2025-09:28:26] [I] Trace averages of 10 runs:
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 1.0455 ms - Host latency: 1.25927 ms (enqueue 0.472223 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 1.04561 ms - Host latency: 1.25957 ms (enqueue 0.459558 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 1.04581 ms - Host latency: 1.26001 ms (enqueue 0.473889 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 1.04663 ms - Host latency: 1.26024 ms (enqueue 0.471767 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 1.04632 ms - Host latency: 1.25989 ms (enqueue 0.468808 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.993584 ms - Host latency: 1.20729 ms (enqueue 0.470203 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.953244 ms - Host latency: 1.16666 ms (enqueue 0.44296 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.953452 ms - Host latency: 1.16676 ms (enqueue 0.425558 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.953647 ms - Host latency: 1.16653 ms (enqueue 0.436011 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.954062 ms - Host latency: 1.16763 ms (enqueue 0.420361 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95314 ms - Host latency: 1.16642 ms (enqueue 0.432745 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95376 ms - Host latency: 1.16737 ms (enqueue 0.425067 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.953549 ms - Host latency: 1.16695 ms (enqueue 0.42634 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.953656 ms - Host latency: 1.1674 ms (enqueue 0.428369 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.953342 ms - Host latency: 1.16688 ms (enqueue 0.423541 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.953656 ms - Host latency: 1.16711 ms (enqueue 0.424481 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.954581 ms - Host latency: 1.1678 ms (enqueue 0.426001 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.954263 ms - Host latency: 1.16714 ms (enqueue 0.427637 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.953241 ms - Host latency: 1.1671 ms (enqueue 0.425681 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.954163 ms - Host latency: 1.16846 ms (enqueue 0.41864 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.953247 ms - Host latency: 1.16706 ms (enqueue 0.413229 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95448 ms - Host latency: 1.1685 ms (enqueue 0.424973 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95448 ms - Host latency: 1.16758 ms (enqueue 0.426224 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.954773 ms - Host latency: 1.16789 ms (enqueue 0.423859 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956006 ms - Host latency: 1.16974 ms (enqueue 0.428455 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.954465 ms - Host latency: 1.16768 ms (enqueue 0.422739 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956314 ms - Host latency: 1.16971 ms (enqueue 0.429205 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956009 ms - Host latency: 1.16979 ms (enqueue 0.419278 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956726 ms - Host latency: 1.17047 ms (enqueue 0.430096 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95549 ms - Host latency: 1.16949 ms (enqueue 0.42507 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955902 ms - Host latency: 1.16915 ms (enqueue 0.423871 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95683 ms - Host latency: 1.1711 ms (enqueue 0.42926 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956622 ms - Host latency: 1.17024 ms (enqueue 0.422263 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957343 ms - Host latency: 1.17095 ms (enqueue 0.430841 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95509 ms - Host latency: 1.16875 ms (enqueue 0.416974 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955804 ms - Host latency: 1.16913 ms (enqueue 0.429962 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956604 ms - Host latency: 1.17014 ms (enqueue 0.421637 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957434 ms - Host latency: 1.17272 ms (enqueue 0.426575 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956525 ms - Host latency: 1.17004 ms (enqueue 0.428076 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956006 ms - Host latency: 1.16951 ms (enqueue 0.428033 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95672 ms - Host latency: 1.17007 ms (enqueue 0.432544 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955408 ms - Host latency: 1.16898 ms (enqueue 0.425598 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956525 ms - Host latency: 1.17012 ms (enqueue 0.423193 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956 ms - Host latency: 1.16938 ms (enqueue 0.426837 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95611 ms - Host latency: 1.16987 ms (enqueue 0.420367 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955902 ms - Host latency: 1.16924 ms (enqueue 0.428357 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956525 ms - Host latency: 1.17039 ms (enqueue 0.425397 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955396 ms - Host latency: 1.16862 ms (enqueue 0.429279 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955798 ms - Host latency: 1.16996 ms (enqueue 0.41991 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.954468 ms - Host latency: 1.16783 ms (enqueue 0.426978 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955383 ms - Host latency: 1.1689 ms (enqueue 0.426172 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956305 ms - Host latency: 1.17042 ms (enqueue 0.418726 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955896 ms - Host latency: 1.16971 ms (enqueue 0.426032 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.954669 ms - Host latency: 1.16763 ms (enqueue 0.42229 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956415 ms - Host latency: 1.17064 ms (enqueue 0.427087 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956622 ms - Host latency: 1.17095 ms (enqueue 0.426526 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955499 ms - Host latency: 1.16899 ms (enqueue 0.427643 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95509 ms - Host latency: 1.16879 ms (enqueue 0.424036 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955994 ms - Host latency: 1.1701 ms (enqueue 0.426361 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95672 ms - Host latency: 1.17018 ms (enqueue 0.428888 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956128 ms - Host latency: 1.16989 ms (enqueue 0.419794 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957037 ms - Host latency: 1.17106 ms (enqueue 0.428595 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956097 ms - Host latency: 1.16939 ms (enqueue 0.431189 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95528 ms - Host latency: 1.16896 ms (enqueue 0.4229 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956116 ms - Host latency: 1.16992 ms (enqueue 0.427545 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955707 ms - Host latency: 1.1683 ms (enqueue 0.423889 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955487 ms - Host latency: 1.16918 ms (enqueue 0.427795 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956201 ms - Host latency: 1.16945 ms (enqueue 0.425177 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955792 ms - Host latency: 1.17006 ms (enqueue 0.428229 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955286 ms - Host latency: 1.16897 ms (enqueue 0.427405 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956927 ms - Host latency: 1.17082 ms (enqueue 0.419452 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955182 ms - Host latency: 1.16865 ms (enqueue 0.429486 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956311 ms - Host latency: 1.17053 ms (enqueue 0.418536 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955591 ms - Host latency: 1.16985 ms (enqueue 0.424298 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955707 ms - Host latency: 1.16925 ms (enqueue 0.423047 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955182 ms - Host latency: 1.16888 ms (enqueue 0.42171 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956317 ms - Host latency: 1.16954 ms (enqueue 0.427252 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955585 ms - Host latency: 1.16942 ms (enqueue 0.423242 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956116 ms - Host latency: 1.17024 ms (enqueue 0.425903 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95517 ms - Host latency: 1.16835 ms (enqueue 0.42149 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956628 ms - Host latency: 1.17147 ms (enqueue 0.431525 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955408 ms - Host latency: 1.16929 ms (enqueue 0.420947 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955817 ms - Host latency: 1.16976 ms (enqueue 0.430682 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95611 ms - Host latency: 1.16913 ms (enqueue 0.42699 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955481 ms - Host latency: 1.16902 ms (enqueue 0.420679 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955701 ms - Host latency: 1.16879 ms (enqueue 0.427197 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956177 ms - Host latency: 1.16969 ms (enqueue 0.425537 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95686 ms - Host latency: 1.17086 ms (enqueue 0.427966 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956421 ms - Host latency: 1.17024 ms (enqueue 0.424512 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955322 ms - Host latency: 1.16871 ms (enqueue 0.426245 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956006 ms - Host latency: 1.16902 ms (enqueue 0.42561 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955261 ms - Host latency: 1.1693 ms (enqueue 0.421179 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955981 ms - Host latency: 1.16909 ms (enqueue 0.424731 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956116 ms - Host latency: 1.16937 ms (enqueue 0.425317 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955676 ms - Host latency: 1.1692 ms (enqueue 0.42688 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956531 ms - Host latency: 1.17032 ms (enqueue 0.432275 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955591 ms - Host latency: 1.16904 ms (enqueue 0.426013 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955725 ms - Host latency: 1.16991 ms (enqueue 0.428223 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957141 ms - Host latency: 1.17098 ms (enqueue 0.427209 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956311 ms - Host latency: 1.16969 ms (enqueue 0.431287 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957031 ms - Host latency: 1.17084 ms (enqueue 0.425488 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956628 ms - Host latency: 1.17098 ms (enqueue 0.428455 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956213 ms - Host latency: 1.16892 ms (enqueue 0.429272 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956531 ms - Host latency: 1.1697 ms (enqueue 0.426917 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956213 ms - Host latency: 1.16948 ms (enqueue 0.427051 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957141 ms - Host latency: 1.17087 ms (enqueue 0.424329 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955078 ms - Host latency: 1.16862 ms (enqueue 0.42749 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956104 ms - Host latency: 1.16948 ms (enqueue 0.421521 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955688 ms - Host latency: 1.16967 ms (enqueue 0.425659 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957532 ms - Host latency: 1.17228 ms (enqueue 0.429749 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956848 ms - Host latency: 1.1708 ms (enqueue 0.423474 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956921 ms - Host latency: 1.17087 ms (enqueue 0.427673 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957727 ms - Host latency: 1.17108 ms (enqueue 0.421814 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955811 ms - Host latency: 1.17004 ms (enqueue 0.429968 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956702 ms - Host latency: 1.1702 ms (enqueue 0.424976 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955493 ms - Host latency: 1.16918 ms (enqueue 0.422412 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956653 ms - Host latency: 1.17114 ms (enqueue 0.42627 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955798 ms - Host latency: 1.16892 ms (enqueue 0.416345 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956396 ms - Host latency: 1.16968 ms (enqueue 0.434509 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956726 ms - Host latency: 1.17007 ms (enqueue 0.424353 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956653 ms - Host latency: 1.17065 ms (enqueue 0.430566 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956616 ms - Host latency: 1.17007 ms (enqueue 0.428137 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955481 ms - Host latency: 1.16881 ms (enqueue 0.419434 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956433 ms - Host latency: 1.16969 ms (enqueue 0.426257 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955603 ms - Host latency: 1.16882 ms (enqueue 0.425378 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957422 ms - Host latency: 1.1715 ms (enqueue 0.428174 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956116 ms - Host latency: 1.16952 ms (enqueue 0.425061 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956323 ms - Host latency: 1.16963 ms (enqueue 0.427197 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955798 ms - Host latency: 1.16956 ms (enqueue 0.429504 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955591 ms - Host latency: 1.16934 ms (enqueue 0.420728 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955603 ms - Host latency: 1.1687 ms (enqueue 0.428259 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956189 ms - Host latency: 1.17037 ms (enqueue 0.425305 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955786 ms - Host latency: 1.16948 ms (enqueue 0.431909 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956714 ms - Host latency: 1.17042 ms (enqueue 0.428564 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956604 ms - Host latency: 1.17057 ms (enqueue 0.421033 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956018 ms - Host latency: 1.16921 ms (enqueue 0.424915 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956006 ms - Host latency: 1.17031 ms (enqueue 0.419482 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956433 ms - Host latency: 1.17006 ms (enqueue 0.432349 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955713 ms - Host latency: 1.16929 ms (enqueue 0.421069 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956104 ms - Host latency: 1.16956 ms (enqueue 0.424072 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956177 ms - Host latency: 1.16913 ms (enqueue 0.427051 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955591 ms - Host latency: 1.16924 ms (enqueue 0.42196 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956311 ms - Host latency: 1.1703 ms (enqueue 0.42793 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957361 ms - Host latency: 1.17107 ms (enqueue 0.41886 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956616 ms - Host latency: 1.16976 ms (enqueue 0.428027 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956042 ms - Host latency: 1.16967 ms (enqueue 0.426892 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95592 ms - Host latency: 1.16923 ms (enqueue 0.426147 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957239 ms - Host latency: 1.17151 ms (enqueue 0.425903 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955212 ms - Host latency: 1.16895 ms (enqueue 0.422205 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955688 ms - Host latency: 1.16959 ms (enqueue 0.431409 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956433 ms - Host latency: 1.17021 ms (enqueue 0.42489 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956018 ms - Host latency: 1.1694 ms (enqueue 0.427283 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956836 ms - Host latency: 1.16992 ms (enqueue 0.426257 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956104 ms - Host latency: 1.16968 ms (enqueue 0.426636 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956836 ms - Host latency: 1.17008 ms (enqueue 0.429102 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956702 ms - Host latency: 1.17046 ms (enqueue 0.425903 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956323 ms - Host latency: 1.17006 ms (enqueue 0.429187 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955786 ms - Host latency: 1.16926 ms (enqueue 0.426453 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95498 ms - Host latency: 1.16904 ms (enqueue 0.431958 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956494 ms - Host latency: 1.17065 ms (enqueue 0.424854 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956091 ms - Host latency: 1.1694 ms (enqueue 0.4255 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956104 ms - Host latency: 1.17009 ms (enqueue 0.433252 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955518 ms - Host latency: 1.16896 ms (enqueue 0.426746 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956616 ms - Host latency: 1.16971 ms (enqueue 0.431165 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955396 ms - Host latency: 1.16875 ms (enqueue 0.422986 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955713 ms - Host latency: 1.16882 ms (enqueue 0.428247 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956213 ms - Host latency: 1.1694 ms (enqueue 0.425708 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955493 ms - Host latency: 1.16885 ms (enqueue 0.425708 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956409 ms - Host latency: 1.16991 ms (enqueue 0.425586 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955249 ms - Host latency: 1.17003 ms (enqueue 0.425354 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956531 ms - Host latency: 1.17034 ms (enqueue 0.428418 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957141 ms - Host latency: 1.17056 ms (enqueue 0.424207 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95592 ms - Host latency: 1.17015 ms (enqueue 0.423206 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956018 ms - Host latency: 1.1692 ms (enqueue 0.425806 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95603 ms - Host latency: 1.16996 ms (enqueue 0.425269 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956958 ms - Host latency: 1.17106 ms (enqueue 0.426294 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956311 ms - Host latency: 1.16982 ms (enqueue 0.424438 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955408 ms - Host latency: 1.16907 ms (enqueue 0.4271 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956201 ms - Host latency: 1.16989 ms (enqueue 0.42616 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956824 ms - Host latency: 1.16985 ms (enqueue 0.421228 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955176 ms - Host latency: 1.16863 ms (enqueue 0.427515 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957031 ms - Host latency: 1.17095 ms (enqueue 0.426367 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955322 ms - Host latency: 1.16843 ms (enqueue 0.425146 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955286 ms - Host latency: 1.16917 ms (enqueue 0.427209 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956409 ms - Host latency: 1.16995 ms (enqueue 0.421814 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956006 ms - Host latency: 1.16929 ms (enqueue 0.428552 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956445 ms - Host latency: 1.16987 ms (enqueue 0.424854 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956714 ms - Host latency: 1.17395 ms (enqueue 0.561072 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957105 ms - Host latency: 1.17379 ms (enqueue 0.878113 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957117 ms - Host latency: 1.17235 ms (enqueue 0.563867 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956116 ms - Host latency: 1.16942 ms (enqueue 0.45437 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955811 ms - Host latency: 1.16892 ms (enqueue 0.430261 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957788 ms - Host latency: 1.17213 ms (enqueue 0.438257 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955835 ms - Host latency: 1.16907 ms (enqueue 0.416992 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.958179 ms - Host latency: 1.17222 ms (enqueue 0.432422 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956445 ms - Host latency: 1.17056 ms (enqueue 0.419775 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955615 ms - Host latency: 1.16936 ms (enqueue 0.427808 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956519 ms - Host latency: 1.17009 ms (enqueue 0.42373 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956787 ms - Host latency: 1.1709 ms (enqueue 0.423047 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956177 ms - Host latency: 1.16941 ms (enqueue 0.427588 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955469 ms - Host latency: 1.1697 ms (enqueue 0.421387 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956079 ms - Host latency: 1.16953 ms (enqueue 0.426245 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956592 ms - Host latency: 1.17019 ms (enqueue 0.426099 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957666 ms - Host latency: 1.17148 ms (enqueue 0.429346 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956274 ms - Host latency: 1.1697 ms (enqueue 0.428687 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956128 ms - Host latency: 1.16997 ms (enqueue 0.421069 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.954907 ms - Host latency: 1.1688 ms (enqueue 0.430127 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95686 ms - Host latency: 1.17026 ms (enqueue 0.417358 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956348 ms - Host latency: 1.17019 ms (enqueue 0.424268 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955542 ms - Host latency: 1.16917 ms (enqueue 0.422583 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956323 ms - Host latency: 1.1707 ms (enqueue 0.422559 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956152 ms - Host latency: 1.16912 ms (enqueue 0.427783 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956152 ms - Host latency: 1.17012 ms (enqueue 0.423096 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955469 ms - Host latency: 1.1688 ms (enqueue 0.427124 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957568 ms - Host latency: 1.17092 ms (enqueue 0.427197 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956641 ms - Host latency: 1.1697 ms (enqueue 0.427612 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95708 ms - Host latency: 1.17058 ms (enqueue 0.423633 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956348 ms - Host latency: 1.17061 ms (enqueue 0.426587 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956616 ms - Host latency: 1.17058 ms (enqueue 0.427588 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956665 ms - Host latency: 1.16992 ms (enqueue 0.427466 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956836 ms - Host latency: 1.17043 ms (enqueue 0.428174 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956128 ms - Host latency: 1.17017 ms (enqueue 0.422607 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95542 ms - Host latency: 1.16868 ms (enqueue 0.424023 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955713 ms - Host latency: 1.16978 ms (enqueue 0.428857 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956738 ms - Host latency: 1.17026 ms (enqueue 0.421973 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955786 ms - Host latency: 1.16904 ms (enqueue 0.427783 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956714 ms - Host latency: 1.17053 ms (enqueue 0.42041 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957105 ms - Host latency: 1.17104 ms (enqueue 0.430859 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956641 ms - Host latency: 1.16941 ms (enqueue 0.419873 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955396 ms - Host latency: 1.16909 ms (enqueue 0.42063 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956104 ms - Host latency: 1.16938 ms (enqueue 0.421558 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956372 ms - Host latency: 1.17021 ms (enqueue 0.416675 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955005 ms - Host latency: 1.16826 ms (enqueue 0.422974 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957153 ms - Host latency: 1.17056 ms (enqueue 0.419312 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955933 ms - Host latency: 1.1698 ms (enqueue 0.430249 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955981 ms - Host latency: 1.16926 ms (enqueue 0.42771 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.9573 ms - Host latency: 1.17056 ms (enqueue 0.42334 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956372 ms - Host latency: 1.17026 ms (enqueue 0.42854 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956421 ms - Host latency: 1.17029 ms (enqueue 0.419678 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955981 ms - Host latency: 1.17014 ms (enqueue 0.429883 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955957 ms - Host latency: 1.16897 ms (enqueue 0.414844 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956299 ms - Host latency: 1.17058 ms (enqueue 0.417432 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955737 ms - Host latency: 1.16956 ms (enqueue 0.42583 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956982 ms - Host latency: 1.17078 ms (enqueue 0.419482 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955981 ms - Host latency: 1.17124 ms (enqueue 0.488989 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.954492 ms - Host latency: 1.171 ms (enqueue 0.861255 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956812 ms - Host latency: 1.17188 ms (enqueue 0.62417 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956494 ms - Host latency: 1.17039 ms (enqueue 0.469556 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95708 ms - Host latency: 1.17019 ms (enqueue 0.438013 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956323 ms - Host latency: 1.1698 ms (enqueue 0.434448 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956738 ms - Host latency: 1.17075 ms (enqueue 0.422925 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.958008 ms - Host latency: 1.17327 ms (enqueue 0.433203 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957031 ms - Host latency: 1.17124 ms (enqueue 0.423999 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.9552 ms - Host latency: 1.16882 ms (enqueue 0.426904 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955811 ms - Host latency: 1.16892 ms (enqueue 0.427051 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956372 ms - Host latency: 1.17053 ms (enqueue 0.425293 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95708 ms - Host latency: 1.17078 ms (enqueue 0.428906 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955933 ms - Host latency: 1.16929 ms (enqueue 0.419043 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955615 ms - Host latency: 1.16899 ms (enqueue 0.427051 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.954834 ms - Host latency: 1.16907 ms (enqueue 0.41958 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957178 ms - Host latency: 1.17107 ms (enqueue 0.427441 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955908 ms - Host latency: 1.16982 ms (enqueue 0.433203 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956543 ms - Host latency: 1.17634 ms (enqueue 0.656445 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.958203 ms - Host latency: 1.17778 ms (enqueue 0.911035 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 1.06826 ms - Host latency: 1.28486 ms (enqueue 1.16592 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956934 ms - Host latency: 1.17188 ms (enqueue 0.560474 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956396 ms - Host latency: 1.16941 ms (enqueue 0.439844 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956812 ms - Host latency: 1.1696 ms (enqueue 0.422778 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956226 ms - Host latency: 1.16975 ms (enqueue 0.423389 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956519 ms - Host latency: 1.16968 ms (enqueue 0.421338 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955347 ms - Host latency: 1.16897 ms (enqueue 0.420532 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955249 ms - Host latency: 1.16895 ms (enqueue 0.424414 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956201 ms - Host latency: 1.16997 ms (enqueue 0.420239 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.9573 ms - Host latency: 1.17063 ms (enqueue 0.432324 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956909 ms - Host latency: 1.16982 ms (enqueue 0.422241 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95647 ms - Host latency: 1.16985 ms (enqueue 0.427954 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956396 ms - Host latency: 1.17019 ms (enqueue 0.425415 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955859 ms - Host latency: 1.16841 ms (enqueue 0.419482 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955664 ms - Host latency: 1.17 ms (enqueue 0.444653 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957837 ms - Host latency: 1.1793 ms (enqueue 0.742969 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957178 ms - Host latency: 1.17654 ms (enqueue 0.840234 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957105 ms - Host latency: 1.17505 ms (enqueue 0.497607 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955713 ms - Host latency: 1.17129 ms (enqueue 0.403491 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956934 ms - Host latency: 1.17117 ms (enqueue 0.398901 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956812 ms - Host latency: 1.17014 ms (enqueue 0.408716 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956689 ms - Host latency: 1.17031 ms (enqueue 0.420605 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955835 ms - Host latency: 1.16912 ms (enqueue 0.405054 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956104 ms - Host latency: 1.16973 ms (enqueue 0.39978 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956909 ms - Host latency: 1.17104 ms (enqueue 0.413892 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955518 ms - Host latency: 1.16904 ms (enqueue 0.421118 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956982 ms - Host latency: 1.17104 ms (enqueue 0.426587 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956616 ms - Host latency: 1.17021 ms (enqueue 0.413647 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956445 ms - Host latency: 1.17048 ms (enqueue 0.417822 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956104 ms - Host latency: 1.16946 ms (enqueue 0.415894 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956348 ms - Host latency: 1.16926 ms (enqueue 0.425879 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956836 ms - Host latency: 1.17192 ms (enqueue 0.472607 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956055 ms - Host latency: 1.17676 ms (enqueue 0.781079 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957837 ms - Host latency: 1.17786 ms (enqueue 0.745459 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955884 ms - Host latency: 1.17405 ms (enqueue 0.46748 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957202 ms - Host latency: 1.17117 ms (enqueue 0.389453 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955933 ms - Host latency: 1.16987 ms (enqueue 0.40835 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956055 ms - Host latency: 1.16929 ms (enqueue 0.412183 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957642 ms - Host latency: 1.17131 ms (enqueue 0.428589 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95564 ms - Host latency: 1.16902 ms (enqueue 0.419946 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955664 ms - Host latency: 1.16985 ms (enqueue 0.425098 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.955518 ms - Host latency: 1.16838 ms (enqueue 0.422607 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957373 ms - Host latency: 1.17263 ms (enqueue 0.429395 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.95542 ms - Host latency: 1.16838 ms (enqueue 0.426562 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956812 ms - Host latency: 1.17078 ms (enqueue 0.420166 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956616 ms - Host latency: 1.17041 ms (enqueue 0.428906 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.956128 ms - Host latency: 1.16885 ms (enqueue 0.427148 ms)
[05/21/2025-09:28:26] [I] Average on 10 runs - GPU latency: 0.957056 ms - Host latency: 1.17117 ms (enqueue 0.434204 ms)
[05/21/2025-09:28:26] [I] 
[05/21/2025-09:28:26] [I] === Performance summary ===
[05/21/2025-09:28:26] [I] Throughput: 1041.31 qps
[05/21/2025-09:28:26] [I] Latency: min = 1.16022 ms, max = 1.50732 ms, mean = 1.17186 ms, median = 1.1698 ms, percentile(90%) = 1.17358 ms, percentile(95%) = 1.17627 ms, percentile(99%) = 1.25966 ms
[05/21/2025-09:28:26] [I] Enqueue Time: min = 0.368652 ms, max = 1.44043 ms, mean = 0.440797 ms, median = 0.426514 ms, percentile(90%) = 0.442749 ms, percentile(95%) = 0.481033 ms, percentile(99%) = 0.88623 ms
[05/21/2025-09:28:26] [I] H2D Latency: min = 0.203613 ms, max = 0.224365 ms, mean = 0.207456 ms, median = 0.207153 ms, percentile(90%) = 0.208252 ms, percentile(95%) = 0.209045 ms, percentile(99%) = 0.215576 ms
[05/21/2025-09:28:26] [I] GPU Compute Time: min = 0.948212 ms, max = 1.28931 ms, mean = 0.958012 ms, median = 0.95639 ms, percentile(90%) = 0.958557 ms, percentile(95%) = 0.960449 ms, percentile(99%) = 1.04652 ms
[05/21/2025-09:28:26] [I] D2H Latency: min = 0.00439453 ms, max = 0.015625 ms, mean = 0.00640021 ms, median = 0.00634766 ms, percentile(90%) = 0.00805664 ms, percentile(95%) = 0.00830078 ms, percentile(99%) = 0.00878906 ms
[05/21/2025-09:28:26] [I] Total Host Walltime: 3.00296 s
[05/21/2025-09:28:26] [I] Total GPU Compute Time: 2.9957 s
[05/21/2025-09:28:26] [W] * GPU compute time is unstable, with coefficient of variance = 1.60089%.
[05/21/2025-09:28:26] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.
[05/21/2025-09:28:26] [I] Explanations of the performance metrics are printed in the verbose logs.
[05/21/2025-09:28:26] [V] 
[05/21/2025-09:28:26] [V] === Explanations of the performance metrics ===
[05/21/2025-09:28:26] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[05/21/2025-09:28:26] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[05/21/2025-09:28:26] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[05/21/2025-09:28:26] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[05/21/2025-09:28:26] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[05/21/2025-09:28:26] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[05/21/2025-09:28:26] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[05/21/2025-09:28:26] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[05/21/2025-09:28:26] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v100700] [b23] # trtexec --verbose --onnx=default_mtq_int8_q_qint8.onnx --saveEngine=tensorrt_10_7/default_mtq_int8_q_qint8.onnx-best/default_mtq_int8_q_qint8.onnx.engine --exportLayerInfo=tensorrt_10_7/default_mtq_int8_q_qint8.onnx-best/default_mtq_int8_q_qint8.onnx.engine.graph.json --timingCacheFile=./timing.cache --profilingVerbosity=detailed --best
