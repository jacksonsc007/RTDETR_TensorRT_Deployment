{"Layers": [{
  "Name": "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "images",
    "Location": "Device",
    "Dimensions": [1,3,640,640],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,3,640,640],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,3,640,640],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 864},
  "Bias": {"Type": "Float", "Count": 32},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_first_layer_i8i8_i8i32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_vect_c_32_tilesize8x16x32x32_stage1_warpsize4x1x1_tensor16x8x16_r3s3_u2v2_aligna4_alignc8",
  "TacticValue": "0x5cc792a989a1d1a6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/conv/Conv]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/act/Relu]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 9216},
  "Bias": {"Type": "Float", "Count": 32},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3",
  "TacticValue": "0x13463e9bf9ae0d73",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/Conv]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/act/Relu]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/MaxPool_output_0",
    "Location": "Device",
    "Dimensions": [1,64,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 18432},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x9dafb2758560cc1d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/Conv]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/backbone/MaxPool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/MaxPool_output_0",
    "Location": "Device",
    "Dimensions": [1,64,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/MaxPool]"
},{
  "Name": "model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x9dafb2758560cc1d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xe2bc5a4963d23ad0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 4096},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x1cfa820c55616892",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x9dafb2758560cc1d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xe2bc5a4963d23ad0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_UP",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 0,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE",
  "TacticValue": "0xd9375d43b61ffbcb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x705baf38e41eee0b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4133eb8759ee0d6d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 8192},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x8e1dd2962c589dd4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x128x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x214f03e23f252333",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4133eb8759ee0d6d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_UP",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 0,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE",
  "TacticValue": "0xd9375d43b61ffbcb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 294912},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xbb88763c3b0e94d4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xad6872a374321f7e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x8e1dd2962c589dd4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xbb88763c3b0e94d4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xad6872a374321f7e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_UP",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 0,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE",
  "TacticValue": "0xd9375d43b61ffbcb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1179648},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32",
  "TacticValue": "0x322f337abc345152",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xc5159665a920f22c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 131072},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x4f8662a723b489e1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x64x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x1d53511430a5d47e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xc5159665a920f22c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/act/Relu]"
},{
  "Name": "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 131072},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x7524377e24bc511f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "dummy_shape_call__mye8926_0_myl38_0",
  "LayerType": "shape_call",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_MulAddResMovTraAddTra_myl38_1",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/Constant_output_0_constantHalf",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/encoder/input_proj_2/norm/BatchNormalization/model/encoder/input_proj_2/norm/BatchNormalization_shift_wHalf",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Half"
  },
  {
    "Name": "Reformatted Input Tensor 0 to {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/encoder/input_proj_2/norm/BatchNormalization/model/encoder/input_proj_2/norm/BatchNormalization_scale_wHalf",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_1_first_transpose_output.1",
    "Dimensions": [400,1,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_4",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/encoder/encoder_0/layers_0/Add_output_0'.1",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_MulAddResMovTraAddTra_0xf4d05087139b538178007bf6bb80a08a",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.2/norm/BatchNormalization]\u001f[ONNX Layer: /model/encoder/Reshape]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/Add]\u001f[ONNX Layer: /model/encoder/Transpose]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1]"
},{
  "Name": "__mye8857_myl38_2",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye8859_myl38_3",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl38_4",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_1_first_transpose_output.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye8790dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye8279/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8280/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8565_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_2]"
},{
  "Name": "__mye8861_myl38_5",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_6",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/Add_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye8716_dconst",
    "Dimensions": [2,256,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye8321/model/encoder/encoder_0/layers_0/self_attn/MatMul_1_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8322/model/encoder/encoder_0/layers_0/self_attn/MatMul_1_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8721_dconst",
    "Dimensions": [2,1,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__mye8628",
    "Dimensions": [2,400,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add]"
},{
  "Name": "__mye8863_myl38_7",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "_gemm_mha_v2_myl38_8",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye8628",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye8628",
    "Dimensions": [8,32,400],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_7",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Half"
  }],
  "TacticName": "_gemm_mha_v2_0xb49a52fc0767aa7be96106641036114d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Softmax]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Mul_1]"
},{
  "Name": "__myl_Tra_myl38_9",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_7",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_5 _ /model/encoder/encoder_0/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [400,8,32],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_Tra_0xb89fdb3500b2782dfe651a509d523a76",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5]\u001e[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3]"
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl38_10",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_5 _ /model/encoder/encoder_0/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye8409_dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye8359/model/encoder/encoder_0/layers_0/self_attn/Gemm_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8360/model/encoder/encoder_0/layers_0/self_attn/Gemm_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_encoder_encoder_0_layers_0_self_attn_out_proj_bias _ ONNXTRT_Broadcast_116_constantHalf",
    "Dimensions": [1,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Half"
  }],
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Gemm]"
},{
  "Name": "__myl_AddCasMeaSubMulMeaAddSqrDivMulCasMulAddCasMulMinMaxRouCas_myl38_11",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "model_encoder_encoder_0_layers_0_norm1_bias _ ONNXTRT_Broadcast_123_constantHalf",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "model_encoder_encoder_0_layers_0_norm1_weight _ ONNXTRT_Broadcast_121_constantHalf",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__mye8922_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_4",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_AddCasMeaSubMulMeaAddSqrDivMulCasMulAddCasMulMinMaxRouCas_0x67d6d88e10867297ea489fcf1246e2e4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/encoder/encoder_0/layers_0/linear1/MatMul_myl38_12",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye8795dconst",
    "Dimensions": [1,256,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye8585_dconst",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8592zero_beta",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8596_dconst",
    "Dimensions": [1,1,1024],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "cast__mye8738_12",
    "Dimensions": [1,400,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_gelu_erf",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Add]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Div]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Erf]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/Add]"
},{
  "Name": "/model/encoder/encoder_0/layers_0/linear2/MatMul_myl38_13",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "cast__mye8738_12",
    "Dimensions": [1,400,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye8800dconst",
    "Dimensions": [1,1024,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye8601_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8608zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]"
},{
  "Name": "__myl_CasAddAddCasMeaSubMulMea_myl38_14",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "model_encoder_encoder_0_layers_0_linear2_bias _ ONNXTRT_Broadcast_145_constantHalf",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,400,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_CasAddAddCasMeaSubMulMea_0x49f50938e3a06c933ca11aab5f20134c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_2]"
},{
  "Name": "__myl_AddSqrDivMulCasMulAddTraRes_myl38_15",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "model_encoder_encoder_0_layers_0_norm2_weight _ ONNXTRT_Broadcast_149_constantHalf",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "model_encoder_encoder_0_layers_0_norm2_bias _ ONNXTRT_Broadcast_151_constantHalf",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Half"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,400,1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Reshape_1_output_0",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Half"
  }],
  "TacticName": "__myl_AddSqrDivMulCasMulAddTraRes_0xd61c74fd4ab12b19fae354ddcd6de65d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]\u001f[ONNX Layer: /model/encoder/Transpose_1]\u001e[ONNX Layer: /model/encoder/Reshape_1]"
},{
  "Name": "model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x483ad1560c6e5e27",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/input_proj.0/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x483ad1560c6e5e27",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/input_proj.1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Reshape_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x7524377e24bc511f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/act/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/act/Mul]"
},{
  "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/act/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Resize_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/encoder/Resize",
  "LayerType": "Resize",
  "Inputs": [
  {
    "Name": "/model/encoder/Resize_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Resize",
  "InterpolationMode": "NEAREST",
  "ResizeScales": [1, 1, 2, 2, 0, 0, 0, 0],
  "ExcludeOutside": 0,
  "CubicCoeff": -0.75,
  "CoordTransform": "kASYMMETRIC",
  "ResizeSelector": "kFORMULA",
  "NNRounding": "kFLOOR",
  "TacticValue": "0x0000000000000003",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Resize]"
},{
  "Name": "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Concat_2]"
},{
  "Name": "model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x8e1dd2962c589dd4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0x6176c23707257237",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0x6176c23707257237",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xad6872a374321f7e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  },
  {
    "Name": "/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/Add]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Mul]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Resize_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/Resize_1",
  "LayerType": "Resize",
  "Inputs": [
  {
    "Name": "/model/encoder/Resize_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Resize",
  "InterpolationMode": "NEAREST",
  "ResizeScales": [1, 1, 2, 2, 0, 0, 0, 0],
  "ExcludeOutside": 0,
  "CubicCoeff": -0.75,
  "CoordTransform": "kASYMMETRIC",
  "ResizeSelector": "kFORMULA",
  "NNRounding": "kFLOOR",
  "TacticValue": "0x0000000000000005",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Resize_1]"
},{
  "Name": "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Concat_3]"
},{
  "Name": "model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x758f8b2079a95b2e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x458f02d2b10db57c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xfdf7509af98902e0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xfdf7509af98902e0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x4133eb8759ee0d6d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  },
  {
    "Name": "/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x000000000000001f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/Add]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x65a38dbc9e991257",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Mul]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.0/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x733ba2a91a48d431",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc722efd60bc6ea84",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/Resize_1_output_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Resize_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Concat_4]"
},{
  "Name": "model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x8e1dd2962c589dd4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0x6176c23707257237",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0x6176c23707257237",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xad6872a374321f7e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  },
  {
    "Name": "/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/Add]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Mul]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.1/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x733ba2a91a48d431",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc985777c89c6b3a4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/act/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x7524377e24bc511f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0xc6cdb1e47323bb01",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc985777c89c6b3a4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc985777c89c6b3a4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x51a916d02de43689",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  },
  {
    "Name": "/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP16 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/Add]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0xc6cdb1e47323bb01",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Mul]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x5e4f6d7c83746fd6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/Conv]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "dummy_shape_call__mye158089_0_myl85_0",
  "LayerType": "shape_call",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "entry^bb^signal^1_myl85_1",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "entry^bb^wait^1_myl85_2",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "__myl_MulAddResMulMinMaxRouCasTra_myl85_3",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye155645_dconst",
    "Dimensions": [1,1,6400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj_0/norm/BatchNormalization/model/decoder/input_proj_0/norm/BatchNormalization_shift_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj.0/conv/Conv_output_0",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj_0/norm/BatchNormalization/model/decoder/input_proj_0/norm/BatchNormalization_scale_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_6",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_5",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MulAddResMulMinMaxRouCasTra_0xb7911a963641d99b9b7644b75b6b02a0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.0/norm/BatchNormalization]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape]\u001e[ONNX Layer: /model/decoder/Transpose]"
},{
  "Name": "__myl_MulMinMaxRouCasResTra_myl85_4",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_5",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye157989_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_7",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRouCasResTra_0x53ec280dcdcbc7be42089db5a99e26ce",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape]\u001e[ONNX Layer: /model/decoder/Transpose]"
},{
  "Name": "__myl_MulAddResMulMinMaxRouCasTra_myl85_5",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye155668_dconst",
    "Dimensions": [1,1,1600],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj_1/norm/BatchNormalization/model/decoder/input_proj_1/norm/BatchNormalization_shift_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj.1/conv/Conv_output_0",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj_1/norm/BatchNormalization/model/decoder/input_proj_1/norm/BatchNormalization_scale_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MulAddResMulMinMaxRouCasTra_0xc7826108fa2ff5e34bf8bfa07dbc52f7",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.1/norm/BatchNormalization]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape_1]\u001e[ONNX Layer: /model/decoder/Transpose_1]"
},{
  "Name": "__myl_MulMinMaxRouCasResTra_myl85_6",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye157989_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRouCasResTra_0x8592f20b4eb6c9ee9a9e56f44ec5871e",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape_1]\u001e[ONNX Layer: /model/decoder/Transpose_1]"
},{
  "Name": "__mye157455_myl85_7",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "__mye157457_myl85_8",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_myl85_9",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye157989_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_7",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye155691_dconst",
    "Dimensions": [1,1,400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_6",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "/model/decoder/input_proj_2/norm/BatchNormalization/model/decoder/input_proj_2/norm/BatchNormalization_shift_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj.2/conv/Conv_output_0",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj_2/norm/BatchNormalization/model/decoder/input_proj_2/norm/BatchNormalization_scale_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye154083_12",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_0x14d97ab92d57b85a1bd3815e99f6e152",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.2/norm/BatchNormalization]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Concat_3]\u001f[ONNX Layer: /model/decoder/Reshape_2]\u001e[ONNX Layer: /model/decoder/Transpose_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye157459_myl85_10",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye157461_myl85_11",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_12",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye154083_12",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156340dconst",
    "Dimensions": [3,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye154107_dconst",
    "Dimensions": [3,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye154128_dconst",
    "Dimensions": [3,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye155126_dconst",
    "Dimensions": [3,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye154083",
    "Dimensions": [3,8400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add]"
},{
  "Name": "/model/decoder/enc_output/proj/MatMul_myl85_13",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156345dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153194_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153201zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_enc_output_proj_bias _ ONNXTRT_Broadcast_275_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_output/proj/MatMul]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_output/proj/Add]"
},{
  "Name": "__myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_14",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "model_decoder_enc_output_norm_weight _ ONNXTRT_Broadcast_279_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_enc_output_norm_bias _ ONNXTRT_Broadcast_281_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye157999_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_16",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0xf1c80ff651c1b506b1815818d6281ad3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_output/norm/LayerNormalization]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye157463_myl85_15",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye157465_myl85_16",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/enc_score_head/MatMul_myl85_17",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156355dconst",
    "Dimensions": [1,256,80],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153232_dconst",
    "Dimensions": [1,80],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153239zero_beta",
    "Dimensions": [1,80],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_enc_score_head_bias _ ONNXTRT_Broadcast_289_constantFloat",
    "Dimensions": [1,1,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [1,8400,80],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/enc_score_head/MatMul]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_score_head/Add]"
},{
  "Name": "__myl_Max_myl85_18",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [1,8400,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/ReduceMax_output_0'_unsqueezed0.1",
    "Dimensions": [1,8400,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Max_0x4330a02939b906fc5f8c1bd769456467",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/ReduceMax]"
},{
  "Name": "__myl_Top_myl85_19",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/ReduceMax_output_0'_unsqueezed0.1",
    "Dimensions": [1,8400],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/TopK_output_0'.1",
    "Dimensions": [1,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_20",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  }],
  "TacticName": "__myl_Top_0x7e62297dffa2e596ee60049838a70f81",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/TopK]"
},{
  "Name": "__mye157467_myl85_20",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/enc_bbox_head/layers_0/MatMul_myl85_21",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157529_xformed___mye156350dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157537_xformed___mye153216_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153212zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye157533_xformed___mye153225_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/enc_bbox_head/layers_2/input_quantizer/QuantizeLinear_output_0'.1_21",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize32x32_stage4_warpsize2x4x1_r1s1_u1v1_hw1_c256_scalebias_relu",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/act/Relu]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/Add]"
},{
  "Name": "/model/decoder/enc_bbox_head/layers_1/MatMul_myl85_22",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/enc_bbox_head/layers_2/input_quantizer/QuantizeLinear_output_0'.1_21",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157541_xformed___mye156360dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157549_xformed___mye153254_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153250zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye157545_xformed___mye153263_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_22",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize32x32_stage4_warpsize2x4x1_r1s1_u1v1_hw1_c256_scalebias_relu",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/act_1/Relu]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/Add]"
},{
  "Name": "__myl_FcAdd_myl85_23",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "model_decoder_anchors_constantFloat",
    "Dimensions": [1,8400,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_22",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156365dconst",
    "Dimensions": [1,256,4],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153270_dconst",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153277zero_beta",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_enc_bbox_head_layers_2_bias _ ONNXTRT_Broadcast_311_constantFloat",
    "Dimensions": [1,1,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_23",
    "Dimensions": [1,8400,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/Add]\u001f[ONNX Layer: /model/decoder/Add]"
},{
  "Name": "__mye157469_myl85_24",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_myl85_25",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_23",
    "Dimensions": [1,8400,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158003_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_20",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_26",
    "Dimensions": [300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,4],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_25",
    "Dimensions": [1,300,1],
    "Format/Datatype": "Int32"
  }],
  "TacticName": "__myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_0xea994e8a02766a6b87cc77a0ab1bb663",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/Unsqueeze]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid]\u001f[ONNX Layer: /model/decoder/GatherElements]"
},{
  "Name": "__myl_MovCon_myl85_26",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye156623",
    "Dimensions": [1,300,12],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/input_quantizer/QuantizeLinear_output_0'.1_27",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MovCon_0x9482c2d60923b5d68d1030431d0b6d2e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl85_27",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/input_quantizer/QuantizeLinear_output_0'.1_27",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156637_dconst",
    "Dimensions": [1,16,512],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153292_dconst",
    "Dimensions": [1,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153288zero_beta",
    "Dimensions": [1,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153301_dconst",
    "Dimensions": [1,1,512],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1_28",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_28",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1_28",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156375dconst",
    "Dimensions": [1,512,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153308_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153315zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149975_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/Add]"
},{
  "Name": "__myl_RepGatResAdd_myl85_29",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_16",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_25",
    "Dimensions": [1,300,1],
    "Format/Datatype": "Int32"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/GatherElements_1_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_RepGatResAdd_0x3585782c9d9cf8f0d2b18744e46affde",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/GatherElements_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/Add]"
},{
  "Name": "__mye157471_myl85_30",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye157473_myl85_31",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl85_32",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/GatherElements_1_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149953_dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149287/model/decoder/decoder/layers_0/self_attn/MatMul_2_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149288/model/decoder/decoder/layers_0/self_attn/MatMul_2_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153089_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_2]"
},{
  "Name": "__mye157475_myl85_33",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_34",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye156380dconst",
    "Dimensions": [2,256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149341/model/decoder/decoder/layers_0/self_attn/MatMul_1_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149342/model/decoder/decoder/layers_0/self_attn/MatMul_1_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye155376_dconst",
    "Dimensions": [2,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye154068",
    "Dimensions": [2,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add]"
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_35",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye154068",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye154068",
    "Dimensions": [8,32,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153149",
    "Dimensions": [1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149376/model/decoder/decoder/layers_0/self_attn/MatMul_3_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_34",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Mul_1]"
},{
  "Name": "__myl_MaxSubExpSumDivMul_myl85_36",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_34",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_34",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_4_output_0'.1_35",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxSubExpSumDivMul_0x4bb1dc97991e61c47e3d11f2b659751f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Softmax]"
},{
  "Name": "__mye157477_myl85_37",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_38",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_4_output_0'.1_35",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149386/model/decoder/decoder/layers_0/self_attn/MatMul_4_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149387/model/decoder/decoder/layers_0/self_attn/MatMul_4_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_36",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_4]"
},{
  "Name": "__myl_Tra_myl85_39",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_36",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Transpose_5 _ /model/decoder/decoder/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,8,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Tra_0xbff89681337b526d248c0838f5d94e94",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Transpose_5]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Reshape_3]"
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/Gemm_myl85_40",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Transpose_5 _ /model/decoder/decoder/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149991_dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149400/model/decoder/decoder/layers_0/self_attn/Gemm_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149401/model/decoder/decoder/layers_0/self_attn/Gemm_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_0_self_attn_out_proj_bias _ ONNXTRT_Broadcast_351_constantFloat",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Gemm]"
},{
  "Name": "__myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_41",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye152985_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye152975_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158007_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/GatherElements_1_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_40",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_0x91b2c7046943674462a660380f1917c4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/norm1/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_FcMulAdd_myl85_42",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__mye154035_dconst",
    "Dimensions": [1,288],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye154017_dconst",
    "Dimensions": [1,288],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156385dconst",
    "Dimensions": [1,256,288],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153994_dconst",
    "Dimensions": [1,1,288],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye154044mul_beta",
    "Dimensions": [1,300,288],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add]"
},{
  "Name": "__mye157479_myl85_43",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye157481_myl85_44",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "__myl_ResMaxSubExpSum_myl85_45",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye154044mul_beta",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_43",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_42",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ResMaxSubExpSum_0x7c7453772a39d1d1294358f10a1e770b",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]"
},{
  "Name": "__mye157483_myl85_46",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_47",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_26",
    "Dimensions": [300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150470_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150470_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150470_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye154083",
    "Dimensions": [1,8400,8,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150490_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150490_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150490_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150490_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150480_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150480_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150480_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150480_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150470_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18222",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150470_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18237",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150470_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18252",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150470_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18267",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150470_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18446",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150480_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18461",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150480_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18476",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150480_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18491",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150480_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18670",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150490_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18685",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150490_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18700",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150490_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18715",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150490_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150465_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158011_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150475_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158011_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150485_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158011_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150579",
    "Dimensions": [1,1,1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150575",
    "Dimensions": [1,1,1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149996_dconst",
    "Dimensions": [1,1,1,12,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye154044mul_beta",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_46",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_45",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_44",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_0x3718754d33237a7346a050fa256f2cc0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Sub]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_1]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Split]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_7]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_8]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8]"
},{
  "Name": "__mye157485_myl85_48",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_49",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_42",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158021_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_45",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_44",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_46",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_43",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye150954_q8",
    "Dimensions": [8,32,300,1],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_DivMulTraResConMulSumMulMinMaxRouCas_0xfdc36321684ce402a67e9cc028ee3fea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_2]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_9]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Concat_10]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/ReduceSum]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_8]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_Mov_myl85_50",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye150954_q8",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_48",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_Mov_0xccd11d8190e5ec819f0de6935e8e6ebe",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]"
},{
  "Name": "__myl_FcAdd_myl85_51",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_40",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_48",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye155546_dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153341_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153348zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_0_cross_attn_output_proj_bias _ ONNXTRT_Broadcast_575_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_49",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/Add_3]"
},{
  "Name": "__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_52",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye152940_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye152930_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158025_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_49",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_51",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_0x7374e3706e69002aff2a29c077287875",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/norm2/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_0/linear1/MatMul_myl85_53",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157553_xformed___mye156390dconst",
    "Dimensions": [1,256,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153363_dconst",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153359zero_beta",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153372_dconst",
    "Dimensions": [1,1,1024],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_52",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/linear1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/activation/Relu]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/Add]"
},{
  "Name": "__myl_FcAdd_myl85_54",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_51",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_52",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156395dconst",
    "Dimensions": [1,1024,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153379_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153386zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_0_linear2_bias _ ONNXTRT_Broadcast_597_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_53",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/linear2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/Add_4]"
},{
  "Name": "__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_55",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye152904_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye152890_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158029_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_53",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0x4e14cc44ca088d44748af6a96514ac7a",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye157487_myl85_56",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye157489_myl85_57",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl85_58",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150056_dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149485/model/decoder/decoder/layers_1/self_attn/MatMul_2_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149486/model/decoder/decoder/layers_1/self_attn/MatMul_2_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye152875_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Add_2_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_2]"
},{
  "Name": "__mye157491_myl85_59",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl85_60",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157557_xformed___mye156400dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153401_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153397zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153410_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/input_quantizer/QuantizeLinear_output_0'.1_57",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl85_61",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/input_quantizer/QuantizeLinear_output_0'.1_57",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157561_xformed___mye156405dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153428_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153424zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153437_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/Add_output_0'.1_58",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/MatMul_myl85_62",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/Add_output_0'.1_58",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156410dconst",
    "Dimensions": [1,256,4],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153444_dconst",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153451zero_beta",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_dec_bbox_head_0_layers_2_bias _ ONNXTRT_Broadcast_627_constantFloat",
    "Dimensions": [1,1,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_59",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add]"
},{
  "Name": "__myl_MaxMinMaxSubMinMaxMinDivLogResAddNegExpAddDivMulMinMaxRouConCas_myl85_63",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_26",
    "Dimensions": [300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_59",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye156644",
    "Dimensions": [1,300,12],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158003_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_61",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_60",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MaxMinMaxSubMinMaxMinDivLogResAddNegExpAddDivMulMinMaxRouConCas_0xefac8e563c6580f9cd110df4750663ce",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/Log]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid_1]\u001f[ONNX Layer: /model/decoder/decoder/Add]\u001f[ONNX Layer: /model/decoder/decoder/Div]\u001f[ONNX Layer: /model/decoder/decoder/Sub]\u001f[ONNX Layer: /model/decoder/decoder/Clip]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl85_64",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_60",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156660_dconst",
    "Dimensions": [1,16,512],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153466_dconst",
    "Dimensions": [1,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153462zero_beta",
    "Dimensions": [1,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153475_dconst",
    "Dimensions": [1,1,512],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1_62",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/Add]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_65",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1_62",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156420dconst",
    "Dimensions": [1,512,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153482_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153489zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150074_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/Add]"
},{
  "Name": "__myl_Add_myl85_66",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Add_0xfcef7142c0478fafffb74a07ab8ea30f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/Add]"
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_67",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye156425dconst",
    "Dimensions": [2,256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149550/model/decoder/decoder/layers_1/self_attn/MatMul_1_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149551/model/decoder/decoder/layers_1/self_attn/MatMul_1_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye155386_dconst",
    "Dimensions": [2,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye153981",
    "Dimensions": [2,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add]"
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_68",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye153981",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153981",
    "Dimensions": [8,32,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153153",
    "Dimensions": [1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149585/model/decoder/decoder/layers_1/self_attn/MatMul_3_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_66",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Mul_1]"
},{
  "Name": "__myl_MaxSubExpSumDivMul_myl85_69",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_66",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_66",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_4_output_0'.1_67",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxSubExpSumDivMul_0x4bb1dc97991e61c47e3d11f2b659751f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Softmax]"
},{
  "Name": "__mye157493_myl85_70",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_71",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_4_output_0'.1_67",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149595/model/decoder/decoder/layers_1/self_attn/MatMul_4_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149596/model/decoder/decoder/layers_1/self_attn/MatMul_4_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_68",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_4]"
},{
  "Name": "__myl_Tra_myl85_72",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_68",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Transpose_5 _ /model/decoder/decoder/layers_1/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,8,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Tra_0xbff89681337b526d248c0838f5d94e94",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Transpose_5]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Reshape_3]"
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/Gemm_myl85_73",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Transpose_5 _ /model/decoder/decoder/layers_1/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150090_dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149609/model/decoder/decoder/layers_1/self_attn/Gemm_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149610/model/decoder/decoder/layers_1/self_attn/Gemm_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_1_self_attn_out_proj_bias _ ONNXTRT_Broadcast_672_constantFloat",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Gemm_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Gemm]"
},{
  "Name": "__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_74",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye152825_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye152815_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158036_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_72",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_0x2ee8fbc8ddb7baf5b46cceba6a86227b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/norm1/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_FcMulAdd_myl85_75",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__mye153948_dconst",
    "Dimensions": [1,288],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153930_dconst",
    "Dimensions": [1,288],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156430dconst",
    "Dimensions": [1,256,288],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153907_dconst",
    "Dimensions": [1,1,288],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye153957mul_beta",
    "Dimensions": [1,300,288],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add]"
},{
  "Name": "__mye157495_myl85_76",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye157497_myl85_77",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "__myl_ResMaxSubExpSum_myl85_78",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye153957mul_beta",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_75",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_74",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ResMaxSubExpSum_0x7c7453772a39d1d1294358f10a1e770b",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]"
},{
  "Name": "__mye157499_myl85_79",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_80",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_61",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150500_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150500_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150500_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye154083",
    "Dimensions": [1,8400,8,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150520_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150520_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150520_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150520_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150510_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150510_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150510_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150510_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150500_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18921",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150500_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18936",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150500_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18951",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150500_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye18966",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150500_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19145",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150510_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19160",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150510_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19175",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150510_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19190",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150510_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19369",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150520_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19384",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150520_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19399",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150520_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19414",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150520_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150495_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158011_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150505_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158011_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150515_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158011_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150607",
    "Dimensions": [1,1,1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150603",
    "Dimensions": [1,1,1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150095_dconst",
    "Dimensions": [1,1,1,12,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153957mul_beta",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_78",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_77",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_76",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_0xc0b46290445cedee2db7e5baf77a0f2e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Sub]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_1]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Split]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_7]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_8]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8]"
},{
  "Name": "__mye157501_myl85_81",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_82",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_74",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158049_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_77",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_76",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_78",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_75",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye150960_q8",
    "Dimensions": [8,32,300,1],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_DivMulTraResConMulSumMulMinMaxRouCas_0xfdc36321684ce402a67e9cc028ee3fea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_2]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_9]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Concat_10]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/ReduceSum]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_Mov_myl85_83",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye150960_q8",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_80",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_Mov_0xccd11d8190e5ec819f0de6935e8e6ebe",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]"
},{
  "Name": "__myl_FcAdd_myl85_84",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_72",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_80",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye155492_dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153515_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153522zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_1_cross_attn_output_proj_bias _ ONNXTRT_Broadcast_896_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_81",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/Add_3]"
},{
  "Name": "__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_85",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye152780_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye152770_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158053_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_81",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_83",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_0x7374e3706e69002aff2a29c077287875",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/norm2/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_1/linear1/MatMul_myl85_86",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157565_xformed___mye156435dconst",
    "Dimensions": [1,256,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153537_dconst",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153533zero_beta",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153546_dconst",
    "Dimensions": [1,1,1024],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_84",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/linear1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/activation/Relu]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/Add]"
},{
  "Name": "__myl_FcAdd_myl85_87",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_83",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_84",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156440dconst",
    "Dimensions": [1,1024,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153553_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153560zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_1_linear2_bias _ ONNXTRT_Broadcast_918_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_85",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/linear2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/Add_4]"
},{
  "Name": "__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_88",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye152744_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye152730_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158057_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_85",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0x4e14cc44ca088d44748af6a96514ac7a",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye157503_myl85_89",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye157505_myl85_90",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl85_91",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150151_dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149694/model/decoder/decoder/layers_2/self_attn/MatMul_2_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149695/model/decoder/decoder/layers_2/self_attn/MatMul_2_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye152715_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Add_2_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_2]"
},{
  "Name": "__mye157507_myl85_92",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl85_93",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157569_xformed___mye156445dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153575_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153571zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153584_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/input_quantizer/QuantizeLinear_output_0'.1_89",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl85_94",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/input_quantizer/QuantizeLinear_output_0'.1_89",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157573_xformed___mye156450dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153602_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153598zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153611_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/Add_output_0'.1_90",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/MatMul_myl85_95",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/Add_output_0'.1_90",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156455dconst",
    "Dimensions": [1,256,4],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153618_dconst",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153625zero_beta",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_dec_bbox_head_1_layers_2_bias _ ONNXTRT_Broadcast_948_constantFloat",
    "Dimensions": [1,1,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_91",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add]"
},{
  "Name": "__myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouConCas_myl85_96",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_61",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_91",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye156667",
    "Dimensions": [1,300,12],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158003_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_93",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_92",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouConCas_0xa06819df43d11e9f71ec4d6314dfc9b2",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/Log_1]\u001f[ONNX Layer: /model/decoder/decoder/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid_2]\u001f[ONNX Layer: /model/decoder/decoder/Div_1]\u001f[ONNX Layer: /model/decoder/decoder/Sub_1]\u001f[ONNX Layer: /model/decoder/decoder/Clip_3]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl85_97",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_92",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156683_dconst",
    "Dimensions": [1,16,512],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153640_dconst",
    "Dimensions": [1,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153636zero_beta",
    "Dimensions": [1,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153649_dconst",
    "Dimensions": [1,1,512],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1_94",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act_2/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/Add]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_98",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1_94",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156465dconst",
    "Dimensions": [1,512,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153656_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153663zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150169_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/Add]"
},{
  "Name": "__myl_Add_myl85_99",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Add_0xfcef7142c0478fafffb74a07ab8ea30f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/Add]"
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_100",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye156470dconst",
    "Dimensions": [2,256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149759/model/decoder/decoder/layers_2/self_attn/MatMul_1_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149760/model/decoder/decoder/layers_2/self_attn/MatMul_1_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye155396_dconst",
    "Dimensions": [2,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye153894",
    "Dimensions": [2,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add]"
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_101",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye153894",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153894",
    "Dimensions": [8,32,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153157",
    "Dimensions": [1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149794/model/decoder/decoder/layers_2/self_attn/MatMul_3_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_98",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Mul_1]"
},{
  "Name": "__myl_MaxSubExpSumDivMul_myl85_102",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_98",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_98",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_4_output_0'.1_99",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxSubExpSumDivMul_0x4bb1dc97991e61c47e3d11f2b659751f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Softmax]"
},{
  "Name": "__mye157509_myl85_103",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_104",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_4_output_0'.1_99",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149804/model/decoder/decoder/layers_2/self_attn/MatMul_4_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149805/model/decoder/decoder/layers_2/self_attn/MatMul_4_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_100",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_4]"
},{
  "Name": "__myl_Tra_myl85_105",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_100",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Transpose_5 _ /model/decoder/decoder/layers_2/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,8,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Tra_0xbff89681337b526d248c0838f5d94e94",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Transpose_5]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Reshape_3]"
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/Gemm_myl85_106",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Transpose_5 _ /model/decoder/decoder/layers_2/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150185_dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149818/model/decoder/decoder/layers_2/self_attn/Gemm_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye149819/model/decoder/decoder/layers_2/self_attn/Gemm_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_2_self_attn_out_proj_bias _ ONNXTRT_Broadcast_993_constantFloat",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Gemm_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Gemm]"
},{
  "Name": "__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_107",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye152665_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye152655_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158064_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_104",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_0x2ee8fbc8ddb7baf5b46cceba6a86227b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/norm1/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_FcMulAdd_myl85_108",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__mye153861_dconst",
    "Dimensions": [1,288],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153843_dconst",
    "Dimensions": [1,288],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156475dconst",
    "Dimensions": [1,256,288],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153820_dconst",
    "Dimensions": [1,1,288],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye153870mul_beta",
    "Dimensions": [1,300,288],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add]"
},{
  "Name": "__mye157511_myl85_109",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye157513_myl85_110",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "__myl_ResMaxSubExpSum_myl85_111",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye153870mul_beta",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_107",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_106",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ResMaxSubExpSum_0x7c7453772a39d1d1294358f10a1e770b",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]"
},{
  "Name": "__mye157515_myl85_112",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_113",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_93",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150530_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150530_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150530_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye154083",
    "Dimensions": [1,8400,8,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150550_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150550_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150550_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150550_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150540_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150540_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150540_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150540_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150530_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19620",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150530_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19635",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150530_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19650",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150530_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19665",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150530_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19844",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150540_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19859",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150540_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19874",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150540_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye19889",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150540_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye20068",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150550_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye20083",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150550_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye20098",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150550_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye20113",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150550_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150525_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158011_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150535_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158011_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150545_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158011_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150635",
    "Dimensions": [1,1,1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150631",
    "Dimensions": [1,1,1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150190_dconst",
    "Dimensions": [1,1,1,12,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153870mul_beta",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_110",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_109",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_108",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_0xc0b46290445cedee2db7e5baf77a0f2e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Sub]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_1]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Split]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_7]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_8]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8]"
},{
  "Name": "__mye157517_myl85_114",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_115",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_106",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158077_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_109",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_108",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_110",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_107",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye150966_q8",
    "Dimensions": [8,32,300,1],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_DivMulTraResConMulSumMulMinMaxRouCas_0xfdc36321684ce402a67e9cc028ee3fea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_2]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_9]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Concat_10]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/ReduceSum]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_Mov_myl85_116",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye150966_q8",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_112",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_Mov_0xccd11d8190e5ec819f0de6935e8e6ebe",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]"
},{
  "Name": "__myl_FcAdd_myl85_117",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_104",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_112",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye155438_dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153689_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153696zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_2_cross_attn_output_proj_bias _ ONNXTRT_Broadcast_1217_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_113",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/Add_3]"
},{
  "Name": "__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_118",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye152620_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye152610_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158081_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_113",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_115",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_0x7374e3706e69002aff2a29c077287875",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/norm2/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_2/linear1/MatMul_myl85_119",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157577_xformed___mye156480dconst",
    "Dimensions": [1,256,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153711_dconst",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153707zero_beta",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153720_dconst",
    "Dimensions": [1,1,1024],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_116",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/linear1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/activation/Relu]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/Add]"
},{
  "Name": "__myl_FcAdd_myl85_120",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_115",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_116",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156485dconst",
    "Dimensions": [1,1024,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153727_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153734zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_2_linear2_bias _ ONNXTRT_Broadcast_1239_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_117",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/linear2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/Add_4]"
},{
  "Name": "__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_121",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye152584_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye158085_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye152578_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_117",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0x3f53c92c8e85fb99f9934c06da28da1c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye157519_myl85_122",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye157521_myl85_123",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/dec_score_head_2/MatMul_myl85_124",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156490dconst",
    "Dimensions": [1,256,80],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153738_dconst",
    "Dimensions": [1,80],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153745zero_beta",
    "Dimensions": [1,80],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_dec_score_head_2_bias _ ONNXTRT_Broadcast_1287_constantFloat",
    "Dimensions": [1,1,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_score_head_2/Add_output_0'.1",
    "Dimensions": [1,300,80],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_score_head.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_score_head.2/Add]"
},{
  "Name": "__myl_GatResNegExpAddDivRes_myl85_125",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_score_head_2/Add_output_0'.1",
    "Dimensions": [1,1,300,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_120",
    "Dimensions": [1,24000],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_GatResNegExpAddDivRes_0x1d563258c32f843400fb4233ccab3fa6",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /postprocessor/Sigmoid]\u001f[ONNX Layer: /postprocessor/Flatten]\u001f[ONNX Layer: /model/decoder/Gather_8]"
},{
  "Name": "__myl_Top_myl85_126",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_120",
    "Dimensions": [1,24000],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "scores",
    "Dimensions": [1,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_122",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  }],
  "TacticName": "__myl_Top_0x1c85ccd1fad109f046189f0d3e8dff44",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /postprocessor/TopK]"
},{
  "Name": "__mye157523_myl85_127",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl85_128",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157581_xformed___mye156495dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153760_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153756zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153769_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/input_quantizer/QuantizeLinear_output_0'.1_123",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl85_129",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/input_quantizer/QuantizeLinear_output_0'.1_123",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye157585_xformed___mye156500dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153787_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153783zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153796_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/Add_output_0'.1_124",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/MatMul_myl85_130",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/Add_output_0'.1_124",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye156505dconst",
    "Dimensions": [1,256,4],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye153803_dconst",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye153810zero_beta",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_dec_bbox_head_2_layers_2_bias _ ONNXTRT_Broadcast_1269_constantFloat",
    "Dimensions": [1,1,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_125",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add]"
},{
  "Name": "__mye157525_myl85_131",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_myl85_132",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "orig_target_sizes",
    "Dimensions": [1,2],
    "Format/Datatype": "Int64"
  },
  {
    "Name": "__myln_k_arg__bb1_122",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye150647",
    "Dimensions": [1,1],
    "Format/Datatype": "Int64"
  },
  {
    "Name": "__mye150651",
    "Dimensions": [1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye150655",
    "Dimensions": [1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_125",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_93",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "labels",
    "Dimensions": [1,300],
    "Format/Datatype": "Int64"
  },
  {
    "Name": "boxes",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_0x046287ea34a14bdbbd780dcf069cdb4a",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: Cast_3039]\u001f[ONNX Layer: /model/decoder/decoder/Clip_6]\u001f[ONNX Layer: /model/decoder/decoder/Sub_2]\u001f[ONNX Layer: /model/decoder/decoder/Div_2]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid_3]\u001f[ONNX Layer: /model/decoder/Gather_9]\u001f[ONNX Layer: /model/decoder/decoder/Unsqueeze_3]\u001f[ONNX Layer: /model/decoder/decoder/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/Log_2]\u001f[ONNX Layer: /postprocessor/Split]\u001f[ONNX Layer: /postprocessor/Squeeze_1]\u001f[ONNX Layer: /postprocessor/Squeeze_2]\u001f[ONNX Layer: /postprocessor/Mul]\u001f[ONNX Layer: /postprocessor/Add]\u001f[ONNX Layer: /postprocessor/Unsqueeze_2]\u001f[ONNX Layer: /postprocessor/Sub]\u001f[ONNX Layer: /postprocessor/Unsqueeze]\u001f[ONNX Layer: /postprocessor/Concat]\u001f[ONNX Layer: /postprocessor/Mul_2]\u001f[ONNX Layer: /postprocessor/GatherElements]\u001f[ONNX Layer: /postprocessor/Unsqueeze_5]\u001f[ONNX Layer: /postprocessor/Unsqueeze_3]\u001f[ONNX Layer: /postprocessor/Add_1]\u001f[ONNX Layer: /postprocessor/Squeeze]\u001f[ONNX Layer: /postprocessor/Unsqueeze_1]\u001f[ONNX Layer: /postprocessor/Sub_1]\u001f[ONNX Layer: /postprocessor/Mul_1]\u001f[ONNX Layer: /postprocessor/Squeeze_3]\u001f[ONNX Layer: /postprocessor/Mul_3]\u001f[ONNX Layer: /postprocessor/Sub_2]\u001f[ONNX Layer: /postprocessor/Div]\u001f[ONNX Layer: /postprocessor/Unsqueeze_4]\u001f[ONNX Layer: /postprocessor/Tile]"
}],
"Bindings": ["images"
,"orig_target_sizes"
,"labels"
,"boxes"
,"scores"
]}
