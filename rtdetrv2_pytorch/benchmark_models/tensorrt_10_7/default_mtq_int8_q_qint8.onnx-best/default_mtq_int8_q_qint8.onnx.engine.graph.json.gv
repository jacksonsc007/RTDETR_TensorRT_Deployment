digraph {
	"__myln_k_arg__bb1_7.0" [label="[1, 6400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_7]
	"__myln_k_arg__bb1_7.1" [label="[1, 6400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_7]
	"__myln_k_arg__bb1_11.0" [label="[1, 8400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_11]
	"__myln_k_arg__bb1_11.1" [label="[1, 8400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_11]
	"__myln_k_arg__bb1_10.0" [label="[1, 1600, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_10]
	"__myln_k_arg__bb1_10.1" [label="[1, 1600, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_10]
	"__myln_k_arg__bb1_15.0" [label="[1, 8400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_15]
	"__myln_k_arg__bb1_15.1" [label="[1, 8400, 256]\nInt8" color="#76b900" fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_15]
	"__myln_k_arg__bb1_14.0" [label="[1, 8400, 256]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_14]
	"__myln_k_arg__bb1_14.1" [label="[1, 8400, 256]\nFloat" color=red fontname=Helvetica penwidth=3 shape=rectangle style=dashed tooltip=__myln_k_arg__bb1_14]
	scores [label="scores
[1, 300]\nFloat" color=red fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=scores]
	labels [label="labels
[1, 300]\nInt64" color=gray fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=labels]
	boxes [label="boxes
[1, 300, 4]\nFloat" color=red fillcolor=gray fontname=Helvetica penwidth=3 shape=rectangle style=filled tooltip=boxes]
	"/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00899023 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00672858 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 32}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_1/conv/Conv]+[ONNX Layer: /model/backbone/conv1/conv1_1/norm/BatchNormalization]+[ONNX Layer: /model/backbone/conv1/conv1_1/act/Relu]+[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv\nOutMaps:32\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_first_layer_i8i8_i8i32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_vect_c_32_tilesize8x16x32x32_stage1_warpsize4x1x1_tensor16x8x16_r3s3_u2v2_aligna4_alignc8\nTacticValue:0x5cc792a989a1d1a6\nWeights:{'Type': 'Int8', 'Count': 864}\n"]
	"model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0121664 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 32}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_2/conv/Conv]+[ONNX Layer: /model/backbone/conv1/conv1_2/norm/BatchNormalization]+[ONNX Layer: /model/backbone/conv1/conv1_2/act/Relu]+[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv\nOutMaps:32\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3\nTacticValue:0x13463e9bf9ae0d73\nWeights:{'Type': 'Int8', 'Count': 9216}\n"]
	"model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0126788 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_3/conv/Conv]+[ONNX Layer: /model/backbone/conv1/conv1_3/norm/BatchNormalization]+[ONNX Layer: /model/backbone/conv1/conv1_3/act/Relu]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x9dafb2758560cc1d\nWeights:{'Type': 'Int8', 'Count': 18432}\n"]
	"/model/backbone/MaxPool" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Pooling</b></TD></TR><TR><TD>0.0075222 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/MaxPool]</TD></TR></TABLE>> color=lightgray fillcolor="#3CB371" fontname=Helvetica shape=Mrecord style=filled tooltip="AverageCountExcludesPadding:1\nBlendFactor:0\nLayerType:CaskPooling\nMetadata:[ONNX Layer: /model/backbone/MaxPool]\nName:/model/backbone/MaxPool\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPoolingType:MAX\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nStreamId:0\nStride:[2, 2]\nTacticName:sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX\nTacticValue:0x94215b398b8eb3ba\nWindowSize:[3, 3]\n"]
	"model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00833572 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x9dafb2758560cc1d\nWeights:{'Type': 'Int8', 'Count': 36864}\n"]
	"model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0122094 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xe2bc5a4963d23ad0\nWeights:{'Type': 'Int8', 'Count': 36864}\n"]
	"model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00767197 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.0/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/Add]+[ONNX Layer: /model/backbone/res_layers.0/blocks.0/act/Relu]\nName:model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x1cfa820c55616892\nWeights:{'Type': 'Int8', 'Count': 4096}\n"]
	"/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00571606 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00833819 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x9dafb2758560cc1d\nWeights:{'Type': 'Int8', 'Count': 36864}\n"]
	"model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0109391 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.0/blocks.1/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 64}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/Add]+[ONNX Layer: /model/backbone/res_layers.0/blocks.1/act/Relu]\nName:model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu\nOutMaps:64\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xe2bc5a4963d23ad0\nWeights:{'Type': 'Int8', 'Count': 36864}\n"]
	"/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00566776 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Pooling</b></TD></TR><TR><TD>0.00411133 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#3CB371" fontname=Helvetica shape=Mrecord style=filled tooltip="AverageCountExcludesPadding:0\nBlendFactor:0\nLayerType:CaskPooling\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool\nPaddingMode:kEXPLICIT_ROUND_UP\nPoolingType:AVERAGE\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nStreamId:0\nStride:[2, 2]\nTacticName:sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE\nTacticValue:0xd9375d43b61ffbcb\nWindowSize:[2, 2]\n"]
	"model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0080263 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x705baf38e41eee0b\nWeights:{'Type': 'Int8', 'Count': 73728}\n"]
	"model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00932439 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x4133eb8759ee0d6d\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00595386 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.0/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/Add]+[ONNX Layer: /model/backbone/res_layers.1/blocks.0/act/Relu]\nName:model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x8e1dd2962c589dd4\nWeights:{'Type': 'Int8', 'Count': 8192}\n"]
	"/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00554324 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0086185 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x128x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x214f03e23f252333\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0100813 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.1/blocks.1/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/Add]+[ONNX Layer: /model/backbone/res_layers.1/blocks.1/act/Relu]\nName:model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x4133eb8759ee0d6d\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00576067 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Pooling</b></TD></TR><TR><TD>0.00481571 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#3CB371" fontname=Helvetica shape=Mrecord style=filled tooltip="AverageCountExcludesPadding:0\nBlendFactor:0\nLayerType:CaskPooling\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool\nPaddingMode:kEXPLICIT_ROUND_UP\nPoolingType:AVERAGE\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nStreamId:0\nStride:[2, 2]\nTacticName:sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE\nTacticValue:0xd9375d43b61ffbcb\nWindowSize:[2, 2]\n"]
	"model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00841351 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xbb88763c3b0e94d4\nWeights:{'Type': 'Int8', 'Count': 294912}\n"]
	"model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0103716 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xad6872a374321f7e\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00634208 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/Add]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/act/Relu]\nName:model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x8e1dd2962c589dd4\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00532983 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00975711 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xbb88763c3b0e94d4\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0102978 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.1/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/Add]+[ONNX Layer: /model/backbone/res_layers.2/blocks.1/act/Relu]\nName:model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xad6872a374321f7e\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.0055062 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x00000000000003ea\n"]
	"/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Pooling</b></TD></TR><TR><TD>0.00491724 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#3CB371" fontname=Helvetica shape=Mrecord style=filled tooltip="AverageCountExcludesPadding:0\nBlendFactor:0\nLayerType:CaskPooling\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool\nPaddingMode:kEXPLICIT_ROUND_UP\nPoolingType:AVERAGE\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nStreamId:0\nStride:[2, 2]\nTacticName:sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE\nTacticValue:0xd9375d43b61ffbcb\nWindowSize:[2, 2]\n"]
	"model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00981923 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32\nTacticValue:0x322f337abc345152\nWeights:{'Type': 'Int8', 'Count': 1179648}\n"]
	"model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0129862 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xc5159665a920f22c\nWeights:{'Type': 'Int8', 'Count': 2359296}\n"]
	"model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00629728 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/Add]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/act/Relu]\nName:model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1\nTacticValue:0x4f8662a723b489e1\nWeights:{'Type': 'Int8', 'Count': 131072}\n"]
	"/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00641664 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]\nName:/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0146042 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]\nName:model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x64x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu\nTacticValue:0x1d53511430a5d47e\nWeights:{'Type': 'Int8', 'Count': 2359296}\n"]
	"model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0134215 ms</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.1/act/Relu]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:RELU\nBias:{'Type': 'Float', 'Count': 512}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:1\nHasResidual:1\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/Add]+[ONNX Layer: /model/backbone/res_layers.3/blocks.1/act/Relu]\nName:model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu\nOutMaps:512\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xc5159665a920f22c\nWeights:{'Type': 'Int8', 'Count': 2359296}\n"]
	"/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.0064355 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear]\nName:/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00629537 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 0}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:0\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/input_proj.2/conv/Conv]+[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x7524377e24bc511f\nWeights:{'Type': 'Int8', 'Count': 131072}\n"]
	"Reformatting CopyNode for Input Tensor 0 to {ForeignNode[onnx######MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00488312 ms</TD></TR><TR><TD>Reformatting CopyNode for Input Tensor 0 to ForeignNode[onnx::MatMul_3620 </TD></TR><TR><TD> ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 </TD></TR><TR><TD> /model/encoder/Reshape_1]</TD></TR><TR><TD>REFORMAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:\nName:Reformatting CopyNode for Input Tensor 0 to {ForeignNode[onnx::MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}\nOrigin:REFORMAT\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	dummy_shape_call__mye8926_0_myl38_0 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>shape_call</b></TD></TR><TR><TD>0.00102401 ms</TD></TR><TR><TD>dummy_shape_call__mye8926_0_myl38_0</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:shape_call\nMetadata:\nName:dummy_shape_call__mye8926_0_myl38_0\nStreamId:0\nTacticName:\n"]
	__myl_MulAddResMovTraAddTra_myl38_1 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Transpose]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/input_proj.2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/Reshape]+[ONNX Layer: /model/encoder/encoder.0/layers.0/Add]+[ONNX Layer: /model/encoder/Transpose]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1]\nName:__myl_MulAddResMovTraAddTra_myl38_1\nStreamId:0\nTacticName:__myl_MulAddResMovTraAddTra_0xf4d05087139b538178007bf6bb80a08a\n"]
	__mye8859_myl38_3 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye8859_myl38_3</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:wait\nMetadata:\nName:__mye8859_myl38_3\nStreamId:1\nTacticName:\n"]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl38_4" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_2]\nName:/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl38_4\nStreamId:1\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16\n"]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_6" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00649599 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_1]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add]\nName:/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_6\nStreamId:0\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16\n"]
	_gemm_mha_v2_myl38_8 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00819156 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Mul_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Softmax]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Mul_1]\nName:_gemm_mha_v2_myl38_8\nStreamId:0\nTacticName:_gemm_mha_v2_0xb49a52fc0767aa7be96106641036114d\n"]
	__myl_Tra_myl38_9 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5]+[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3]\nName:__myl_Tra_myl38_9\nStreamId:0\nTacticName:__myl_Tra_0xb89fdb3500b2782dfe651a509d523a76\n"]
	"/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl38_10" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00649502 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Gemm]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Gemm]\nName:/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl38_10\nStreamId:0\nTacticName:sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16\n"]
	__myl_AddCasMeaSubMulMeaAddSqrDivMulCasMulAddCasMulMinMaxRouCas_myl38_11 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_1]+[ONNX Layer: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear]\nName:__myl_AddCasMeaSubMulMeaAddSqrDivMulCasMulAddCasMulMinMaxRouCas_myl38_11\nStreamId:0\nTacticName:__myl_AddCasMeaSubMulMeaAddSqrDivMulCasMulAddCasMulMinMaxRouCas_0x67d6d88e10867297ea489fcf1246e2e4\n"]
	"/model/encoder/encoder_0/layers_0/linear1/MatMul_myl38_12" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00819107 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Div]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Erf]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/MatMul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul_1]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Add]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Div]+[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Erf]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/Add]\nName:/model/encoder/encoder_0/layers_0/linear1/MatMul_myl38_12\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_gelu_erf\n"]
	"/model/encoder/encoder_0/layers_0/linear2/MatMul_myl38_13" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614343 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]\nName:/model/encoder/encoder_0/layers_0/linear2/MatMul_myl38_13\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_CasAddAddCasMeaSubMulMea_myl38_14 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]+[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]+[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_2]\nName:__myl_CasAddAddCasMeaSubMulMea_myl38_14\nStreamId:0\nTacticName:__myl_CasAddAddCasMeaSubMulMea_0x49f50938e3a06c933ca11aab5f20134c\n"]
	__myl_AddSqrDivMulCasMulAddTraRes_myl38_15 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Transpose_1]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Reshape_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]+[ONNX Layer: /model/encoder/Transpose_1]+[ONNX Layer: /model/encoder/Reshape_1]\nName:__myl_AddSqrDivMulCasMulAddTraRes_myl38_15\nStreamId:0\nTacticName:__myl_AddSqrDivMulCasMulAddTraRes_0xd61c74fd4ab12b19fae354ddcd6de65d\n"]
	"model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00722501 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.0/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/input_proj.0/conv/Conv]+[ONNX Layer: /model/encoder/input_proj.0/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x483ad1560c6e5e27\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00643287 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/input_proj.1/conv/Conv]+[ONNX Layer: /model/encoder/input_proj.1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x483ad1560c6e5e27\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00762433 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear]\nName:/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear\nOrigin:QDQ\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00540968 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.0/conv/Conv]+[ONNX Layer: /model/encoder/lateral_convs.0/norm/BatchNormalization]+[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x7524377e24bc511f\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00387055 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.0/act/Mul]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/lateral_convs.0/act/Sigmoid]+[ONNX Layer: /model/encoder/lateral_convs.0/act/Mul]\nName:PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)\nNbInputArgs:1\nNbLiterals:5\nNbOperations:5\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);']\nOutputVars:['var4']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x0000000000000018\n"]
	"/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00524045 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\nName:/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0\nOrigin:QDQ\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"/model/encoder/Resize" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Resize</b></TD></TR><TR><TD>0.00446301 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Resize]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="CoordTransform:kASYMMETRIC\nCubicCoeff:-0.75\nExcludeOutside:0\nInterpolationMode:NEAREST\nLayerType:Resize\nMetadata:[ONNX Layer: /model/encoder/Resize]\nNNRounding:kFLOOR\nName:/model/encoder/Resize\nResizeScales:[1, 1, 2, 2, 0, 0, 0, 0]\nResizeSelector:kFORMULA\nStreamId:0\nTacticValue:0x0000000000000003\n"]
	"/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00416254 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Concat_2]</TD></TR><TR><TD>CONCAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/Concat_2]\nName:/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy\nOrigin:CONCAT\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00637856 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x8e1dd2962c589dd4\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00643983 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00805 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0x6176c23707257237\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00806058 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0x6176c23707257237\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00780179 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xad6872a374321f7e\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00482759 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0', 'arg1']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f', '0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.0/Add]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]\nName:PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))\nNbInputArgs:2\nNbLiterals:10\nNbOperations:11\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);', 'auto const var5 = pwgen::iMul(literal9, arg1);', 'auto const var6 = pwgen::iTanh(var5);', 'auto const var7 = pwgen::iMul(var6, literal9);', 'auto const var8 = pwgen::iPlus(var7, literal9);', 'auto const var9 = pwgen::iMul(arg1, var8);', 'auto const var10 = pwgen::iPlus(var4, var9);']\nOutputVars:['var10']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x0000000000000018\n"]
	"model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00607224 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Mul]+[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00624638 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.1/conv/Conv]+[ONNX Layer: /model/encoder/lateral_convs.1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/lateral_convs.1/act/Sigmoid]+[ONNX Layer: /model/encoder/lateral_convs.1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"/model/encoder/Resize_1" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Resize</b></TD></TR><TR><TD>0.00489992 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Resize_1]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="CoordTransform:kASYMMETRIC\nCubicCoeff:-0.75\nExcludeOutside:0\nInterpolationMode:NEAREST\nLayerType:Resize\nMetadata:[ONNX Layer: /model/encoder/Resize_1]\nNNRounding:kFLOOR\nName:/model/encoder/Resize_1\nResizeScales:[1, 1, 2, 2, 0, 0, 0, 0]\nResizeSelector:kFORMULA\nStreamId:0\nTacticValue:0x0000000000000005\n"]
	"/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00534319 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Concat_3]</TD></TR><TR><TD>CONCAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/Concat_3]\nName:/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy\nOrigin:CONCAT\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00831667 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x758f8b2079a95b2e\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00878259 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x458f02d2b10db57c\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.010688 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xfdf7509af98902e0\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00956653 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xfdf7509af98902e0\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00971635 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x4133eb8759ee0d6d\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00667123 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0', 'arg1']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f', '0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Mul]+[ONNX Layer: /model/encoder/fpn_blocks.1/Add]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]\nName:PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))\nNbInputArgs:2\nNbLiterals:10\nNbOperations:11\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);', 'auto const var5 = pwgen::iMul(literal9, arg1);', 'auto const var6 = pwgen::iTanh(var5);', 'auto const var7 = pwgen::iMul(var6, literal9);', 'auto const var8 = pwgen::iPlus(var7, literal9);', 'auto const var9 = pwgen::iMul(arg1, var8);', 'auto const var10 = pwgen::iPlus(var4, var9);']\nOutputVars:['var10']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x000000000000001f\n"]
	"model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0120788 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/Conv]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Mul]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x65a38dbc9e991257\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0126483 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 0}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:0\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/input_proj.0/conv/Conv]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]\nName:model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4\nTacticValue:0x733ba2a91a48d431\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0112214 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/Conv]+[ONNX Layer: /model/encoder/downsample_convs.0/norm/BatchNormalization]+[ONNX Layer: /model/encoder/downsample_convs.0/act/Sigmoid]+[ONNX Layer: /model/encoder/downsample_convs.0/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc722efd60bc6ea84\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"/model/encoder/Resize_1_output_0 copy" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00409866 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/Concat_4]</TD></TR><TR><TD>CONCAT</TD></TR></TABLE>> color=lightgray fillcolor="#00FFFF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/Concat_4]\nName:/model/encoder/Resize_1_output_0 copy\nOrigin:CONCAT\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0063974 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x8e1dd2962c589dd4\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00675419 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00783969 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0x6176c23707257237\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00793426 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0x6176c23707257237\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00780648 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0xad6872a374321f7e\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00482966 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0', 'arg1']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f', '0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.0/Add]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]\nName:PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))\nNbInputArgs:2\nNbLiterals:10\nNbOperations:11\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);', 'auto const var5 = pwgen::iMul(literal9, arg1);', 'auto const var6 = pwgen::iTanh(var5);', 'auto const var7 = pwgen::iMul(var6, literal9);', 'auto const var8 = pwgen::iPlus(var7, literal9);', 'auto const var9 = pwgen::iMul(arg1, var8);', 'auto const var10 = pwgen::iPlus(var4, var9);']\nOutputVars:['var10']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x0000000000000018\n"]
	"model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00609117 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Mul]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0x2eba0b6a8ec55fa3\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00811614 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 0}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:0\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/input_proj.1/conv/Conv]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]\nName:model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4\nTacticValue:0x733ba2a91a48d431\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00919975 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/Conv]+[ONNX Layer: /model/encoder/downsample_convs.1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/downsample_convs.1/act/Sigmoid]+[ONNX Layer: /model/encoder/downsample_convs.1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[2, 2]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc985777c89c6b3a4\nWeights:{'Type': 'Int8', 'Count': 589824}\n"]
	"/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Reformat</b></TD></TR><TR><TD>0.00529128 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>QDQ</TD></TR></TABLE>> color=lightgray fillcolor="#6B8E23" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:Reformat\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\nName:/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1\nOrigin:QDQ\nStreamId:0\nTacticValue:0x0000000000000000\n"]
	"model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.0062023 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\nTacticValue:0x7524377e24bc511f\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00597263 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0xc6cdb1e47323bb01\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	"model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00687372 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc985777c89c6b3a4\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00663216 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish\nTacticValue:0xc985777c89c6b3a4\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00744194 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 128}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[3, 3]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv\nOutMaps:128\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[1, 1]\nPrePadding:[1, 1]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3\nTacticValue:0x51a916d02de43689\nWeights:{'Type': 'Int8', 'Count': 147456}\n"]
	"PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>PointWise</b></TD></TR><TR><TD>0.00402909 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/Add]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#9ACD32" fontname=Helvetica shape=Mrecord style=filled tooltip="InputArgs:['arg0', 'arg1']\nLayerType:PointWiseV2\nLiterals:['0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f', '0.000000e+00f', '1.000000e+00f', '0.000000e+00f', '0.000000e+00f', '5.000000e-01f']\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Mul]+[ONNX Layer: /model/encoder/pan_blocks.1/Add]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]\nName:PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))\nNbInputArgs:2\nNbLiterals:10\nNbOperations:11\nNbOutputVars:1\nNbParams:0\nOperations:['auto const var0 = pwgen::iMul(literal4, arg0);', 'auto const var1 = pwgen::iTanh(var0);', 'auto const var2 = pwgen::iMul(var1, literal4);', 'auto const var3 = pwgen::iPlus(var2, literal4);', 'auto const var4 = pwgen::iMul(arg0, var3);', 'auto const var5 = pwgen::iMul(literal9, arg1);', 'auto const var6 = pwgen::iTanh(var5);', 'auto const var7 = pwgen::iMul(var6, literal9);', 'auto const var8 = pwgen::iPlus(var7, literal9);', 'auto const var9 = pwgen::iMul(arg1, var8);', 'auto const var10 = pwgen::iPlus(var4, var9);']\nOutputVars:['var10']\nParameterSubType:PointWiseExpression\nParams:[]\nStreamId:0\nTacticValue:0x0000000000000018\n"]
	"model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00539851 ms</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:SWISH\nBias:{'Type': 'Float', 'Count': 256}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:1\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/Conv]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Sigmoid]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Mul]+[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]\nName:model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish\nTacticValue:0xc6cdb1e47323bb01\nWeights:{'Type': 'Int8', 'Count': 32768}\n"]
	"model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>Convolution</b></TD></TR><TR><TD>0.00757048 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/Conv]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#4682B4" fontname=Helvetica shape=Mrecord style=filled tooltip="Activation:NONE\nBias:{'Type': 'Float', 'Count': 0}\nBiasAsActInputIdx:-1\nConvXAsActInputIdx:-1\nDilation:[1, 1]\nGroups:1\nHasBias:0\nHasDynamicBias:0\nHasDynamicFilter:0\nHasReLU:0\nHasResidual:0\nHasSparseWeights:0\nKernel:[1, 1]\nLayerType:CaskConvolution\nMetadata:[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/input_proj.2/conv/Conv]+[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]\nName:model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv\nOutMaps:256\nPaddingMode:kEXPLICIT_ROUND_DOWN\nPostPadding:[0, 0]\nPrePadding:[0, 0]\nResAsActInputIdx:-1\nStreamId:0\nStride:[1, 1]\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4\nTacticValue:0x5e4f6d7c83746fd6\nWeights:{'Type': 'Int8', 'Count': 65536}\n"]
	dummy_shape_call__mye158089_0_myl85_0 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>shape_call</b></TD></TR><TR><TD>0.00102401 ms</TD></TR><TR><TD>dummy_shape_call__mye158089_0_myl85_0</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:shape_call\nMetadata:\nName:dummy_shape_call__mye158089_0_myl85_0\nStreamId:0\nTacticName:\n"]
	"entry^bb^wait^1_myl85_2" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>entry^bb^wait^1_myl85_2</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:wait\nMetadata:\nName:entry^bb^wait^1_myl85_2\nStreamId:1\nTacticName:\n"]
	__myl_MulAddResMulMinMaxRouCasTra_myl85_3 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0102395 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.0/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/input_proj.0/norm/BatchNormalization]+[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Reshape]+[ONNX Layer: /model/decoder/Transpose]\nName:__myl_MulAddResMulMinMaxRouCasTra_myl85_3\nStreamId:0\nTacticName:__myl_MulAddResMulMinMaxRouCasTra_0xb7911a963641d99b9b7644b75b6b02a0\n"]
	__myl_MulMinMaxRouCasResTra_myl85_4 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Reshape]+[ONNX Layer: /model/decoder/Transpose]\nName:__myl_MulMinMaxRouCasResTra_myl85_4\nStreamId:0\nTacticName:__myl_MulMinMaxRouCasResTra_0x53ec280dcdcbc7be42089db5a99e26ce\n"]
	__myl_MulAddResMulMinMaxRouCasTra_myl85_5 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0102395 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.1/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/input_proj.1/norm/BatchNormalization]+[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Reshape_1]+[ONNX Layer: /model/decoder/Transpose_1]\nName:__myl_MulAddResMulMinMaxRouCasTra_myl85_5\nStreamId:1\nTacticName:__myl_MulAddResMulMinMaxRouCasTra_0xc7826108fa2ff5e34bf8bfa07dbc52f7\n"]
	__myl_MulMinMaxRouCasResTra_myl85_6 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose_1]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Reshape_1]+[ONNX Layer: /model/decoder/Transpose_1]\nName:__myl_MulMinMaxRouCasResTra_myl85_6\nStreamId:1\nTacticName:__myl_MulMinMaxRouCasResTra_0x8592f20b4eb6c9ee9a9e56f44ec5871e\n"]
	__mye157457_myl85_8 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye157457_myl85_8</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:wait\nMetadata:\nName:__mye157457_myl85_8\nStreamId:0\nTacticName:\n"]
	__myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_myl85_9 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0104955 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/input_proj.2/norm/BatchNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Concat_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Reshape_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Transpose_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/input_proj.2/norm/BatchNormalization]+[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/Concat_3]+[ONNX Layer: /model/decoder/Reshape_2]+[ONNX Layer: /model/decoder/Transpose_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]\nName:__myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_myl85_9\nStreamId:0\nTacticName:__myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_0x14d97ab92d57b85a1bd3815e99f6e152\n"]
	__mye157461_myl85_11 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye157461_myl85_11</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:wait\nMetadata:\nName:__mye157461_myl85_11\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_12" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0337888 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add]\nName:/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_12\nStreamId:1\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32\n"]
	"/model/decoder/enc_output/proj/MatMul_myl85_13" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0163836 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/enc_output/proj/MatMul]+[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_output/proj/Add]\nName:/model/decoder/enc_output/proj/MatMul_myl85_13\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32\n"]
	__myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_14 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0153589 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_output/norm/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/enc_output/norm/LayerNormalization]+[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear]\nName:__myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_14\nStreamId:0\nTacticName:__myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0xf1c80ff651c1b506b1815818d6281ad3\n"]
	__mye157465_myl85_16 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye157465_myl85_16</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:wait\nMetadata:\nName:__mye157465_myl85_16\nStreamId:1\nTacticName:\n"]
	"/model/decoder/enc_score_head/MatMul_myl85_17" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0163836 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/enc_score_head/MatMul]+[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_score_head/Add]\nName:/model/decoder/enc_score_head/MatMul_myl85_17\nStreamId:1\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32\n"]
	__myl_Max_myl85_18 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00614435 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/ReduceMax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/ReduceMax]\nName:__myl_Max_myl85_18\nStreamId:1\nTacticName:__myl_Max_0x4330a02939b906fc5f8c1bd769456467\n"]
	__myl_Top_myl85_19 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0358394 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/TopK]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/TopK]\nName:__myl_Top_myl85_19\nStreamId:1\nTacticName:__myl_Top_0x7e62297dffa2e596ee60049838a70f81\n"]
	"/model/decoder/enc_bbox_head/layers_0/MatMul_myl85_21" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0102405 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/MatMul]+[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/act/Relu]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/Add]\nName:/model/decoder/enc_bbox_head/layers_0/MatMul_myl85_21\nStreamId:0\nTacticName:sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize32x32_stage4_warpsize2x4x1_r1s1_u1v1_hw1_c256_scalebias_relu\n"]
	"/model/decoder/enc_bbox_head/layers_1/MatMul_myl85_22" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.0112637 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/MatMul]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/act_1/Relu]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/Add]\nName:/model/decoder/enc_bbox_head/layers_1/MatMul_myl85_22\nStreamId:0\nTacticName:sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize32x32_stage4_warpsize2x4x1_r1s1_u1v1_hw1_c256_scalebias_relu\n"]
	__myl_FcAdd_myl85_23 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00819156 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/MatMul]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/Add]+[ONNX Layer: /model/decoder/Add]\nName:__myl_FcAdd_myl85_23\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_myl85_25 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Unsqueeze]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/GatherElements]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/Unsqueeze]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/Sigmoid]+[ONNX Layer: /model/decoder/GatherElements]\nName:__myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_myl85_25\nStreamId:0\nTacticName:__myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_0xea994e8a02766a6b87cc77a0ab1bb663\n"]
	__myl_MovCon_myl85_26 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]\nName:__myl_MovCon_myl85_26\nStreamId:0\nTacticName:__myl_MovCon_0x9482c2d60923b5d68d1030431d0b6d2e\n"]
	"/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl85_27" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614346 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]\nName:/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl85_27\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	"/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_28" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614343 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/Add]\nName:/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_28\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_RepGatResAdd_myl85_29 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409522 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/GatherElements_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/GatherElements_1]+[ONNX Layer: /model/decoder/decoder/layers.0/Add]\nName:__myl_RepGatResAdd_myl85_29\nStreamId:0\nTacticName:__myl_RepGatResAdd_0x3585782c9d9cf8f0d2b18744e46affde\n"]
	__mye157473_myl85_31 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye157473_myl85_31</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:wait\nMetadata:\nName:__mye157473_myl85_31\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl85_32" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00921517 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_2]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_2]\nName:/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl85_32\nStreamId:1\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_34" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00921469 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_1]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add]\nName:/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_34\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8\n"]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_35" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00751942 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Mul_1]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_3]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Mul_1]\nName:/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_35\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8\n"]
	__myl_MaxSubExpSumDivMul_myl85_36 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Softmax]\nName:__myl_MaxSubExpSumDivMul_myl85_36\nStreamId:0\nTacticName:__myl_MaxSubExpSumDivMul_0x4bb1dc97991e61c47e3d11f2b659751f\n"]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_38" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00716739 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_4]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_4]\nName:/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_38\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	__myl_Tra_myl85_39 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Transpose_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Reshape_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Transpose_5]+[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Reshape_3]\nName:__myl_Tra_myl85_39\nStreamId:0\nTacticName:__myl_Tra_0xbff89681337b526d248c0838f5d94e94\n"]
	"/model/decoder/decoder/layers_0/self_attn/Gemm_myl85_40" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Gemm]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Gemm]\nName:/model/decoder/decoder/layers_0/self_attn/Gemm_myl85_40\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	__myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_41 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511903 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/norm1/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.0/norm1/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.0/Add_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]\nName:__myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_41\nStreamId:0\nTacticName:__myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_0x91b2c7046943674462a660380f1917c4\n"]
	__myl_FcMulAdd_myl85_42 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/attention_weights/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/Add]\nName:__myl_FcMulAdd_myl85_42\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__mye157481_myl85_44 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye157481_myl85_44</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:wait\nMetadata:\nName:__mye157481_myl85_44\nStreamId:1\nTacticName:\n"]
	__myl_ResMaxSubExpSum_myl85_45 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00308414 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]\nName:__myl_ResMaxSubExpSum_myl85_45\nStreamId:1\nTacticName:__myl_ResMaxSubExpSum_0x7c7453772a39d1d1294358f10a1e770b\n"]
	__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_47 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0348803 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Sub]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Split]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_7]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_8]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Sub]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_5]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_6]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Split]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_4]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_4]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_5]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_6]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_6]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_7]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_8]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_1]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Unsqueeze_8]\nName:__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_47\nStreamId:0\nTacticName:__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_0x3718754d33237a7346a050fa256f2cc0\n"]
	__myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_49 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00633605 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_9]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Concat_10]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/ReduceSum]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_8]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_2]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_9]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Concat_10]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/ReduceSum]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_8]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear]\nName:__myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_49\nStreamId:0\nTacticName:__myl_DivMulTraResConMulSumMulMinMaxRouCas_0xfdc36321684ce402a67e9cc028ee3fea\n"]
	__myl_Mov_myl85_50 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00518358 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]\nName:__myl_Mov_myl85_50\nStreamId:0\nTacticName:__myl_Mov_0xccd11d8190e5ec819f0de6935e8e6ebe\n"]
	__myl_FcAdd_myl85_51 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00521539 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add_3]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/Add_3]\nName:__myl_FcAdd_myl85_51\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_52 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/norm2/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear]\nName:__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_52\nStreamId:0\nTacticName:__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_0x7374e3706e69002aff2a29c077287875\n"]
	"/model/decoder/decoder/layers_0/linear1/MatMul_myl85_53" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/activation/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/linear1/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/activation/Relu]+[ONNX Layer: /model/decoder/decoder/layers.0/linear1/Add]\nName:/model/decoder/decoder/layers_0/linear1/MatMul_myl85_53\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	__myl_FcAdd_myl85_54 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00547198 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/linear2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/Add_4]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/linear2/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.0/linear2/Add]+[ONNX Layer: /model/decoder/decoder/layers.0/Add_4]\nName:__myl_FcAdd_myl85_54\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_55 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear]\nName:__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_55\nStreamId:0\nTacticName:__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0x4e14cc44ca088d44748af6a96514ac7a\n"]
	__mye157489_myl85_57 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye157489_myl85_57</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:wait\nMetadata:\nName:__mye157489_myl85_57\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl85_58" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00716739 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_2]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_2]\nName:/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl85_58\nStreamId:1\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	"/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl85_60" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614288 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add]\nName:/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl85_60\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	"/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl85_61" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add]\nName:/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl85_61\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	"/model/decoder/decoder/dec_bbox_head_0/layers_2/MatMul_myl85_62" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add]\nName:/model/decoder/decoder/dec_bbox_head_0/layers_2/MatMul_myl85_62\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_MaxMinMaxSubMinMaxMinDivLogResAddNegExpAddDivMulMinMaxRouConCas_myl85_63 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00323193 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Log]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sigmoid_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Div]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sub]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Clip]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/Log]+[ONNX Layer: /model/decoder/decoder/Sigmoid_1]+[ONNX Layer: /model/decoder/decoder/Add]+[ONNX Layer: /model/decoder/decoder/Div]+[ONNX Layer: /model/decoder/decoder/Sub]+[ONNX Layer: /model/decoder/decoder/Clip]\nName:__myl_MaxMinMaxSubMinMaxMinDivLogResAddNegExpAddDivMulMinMaxRouConCas_myl85_63\nStreamId:0\nTacticName:__myl_MaxMinMaxSubMinMaxMinDivLogResAddNegExpAddDivMulMinMaxRouConCas_0xefac8e563c6580f9cd110df4750663ce\n"]
	"/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl85_64" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511956 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/act_1/Relu]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/Add]\nName:/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl85_64\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	"/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_65" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00512001 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/Add]\nName:/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_65\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_Add_myl85_66 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00307164 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/Add]\nName:__myl_Add_myl85_66\nStreamId:0\nTacticName:__myl_Add_0xfcef7142c0478fafffb74a07ab8ea30f\n"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_67" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00819107 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_1]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add]\nName:/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_67\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8\n"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_68" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00716745 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Mul_1]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_3]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Mul_1]\nName:/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_68\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8\n"]
	__myl_MaxSubExpSumDivMul_myl85_69 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00512001 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Softmax]\nName:__myl_MaxSubExpSumDivMul_myl85_69\nStreamId:0\nTacticName:__myl_MaxSubExpSumDivMul_0x4bb1dc97991e61c47e3d11f2b659751f\n"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_71" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00601591 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_4]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_4]\nName:/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_71\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	__myl_Tra_myl85_72 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511871 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Transpose_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Reshape_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Transpose_5]+[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Reshape_3]\nName:__myl_Tra_myl85_72\nStreamId:0\nTacticName:__myl_Tra_0xbff89681337b526d248c0838f5d94e94\n"]
	"/model/decoder/decoder/layers_1/self_attn/Gemm_myl85_73" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614386 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Gemm]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Gemm]\nName:/model/decoder/decoder/layers_1/self_attn/Gemm_myl85_73\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_74 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/norm1/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.1/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.1/norm1/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.1/Add_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]\nName:__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_74\nStreamId:0\nTacticName:__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_0x2ee8fbc8ddb7baf5b46cceba6a86227b\n"]
	__myl_FcMulAdd_myl85_75 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/attention_weights/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/Add]\nName:__myl_FcMulAdd_myl85_75\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__mye157497_myl85_77 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye157497_myl85_77</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:wait\nMetadata:\nName:__mye157497_myl85_77\nStreamId:1\nTacticName:\n"]
	__myl_ResMaxSubExpSum_myl85_78 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00410726 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]\nName:__myl_ResMaxSubExpSum_myl85_78\nStreamId:1\nTacticName:__myl_ResMaxSubExpSum_0x7c7453772a39d1d1294358f10a1e770b\n"]
	__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_80 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0337913 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Sub]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Split]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_7]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_8]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Sub]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_5]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_3]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Split]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_4]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_4]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_5]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_6]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_6]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_7]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_8]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_1]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Unsqueeze_8]\nName:__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_80\nStreamId:0\nTacticName:__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_0xc0b46290445cedee2db7e5baf77a0f2e\n"]
	__myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_82 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00614386 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_9]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Concat_10]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/ReduceSum]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_2]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_9]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Concat_10]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/ReduceSum]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_5]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear]\nName:__myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_82\nStreamId:0\nTacticName:__myl_DivMulTraResConMulSumMulMinMaxRouCas_0xfdc36321684ce402a67e9cc028ee3fea\n"]
	__myl_Mov_myl85_83 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511903 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]\nName:__myl_Mov_myl85_83\nStreamId:0\nTacticName:__myl_Mov_0xccd11d8190e5ec819f0de6935e8e6ebe\n"]
	__myl_FcAdd_myl85_84 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614288 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add_3]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/Add_3]\nName:__myl_FcAdd_myl85_84\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_85 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00431996 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/norm2/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear]\nName:__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_85\nStreamId:0\nTacticName:__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_0x7374e3706e69002aff2a29c077287875\n"]
	"/model/decoder/decoder/layers_1/linear1/MatMul_myl85_86" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614288 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/activation/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/linear1/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/activation/Relu]+[ONNX Layer: /model/decoder/decoder/layers.1/linear1/Add]\nName:/model/decoder/decoder/layers_1/linear1/MatMul_myl85_86\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	__myl_FcAdd_myl85_87 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/linear2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/Add_4]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/linear2/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.1/linear2/Add]+[ONNX Layer: /model/decoder/decoder/layers.1/Add_4]\nName:__myl_FcAdd_myl85_87\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_88 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00415946 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear]\nName:__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_88\nStreamId:0\nTacticName:__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0x4e14cc44ca088d44748af6a96514ac7a\n"]
	__mye157505_myl85_90 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye157505_myl85_90</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:wait\nMetadata:\nName:__mye157505_myl85_90\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl85_91" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00716739 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_2]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_2]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_2]\nName:/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl85_91\nStreamId:1\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	"/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl85_93" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add]\nName:/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl85_93\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	"/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl85_94" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add]\nName:/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl85_94\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	"/model/decoder/decoder/dec_bbox_head_1/layers_2/MatMul_myl85_95" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add]\nName:/model/decoder/decoder/dec_bbox_head_1/layers_2/MatMul_myl85_95\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouConCas_myl85_96 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Log_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sigmoid_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Div_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sub_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Clip_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/Log_1]+[ONNX Layer: /model/decoder/decoder/Add_1]+[ONNX Layer: /model/decoder/decoder/Sigmoid_2]+[ONNX Layer: /model/decoder/decoder/Div_1]+[ONNX Layer: /model/decoder/decoder/Sub_1]+[ONNX Layer: /model/decoder/decoder/Clip_3]\nName:__myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouConCas_myl85_96\nStreamId:0\nTacticName:__myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouConCas_0xa06819df43d11e9f71ec4d6314dfc9b2\n"]
	"/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl85_97" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00512001 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/act_2/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/act_2/Relu]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/Add]\nName:/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl85_97\nStreamId:0\nTacticName:sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	"/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_98" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511972 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/Add]\nName:/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_98\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_Add_myl85_99 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409554 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/Add]\nName:__myl_Add_myl85_99\nStreamId:0\nTacticName:__myl_Add_0xfcef7142c0478fafffb74a07ab8ea30f\n"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_100" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00630378 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_1]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add]\nName:/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_100\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x32x64_stage4_warpsize2x2x1_tensor16x8x8\n"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_101" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614435 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Mul_1]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_3]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Mul_1]\nName:/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_101\nStreamId:0\nTacticName:sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8\n"]
	__myl_MaxSubExpSumDivMul_myl85_102 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00512001 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Softmax]\nName:__myl_MaxSubExpSumDivMul_myl85_102\nStreamId:0\nTacticName:__myl_MaxSubExpSumDivMul_0x4bb1dc97991e61c47e3d11f2b659751f\n"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_104" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00716739 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_4]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_4]\nName:/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_104\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	__myl_Tra_myl85_105 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409555 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Transpose_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Reshape_3]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Transpose_5]+[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Reshape_3]\nName:__myl_Tra_myl85_105\nStreamId:0\nTacticName:__myl_Tra_0xbff89681337b526d248c0838f5d94e94\n"]
	"/model/decoder/decoder/layers_2/self_attn/Gemm_myl85_106" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614337 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Gemm]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Gemm]\nName:/model/decoder/decoder/layers_2/self_attn/Gemm_myl85_106\nStreamId:0\nTacticName:sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8\n"]
	__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_107 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00511952 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/norm1/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.2/Add_1]+[ONNX Layer: /model/decoder/decoder/layers.2/norm1/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.2/Add_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]\nName:__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_107\nStreamId:0\nTacticName:__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_0x2ee8fbc8ddb7baf5b46cceba6a86227b\n"]
	__myl_FcMulAdd_myl85_108 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.00518407 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/attention_weights/Add]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/Add]\nName:__myl_FcMulAdd_myl85_108\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__mye157513_myl85_110 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye157513_myl85_110</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:wait\nMetadata:\nName:__mye157513_myl85_110\nStreamId:1\nTacticName:\n"]
	__myl_ResMaxSubExpSum_myl85_111 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00410775 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]\nName:__myl_ResMaxSubExpSum_myl85_111\nStreamId:1\nTacticName:__myl_ResMaxSubExpSum_0x7c7453772a39d1d1294358f10a1e770b\n"]
	__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_113 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0348161 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Sub]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Split]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_4]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_7]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_8]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_1]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Sub]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_5]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_3]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Add]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Split]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_4]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_4]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_5]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_6]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_6]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_7]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_8]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_1]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Unsqueeze_8]\nName:__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_113\nStreamId:0\nTacticName:__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_0xc0b46290445cedee2db7e5baf77a0f2e\n"]
	__myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_115 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00575981 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_9]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Concat_10]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/ReduceSum]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_5]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_2]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_9]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Concat_10]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/ReduceSum]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_5]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear]\nName:__myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_115\nStreamId:0\nTacticName:__myl_DivMulTraResConMulSumMulMinMaxRouCas_0xfdc36321684ce402a67e9cc028ee3fea\n"]
	__myl_Mov_myl85_116 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]\nName:__myl_Mov_myl85_116\nStreamId:0\nTacticName:__myl_Mov_0xccd11d8190e5ec819f0de6935e8e6ebe\n"]
	__myl_FcAdd_myl85_117 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.0044159 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add_3]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]+[ONNX Layer: /model/decoder/decoder/layers.2/Add_3]\nName:__myl_FcAdd_myl85_117\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_118 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00415992 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/norm2/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/norm2/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear]\nName:__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_118\nStreamId:0\nTacticName:__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_0x7374e3706e69002aff2a29c077287875\n"]
	"/model/decoder/decoder/layers_2/linear1/MatMul_myl85_119" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00511958 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/activation/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/linear1/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/activation/Relu]+[ONNX Layer: /model/decoder/decoder/layers.2/linear1/Add]\nName:/model/decoder/decoder/layers_2/linear1/MatMul_myl85_119\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	__myl_FcAdd_myl85_120 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>fusion</b></TD></TR><TR><TD>0.0064639 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/linear2/Add]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/Add_4]</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:fusion\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/linear2/MatMul]+[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/layers.2/linear2/Add]+[ONNX Layer: /model/decoder/decoder/layers.2/Add_4]\nName:__myl_FcAdd_myl85_120\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic\n"]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_121 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00451172 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/layers.2/norm3/LayerNormalization]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /model/decoder/decoder/layers.2/norm3/LayerNormalization]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear]\nName:__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_121\nStreamId:0\nTacticName:__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0x3f53c92c8e85fb99f9934c06da28da1c\n"]
	__mye157521_myl85_123 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>wait</b></TD></TR><TR><TD>__mye157521_myl85_123</TD></TR></TABLE>> color=lightgray fillcolor=gray fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:wait\nMetadata:\nName:__mye157521_myl85_123\nStreamId:1\nTacticName:\n"]
	"/model/decoder/decoder/dec_score_head_2/MatMul_myl85_124" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00512049 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_score_head.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_score_head.2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_score_head.2/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_score_head.2/Add]\nName:/model/decoder/decoder/dec_score_head_2/MatMul_myl85_124\nStreamId:1\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_GatResNegExpAddDivRes_myl85_125 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Sigmoid]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Flatten]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Gather_8]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /postprocessor/Sigmoid]+[ONNX Layer: /postprocessor/Flatten]+[ONNX Layer: /model/decoder/Gather_8]\nName:__myl_GatResNegExpAddDivRes_myl85_125\nStreamId:1\nTacticName:__myl_GatResNegExpAddDivRes_0x1d563258c32f843400fb4233ccab3fa6\n"]
	__myl_Top_myl85_126 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0788477 ms</TD></TR><TR><TD>[ONNX Layer: /postprocessor/TopK]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: /postprocessor/TopK]\nName:__myl_Top_myl85_126\nStreamId:1\nTacticName:__myl_Top_0x1c85ccd1fad109f046189f0d3e8dff44\n"]
	"/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl85_128" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00614288 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add]\nName:/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl85_128\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	"/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl85_129" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00512001 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add]\nName:/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl85_129\nStreamId:0\nTacticName:sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1\n"]
	"/model/decoder/decoder/dec_bbox_head_2/layers_2/MatMul_myl85_130" [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>gemm</b></TD></TR><TR><TD>0.00409603 ms</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add]</TD></TR></TABLE>> color=lightgray fillcolor="#1E90FF" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:gemm\nMetadata:[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear]+[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add]\nName:/model/decoder/decoder/dec_bbox_head_2/layers_2/MatMul_myl85_130\nStreamId:0\nTacticName:sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32\n"]
	__myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_myl85_132 [label=<
            <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4" color="transparent">"<TR><TD><b>kgen</b></TD></TR><TR><TD>0.0040959 ms</TD></TR><TR><TD>[ONNX Layer: Cast_3039]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Clip_6]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sub_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Div_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Sigmoid_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/Gather_9]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Unsqueeze_3]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Add_2]</TD></TR><TR><TD>[ONNX Layer: /model/decoder/decoder/Log_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Split]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Squeeze_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Squeeze_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Mul]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Add]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Sub]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Concat]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Mul_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/GatherElements]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_5]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_3]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Add_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Squeeze]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Sub_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Mul_1]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Squeeze_3]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Mul_3]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Sub_2]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Div]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Unsqueeze_4]</TD></TR><TR><TD>[ONNX Layer: /postprocessor/Tile]</TD></TR></TABLE>> color=lightgray fillcolor="#B39C4D" fontname=Helvetica shape=Mrecord style=filled tooltip="LayerType:kgen\nMetadata:[ONNX Layer: Cast_3039]+[ONNX Layer: /model/decoder/decoder/Clip_6]+[ONNX Layer: /model/decoder/decoder/Sub_2]+[ONNX Layer: /model/decoder/decoder/Div_2]+[ONNX Layer: /model/decoder/decoder/Sigmoid_3]+[ONNX Layer: /model/decoder/Gather_9]+[ONNX Layer: /model/decoder/decoder/Unsqueeze_3]+[ONNX Layer: /model/decoder/decoder/Add_2]+[ONNX Layer: /model/decoder/decoder/Log_2]+[ONNX Layer: /postprocessor/Split]+[ONNX Layer: /postprocessor/Squeeze_1]+[ONNX Layer: /postprocessor/Squeeze_2]+[ONNX Layer: /postprocessor/Mul]+[ONNX Layer: /postprocessor/Add]+[ONNX Layer: /postprocessor/Unsqueeze_2]+[ONNX Layer: /postprocessor/Sub]+[ONNX Layer: /postprocessor/Unsqueeze]+[ONNX Layer: /postprocessor/Concat]+[ONNX Layer: /postprocessor/Mul_2]+[ONNX Layer: /postprocessor/GatherElements]+[ONNX Layer: /postprocessor/Unsqueeze_5]+[ONNX Layer: /postprocessor/Unsqueeze_3]+[ONNX Layer: /postprocessor/Add_1]+[ONNX Layer: /postprocessor/Squeeze]+[ONNX Layer: /postprocessor/Unsqueeze_1]+[ONNX Layer: /postprocessor/Sub_1]+[ONNX Layer: /postprocessor/Mul_1]+[ONNX Layer: /postprocessor/Squeeze_3]+[ONNX Layer: /postprocessor/Mul_3]+[ONNX Layer: /postprocessor/Sub_2]+[ONNX Layer: /postprocessor/Div]+[ONNX Layer: /postprocessor/Unsqueeze_4]+[ONNX Layer: /postprocessor/Tile]\nName:__myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_myl85_132\nStreamId:0\nTacticName:__myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_0x046287ea34a14bdbbd780dcf069cdb4a\n"]
	"/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear" -> "model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv" [label="[1, 3, 640, 640]\nInt8 NC/4HW4" color="#76b900"]
	"model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv" -> "model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv" [label="[1, 32, 320, 320]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv" -> "model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv" [label="[1, 32, 320, 320]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv" -> "/model/backbone/MaxPool" [label="[1, 64, 320, 320]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/MaxPool" -> "model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/MaxPool" -> "model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv" -> "model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv" -> "model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" [label="[1, 64, 160, 160]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" -> "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 64, 160, 160]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu" -> "model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu" [label="[1, 64, 160, 160]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv" -> "model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu" -> "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 64, 160, 160]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv" [label="[1, 64, 160, 160]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool" -> "model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" [label="[1, 64, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv" -> "model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv" -> "model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" [label="[1, 128, 80, 80]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" -> "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 128, 80, 80]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu" -> "model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu" [label="[1, 128, 80, 80]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv" -> "model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu" -> "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 128, 80, 80]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool" -> "model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv" -> "model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv" -> "model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" [label="[1, 256, 40, 40]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" -> "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 256, 40, 40]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu" -> "model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu" [label="[1, 256, 40, 40]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv" -> "model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu" -> "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 256, 40, 40]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool" -> "model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" [label="[1, 256, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv" -> "model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv" -> "model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" [label="[1, 512, 20, 20]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" -> "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" [label="[1, 512, 20, 20]\nFP16 NC/32HW32" color=orange]
	"model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu" -> "model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu" [label="[1, 512, 20, 20]\nFP16 NC/32HW32" color=orange]
	"/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear" -> "model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv" -> "model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu" -> "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear" [label="[1, 512, 20, 20]\nFP16 NC/32HW32" color=orange]
	"/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear" -> "model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv" -> "Reformatting CopyNode for Input Tensor 0 to {ForeignNode[onnx######MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}" [label="[1, 256, 20, 20]\nFP16 NC/32HW32" color=orange]
	"Reformatting CopyNode for Input Tensor 0 to {ForeignNode[onnx######MatMul_3620 + ONNXTRT_Broadcast_101.../model/encoder/Transpose_1 + /model/encoder/Reshape_1]}" -> __myl_MulAddResMovTraAddTra_myl38_1 [label="[1, 256, 20, 20]\nFP16 NHWC8" color=orange]
	__myl_MulAddResMovTraAddTra_myl38_1 -> "/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl38_4" [label="[400, 1, 256]\nHalf" color=orange]
	__myl_MulAddResMovTraAddTra_myl38_1 -> __myl_AddCasMeaSubMulMeaAddSqrDivMulCasMulAddCasMulMinMaxRouCas_myl38_11 [label="[1, 400, 256]\nHalf" color=orange]
	__myl_MulAddResMovTraAddTra_myl38_1 -> "/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_6" [label="[1, 400, 256]\nHalf" color=orange]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl38_4" -> _gemm_mha_v2_myl38_8 [label="[400, 256]\nHalf" color=orange]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_6" -> _gemm_mha_v2_myl38_8 [label="[2, 400, 256]\nHalf" color=orange]
	"/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl38_6" -> _gemm_mha_v2_myl38_8 [label="[2, 400, 256]\nHalf" color=orange]
	_gemm_mha_v2_myl38_8 -> "__myln_k_arg__bb1_7.0" [label="[1, 6400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_7.0" -> __myl_Tra_myl38_9 [label="[1, 6400, 256]\nInt8" color="#76b900"]
	__myl_MulMinMaxRouCasResTra_myl85_4 -> "__myln_k_arg__bb1_7.1" [label="[1, 6400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_7.1" -> __myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_myl85_9 [label="[1, 6400, 256]\nInt8" color="#76b900"]
	__myl_Tra_myl38_9 -> "/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl38_10" [label="[400, 8, 32]\nHalf" color=orange]
	"/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl38_10" -> __myl_AddCasMeaSubMulMeaAddSqrDivMulCasMulAddCasMulMinMaxRouCas_myl38_11 [label="[400, 256]\nHalf" color=orange]
	__myl_AddCasMeaSubMulMeaAddSqrDivMulCasMulAddCasMulMinMaxRouCas_myl38_11 -> "__myln_k_arg__bb1_11.0" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_11.0" -> __myl_CasAddAddCasMeaSubMulMea_myl38_14 [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_myl85_9 -> "__myln_k_arg__bb1_11.1" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_11.1" -> "/model/decoder/enc_output/proj/MatMul_myl85_13" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_AddCasMeaSubMulMeaAddSqrDivMulCasMulAddCasMulMinMaxRouCas_myl38_11 -> "__myln_k_arg__bb1_10.0" [label="[1, 1600, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_10.0" -> "/model/encoder/encoder_0/layers_0/linear1/MatMul_myl38_12" [label="[1, 1600, 256]\nInt8" color="#76b900"]
	__myl_MulMinMaxRouCasResTra_myl85_6 -> "__myln_k_arg__bb1_10.1" [label="[1, 1600, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_10.1" -> __myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_myl85_9 [label="[1, 1600, 256]\nInt8" color="#76b900"]
	"/model/encoder/encoder_0/layers_0/linear1/MatMul_myl38_12" -> "/model/encoder/encoder_0/layers_0/linear2/MatMul_myl38_13" [label="[1, 400, 1024]\nInt8" color="#76b900"]
	"/model/encoder/encoder_0/layers_0/linear2/MatMul_myl38_13" -> __myl_CasAddAddCasMeaSubMulMea_myl38_14 [label="[1, 400, 256]\nFloat" color=red]
	__myl_CasAddAddCasMeaSubMulMea_myl38_14 -> "__myln_k_arg__bb1_15.0" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_15.0" -> __myl_AddSqrDivMulCasMulAddTraRes_myl38_15 [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_14 -> "__myln_k_arg__bb1_15.1" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_15.1" -> "/model/decoder/enc_score_head/MatMul_myl85_17" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_15.1" -> "/model/decoder/enc_bbox_head/layers_0/MatMul_myl85_21" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_CasAddAddCasMeaSubMulMea_myl38_14 -> "__myln_k_arg__bb1_14.0" [label="[1, 8400, 256]\nFloat" color=red]
	"__myln_k_arg__bb1_14.0" -> __myl_AddSqrDivMulCasMulAddTraRes_myl38_15 [label="[1, 8400, 256]\nFloat" color=red]
	"/model/decoder/enc_output/proj/MatMul_myl85_13" -> "__myln_k_arg__bb1_14.1" [label="[1, 8400, 256]\nFloat" color=red]
	"__myln_k_arg__bb1_14.1" -> __myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_14 [label="[1, 8400, 256]\nFloat" color=red]
	"__myln_k_arg__bb1_14.1" -> __myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_14 [label="[1, 8400, 256]\nFloat" color=red]
	__myl_AddSqrDivMulCasMulAddTraRes_myl38_15 -> "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear" [label="[1, 256, 20, 20]\nHalf" color=orange]
	"model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv" -> "model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv" [label="[1, 512, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv" -> "model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)" [label="[1, 512, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy" -> "model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv" [label="[1, 512, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy" -> "model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)" [label="[1, 512, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv" -> "model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv" -> "model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy" -> "model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy" -> "model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear" -> "model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv" [label="[1, 256, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv" -> "PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)" [label="[1, 256, 20, 20]\nFP16 NC/32HW32" color=orange]
	"PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)" -> "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0" [label="[1, 256, 20, 20]\nFP16 NC/32HW32" color=orange]
	"PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)" -> "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1" [label="[1, 256, 20, 20]\nFP16 NC/32HW32" color=orange]
	"/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0" -> "/model/encoder/Resize" [label="[1, 256, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Resize" -> "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv" -> "PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))" [label="[1, 128, 40, 40]\nFP16 NC/32HW32" color=orange]
	"model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)" -> "model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" -> "model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" -> "model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" -> "PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))" [label="[1, 128, 40, 40]\nFP16 NC/32HW32" color=orange]
	"PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))" -> "model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)" -> "model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)" -> "/model/encoder/Resize_1" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)" -> "/model/encoder/Resize_1_output_0 copy" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Resize_1" -> "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy" [label="[1, 256, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv" -> "PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))" [label="[1, 128, 80, 80]\nFP16 NC/32HW32" color=orange]
	"model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)" -> "model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" -> "model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" -> "model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" -> "PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))" [label="[1, 128, 80, 80]\nFP16 NC/32HW32" color=orange]
	"PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))" -> "model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)" [label="[1, 128, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)" -> "model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv" [label="[1, 256, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)" -> "model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)" [label="[1, 256, 80, 80]\nInt8 NC/32HW32" color="#76b900"]
	"model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv" -> __myl_MulAddResMulMinMaxRouCasTra_myl85_3 [label="[1, 256, 80, 80]\nFP32 NCHW" color=red]
	"model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)" -> "model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)" -> "model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Resize_1_output_0 copy" -> "model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/Resize_1_output_0 copy" -> "model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)" [label="[1, 512, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv" -> "PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))" [label="[1, 128, 40, 40]\nFP16 NC/32HW32" color=orange]
	"model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)" -> "model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)" -> "model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)" -> "model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv" -> "PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))" [label="[1, 128, 40, 40]\nFP16 NC/32HW32" color=orange]
	"PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))" -> "model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)" [label="[1, 128, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)" -> "model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)" -> "model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)" [label="[1, 256, 40, 40]\nInt8 NC/32HW32" color="#76b900"]
	"model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv" -> __myl_MulAddResMulMinMaxRouCasTra_myl85_5 [label="[1, 256, 40, 40]\nFP32 NCHW" color=red]
	"model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)" -> "model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)" -> "model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1" -> "model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1" -> "model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)" [label="[1, 512, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv" -> "PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))" [label="[1, 128, 20, 20]\nFP16 NC/32HW32" color=orange]
	"model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)" -> "model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" [label="[1, 128, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)" -> "model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" [label="[1, 128, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)" -> "model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" [label="[1, 128, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv" -> "PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))" [label="[1, 128, 20, 20]\nFP16 NC/32HW32" color=orange]
	"PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))" -> "model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)" [label="[1, 128, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)" -> "model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv" [label="[1, 256, 20, 20]\nInt8 NC/32HW32" color="#76b900"]
	"model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv" -> __myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_myl85_9 [label="[1, 256, 20, 20]\nFP32 NCHW" color=red]
	__myl_MulAddResMulMinMaxRouCasTra_myl85_3 -> __myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_myl85_9 [label="[1, 6400, 256]\nInt8" color="#76b900"]
	__myl_MulAddResMulMinMaxRouCasTra_myl85_3 -> __myl_MulMinMaxRouCasResTra_myl85_4 [label="[1, 256, 80, 80]\nFloat" color=red]
	__myl_MulAddResMulMinMaxRouCasTra_myl85_5 -> __myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_myl85_9 [label="[1, 1600, 256]\nInt8" color="#76b900"]
	__myl_MulAddResMulMinMaxRouCasTra_myl85_5 -> __myl_MulMinMaxRouCasResTra_myl85_6 [label="[1, 256, 40, 40]\nFloat" color=red]
	__myl_MulAddMulMinMaxRouCasResResTraMulMinMaxRouCasTraConCon_myl85_9 -> "/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_12" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_12" -> __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_47 [label="[3, 8400, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_12" -> __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_80 [label="[3, 8400, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul+/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl85_12" -> __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_113 [label="[3, 8400, 256]\nFloat" color=red]
	__myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_14 -> __myl_RepGatResAdd_myl85_29 [label="[1, 8400, 256]\nFloat" color=red]
	"/model/decoder/enc_score_head/MatMul_myl85_17" -> __myl_Max_myl85_18 [label="[1, 8400, 80]\nFloat" color=red]
	__myl_Max_myl85_18 -> __myl_Top_myl85_19 [label="[1, 8400, 1]\nFloat" color=red]
	__myl_Top_myl85_19 -> __myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_myl85_25 [label="[1, 300]\nInt32" color=lightgray]
	"/model/decoder/enc_bbox_head/layers_0/MatMul_myl85_21" -> "/model/decoder/enc_bbox_head/layers_1/MatMul_myl85_22" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"/model/decoder/enc_bbox_head/layers_1/MatMul_myl85_22" -> __myl_FcAdd_myl85_23 [label="[1, 8400, 256]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_23 -> __myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_myl85_25 [label="[1, 8400, 4]\nFloat" color=red]
	__myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_myl85_25 -> __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_47 [label="[300, 4]\nFloat" color=red]
	__myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_myl85_25 -> __myl_MaxMinMaxSubMinMaxMinDivLogResAddNegExpAddDivMulMinMaxRouConCas_myl85_63 [label="[300, 4]\nFloat" color=red]
	__myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_myl85_25 -> __myl_MovCon_myl85_26 [label="[300, 4]\nInt8" color="#76b900"]
	__myl_CasResCasRepGatResNegExpAddDivMulMinMaxRouCas_myl85_25 -> __myl_RepGatResAdd_myl85_29 [label="[1, 300, 1]\nInt32" color=lightgray]
	__myl_MovCon_myl85_26 -> "/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl85_27" [label="[1, 300, 16]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl85_27" -> "/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_28" [label="[1, 300, 512]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_28" -> __myl_RepGatResAdd_myl85_29 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl85_28" -> __myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_41 [label="[1, 300, 256]\nFloat" color=red]
	__myl_RepGatResAdd_myl85_29 -> "/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_34" [label="[300, 256]\nFloat" color=red]
	__myl_RepGatResAdd_myl85_29 -> "/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl85_32" [label="[1, 300, 256]\nFloat" color=red]
	__myl_RepGatResAdd_myl85_29 -> __myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_41 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl85_32" -> "/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_38" [label="[300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_34" -> "/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_35" [label="[2, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl85_34" -> "/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_35" [label="[2, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_35" -> __myl_MaxSubExpSumDivMul_myl85_36 [label="[8, 300, 300]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl85_35" -> __myl_MaxSubExpSumDivMul_myl85_36 [label="[8, 300, 300]\nFloat" color=red]
	__myl_MaxSubExpSumDivMul_myl85_36 -> "/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_38" [label="[8, 300, 300]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl85_38" -> __myl_Tra_myl85_39 [label="[8, 300, 32]\nFloat" color=red]
	__myl_Tra_myl85_39 -> "/model/decoder/decoder/layers_0/self_attn/Gemm_myl85_40" [label="[300, 8, 32]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/self_attn/Gemm_myl85_40" -> __myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_41 [label="[300, 256]\nFloat" color=red]
	__myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_41 -> __myl_FcMulAdd_myl85_42 [label="[300, 256]\nInt8" color="#76b900"]
	__myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_41 -> __myl_FcAdd_myl85_51 [label="[1, 300, 256]\nFloat" color=red]
	__myl_FcMulAdd_myl85_42 -> __myl_ResMaxSubExpSum_myl85_45 [label="[1, 300, 288]\nFloat" color=red]
	__myl_FcMulAdd_myl85_42 -> __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_47 [label="[1, 300, 288]\nFloat" color=red]
	__myl_ResMaxSubExpSum_myl85_45 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_49 [label="[1, 300, 8, 12]\nFloat" color=red]
	__myl_ResMaxSubExpSum_myl85_45 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_49 [label="[1, 300, 8, 1]\nFloat" color=red]
	__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_47 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_49 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_47 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_49 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_47 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_49 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_49 -> __myl_Mov_myl85_50 [label="[8, 32, 300, 1]\nInt8" color="#76b900"]
	__myl_Mov_myl85_50 -> __myl_FcAdd_myl85_51 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_51 -> __myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_52 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_52 -> "/model/decoder/decoder/layers_0/linear1/MatMul_myl85_53" [label="[300, 256]\nInt8" color="#76b900"]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_52 -> __myl_FcAdd_myl85_54 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_0/linear1/MatMul_myl85_53" -> __myl_FcAdd_myl85_54 [label="[1, 300, 1024]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_54 -> __myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_55 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_55 -> "/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl85_58" [label="[300, 256]\nFloat" color=red]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_55 -> __myl_Add_myl85_66 [label="[300, 256]\nFloat" color=red]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_55 -> __myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_74 [label="[300, 256]\nFloat" color=red]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_55 -> "/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl85_60" [label="[300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl85_58" -> "/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_71" [label="[300, 256]\nFloat" color=red]
	"/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl85_60" -> "/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl85_61" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl85_61" -> "/model/decoder/decoder/dec_bbox_head_0/layers_2/MatMul_myl85_62" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_bbox_head_0/layers_2/MatMul_myl85_62" -> __myl_MaxMinMaxSubMinMaxMinDivLogResAddNegExpAddDivMulMinMaxRouConCas_myl85_63 [label="[1, 300, 4]\nFloat" color=red]
	__myl_MaxMinMaxSubMinMaxMinDivLogResAddNegExpAddDivMulMinMaxRouConCas_myl85_63 -> __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_80 [label="[1, 300, 4]\nFloat" color=red]
	__myl_MaxMinMaxSubMinMaxMinDivLogResAddNegExpAddDivMulMinMaxRouConCas_myl85_63 -> __myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouConCas_myl85_96 [label="[1, 300, 4]\nFloat" color=red]
	__myl_MaxMinMaxSubMinMaxMinDivLogResAddNegExpAddDivMulMinMaxRouConCas_myl85_63 -> "/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl85_64" [label="[1, 300, 16]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl85_64" -> "/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_65" [label="[1, 300, 512]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_65" -> __myl_Add_myl85_66 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl85_65" -> __myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_74 [label="[1, 300, 256]\nFloat" color=red]
	__myl_Add_myl85_66 -> "/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_67" [label="[300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_67" -> "/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_68" [label="[2, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl85_67" -> "/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_68" [label="[2, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_68" -> __myl_MaxSubExpSumDivMul_myl85_69 [label="[8, 300, 300]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl85_68" -> __myl_MaxSubExpSumDivMul_myl85_69 [label="[8, 300, 300]\nFloat" color=red]
	__myl_MaxSubExpSumDivMul_myl85_69 -> "/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_71" [label="[8, 300, 300]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl85_71" -> __myl_Tra_myl85_72 [label="[8, 300, 32]\nFloat" color=red]
	__myl_Tra_myl85_72 -> "/model/decoder/decoder/layers_1/self_attn/Gemm_myl85_73" [label="[300, 8, 32]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/self_attn/Gemm_myl85_73" -> __myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_74 [label="[300, 256]\nFloat" color=red]
	__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_74 -> __myl_FcMulAdd_myl85_75 [label="[300, 256]\nInt8" color="#76b900"]
	__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_74 -> __myl_FcAdd_myl85_84 [label="[1, 300, 256]\nFloat" color=red]
	__myl_FcMulAdd_myl85_75 -> __myl_ResMaxSubExpSum_myl85_78 [label="[1, 300, 288]\nFloat" color=red]
	__myl_FcMulAdd_myl85_75 -> __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_80 [label="[1, 300, 288]\nFloat" color=red]
	__myl_ResMaxSubExpSum_myl85_78 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_82 [label="[1, 300, 8, 12]\nFloat" color=red]
	__myl_ResMaxSubExpSum_myl85_78 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_82 [label="[1, 300, 8, 1]\nFloat" color=red]
	__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_80 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_82 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_80 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_82 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_80 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_82 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_82 -> __myl_Mov_myl85_83 [label="[8, 32, 300, 1]\nInt8" color="#76b900"]
	__myl_Mov_myl85_83 -> __myl_FcAdd_myl85_84 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_84 -> __myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_85 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_85 -> "/model/decoder/decoder/layers_1/linear1/MatMul_myl85_86" [label="[300, 256]\nInt8" color="#76b900"]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_85 -> __myl_FcAdd_myl85_87 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_1/linear1/MatMul_myl85_86" -> __myl_FcAdd_myl85_87 [label="[1, 300, 1024]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_87 -> __myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_88 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_88 -> "/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl85_91" [label="[300, 256]\nFloat" color=red]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_88 -> __myl_Add_myl85_99 [label="[300, 256]\nFloat" color=red]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_88 -> __myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_107 [label="[300, 256]\nFloat" color=red]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_88 -> "/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl85_93" [label="[300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl85_91" -> "/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_104" [label="[300, 256]\nFloat" color=red]
	"/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl85_93" -> "/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl85_94" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl85_94" -> "/model/decoder/decoder/dec_bbox_head_1/layers_2/MatMul_myl85_95" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_bbox_head_1/layers_2/MatMul_myl85_95" -> __myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouConCas_myl85_96 [label="[1, 300, 4]\nFloat" color=red]
	__myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouConCas_myl85_96 -> __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_113 [label="[1, 300, 4]\nFloat" color=red]
	__myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouConCas_myl85_96 -> __myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_myl85_132 [label="[1, 300, 4]\nFloat" color=red]
	__myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouConCas_myl85_96 -> "/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl85_97" [label="[1, 300, 16]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl85_97" -> "/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_98" [label="[1, 300, 512]\nInt8" color="#76b900"]
	"/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_98" -> __myl_Add_myl85_99 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl85_98" -> __myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_107 [label="[1, 300, 256]\nFloat" color=red]
	__myl_Add_myl85_99 -> "/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_100" [label="[300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_100" -> "/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_101" [label="[2, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl85_100" -> "/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_101" [label="[2, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_101" -> __myl_MaxSubExpSumDivMul_myl85_102 [label="[8, 300, 300]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl85_101" -> __myl_MaxSubExpSumDivMul_myl85_102 [label="[8, 300, 300]\nFloat" color=red]
	__myl_MaxSubExpSumDivMul_myl85_102 -> "/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_104" [label="[8, 300, 300]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl85_104" -> __myl_Tra_myl85_105 [label="[8, 300, 32]\nFloat" color=red]
	__myl_Tra_myl85_105 -> "/model/decoder/decoder/layers_2/self_attn/Gemm_myl85_106" [label="[300, 8, 32]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/self_attn/Gemm_myl85_106" -> __myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_107 [label="[300, 256]\nFloat" color=red]
	__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_107 -> __myl_FcMulAdd_myl85_108 [label="[300, 256]\nInt8" color="#76b900"]
	__myl_ResAddResMeaSubMulMeaAddSqrDivMulMulAddResAddMulMinMaxRouCas_myl85_107 -> __myl_FcAdd_myl85_117 [label="[1, 300, 256]\nFloat" color=red]
	__myl_FcMulAdd_myl85_108 -> __myl_ResMaxSubExpSum_myl85_111 [label="[1, 300, 288]\nFloat" color=red]
	__myl_FcMulAdd_myl85_108 -> __myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_113 [label="[1, 300, 288]\nFloat" color=red]
	__myl_ResMaxSubExpSum_myl85_111 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_115 [label="[1, 300, 8, 12]\nFloat" color=red]
	__myl_ResMaxSubExpSum_myl85_111 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_115 [label="[1, 300, 8, 1]\nFloat" color=red]
	__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_113 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_115 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_113 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_115 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_TraResSliResSliResSliResResSliSliResMulMulMulAddMulAddTraResSliRevTraAddMulAddMulFloCasSubEtc_myl85_113 -> __myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_115 [label="[8, 32, 300, 4]\nFloat" color=red]
	__myl_DivMulTraResConMulSumMulMinMaxRouCas_myl85_115 -> __myl_Mov_myl85_116 [label="[8, 32, 300, 1]\nInt8" color="#76b900"]
	__myl_Mov_myl85_116 -> __myl_FcAdd_myl85_117 [label="[1, 300, 256]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_117 -> __myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_118 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_118 -> "/model/decoder/decoder/layers_2/linear1/MatMul_myl85_119" [label="[300, 256]\nInt8" color="#76b900"]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl85_118 -> __myl_FcAdd_myl85_120 [label="[1, 300, 256]\nFloat" color=red]
	"/model/decoder/decoder/layers_2/linear1/MatMul_myl85_119" -> __myl_FcAdd_myl85_120 [label="[1, 300, 1024]\nInt8" color="#76b900"]
	__myl_FcAdd_myl85_120 -> __myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_121 [label="[1, 300, 256]\nFloat" color=red]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_121 -> "/model/decoder/decoder/dec_score_head_2/MatMul_myl85_124" [label="[300, 256]\nInt8" color="#76b900"]
	__myl_ResMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl85_121 -> "/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl85_128" [label="[300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_score_head_2/MatMul_myl85_124" -> __myl_GatResNegExpAddDivRes_myl85_125 [label="[1, 300, 80]\nFloat" color=red]
	__myl_GatResNegExpAddDivRes_myl85_125 -> __myl_Top_myl85_126 [label="[1, 24000]\nFloat" color=red]
	__myl_Top_myl85_126 -> scores [label="[1, 300]\nFloat" color=red]
	__myl_Top_myl85_126 -> __myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_myl85_132 [label="[1, 300]\nInt32" color=lightgray]
	"/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl85_128" -> "/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl85_129" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl85_129" -> "/model/decoder/decoder/dec_bbox_head_2/layers_2/MatMul_myl85_130" [label="[1, 300, 256]\nInt8" color="#76b900"]
	"/model/decoder/decoder/dec_bbox_head_2/layers_2/MatMul_myl85_130" -> __myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_myl85_132 [label="[1, 300, 4]\nFloat" color=red]
	__myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_myl85_132 -> labels [label="[1, 300]\nInt64" color=gray]
	__myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_myl85_132 -> boxes [label="[1, 300, 4]\nFloat" color=red]
	"__myln_k_arg__bb1_7.0" -> "__myln_k_arg__bb1_7.1" [label="[1, 6400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_11.0" -> "__myln_k_arg__bb1_11.1" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_10.0" -> "__myln_k_arg__bb1_10.1" [label="[1, 1600, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_15.0" -> "__myln_k_arg__bb1_15.1" [label="[1, 8400, 256]\nInt8" color="#76b900"]
	"__myln_k_arg__bb1_14.0" -> "__myln_k_arg__bb1_14.1" [label="[1, 8400, 256]\nFloat" color=red]
}
