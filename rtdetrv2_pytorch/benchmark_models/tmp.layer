{"Layers": [{
  "Name": "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "images",
    "Location": "Device",
    "Dimensions": [1,3,640,640],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,3,640,640],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.conv1.conv1_1.conv.weight + /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_1/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/conv1/conv1_1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,3,640,640],
    "Format/Datatype": "Four wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 864},
  "Bias": {"Type": "Float", "Count": 32},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_first_layer_i8i8_i8i32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_vect_c_32_tilesize8x16x32x32_stage1_warpsize4x1x1_tensor16x8x16_r3s3_u2v2_aligna4_alignc8",
  "TacticValue": "0x5cc792a989a1d1a6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/conv/Conv]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/act/Relu]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.conv1.conv1_2.conv.weight + /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/conv1/conv1_2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 9216},
  "Bias": {"Type": "Float", "Count": 32},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3",
  "TacticValue": "0x13463e9bf9ae0d73",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/Conv]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/act/Relu]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.conv1.conv1_3.conv.weight + /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear + /model/backbone/conv1/conv1_3/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/conv1/conv1_3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,32,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/MaxPool_output_0",
    "Location": "Device",
    "Dimensions": [1,64,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 18432},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x9dafb2758560cc1d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/Conv]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/conv1/conv1_3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/backbone/MaxPool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/MaxPool_output_0",
    "Location": "Device",
    "Dimensions": [1,64,320,320],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX",
  "TacticValue": "0x94215b398b8eb3ba",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/MaxPool]"
},{
  "Name": "model.backbone.res_layers.0.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x9dafb2758560cc1d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x64x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x23b890da05937b9e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.0.short.conv.weight + /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.0/short/conv/Conv + /model/backbone/res_layers.0/blocks.0/Add + /model/backbone/res_layers.0/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 4096},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x733ba2a91a48d431",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/short/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x256x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x9dafb2758560cc1d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.0.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.0/blocks.1/Add + /model/backbone/res_layers.0/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.0/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 36864},
  "Bias": {"Type": "Float", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x64x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_alignc4",
  "TacticValue": "0x23b890da05937b9e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.0/blocks.1/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.0/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/backbone/res_layers.1/blocks.0/short/pool/AveragePool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_UP",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 0,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE",
  "TacticValue": "0xd9375d43b61ffbcb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/pool/AveragePool]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,160,160],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 73728},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x705baf38e41eee0b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32",
  "TacticValue": "0x5f1a472d416ff35e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.1/blocks.0/Add + /model/backbone/res_layers.1/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,64,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 8192},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x128x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x214f03e23f252333",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.1.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.1/blocks.1/Add + /model/backbone/res_layers.1/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.1/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xad886d4d69834922",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.1/blocks.1/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.1/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/backbone/res_layers.2/blocks.0/short/pool/AveragePool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_UP",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 0,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE",
  "TacticValue": "0xd9375d43b61ffbcb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/pool/AveragePool]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 294912},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xbb88763c3b0e94d4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x2d8ab2aa0639fda9",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.2/blocks.0/Add + /model/backbone/res_layers.2/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xbb88763c3b0e94d4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.2.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.2/blocks.1/Add + /model/backbone/res_layers.2/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x2d8ab2aa0639fda9",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.1/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/backbone/res_layers.3/blocks.0/short/pool/AveragePool",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [2,2],
  "PaddingMode": "kEXPLICIT_ROUND_UP",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 0,
  "TacticName": "sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE",
  "TacticValue": "0xd9375d43b61ffbcb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/pool/AveragePool]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.0.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1179648},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32",
  "TacticValue": "0x322f337abc345152",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.0.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x45f7566cdb2b10fb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2b/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.0.short.conv.conv.weight + /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv + /model/backbone/res_layers.3/blocks.0/Add + /model/backbone/res_layers.3/blocks.0/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2b/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 131072},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x65fbe45b4cb1d8a5",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/short/conv/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/Add]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/act/Relu]"
},{
  "Name": "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.1.branch2a.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_avdt_dense_int8int8_tilesize64x64x32_tapsperload3_threadspercta128_r3s3_u1v1_scalebias_relu",
  "TacticValue": "0x1d53511430a5d47e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/act/Relu]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2a/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.backbone.res_layers.3.blocks.1.branch2b.conv.weight + /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear + /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv + /model/backbone/res_layers.3/blocks.1/Add + /model/backbone/res_layers.3/blocks.1/act/Relu",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  },
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0x45f7566cdb2b10fb",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/Conv]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/norm/BatchNormalization]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/branch2b/conv/weight_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/Add]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.1/act/Relu]"
},{
  "Name": "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.1/act/Relu_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003ea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.input_proj.2.conv.weight + /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/input_proj.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 131072},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x5e4f6d7c83746fd6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/input_proj.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "dummy_shape_call__mye9020_0_myl37_0",
  "LayerType": "shape_call",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_MulAddResTra_myl37_1",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/encoder/input_proj_2/norm/BatchNormalization/model/encoder/input_proj_2/norm/BatchNormalization_shift_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/encoder/input_proj.2/conv/Conv_output_0",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/encoder/input_proj_2/norm/BatchNormalization/model/encoder/input_proj_2/norm/BatchNormalization_scale_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_1_first_transpose_output.1",
    "Dimensions": [400,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_3",
    "Dimensions": [1,256,400],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MulAddResTra_0x862813689358e08ec79eab32f31fafdf",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.2/norm/BatchNormalization]\u001f[ONNX Layer: /model/encoder/Reshape]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_1]"
},{
  "Name": "__mye8937_myl37_2",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_TraAdd_myl37_3",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/Constant_output_0_constantFloat",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_3",
    "Dimensions": [1,256,400],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/Add_output_0'.1",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_5",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_TraAdd_0x5a9388c92c5b2a167638420a28fa3cf0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Transpose]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/Add]"
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_1+/model/encoder/encoder_0/layers_0/self_attn/MatMul_myl37_4",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/Add_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8769_dconst",
    "Dimensions": [2,256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8319/model/encoder/encoder_0/layers_0/self_attn/MatMul_1_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8320/model/encoder/encoder_0/layers_0/self_attn/MatMul_1_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8774_dconst",
    "Dimensions": [2,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye8684",
    "Dimensions": [2,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x32x64_stage4_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add]"
},{
  "Name": "__mye8939_myl37_5",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_myl37_6",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_1_first_transpose_output.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8387_dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8277/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8278/model/encoder/encoder_0/layers_0/self_attn/MatMul_2_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8606_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_2]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Add_2]"
},{
  "Name": "__mye8941_myl37_7",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_3_myl37_8",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye8684",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8684",
    "Dimensions": [8,32,400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8642",
    "Dimensions": [1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8333/model/encoder/encoder_0/layers_0/self_attn/MatMul_3_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [8,400,400],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_3]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Mul_1]"
},{
  "Name": "__myl_MaxSubExpSumDivMul_myl37_9",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [8,400,400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [8,400,400],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_output_0'.1_9",
    "Dimensions": [8,400,400],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxSubExpSumDivMul_0x486901888507314d28178a529899ff30",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Softmax]"
},{
  "Name": "__mye8943_myl37_10",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_myl37_11",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_output_0'.1_9",
    "Dimensions": [8,400,400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8343/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8344/model/encoder/encoder_0/layers_0/self_attn/MatMul_4_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/MatMul_4]"
},{
  "Name": "__myl_Tra_myl37_12",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [8,400,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_5 _ /model/encoder/encoder_0/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [400,8,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Tra_0x053154cc4b930530fcf23b0caf04c63a",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Transpose_5]\u001e[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Reshape_3]"
},{
  "Name": "/model/encoder/encoder_0/layers_0/self_attn/Gemm_myl37_13",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Transpose_5 _ /model/encoder/encoder_0/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8849dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8357/model/encoder/encoder_0/layers_0/self_attn/Gemm_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8358/model/encoder/encoder_0/layers_0/self_attn/Gemm_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_encoder_encoder_0_layers_0_self_attn_out_proj_bias _ ONNXTRT_Broadcast_240_constantFloat",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/self_attn/Gemm]"
},{
  "Name": "__myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_myl37_14",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye8585_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8575_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye9016_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_5",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/encoder/encoder_0/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddResMeaSubMulMeaAddSqrDivMulMulAddResMulMinMaxRouCas_0x81c6f38dc18b20647aef42cb9b16a94b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/norm1/LayerNormalization]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/encoder/encoder_0/layers_0/linear1/MatMul_myl37_15",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/encoder/encoder_0/layers_0/linear1/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye8854dconst",
    "Dimensions": [1,256,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye8646_dconst",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8653zero_beta",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_encoder_encoder_0_layers_0_linear1_bias _ ONNXTRT_Broadcast_253_constantFloat",
    "Dimensions": [1,1,1024],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,400,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_gelu_erf",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul_1]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Mul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Add]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Div]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/activation/Erf]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear1/Add]"
},{
  "Name": "__myl_FcAdd_myl37_16",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,400,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye8859dconst",
    "Dimensions": [1,1024,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye8657_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8664zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_encoder_encoder_0_layers_0_linear2_bias _ ONNXTRT_Broadcast_265_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_16",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/MatMul]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/linear2/Add]\u001f[ONNX Layer: /model/encoder/encoder.0/layers.0/Add_2]"
},{
  "Name": "__myl_ResMeaSubMulMea_myl37_17",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_16",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_18",
    "Dimensions": [400,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ResMeaSubMulMea_0xade3a566ff3432c2f2753f66a7f593a6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]"
},{
  "Name": "__myl_AddSqrDivMulMulAddResTra_myl37_18",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye8539_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye8549_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_18",
    "Dimensions": [400,1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Reshape_1_output_0",
    "Dimensions": [1,256,400],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddSqrDivMulMulAddResTra_0x0caebe133d43683f5670c896620d9227",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/encoder.0/layers.0/norm2/LayerNormalization]\u001f[ONNX Layer: /model/encoder/Transpose_1]\u001e[ONNX Layer: /model/encoder/Reshape_1]"
},{
  "Name": "model.encoder.input_proj.0.conv.weight + /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.0/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x483ad1560c6e5e27",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/input_proj.0/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.2/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.input_proj.1.conv.weight + /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/input_proj.1/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x483ad1560c6e5e27",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/input_proj.1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/backbone/res_layers.3/blocks.0/branch2a/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Reshape_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.lateral_convs.0.conv.weight + /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.0/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x5e4f6d7c83746fd6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Output Tensor 0 to PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var4"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 5,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 5,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);"],
  "TacticValue": "0x0000000000000005",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/lateral_convs.0/act/Mul]"
},{
  "Name": "Reformatting CopyNode for Output Tensor 0 to PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Output Tensor 0 to PWN(/model/encoder/lateral_convs.0/act/Sigmoid, /model/encoder/lateral_convs.0/act/Mul)",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/act/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_clone_0",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/act/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Resize_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/encoder/Resize",
  "LayerType": "Resize",
  "Inputs": [
  {
    "Name": "/model/encoder/Resize_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Resize",
  "InterpolationMode": "NEAREST",
  "ResizeScales": [1, 1, 2, 2, 0, 0, 0, 0],
  "ExcludeOutside": 0,
  "CubicCoeff": -0.75,
  "CoordTransform": "kASYMMETRIC",
  "ResizeSelector": "kFORMULA",
  "NNRounding": "kFLOOR",
  "TacticValue": "0x0000000000000005",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Resize]"
},{
  "Name": "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Concat_2_/model/encoder/Resize_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Concat_2]"
},{
  "Name": "model.encoder.fpn_blocks.0.conv2.conv.weight + /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x9ec201b34455146e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.conv1.conv.weight + /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv1/act/Sigmoid, /model/encoder/fpn_blocks.0/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0x6176c23707257237",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0x6176c23707257237",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xb936321f82fd390c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.0/conv2/act/Sigmoid, /model/encoder/fpn_blocks.0/conv2/act/Mul), /model/encoder/fpn_blocks.0/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  },
  {
    "Name": "/model/encoder/fpn_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/Add]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.0.conv3.conv.weight + /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.0/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.0/conv3/act/Sigmoid, /model/encoder/fpn_blocks.0/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/act/Mul]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.lateral_convs.1.conv.weight + /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/lateral_convs.1/conv/Conv + PWN(/model/encoder/lateral_convs.1/act/Sigmoid, /model/encoder/lateral_convs.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Resize_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/lateral_convs.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/Resize_1",
  "LayerType": "Resize",
  "Inputs": [
  {
    "Name": "/model/encoder/Resize_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Resize",
  "InterpolationMode": "NEAREST",
  "ResizeScales": [1, 1, 2, 2, 0, 0, 0, 0],
  "ExcludeOutside": 0,
  "CubicCoeff": -0.75,
  "CoordTransform": "kASYMMETRIC",
  "ResizeSelector": "kFORMULA",
  "NNRounding": "kFLOOR",
  "TacticValue": "0x0000000000000005",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Resize_1]"
},{
  "Name": "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Concat_3_/model/encoder/Resize_1_output_0_clone_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Concat_3]"
},{
  "Name": "model.encoder.fpn_blocks.1.conv2.conv.weight + /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0x844ea9c00f711f19",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.conv1.conv.weight + /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv1/act/Sigmoid, /model/encoder/fpn_blocks.1/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x458f02d2b10db57c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.bottlenecks.0.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xfdf7509af98902e0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.bottlenecks.1.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xfdf7509af98902e0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.bottlenecks.2.conv.weight + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32",
  "TacticValue": "0x5f1a472d416ff35e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/fpn_blocks.1/conv2/act/Sigmoid, /model/encoder/fpn_blocks.1/conv2/act/Mul), /model/encoder/fpn_blocks.1/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  },
  {
    "Name": "/model/encoder/fpn_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000019",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/Add]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.fpn_blocks.1.conv3.conv.weight + /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/fpn_blocks.1/conv3/conv/Conv + PWN(/model/encoder/fpn_blocks.1/conv3/act/Sigmoid, /model/encoder/fpn_blocks.1/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x65a38dbc9e991257",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/act/Mul]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/fpn_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.decoder.input_proj.0.conv.weight + /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.0/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.0/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x733ba2a91a48d431",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.downsample_convs.0.conv.weight + /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.0/conv/Conv + PWN(/model/encoder/downsample_convs.0/act/Sigmoid, /model/encoder/downsample_convs.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc722efd60bc6ea84",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/Resize_1_output_0 copy",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/Resize_1_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "CONCAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/Concat_4]"
},{
  "Name": "model.encoder.pan_blocks.0.conv2.conv.weight + /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x9ec201b34455146e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.conv1.conv.weight + /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv1/act/Sigmoid, /model/encoder/pan_blocks.0/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0x6176c23707257237",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0x6176c23707257237",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xb936321f82fd390c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.0/conv2/act/Sigmoid, /model/encoder/pan_blocks.0/conv2/act/Mul), /model/encoder/pan_blocks.0/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  },
  {
    "Name": "/model/encoder/pan_blocks.0/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/Add]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.0.conv3.conv.weight + /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.0/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.0/conv3/act/Sigmoid, /model/encoder/pan_blocks.0/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.0/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x2eba0b6a8ec55fa3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/act/Mul]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.0/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.decoder.input_proj.1.conv.weight + /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.1/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.1/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x733ba2a91a48d431",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.downsample_convs.1.conv.weight + /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/downsample_convs.1/conv/Conv + PWN(/model/encoder/downsample_convs.1/act/Sigmoid, /model/encoder/downsample_convs.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/downsample_convs.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc985777c89c6b3a4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/downsample_convs.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_clone_1",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/encoder/lateral_convs.0/act/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.conv2.conv.weight + /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x6d377e4222886190",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.conv1.conv.weight + /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv1/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv1/act/Sigmoid, /model/encoder/pan_blocks.1/conv1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,512,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0xc6cdb1e47323bb01",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.bottlenecks.0.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc985777c89c6b3a4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.0/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.bottlenecks.1.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv + PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_swish",
  "TacticValue": "0xc985777c89c6b3a4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.1/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.bottlenecks.2.conv.weight + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 147456},
  "Bias": {"Type": "Float", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3",
  "TacticValue": "0xd14bd6d95fefd45e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "PWN(PWN(/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid, /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul), PWN(PWN(/model/encoder/pan_blocks.1/conv2/act/Sigmoid, /model/encoder/pan_blocks.1/conv2/act/Mul), /model/encoder/pan_blocks.1/Add))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  },
  {
    "Name": "/model/encoder/pan_blocks.1/conv2/norm/BatchNormalization_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var10"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 10,
  "Literals": ["0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "5.000000e-01f"],
  "NbOperations": 11,
  "Operations": ["auto const var0 = pwgen::iMul(literal4, arg0);", "auto const var1 = pwgen::iTanh(var0);", "auto const var2 = pwgen::iMul(var1, literal4);", "auto const var3 = pwgen::iPlus(var2, literal4);", "auto const var4 = pwgen::iMul(arg0, var3);", "auto const var5 = pwgen::iMul(literal9, arg1);", "auto const var6 = pwgen::iTanh(var5);", "auto const var7 = pwgen::iMul(var6, literal9);", "auto const var8 = pwgen::iPlus(var7, literal9);", "auto const var9 = pwgen::iMul(arg1, var8);", "auto const var10 = pwgen::iPlus(var4, var9);"],
  "TacticValue": "0x0000000000000018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/bottlenecks/bottlenecks.2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv2/act/Mul]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/Add]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear]"
},{
  "Name": "model.encoder.pan_blocks.1.conv3.conv.weight + /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear + /model/encoder/pan_blocks.1/conv3/conv/Conv + PWN(/model/encoder/pan_blocks.1/conv3/act/Sigmoid, /model/encoder/pan_blocks.1/conv3/act/Mul)",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/encoder/pan_blocks.1/conv3/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,128,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 32768},
  "Bias": {"Type": "Float", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "SWISH",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_swish",
  "TacticValue": "0x709ddd0e503c7fd7",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/Conv]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/norm/BatchNormalization]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Sigmoid]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/act/Mul]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/encoder/pan_blocks.1/conv3/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "model.decoder.input_proj.2.conv.weight + /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear + /model/decoder/input_proj.2/conv/Conv",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/input_proj.2/conv/Conv_output_0",
    "Location": "Device",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 65536},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4",
  "TacticValue": "0x5e4f6d7c83746fd6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/QuantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/Conv]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/input_quantizer/DequantizeLinear]\u001e[ONNX Layer: /model/decoder/input_proj.2/conv/weight_quantizer/DequantizeLinear]"
},{
  "Name": "dummy_shape_call__mye24765_0_myl86_0",
  "LayerType": "shape_call",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "entry^bb^signal^1_myl86_1",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "entry^bb^wait^1_myl86_2",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "__myl_MulAddResTraMov_myl86_3",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/input_proj_0/norm/BatchNormalization/model/decoder/input_proj_0/norm/BatchNormalization_shift_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj.0/conv/Conv_output_0",
    "Dimensions": [1,256,80,80],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj_0/norm/BatchNormalization/model/decoder/input_proj_0/norm/BatchNormalization_scale_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/Concat_3_output_0",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_5",
    "Dimensions": [1,256,6400],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MulAddResTraMov_0x5b16ea5016173aa2a5693d1bd4ff5b7d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.0/norm/BatchNormalization]\u001f[ONNX Layer: /model/decoder/Reshape]\u001e[ONNX Layer: /model/decoder/Transpose]"
},{
  "Name": "__myl_MulAddResTraMov_myl86_4",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/input_proj_1/norm/BatchNormalization/model/decoder/input_proj_1/norm/BatchNormalization_shift_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj.1/conv/Conv_output_0",
    "Dimensions": [1,256,40,40],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj_1/norm/BatchNormalization/model/decoder/input_proj_1/norm/BatchNormalization_scale_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/Concat_3_output_0",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_7",
    "Dimensions": [1,256,1600],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MulAddResTraMov_0x55e04df7c9c453d83bf3d67dd91ee9c9",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.1/norm/BatchNormalization]\u001f[ONNX Layer: /model/decoder/Reshape_1]\u001e[ONNX Layer: /model/decoder/Transpose_1]"
},{
  "Name": "__myl_MulMinMaxRouCasTra_myl86_5",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_5",
    "Dimensions": [1,256,6400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye24195_dconst",
    "Dimensions": [1,1,6400],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRouCasTra_0x4dd0c5f28cefd2a6d9b12b22d6e8ad18",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape]\u001e[ONNX Layer: /model/decoder/Transpose]"
},{
  "Name": "__myl_MulMinMaxRouCasTra_myl86_6",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_7",
    "Dimensions": [1,256,1600],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye24208_dconst",
    "Dimensions": [1,1,1600],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRouCasTra_0xff04ab997241ba685fc1a4c9f9d8f55e",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Reshape_1]\u001e[ONNX Layer: /model/decoder/Transpose_1]"
},{
  "Name": "__mye24586_myl86_7",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "__mye24588_myl86_8",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_MulAddResMulMinMaxRouCasTraTraMovCon_myl86_9",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye24221_dconst",
    "Dimensions": [1,1,400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [1,6400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [1,1600,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "/model/decoder/input_proj_2/norm/BatchNormalization/model/decoder/input_proj_2/norm/BatchNormalization_shift_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj.2/conv/Conv_output_0",
    "Dimensions": [1,256,20,20],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/input_proj_2/norm/BatchNormalization/model/decoder/input_proj_2/norm/BatchNormalization_scale_wFloat",
    "Dimensions": [1,256,1,1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/enc_output/proj/Add_output_0'.1_11",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "/model/decoder/Concat_3_output_0",
    "Dimensions": [1,400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MulAddResMulMinMaxRouCasTraTraMovCon_0x5c809c23f09434ff21c545e71d265fe0",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/input_proj.2/norm/BatchNormalization]\u001f[ONNX Layer: /model/decoder/Reshape_2]\u001e[ONNX Layer: /model/decoder/Transpose_2]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/Concat_3]"
},{
  "Name": "/model/decoder/enc_output/proj/MatMul_myl86_10",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/enc_output/proj/Add_output_0'.1_11",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye24410dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye23635_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23642zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_enc_output_proj_bias _ ONNXTRT_Broadcast_345_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_12",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_output/proj/MatMul]\u001f[ONNX Layer: /model/decoder/enc_output/proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_output/proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_output/proj/Add]"
},{
  "Name": "__myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl86_11",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "model_decoder_enc_output_norm_weight _ ONNXTRT_Broadcast_352_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_enc_output_norm_bias _ ONNXTRT_Broadcast_354_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye24757_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_12",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_12",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0xf1c80ff651c1b506b1815818d6281ad3",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_output/norm/LayerNormalization]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye24590_myl86_12",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye24592_myl86_13",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/enc_score_head/MatMul_myl86_14",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye24420dconst",
    "Dimensions": [1,256,80],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye23673_dconst",
    "Dimensions": [1,80],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23680zero_beta",
    "Dimensions": [1,80],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_enc_score_head_bias _ ONNXTRT_Broadcast_668_constantFloat",
    "Dimensions": [1,1,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,8400,80],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/enc_score_head/MatMul]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_score_head/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_score_head/Add]"
},{
  "Name": "__myl_Max_myl86_15",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,8400,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/ReduceMax_output_0'_unsqueezed0.1",
    "Dimensions": [1,8400,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Max_0x4330a02939b906fc5f8c1bd769456467",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/ReduceMax]"
},{
  "Name": "__myl_Top_myl86_16",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/ReduceMax_output_0'_unsqueezed0.1",
    "Dimensions": [1,8400],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/TopK_output_0'.1",
    "Dimensions": [1,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_18",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  }],
  "TacticName": "__myl_Top_0x7e62297dffa2e596ee60049838a70f81",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/TopK]"
},{
  "Name": "__mye24594_myl86_17",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/enc_bbox_head/layers_0/MatMul_myl86_18",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye24608_xformed___mye24415dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye23657_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23653zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23666_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/enc_bbox_head/layers_2/input_quantizer/QuantizeLinear_output_0'.1_19",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/enc_score_head/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/act/Relu]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.0/Add]"
},{
  "Name": "/model/decoder/enc_bbox_head/layers_1/MatMul_myl86_19",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/enc_bbox_head/layers_2/input_quantizer/QuantizeLinear_output_0'.1_19",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye24612_xformed___mye24425dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye23695_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23691zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23704_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_20",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/act_1/Relu]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.1/Add]"
},{
  "Name": "__myl_FcAdd_myl86_20",
  "LayerType": "fusion",
  "Inputs": [
  {
    "Name": "model_decoder_anchors_constantFloat",
    "Dimensions": [1,8400,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_20",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye24430dconst",
    "Dimensions": [1,256,4],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye23711_dconst",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23718zero_beta",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_enc_bbox_head_layers_2_bias _ ONNXTRT_Broadcast_691_constantFloat",
    "Dimensions": [1,1,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_21",
    "Dimensions": [1,8400,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x32_by_fusion_tactic",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/enc_bbox_head/layers.2/Add]\u001f[ONNX Layer: /model/decoder/Add]"
},{
  "Name": "__mye24596_myl86_21",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_CasResCasRepGatResNegExpAddDiv_myl86_22",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_21",
    "Dimensions": [1,8400,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_18",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/Sigmoid_output_0",
    "Dimensions": [300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_23",
    "Dimensions": [1,300,1],
    "Format/Datatype": "Int32"
  }],
  "TacticName": "__myl_CasResCasRepGatResNegExpAddDiv_0x72db5f7553c58786e882348d551a39ef",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/Unsqueeze]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid]\u001f[ONNX Layer: /model/decoder/GatherElements]"
},{
  "Name": "__myl_MulMinMaxRouCas_myl86_23",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/Sigmoid_output_0",
    "Dimensions": [300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye24761_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [300,4],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRouCas_0x27a8e24587158d1362e3697b096c8edd",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_MovCon_myl86_24",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye24493",
    "Dimensions": [1,300,12],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_0/input_quantizer/QuantizeLinear_output_0'.1",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/input_quantizer/QuantizeLinear_output_0'.1_25",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MovCon_0x9482c2d60923b5d68d1030431d0b6d2e",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_0/MatMul_myl86_25",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/input_quantizer/QuantizeLinear_output_0'.1_25",
    "Dimensions": [1,300,16],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye24507_dconst",
    "Dimensions": [1,16,512],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye23733_dconst",
    "Dimensions": [1,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23729zero_beta",
    "Dimensions": [1,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23742_dconst",
    "Dimensions": [1,1,512],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1_26",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_gemm_i8i8_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_1/MatMul_myl86_26",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1_26",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye24445dconst",
    "Dimensions": [1,512,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye23749_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23756zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23151_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/Add]"
},{
  "Name": "__myl_RepGatResAdd_myl86_27",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_23",
    "Dimensions": [1,300,1],
    "Format/Datatype": "Int32"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/GatherElements_1_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_RepGatResAdd_0x3585782c9d9cf8f0d2b18744e46affde",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/GatherElements_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/Add]"
},{
  "Name": "__mye24598_myl86_28",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye24600_myl86_29",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_2_myl86_30",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/GatherElements_1_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye24435dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23008/model/decoder/decoder/layers_0/self_attn/MatMul_2_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23009/model/decoder/decoder/layers_0/self_attn/MatMul_2_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23615_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_2]"
},{
  "Name": "__mye24602_myl86_31",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "__myl_Mov_myl86_32",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye24177_dconst",
    "Dimensions": [4,512],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers.0/Transpose_output_0",
    "Dimensions": [4,512],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Mov_0xbab60177cdd500527f49964c0373b512",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_Mov_myl86_33",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye24184_dconst",
    "Dimensions": [512,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers.1/Transpose_output_0",
    "Dimensions": [512,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Mov_0x7916c0dc740d15b74d232414fc807ae5",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_1+/model/decoder/decoder/layers_0/self_attn/MatMul_myl86_34",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye24107_dconst",
    "Dimensions": [2,256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23062/model/decoder/decoder/layers_0/self_attn/MatMul_1_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23063/model/decoder/decoder/layers_0/self_attn/MatMul_1_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye24112_dconst",
    "Dimensions": [2,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye23776",
    "Dimensions": [2,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x32x64_stage4_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Add]"
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_3_myl86_35",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye23776",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23776",
    "Dimensions": [8,32,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23631",
    "Dimensions": [1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23097/model/decoder/decoder/layers_0/self_attn/MatMul_3_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_34",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Mul_1]"
},{
  "Name": "__myl_MaxSubExpSumDivMul_myl86_36",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_34",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_34",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_4_output_0'.1_35",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxSubExpSumDivMul_0x4bb1dc97991e61c47e3d11f2b659751f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Softmax]"
},{
  "Name": "__mye24604_myl86_37",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_4_myl86_38",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/MatMul_4_output_0'.1_35",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23107/model/decoder/decoder/layers_0/self_attn/MatMul_4_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23108/model/decoder/decoder/layers_0/self_attn/MatMul_4_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_36",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/MatMul_4]"
},{
  "Name": "__myl_Tra_myl86_39",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_36",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Transpose_5 _ /model/decoder/decoder/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,8,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Tra_0xbff89681337b526d248c0838f5d94e94",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Transpose_5]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Reshape_3]"
},{
  "Name": "/model/decoder/decoder/layers_0/self_attn/Gemm_myl86_40",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Transpose_5 _ /model/decoder/decoder/layers_0/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23167_dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23121/model/decoder/decoder/layers_0/self_attn/Gemm_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23122/model/decoder/decoder/layers_0/self_attn/Gemm_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_0_self_attn_out_proj_bias _ ONNXTRT_Broadcast_798_constantFloat",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/self_attn/Gemm]"
},{
  "Name": "__myl_AddResMeaSubMulMeaAddSqrDivMulMulAdd_myl86_41",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye23544_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye23534_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/GatherElements_1_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers.0/norm1/LayerNormalization_output_0",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddResMeaSubMulMeaAddSqrDivMulMulAdd_0xacc7425966e01cbf2d54cce95aac9db9",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/norm1/LayerNormalization]"
},{
  "Name": "__myl_Add_myl86_42",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers.0/norm1/LayerNormalization_output_0",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers.0/Add_2_output_0",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Add_0xf9228e65954528dd1a94496f60ffe46d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/Add_2]"
},{
  "Name": "/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers.0/Add_2_output_0",
    "Location": "Device",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]"
},{
  "Name": "FusedAttnOffsetPrediction_layer0",
  "LayerType": "PluginV3",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers.0/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_attn_layer0_decoder",
    "Location": "Device",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_sp_layer0_decoder",
    "Location": "Device",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Row major linear FP32"
  }],
  "PluginType": "fused_attn_offset_prediction",
  "PluginVersion": "1",
  "PluginMetadata": "[Metadata not provided by plugin]",
  "TacticValue": "0x0000000000000001",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: FusedAttnOffsetPrediction_layer0]"
},{
  "Name": "dummy_shape_call__mye39253_0_myl89_0",
  "LayerType": "shape_call",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_MulMinMaxRouCasCasMul_myl89_1",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye39207_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/Concat_3_output_0",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39211_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear_output_0",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_MulMinMaxRouCasCasMul_0x11414e8043a39dd8ed61f2c0ee57554c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_0/cross_attn/value_proj/MatMul_myl89_2",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38694dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38022_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38029zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_0_cross_attn_value_proj_bias _ ONNXTRT_Broadcast_339_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/cross_attn/value_proj/Add_output_0'.1",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/value_proj/Add]"
},{
  "Name": "__myl_TraResSli_myl89_3",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/cross_attn/value_proj/Add_output_0'.1",
    "Dimensions": [1,8400,8,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_12",
    "Dimensions": [8,32,6400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [8,32,8400],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_TraResSli_0xab45aa89d10102758aad83e232e683bf",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_4]"
},{
  "Name": "__myl_SliResSliResResSliSliMulMulMulAddMulAddTraResSliSliSliRevTraAddMulAddMulFloCasSubSubAddMaxEtc_myl89_4",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/Sigmoid_output_0",
    "Dimensions": [1,300,1,1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_sp_layer0_decoder",
    "Dimensions": [1,300,8,12,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37367_dconst",
    "Dimensions": [1,1,1,12,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37561",
    "Dimensions": [1,1,1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37565",
    "Dimensions": [1,1,1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39215_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37519_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39215_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37529_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39215_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37539_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37524_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4662",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37524_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4647",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37524_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4632",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37524_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4617",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37534_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4886",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37534_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4871",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37534_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4856",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37534_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4841",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37544_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5110",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37544_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5095",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37544_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5080",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37544_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5065",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37524_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37524_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37524_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [8,32,8400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37524_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37534_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37534_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37534_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [8,32,8400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37534_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37544_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37544_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37544_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_12",
    "Dimensions": [8,32,6400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37544_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "/model/decoder/decoder/Sigmoid_output_0",
    "Dimensions": [1,300,1,1,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_SliResSliResResSliSliMulMulMulAddMulAddTraResSliSliSliRevTraAddMulAddMulFloCasSubSubAddMaxEtc_0xb403dcae758e7fd986a2fd67e861fec2",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_7]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/GridSample_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_8]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Split]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Sub]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_1]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Slice_1]"
},{
  "Name": "__myl_MaxSubExpSum_myl89_5",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_attn_layer0_decoder",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  },
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_attn_layer0_decoder",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_16",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxSubExpSum_0x347c06f19d5104086c13b59c8ee7e1d6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]"
},{
  "Name": "__myl_ConDivMulTraResMulSumMulMinMaxRouCas_myl89_6",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39225_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_16",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye37649_q8",
    "Dimensions": [8,32,300,1],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_ConDivMulTraResMulSumMulMinMaxRouCas_0xfdc36321684ce402a67e9cc028ee3fea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Transpose_2]\u001e[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Reshape_9]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Concat_10]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/ReduceSum]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/Mul_8]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_Mov_myl89_7",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye37649_q8",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/cross_attn/output_proj/Add_output_0'.1_19",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_Mov_0xccd11d8190e5ec819f0de6935e8e6ebe",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]"
},{
  "Name": "/model/decoder/decoder/layers_0/cross_attn/output_proj/MatMul_myl89_8",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/cross_attn/output_proj/Add_output_0'.1_19",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38513_dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38033_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38040zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_0_cross_attn_output_proj_bias _ ONNXTRT_Broadcast_831_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_20",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/cross_attn/output_proj/Add]"
},{
  "Name": "__myl_AddMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl89_9",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "model_decoder_decoder_layers_0_norm2_weight _ ONNXTRT_Broadcast_835_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_0_norm2_bias _ ONNXTRT_Broadcast_837_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39229_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers.0/norm1/LayerNormalization_output_0",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_20",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_22",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_21",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_AddMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0xb59b836070d69f7c879c253fbd39ca68",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/Add_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/norm2/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_0/linear1/MatMul_myl89_10",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_21",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye39047_xformed___mye38699dconst",
    "Dimensions": [1,256,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38055_dconst",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38051zero_beta",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38064_dconst",
    "Dimensions": [1,1,1024],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/linear2/Add_output_0'.1_23",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/linear1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/activation/Relu]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear1/Add]"
},{
  "Name": "/model/decoder/decoder/layers_0/linear2/MatMul_myl89_11",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/linear2/Add_output_0'.1_23",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38704dconst",
    "Dimensions": [1,1024,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38071_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38078zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_0_linear2_bias _ ONNXTRT_Broadcast_849_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_24",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/linear2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/linear2/Add]"
},{
  "Name": "__myl_AddMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl89_12",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "model_decoder_decoder_layers_0_norm3_weight _ ONNXTRT_Broadcast_853_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_0_norm3_bias _ ONNXTRT_Broadcast_855_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39233_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_22",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_24",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_26",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_AddMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0x1d93f21368c020160f3070535119087c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.0/Add_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.0/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye39039_myl89_13",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye39041_myl89_14",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_2_myl89_15",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38719dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37218/model/decoder/decoder/layers_1/self_attn/MatMul_2_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37219/model/decoder/decoder/layers_1/self_attn/MatMul_2_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38004_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Add_2_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_2]"
},{
  "Name": "__mye39043_myl89_16",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_0/MatMul_myl89_17",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_26",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye39051_xformed___mye38709dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38093_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38089zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38102_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/input_quantizer/QuantizeLinear_output_0'.1_28",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_1/MatMul_myl89_18",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/input_quantizer/QuantizeLinear_output_0'.1_28",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye39055_xformed___mye38714dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38120_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38116zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38129_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/Add_output_0'.1_29",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.1/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/MatMul_myl89_19",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_0/layers_2/Add_output_0'.1_29",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38724dconst",
    "Dimensions": [1,256,4],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38136_dconst",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38143zero_beta",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_dec_bbox_head_0_layers_2_bias _ ONNXTRT_Broadcast_878_constantFloat",
    "Dimensions": [1,1,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_30",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.0/layers.2/Add]"
},{
  "Name": "__myl_MaxMinMaxSubMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouCasCasMul_myl89_20",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/Sigmoid_output_0",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_30",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39237_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39241_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/Sigmoid_1_output_0",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_32",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxMinMaxSubMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouCasCasMul_0x3d84daddeb95da051305838dcd2ec8cc",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_1/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/Log]\u001f[ONNX Layer: /model/decoder/decoder/Add]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid_1]\u001f[ONNX Layer: /model/decoder/decoder/Div]\u001f[ONNX Layer: /model/decoder/decoder/Sub]\u001f[ONNX Layer: /model/decoder/decoder/Clip]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_myl89_21",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_32",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers.0/Transpose_output_0",
    "Dimensions": [1,4,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37242/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37243/model/decoder/decoder/query_pos_head/layers_0_1/MatMul_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37428_dconst",
    "Dimensions": [1,1,512],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_33",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_1/Add]"
},{
  "Name": "__myl_MulMinMaxRouCasCasMul_myl89_22",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye39245_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_33",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39249_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1_34",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MulMinMaxRouCasCasMul_0xde5a6c254dbde3e5bc3e88fcd6bc4e63",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_1/DequantizeLinear]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_myl89_23",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1_34",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers.1/Transpose_output_0",
    "Dimensions": [1,512,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37253/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37254/model/decoder/decoder/query_pos_head/layers_1_1/MatMul_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37433_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_1/Add]"
},{
  "Name": "__myl_Add_myl89_24",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Add_0x8688bcddc1731a1023a26fa506504fd7",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/Add]"
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_1+/model/decoder/decoder/layers_1/self_attn/MatMul_myl89_25",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38472_dconst",
    "Dimensions": [2,256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37272/model/decoder/decoder/layers_1/self_attn/MatMul_1_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37273/model/decoder/decoder/layers_1/self_attn/MatMul_1_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38477_dconst",
    "Dimensions": [2,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye38163",
    "Dimensions": [2,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x32x64_stage4_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Add]"
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_3_myl89_26",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye38163",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38163",
    "Dimensions": [8,32,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38018",
    "Dimensions": [1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37307/model/decoder/decoder/layers_1/self_attn/MatMul_3_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_38",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Mul_1]"
},{
  "Name": "__myl_MaxSubExpSumDivMul_myl89_27",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_38",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_38",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_4_output_0'.1_39",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxSubExpSumDivMul_0x4bb1dc97991e61c47e3d11f2b659751f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Softmax]"
},{
  "Name": "__mye39045_myl89_28",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_4_myl89_29",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/MatMul_4_output_0'.1_39",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37317/model/decoder/decoder/layers_1/self_attn/MatMul_4_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37318/model/decoder/decoder/layers_1/self_attn/MatMul_4_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_40",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/MatMul_4]"
},{
  "Name": "__myl_Tra_myl89_30",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_40",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Transpose_5 _ /model/decoder/decoder/layers_1/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,8,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Tra_0xbff89681337b526d248c0838f5d94e94",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Transpose_5]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Reshape_3]"
},{
  "Name": "/model/decoder/decoder/layers_1/self_attn/Gemm_myl89_31",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Transpose_5 _ /model/decoder/decoder/layers_1/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37449_dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37331/model/decoder/decoder/layers_1/self_attn/Gemm_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37332/model/decoder/decoder/layers_1/self_attn/Gemm_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_1_self_attn_out_proj_bias _ ONNXTRT_Broadcast_984_constantFloat",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Gemm_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/self_attn/Gemm]"
},{
  "Name": "__myl_AddResMeaSubMulMeaAddSqrDivMulMulAdd_myl89_32",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye37963_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37953_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_0/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers.1/norm1/LayerNormalization_output_0",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddResMeaSubMulMeaAddSqrDivMulMulAdd_0xacc7425966e01cbf2d54cce95aac9db9",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/norm1/LayerNormalization]"
},{
  "Name": "__myl_Add_myl89_33",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers.1/norm1/LayerNormalization_output_0",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_1/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers.1/Add_2_output_0",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Add_0xf9228e65954528dd1a94496f60ffe46d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/Add_2]"
},{
  "Name": "/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers.1/Add_2_output_0",
    "Location": "Device",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]"
},{
  "Name": "FusedAttnOffsetPrediction_layer1",
  "LayerType": "PluginV3",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers.1/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_attn_layer1_decoder",
    "Location": "Device",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_sp_layer1_decoder",
    "Location": "Device",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Row major linear FP32"
  }],
  "PluginType": "fused_attn_offset_prediction",
  "PluginVersion": "1",
  "PluginMetadata": "[Metadata not provided by plugin]",
  "TacticValue": "0x0000000000000001",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: FusedAttnOffsetPrediction_layer1]"
},{
  "Name": "dummy_shape_call__mye39166_0_myl92_0",
  "LayerType": "shape_call",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul_myl92_1",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear_output_0",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38459_dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37122/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37123/model/decoder/decoder/layers_1/cross_attn/value_proj/MatMul_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_1_cross_attn_value_proj_bias _ ONNXTRT_Broadcast_341_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/cross_attn/value_proj/Add_output_0'.1",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/value_proj/Add]"
},{
  "Name": "__myl_TraResSli_myl92_2",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/cross_attn/value_proj/Add_output_0'.1",
    "Dimensions": [1,8400,8,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [8,32,6400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [8,32,8400],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_TraResSli_0xab45aa89d10102758aad83e232e683bf",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_4]"
},{
  "Name": "__myl_SliResSliResResSliSliMulMulMulAddMulAddTraResSliSliSliRevTraAddMulAddMulFloCasSubSubAddMaxEtc_myl92_3",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/Sigmoid_1_output_0",
    "Dimensions": [1,300,1,1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_sp_layer1_decoder",
    "Dimensions": [1,300,8,12,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37345_dconst",
    "Dimensions": [1,1,1,12,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37539",
    "Dimensions": [1,1,1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37543",
    "Dimensions": [1,1,1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39128_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37497_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39128_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37507_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39128_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37517_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37502_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4643",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37502_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4628",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37502_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4613",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37502_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4598",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37512_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4867",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37512_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4852",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37512_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4837",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37512_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye4822",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37522_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5091",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37522_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5076",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37522_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5061",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37522_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5046",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37502_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37502_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37502_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [8,32,8400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37502_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37512_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37512_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37512_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [8,32,8400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37512_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37522_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37522_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye37522_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [8,32,6400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37522_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "/model/decoder/decoder/Sigmoid_1_output_0",
    "Dimensions": [1,300,1,1,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_12",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_SliResSliResResSliSliMulMulMulAddMulAddTraResSliSliSliRevTraAddMulAddMulFloCasSubSubAddMaxEtc_0xb403dcae758e7fd986a2fd67e861fec2",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_7]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/GridSample_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_8]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Split]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Sub]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_1]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Slice_1]"
},{
  "Name": "__myl_MaxSubExpSum_myl92_4",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_attn_layer1_decoder",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  },
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_attn_layer1_decoder",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxSubExpSum_0x347c06f19d5104086c13b59c8ee7e1d6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]"
},{
  "Name": "__myl_ConDivMulTraResMulSumMulMinMaxRouCas_myl92_5",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_15",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39138_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_12",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye37627_q8",
    "Dimensions": [8,32,300,1],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_ConDivMulTraResMulSumMulMinMaxRouCas_0xfdc36321684ce402a67e9cc028ee3fea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Transpose_2]\u001e[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Reshape_9]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Concat_10]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/ReduceSum]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/Mul_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_Mov_myl92_6",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye37627_q8",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/cross_attn/output_proj/Add_output_0'.1_17",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_Mov_0xccd11d8190e5ec819f0de6935e8e6ebe",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]"
},{
  "Name": "/model/decoder/decoder/layers_1/cross_attn/output_proj/MatMul_myl92_7",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/cross_attn/output_proj/Add_output_0'.1_17",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38438_dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye37972_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37979zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_1_cross_attn_output_proj_bias _ ONNXTRT_Broadcast_1017_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_18",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/cross_attn/output_proj/Add]"
},{
  "Name": "__myl_AddMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl92_8",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "model_decoder_decoder_layers_1_norm2_weight _ ONNXTRT_Broadcast_1021_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_1_norm2_bias _ ONNXTRT_Broadcast_1023_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39142_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers.1/norm1/LayerNormalization_output_0",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_18",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_20",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_19",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_AddMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0xb59b836070d69f7c879c253fbd39ca68",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/Add_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/norm2/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_1/linear1/MatMul_myl92_9",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_19",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38968_xformed___mye38622dconst",
    "Dimensions": [1,256,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye37994_dconst",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37990zero_beta",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38003_dconst",
    "Dimensions": [1,1,1024],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/linear2/Add_output_0'.1_21",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/linear1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/activation/Relu]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear1/Add]"
},{
  "Name": "/model/decoder/decoder/layers_1/linear2/MatMul_myl92_10",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/linear2/Add_output_0'.1_21",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38627dconst",
    "Dimensions": [1,1024,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38010_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38017zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_1_linear2_bias _ ONNXTRT_Broadcast_1035_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_22",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/linear2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/linear2/Add]"
},{
  "Name": "__myl_AddMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl92_11",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "model_decoder_decoder_layers_1_norm3_weight _ ONNXTRT_Broadcast_1039_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_1_norm3_bias _ ONNXTRT_Broadcast_1041_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39146_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_20",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_22",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_24",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_AddMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0x1d93f21368c020160f3070535119087c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.1/Add_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.1/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye38960_myl92_12",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye38962_myl92_13",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_2_myl92_14",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38642dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37196/model/decoder/decoder/layers_2/self_attn/MatMul_2_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37197/model/decoder/decoder/layers_2/self_attn/MatMul_2_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37954_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Add_2_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_2]"
},{
  "Name": "__mye38964_myl92_15",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_0/MatMul_myl92_16",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_24",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38972_xformed___mye38632dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38032_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38028zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38041_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/input_quantizer/QuantizeLinear_output_0'.1_26",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_1/MatMul_myl92_17",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/input_quantizer/QuantizeLinear_output_0'.1_26",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38976_xformed___mye38637dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38059_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38055zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38068_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/Add_output_0'.1_27",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.1/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/MatMul_myl92_18",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_1/layers_2/Add_output_0'.1_27",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38647dconst",
    "Dimensions": [1,256,4],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye38075_dconst",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38082zero_beta",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_dec_bbox_head_1_layers_2_bias _ ONNXTRT_Broadcast_1064_constantFloat",
    "Dimensions": [1,1,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_28",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.1/layers.2/Add]"
},{
  "Name": "__myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouCasCasMul_myl92_19",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/Sigmoid_1_output_0",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_28",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39150_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39154_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/Sigmoid_2_output_0",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_30",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxMinSubMaxMinMaxMinDivLogAddNegExpAddDivMulMinMaxRouCasCasMul_0x3d84daddeb95da051305838dcd2ec8cc",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0/input_quantizer_2/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/Log_1]\u001f[ONNX Layer: /model/decoder/decoder/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid_2]\u001f[ONNX Layer: /model/decoder/decoder/Div_1]\u001f[ONNX Layer: /model/decoder/decoder/Sub_1]\u001f[ONNX Layer: /model/decoder/decoder/Clip_3]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_myl92_20",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_30",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers.0/Transpose_output_0",
    "Dimensions": [1,4,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37220/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37221/model/decoder/decoder/query_pos_head/layers_0_2/MatMul_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37406_dconst",
    "Dimensions": [1,1,512],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_31",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/act_2/Relu]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.0_2/Add]"
},{
  "Name": "__myl_MulMinMaxRouCasCasMul_myl92_21",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye39158_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_31",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye39162_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1_32",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MulMinMaxRouCasCasMul_0xde5a6c254dbde3e5bc3e88fcd6bc4e63",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1/input_quantizer_2/DequantizeLinear]"
},{
  "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_myl92_22",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1_32",
    "Dimensions": [1,300,512],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers.1/Transpose_output_0",
    "Dimensions": [1,512,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37231/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37232/model/decoder/decoder/query_pos_head/layers_1_2/MatMul_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37411_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/query_pos_head/layers.1_2/Add]"
},{
  "Name": "__myl_Add_myl92_23",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/Add_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Add_0x8688bcddc1731a1023a26fa506504fd7",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/Add]"
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_1+/model/decoder/decoder/layers_2/self_attn/MatMul_myl92_24",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38397_dconst",
    "Dimensions": [2,256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37250/model/decoder/decoder/layers_2/self_attn/MatMul_1_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37251/model/decoder/decoder/layers_2/self_attn/MatMul_1_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38402_dconst",
    "Dimensions": [2,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye38102",
    "Dimensions": [2,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x32x64_stage4_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Add]"
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_3_myl92_25",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__mye38102",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye38102",
    "Dimensions": [8,32,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37968",
    "Dimensions": [1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37285/model/decoder/decoder/layers_2/self_attn/MatMul_3_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_36",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Mul_1]"
},{
  "Name": "__myl_MaxSubExpSumDivMul_myl92_26",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_36",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_36",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_4_output_0'.1_37",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxSubExpSumDivMul_0x4bb1dc97991e61c47e3d11f2b659751f",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Softmax]"
},{
  "Name": "__mye38966_myl92_27",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_4_myl92_28",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/MatMul_4_output_0'.1_37",
    "Dimensions": [8,300,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Add_2_output_0'.1",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37295/model/decoder/decoder/layers_2/self_attn/MatMul_4_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37296/model/decoder/decoder/layers_2/self_attn/MatMul_4_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_38",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x1x2_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/MatMul_4]"
},{
  "Name": "__myl_Tra_myl92_29",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_38",
    "Dimensions": [8,300,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Transpose_5 _ /model/decoder/decoder/layers_2/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,8,32],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Tra_0xbff89681337b526d248c0838f5d94e94",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Transpose_5]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Reshape_3]"
},{
  "Name": "/model/decoder/decoder/layers_2/self_attn/Gemm_myl92_30",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Transpose_5 _ /model/decoder/decoder/layers_2/self_attn/Reshape_3_first_transpose_output.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37427_dconst",
    "Dimensions": [256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37309/model/decoder/decoder/layers_2/self_attn/Gemm_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37310/model/decoder/decoder/layers_2/self_attn/Gemm_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_2_self_attn_out_proj_bias _ ONNXTRT_Broadcast_1170_constantFloat",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Gemm_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/self_attn/Gemm]"
},{
  "Name": "__myl_AddResMeaSubMulMeaAddSqrDivMulMulAdd_myl92_31",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye37913_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye37903_reshape",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_1/norm3/LayerNormalization_normalizationBiased.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers_2/self_attn/Gemm_output_0'.1",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers.2/norm1/LayerNormalization_output_0",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddResMeaSubMulMeaAddSqrDivMulMulAdd_0xacc7425966e01cbf2d54cce95aac9db9",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/Add_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/norm1/LayerNormalization]"
},{
  "Name": "__myl_Add_myl92_32",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers.2/norm1/LayerNormalization_output_0",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/query_pos_head/layers_1_2/Add_output_0'.1",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers.2/Add_2_output_0",
    "Dimensions": [300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Add_0xf9228e65954528dd1a94496f60ffe46d",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/Add_2]"
},{
  "Name": "/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers.2/Add_2_output_0",
    "Location": "Device",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "QDQ",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear]"
},{
  "Name": "FusedAttnOffsetPrediction_layer2",
  "LayerType": "PluginV3",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers.2/cross_attn/sampling_offsets/input_quantizer/QuantizeLinear_output_0",
    "Location": "Device",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_attn_layer2_decoder",
    "Location": "Device",
    "Dimensions": [1,300,96],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_sp_layer2_decoder",
    "Location": "Device",
    "Dimensions": [1,300,192],
    "Format/Datatype": "Row major linear FP32"
  }],
  "PluginType": "fused_attn_offset_prediction",
  "PluginVersion": "1",
  "PluginMetadata": "[Metadata not provided by plugin]",
  "TacticValue": "0x0000000000000001",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: FusedAttnOffsetPrediction_layer2]"
},{
  "Name": "dummy_shape_call__mye53936_0_myl95_0",
  "LayerType": "shape_call",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul_myl95_1",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers.0/cross_attn/value_proj/input_quantizer/DequantizeLinear_output_0",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53477_dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52356/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul_alpha",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52357/model/decoder/decoder/layers_2/cross_attn/value_proj/MatMul_beta",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_2_cross_attn_value_proj_bias _ ONNXTRT_Broadcast_343_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/cross_attn/value_proj/Add_output_0'.1",
    "Dimensions": [1,8400,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/value_proj/Add]"
},{
  "Name": "__myl_TraResSli_myl95_2",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/cross_attn/value_proj/Add_output_0'.1",
    "Dimensions": [1,8400,8,32],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [8,32,6400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [8,32,8400],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_TraResSli_0xab45aa89d10102758aad83e232e683bf",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_4]"
},{
  "Name": "__myl_SliResSliResResSliSliMulMulMulAddMulAddTraResSliSliSliRevTraAddMulAddMulFloCasSubSubAddMaxEtc_myl95_3",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/Sigmoid_2_output_0",
    "Dimensions": [1,300,1,1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_sp_layer2_decoder",
    "Dimensions": [1,300,8,12,2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52473_dconst",
    "Dimensions": [1,1,1,12,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52657",
    "Dimensions": [1,1,1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52661",
    "Dimensions": [1,1,1,1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53914_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52613_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53914_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52623_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53914_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52633_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52618_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5699",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52618_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5684",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52618_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5669",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52618_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5654",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52628_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5923",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52628_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5908",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52628_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5893",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52628_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye5878",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52638_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye6147",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52638_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye6132",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52638_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye6117",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52638_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye6102",
    "Dimensions": [1,1,1,2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52618_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52618_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52618_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [8,32,8400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52618_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52628_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52628_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52628_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_8",
    "Dimensions": [8,32,8400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52628_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52638_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52638_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52638_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__myln_k_arg__bb1_9",
    "Dimensions": [8,32,6400],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52638_dconst",
    "Dimensions": [2],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "/model/decoder/decoder/Sigmoid_2_output_0",
    "Dimensions": [1,300,1,1,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_12",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_SliResSliResResSliSliMulMulMulAddMulAddTraResSliSliSliRevTraAddMulAddMulFloCasSubSubAddMaxEtc_0xb403dcae758e7fd986a2fd67e861fec2",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_7]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/GridSample_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_8]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_6]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Split]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Sub]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_1]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_2]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Add]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_1]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Slice_1]"
},{
  "Name": "__myl_MaxSubExpSum_myl95_4",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_attn_layer2_decoder",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  },
  {
    "Name": "FusedPredictionsAttnSamplingOffsets_attn_layer2_decoder",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_MaxSubExpSum_0x347c06f19d5104086c13b59c8ee7e1d6",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]"
},{
  "Name": "__myl_ConDivMulTraResMulSumMulMinMaxRouCas_myl95_5",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_14",
    "Dimensions": [1,300,8,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53924_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_10",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_11",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_12",
    "Dimensions": [8,32,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_13",
    "Dimensions": [1,300,8,12],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__mye52753_q8",
    "Dimensions": [8,32,300,1],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_ConDivMulTraResMulSumMulMinMaxRouCas_0xfdc36321684ce402a67e9cc028ee3fea",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Softmax]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Transpose_2]\u001e[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Reshape_9]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Concat_10]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/ReduceSum]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/Mul_5]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/QuantizeLinear]"
},{
  "Name": "__myl_Mov_myl95_6",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__mye52753_q8",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/cross_attn/output_proj/Add_output_0'.1_16",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_Mov_0xccd11d8190e5ec819f0de6935e8e6ebe",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]"
},{
  "Name": "/model/decoder/decoder/layers_2/cross_attn/output_proj/MatMul_myl95_7",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/cross_attn/output_proj/Add_output_0'.1_16",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53456_dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53059_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53066zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_2_cross_attn_output_proj_bias _ ONNXTRT_Broadcast_1203_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/cross_attn/output_proj/Add]"
},{
  "Name": "__myl_AddMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl95_8",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "model_decoder_decoder_layers_2_norm2_weight _ ONNXTRT_Broadcast_1207_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_2_norm2_bias _ ONNXTRT_Broadcast_1209_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53928_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/layers.2/norm1/LayerNormalization_output_0",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_17",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_19",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_18",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_AddMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0xb59b836070d69f7c879c253fbd39ca68",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/Add_3]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/norm2/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/QuantizeLinear]"
},{
  "Name": "/model/decoder/decoder/layers_2/linear1/MatMul_myl95_9",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_18",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53846_xformed___mye53582dconst",
    "Dimensions": [1,256,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53081_dconst",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53077zero_beta",
    "Dimensions": [1,1024],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53090_dconst",
    "Dimensions": [1,1,1024],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/linear2/Add_output_0'.1_20",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/linear1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/activation/Relu]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear1/Add]"
},{
  "Name": "/model/decoder/decoder/layers_2/linear2/MatMul_myl95_10",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/layers_2/linear2/Add_output_0'.1_20",
    "Dimensions": [1,300,1024],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53587dconst",
    "Dimensions": [1,1024,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53097_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53104zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_2_linear2_bias _ ONNXTRT_Broadcast_1221_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_21",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/linear2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/linear2/Add]"
},{
  "Name": "__myl_AddMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_myl95_11",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "model_decoder_decoder_layers_2_norm3_weight _ ONNXTRT_Broadcast_1225_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53932_const-lit-in",
    "Dimensions": [1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_decoder_layers_2_norm3_bias _ ONNXTRT_Broadcast_1227_constantFloat",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_19",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_21",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_1/input_quantizer/QuantizeLinear_output_0'.1_22",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "__myl_AddMeaSubMulMeaAddSqrDivMulMulAddMulMinMaxRouCas_0x79cc2ca33c4d405b342c633407b80da1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/layers.2/Add_4]\u001f[ONNX Layer: /model/decoder/decoder/layers.2/norm3/LayerNormalization]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/QuantizeLinear]"
},{
  "Name": "__mye53838_myl95_12",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__mye53840_myl95_13",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/dec_score_head_2/MatMul_myl95_14",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_1/input_quantizer/QuantizeLinear_output_0'.1_22",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53592dconst",
    "Dimensions": [1,256,80],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53108_dconst",
    "Dimensions": [1,80],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53115zero_beta",
    "Dimensions": [1,80],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_dec_score_head_2_bias _ ONNXTRT_Broadcast_1237_constantFloat",
    "Dimensions": [1,1,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_score_head_2/Add_output_0'.1",
    "Dimensions": [1,300,80],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_score_head.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_score_head.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_score_head.2/Add]"
},{
  "Name": "__myl_GatNegExpAddDivRes_myl95_15",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_score_head_2/Add_output_0'.1",
    "Dimensions": [1,1,300,80],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_24",
    "Dimensions": [1,24000],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_GatNegExpAddDivRes_0x4a3deee2e0f840e1e188b163ed91f5bb",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /postprocessor/Sigmoid]\u001f[ONNX Layer: /postprocessor/Flatten]\u001f[ONNX Layer: /model/decoder/Gather_8]"
},{
  "Name": "__myl_Top_myl95_16",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "__myln_k_arg__bb1_24",
    "Dimensions": [1,24000],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "scores",
    "Dimensions": [1,300],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_26",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  }],
  "TacticName": "__myl_Top_0x1c85ccd1fad109f046189f0d3e8dff44",
  "StreamId": 1,
  "Metadata": "[ONNX Layer: /postprocessor/TopK]"
},{
  "Name": "__mye53842_myl95_17",
  "LayerType": "signal",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 1,
  "Metadata": ""
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_0/MatMul_myl95_18",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_1/input_quantizer/QuantizeLinear_output_0'.1_22",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53850_xformed___mye53597dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53130_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53126zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53139_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/input_quantizer/QuantizeLinear_output_0'.1_27",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.0/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_1/MatMul_myl95_19",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/input_quantizer/QuantizeLinear_output_0'.1_27",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53854_xformed___mye53602dconst",
    "Dimensions": [1,256,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53157_dconst",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53153zero_beta",
    "Dimensions": [1,256],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53166_dconst",
    "Dimensions": [1,1,256],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/Add_output_0'.1_28",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  }],
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/QuantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/act_1/Relu]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.1/Add]"
},{
  "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/MatMul_myl95_20",
  "LayerType": "gemm",
  "Inputs": [
  {
    "Name": "/model/decoder/decoder/dec_bbox_head_2/layers_2/Add_output_0'.1_28",
    "Dimensions": [1,300,256],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53607dconst",
    "Dimensions": [1,256,4],
    "Format/Datatype": "Int8"
  },
  {
    "Name": "__mye53173_dconst",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye53180zero_beta",
    "Dimensions": [1,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "model_decoder_dec_bbox_head_2_layers_2_bias _ ONNXTRT_Broadcast_1260_constantFloat",
    "Dimensions": [1,1,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "__myln_k_arg__bb1_29",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "sm80_xmma_gemm_i8f32_i8i32_f32_tn_n_tilesize32x64x64_stage6_warpsize2x2x1_tensor16x8x32",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/MatMul]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/input_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/weight_quantizer/DequantizeLinear]\u001f[ONNX Layer: /model/decoder/decoder/dec_bbox_head.2/layers.2/Add]"
},{
  "Name": "__mye53844_myl95_21",
  "LayerType": "wait",
  "Inputs": [],
  "Outputs": [],
  "TacticName": "",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "__myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_myl95_22",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "orig_target_sizes",
    "Dimensions": [1,2],
    "Format/Datatype": "Int64"
  },
  {
    "Name": "__myln_k_arg__bb1_26",
    "Dimensions": [1,300],
    "Format/Datatype": "Int32"
  },
  {
    "Name": "__mye52673",
    "Dimensions": [1,1],
    "Format/Datatype": "Int64"
  },
  {
    "Name": "__mye52677",
    "Dimensions": [1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__mye52681",
    "Dimensions": [1,1],
    "Format/Datatype": "Float"
  },
  {
    "Name": "__myln_k_arg__bb1_29",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/model/decoder/decoder/Sigmoid_2_output_0",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "labels",
    "Dimensions": [1,300],
    "Format/Datatype": "Int64"
  },
  {
    "Name": "boxes",
    "Dimensions": [1,300,4],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_RepResCasMaxMinSubMaxMinMaxMinDivLogCasDivResCasRepMulSubAddNegExpAddDivResGatSliResSliResEtc_0x37beece40a89d52f1608abf754969c9a",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: Cast_3039]\u001f[ONNX Layer: /model/decoder/decoder/Clip_6]\u001f[ONNX Layer: /model/decoder/decoder/Sub_2]\u001f[ONNX Layer: /model/decoder/decoder/Div_2]\u001f[ONNX Layer: /model/decoder/decoder/Sigmoid_3]\u001f[ONNX Layer: /model/decoder/Gather_9]\u001f[ONNX Layer: /model/decoder/decoder/Unsqueeze_3]\u001f[ONNX Layer: /model/decoder/decoder/Add_2]\u001f[ONNX Layer: /model/decoder/decoder/Log_2]\u001f[ONNX Layer: /postprocessor/Split]\u001f[ONNX Layer: /postprocessor/Squeeze_1]\u001f[ONNX Layer: /postprocessor/Squeeze_2]\u001f[ONNX Layer: /postprocessor/Mul]\u001f[ONNX Layer: /postprocessor/Add]\u001f[ONNX Layer: /postprocessor/Unsqueeze_2]\u001f[ONNX Layer: /postprocessor/Sub]\u001f[ONNX Layer: /postprocessor/Unsqueeze]\u001f[ONNX Layer: /postprocessor/Concat]\u001f[ONNX Layer: /postprocessor/Mul_2]\u001f[ONNX Layer: /postprocessor/GatherElements]\u001f[ONNX Layer: /postprocessor/Unsqueeze_5]\u001f[ONNX Layer: /postprocessor/Unsqueeze_3]\u001f[ONNX Layer: /postprocessor/Add_1]\u001f[ONNX Layer: /postprocessor/Squeeze]\u001f[ONNX Layer: /postprocessor/Unsqueeze_1]\u001f[ONNX Layer: /postprocessor/Sub_1]\u001f[ONNX Layer: /postprocessor/Mul_1]\u001f[ONNX Layer: /postprocessor/Squeeze_3]\u001f[ONNX Layer: /postprocessor/Mul_3]\u001f[ONNX Layer: /postprocessor/Sub_2]\u001f[ONNX Layer: /postprocessor/Div]\u001f[ONNX Layer: /postprocessor/Unsqueeze_4]\u001f[ONNX Layer: /postprocessor/Tile]"
}],
"Bindings": ["images"
,"orig_target_sizes"
,"labels"
,"boxes"
,"scores"
]}
